{"video_file": "/osgeo/foss4gvideos/2022-08-24/Auditorium/01 - Opening Session_1.mp4", "persons": "Luca Delucchi", "pretalx_id": "YSAHS9", "title": "FOSS4G 2022 | Opening Session", "description": "Opening session with institutional greetings.\\n\\nLuca Delucchi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/YSAHS9/\\n\\n#foss4g2022\\n#generaltrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Auditorium/02 - Patricia Solis.mp4", "persons": "Patricia Solis", "pretalx_id": "TZBQC9", "title": "FOSS4G 2022 | YouthMappers: a global youth movement on open mapping for humanitarian and development action", "description": "Increasingly ubiquitous open spatial technologies offer the opportunity for new actors to participate in creating knowledge about the places where they live and work, and where they navigate the shocks and stresses of an uncertain world. This presentation offers insights about university student engagement in open mapping through the experiences of YouthMappers around the world. This inclusive international network of youth-led, faculty-mentored, and technology-enabled chapters on more than 300 campuses in 65+ countries work together to organize, collaborate, and implement mapping action that respond to needs around the globe. Specific examples will illuminate how students are creating and using spatial information that is collected using open software tools and made publicly available through open platforms, and in turn inform us about both the power and the limits of open spatial technologies in the hands of students working to build a more resilient, equitable and sustainable future.\\n\\nPatricia Solis\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/TZBQC9/\\n\\n#foss4g2022\\n#generaltrack\\n#Education"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Auditorium/03 - Joshua Ogure.mp4", "persons": "Joshua Ogure", "pretalx_id": "GENPXP", "title": "FOSS4G 2022 | Map Kibera Mapping Counties on OpenStreetMap", "description": "The talk will focus on how Map Kibera has empowered different Counties in Kenya to Map their projects using Open Street Map, Kobo collect and ODK. During the exercise Map Kibera collaborated with World Bank to produce large maps that are used during the participatory budgeting meetings for members of the community to decide the projects they want implemented. Map Kibera's approach is to empower the youth and some selected County officials with new mapping skills and methodologies. Members of the community are then able to make informed decisions by seeing what they already have and what might be missing. Map Kibera also helped the Four selected counties to develop a website that shows the status and the budget allocation for each and every project mapped. This helps promote transparency and accountability within the counties. Before the mapping happened, people would be asked to propose what project they wanted but it became hard without knowing what was already in existence. Now they can tell, We have a hospital we want a school for example.\\n\\nJoshua Ogure\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/GENPXP/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Auditorium/05 - Maggie Cawley.mp4", "persons": "Maggie Cawley", "pretalx_id": "ZGSGBQ", "title": "FOSS4G 2022 | Crowdsourcing the Future of Government Data: OpenStreetMap in the Public Domain", "description": "Is your government utilizing OpenStreetMap data in their workflows? How can crowdsourcing be leveraged to improve the completeness, freshness, and breadth of government geospatial data? As the world\u2019s largest crowdsourced geospatial database, OpenStreetMap is poised to serve this need.  Two years ago, OpenStreetMap US formed a Government Working Group to seek out mutually beneficial relationships between the public and open data communities. As part of this effort, OSM community members and representatives from federal agencies have been investigating solutions for feature collection. This collaboration has led to the development of Public Domain Map, which connects OpenStreetMap and government datasets. Through the Public Domain Map workflow, OpenStreetMap and government open geospatial data becomes more complete, current and readily usable by government agencies and the millions of users relying on both datasets. In this session, I will share the journey of Public Domain Map, how the project is bringing together US federal agencies and open source contributors to meet this goal, and how you can be part of it.\\n\\nMaggie Cawley\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ZGSGBQ/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Auditorium/06 - Nicholaus Hanowsky.mp4", "persons": "Nicolaus Hanowski", "pretalx_id": "LTW3VV", "title": "FOSS4G 2022 | Data Management in Earth Observation - The Potential of Open Digital Twins of the Earth", "description": "Several ambitious initiatives, such as Destination Earth of the European Union,  are harnessing large amounts of Earth Observation and other data to develop so-called digital twins of the Earth. The combination of large and diverse data assets, cloud- & HPC-computing as well as sophisticates models and AI algorithms now permit to generate predictive EO scenarios. One key aspect of Digital Twins is the possibility to employ openness as one of the key principles for all its functions. Data policy, data access, software development, processing and information management are important considerations for engaging and integrating users of all kinds. Due to their high potential for science and society the European Space Agency, with its unique geospatial data holdings, is fully engaged in the development of Digital Twins of the Earth.\\n\\nNicolaus Hanowski\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/LTW3VV/\\n\\n#foss4g2022\\n#generaltrack\\n#AI4EOChallenges&Opportunities"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Auditorium/07 - Chris Rampersad.mp4", "persons": "Chris Rampersad", "pretalx_id": "EAPQLM", "title": "FOSS4G 2022 | \"Earth in Colour\" with EarthDaily Analytics", "description": "EarthDaily Analytics is building a powerful new constellation that will collect scientific-grade, 5 meter resolution imagery of the planet in a unique combination of 22 spectral bands using 3 different camera types, covering a broad spectral range from visible to thermal wavelengths.  The mission will be launched in 2023 and will allow us to see the Earth\u2019s global land mass each day in a wholly new way with more spectral bands, higher revisit, and at a higher resolution than ever before.  It will allow us to monitor, detect changes, alert, and predict what is happening anywhere on the planet to help with some of world\u2019s most pressing challenges in agriculture, Environmental, Social and Governance (ESG), and disaster prevention and recovery.\n\nThis mission has been made possible by a near-perfect convergence of three major technology breakthroughs in the last 10 years: 1) lower cost satellite launch and manufacturing, 2) advancements in computer vision and machine learning to support automation of petabyte scale processing, and 3) cloud compute power and storage necessary to drive the processing and calibration of trillions of pixels each day. Together these three emerging technologies are key to driving next generation geospatial insights, but to bring them together requires a software solution capable of handing the complexity of raw satellite with automation driven by machine learning, and cloud-based Big Geo Data pipelines for cost-effective scale and latency.\n\nAt EarthDaily Analytics, our software solution has been made possible by leveraging many open source software packages to form the backbone for our satellite processing, calibration and quality services called the EarthPipeline.  Together with open source packages and custom machine learning and computer vision approaches, we are working on delivering true scientific satellite image products that can be applied directly to algorithms without the need for very costly (and dreaded) end user data normalization and correction procedures.  This talk will focus on how EarthDaily Analytics uses open source packages and machine learning to create normalized scientific quality data, and will also provide some example applications of how the data can be used.\\n\\nChris Rampersad\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/EAPQLM/\\n\\n#foss4g2022\\n#generaltrack\\n#AI4EOChallenges&Opportunities"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Auditorium/08 - Devis Peressutti.mp4", "persons": "Devis Peressutti, Nejc Vesel", "pretalx_id": "DS9R78", "title": "FOSS4G 2022 | HIECTOR: Hierarchical object detector for cost-efficient detection at scale", "description": "Object detection, classification and semantic segmentation are ubiquitous and fundamental tasks in extracting, interpreting and understanding the information acquired by satellite imagery. Applications for locating and classifying man-made objects, such as buildings, roads, aeroplanes, and cars typically require Very High Resolution (VHR) imagery, with spatial resolution ranging approximately from 0.3 m to 5 m. However, such VHR imagery is generally proprietary and commercially available at a high cost. This prevents its uptake from the wider community, in particular when analysis at large scale is desired. HIECTOR (HIErarchical deteCTOR) tackles the problem of efficiently scaling object detection in satellite imagery to large areas by leveraging the sparsity of such objects over the considered area-of-interest (AOI). This talk presents a hierarchical method for detection of man-made objects, using multiple satellite image sources with different Ground Sample Distance (GSD). The detection is carried out in a hierarchical fashion, starting at the lowest resolution and proceeding to the highest. Detections at each stage of the pyramid are used to request imagery and apply the detection at the next higher resolution, therefore reducing the amount of data required and processed. We evaluate HIECTOR for the task of building detection for a middle-eastern country, estimating oriented bounding boxes around each object of interest.\n\nFor the detection of buildings, HIECTOR is demonstrated using the following data sources: Sentinel-2 imagery with 10 m GSD, Airbus SPOT imagery pan-sharpened to 1.5 m pixel size and Airbus Pleiades imagery pan-sharpened to 0.5 m pixel size. Sentinel-2 imagery is openly available, making their use very cost efficient. The Single-Stage Rotation-Decoupled Detector (SSRDD) algorithm is used. Given that single buildings are not discernible at 10 m GSD, a bounding box does not describe a single building but rather a cluster of buildings. The estimated bounding boxes at 10 m are joined and the resulting polygon area is used to further request SPOT imagery at the pan-sharpened pixels size of 1.5 m. In the case of SPOT imagery, given the higher spatial resolution, one bounding box is estimated for each building. As a final step, predictions are improved in areas with low confidence by requesting Airbus Pleiades imagery at the pan-sharpened 0.5 m pixel size. Ablation studies show that HIECTOR achieves a mean Average Precision (mAP) score of 0.383 and 20-fold reduction in costs compared to using only VHR at the highest resolution, which achieves a mAP of 0.452.\n\nCode will be released under MIT license. We will also release the trained models on Sentinel, SPOT and Pleiades imagery. In addition, manually labelled building footprints over Dakar will be open-sourced to allow users evaluate the generalisation of the models over different geographical areas. The Sentinel Hub service is used by HIECTOR to request the commercial imagery sources on the specified polygons determined at each level of the pyramid, allowing to request, access and process specific sub-parts of the AOI.\\n\\nDevis Peressutti\\nNejc Vesel\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/DS9R78/\\n\\n#foss4g2022\\n#generaltrack\\n#AI4EOChallenges&Opportunities"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Auditorium/09 - Blagoj Delipetrev.mp4", "persons": "Blagoj Delipetrev", "pretalx_id": "EALH73", "title": "FOSS4G 2022 | No-code geoAI", "description": "Artificial Intelligence (AI) has made an impact in almost every field and has become an incredibly powerful technology. However, while some players in big tech and academia have access to a highly skilful workforce that can create sophisticated AI solutions, many companies, governments, public organisations, and other societal stakeholders are lacking sufficient AI expertise and know-how.\n\nMany AI and Machine Learning (ML) frameworks aim to simplify and democratise AI development, even if typically focusing on those with software engineering skills. Some of these solutions, those that provide no-code tools, get the closest to the ideal of enabling \"any person without prior training\u201d. Collectively, these could represent a major breakthrough, as it has been proven time and time again that many businesses and organisations still struggle to implement AI to its full potential and scale.\n\nVisual, often drag-and-drop, no-code AI tools can make AI less intimidating and more comprehensible to non-technical profiles and those who lack the time and resources to build such systems from the ground up. No-code AI frameworks are expected to require minimum technical knowledge to develop practical AI solutions at scale. This is an emerging field, like was previously the case with no-code web development, starting with Dreamweaver and MS Frontpage, the first WYSIWYG (what you see is what you get) solutions, both launched in 1997.\n\nThe European Commission is supporting the establishment of an AI-on-demand platform that will provide easy and simple access to AI tools that are made in Europe and are \u2018trustworthy\u2019. The platform will gather all the AI resources (algorithms and tools), and make them available to the potential users, businesses, and public administration, with the necessary services to facilitate their integration.\n\nWithin the context of the EU\u2019s commitment to trustworthy AI, we are exploring the landscape of AI solutions for non-experts, including no-code, low-code, AutoML and similar approaches, and evaluating them in an experimental setting via prototyping. Our findings are expected to inform the development of relevant European digital initiatives. For instance, we will consider how these emerging AI solutions for non-experts could be integrated and used in the context of digital infrastructures such as EuroGEOSS or the European Data Spaces.\n\nFurther democratization of AI will happen when domain experts without prior AI expertise are enabled to tap into high-quality data to solve complex problems on their own, with technical details being abstracted away, such as algorithm selection, model training, software frameworks, hardware dependencies, and platform aspects. We expect that open-source AI technologies for non-experts represent a step towards such a future.\n\nDuring the conference, we will present the initial results of our geoAI activity, including a high-level architecture and a stack expected to be composed of various open-source software tools and open standards for digital infrastructures, data engineering and AI development. Our intention is to gather feedback from the audience and establish possible future collaborations in this space.\\n\\nBlagoj Delipetrev\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/EALH73/\\n\\n#foss4g2022\\n#generaltrack\\n#AI4EOChallenges&Opportunities"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Auditorium/10 - Howard Butler.mp4", "persons": "Howard Butler", "pretalx_id": "VPDKN7", "title": "FOSS4G 2022 | Cloud Optimized Point Cloud: Compressed, Geospatial, Lossless and Compatible Data Organization for Analysis Ready Point Cloud Data", "description": "Point cloud data are an important component of geospatial data workflows, but software and formats to manage it often have compromises that work against efficient storage and processing of data. While commonly seen characterizing topographic information in LiDAR applications, point cloud data are an important driver of change detection applications in SAR workflows and provide important raw data to bring the physical world to the augmented one through handset capture on devices like the iPhone 12+. COPC.io is an open specification by Hobu, Inc. for organizing point cloud data in LAZ that allows it to be streamable over HTTP, selectable for resolution or spatial window, and adaptable to existing point cloud workflows in a backward compatible way. We will discuss the design choices and evolution of COPC, demonstrate its use in PDAL and QGIS scenarios, and show how COPC can be used in the cloud for management of massive point cloud collections.\\n\\nHoward Butler\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/VPDKN7/\\n\\n#foss4g2022\\n#generaltrack\\n#AI4EOChallenges&Opportunities"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Auditorium/11 - Brad Chambers.mp4", "persons": "Brad Chambers", "pretalx_id": "NWCQRX", "title": "FOSS4G 2022 | Open Source Point Cloud Semantic Segmentation Using AI/ML", "description": "Assigning semantic labels to points within a point cloud aids in both visual interpretation of the data and as a preprocessing step to other forms of analysis like building footprint extraction, hydrological modeling, and biomass estimation. Our talk will focus primarily on earth observation data and airborne lidar data sources in particular, where labels are commonly aligned with those classes specified in the ASPRS LAS specification (e.g., ground, vegetation, and building), but we are also beginning to explore the extension of these same methods to data generated by commodity, consumer-grade devices like iPhones. For many years, hand-tuned models have been developed for this segmentation task, building on reasonable assumptions about the data. For example, ground points should include those lowest elevation returns within a local window or building segments should typically be planar. Within the past decade, we have seen a surge in AI/ML powered models that are able in many cases of outperforming the prior methods, being able to learn novel features and adapt to the intrinsic variability of data. We will provide an overview of the open source ecosystem powering this trend, from benchmark datasets like US3D and DALES to machine learning frameworks (i.e., PyTorch and Tensorflow) and key libraries such as PDAL, Open3D, and PyG.\\n\\nBrad Chambers\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/NWCQRX/\\n\\n#foss4g2022\\n#generaltrack\\n#AI4EOChallenges&Opportunities"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Auditorium/12 - Alexander Salveson Nossum.mp4", "persons": "Alexander Salveson Nossum", "pretalx_id": "RGYMR3", "title": "FOSS4G 2022 | KartAi \u2013 An open living lab for Ai in Norway", "description": "High resolution aerial photos combined with accurate map data represents a perfect data set for training artificial intelligence models. The \u2018KartAi\u2019 project is an innovation project in public sector aimed at developing Ai-methods that detects buildings not in the cadastre or the building map dataset. Thereafter involving the property owner/citizen in a digital dialog and validate or crowdsource more detailed data. The foundation for this is high quality datasets for training and validating the different Ai-models. High resolution aerial photos are collected in large parts of Norway on a regular basis \u2013 often yearly \u2013 in a collaboration between federal and municipal. Thereby there exists a vast amount of extremely detailed image data combined with building map data and cadastre data. However, training the Ai-models have uncovered that minor errors and \u2018skewed\u2019 photos and/or vector data affects the results of the segmentation of roof tops/buildings. Therefore the KartAi projects has made fine tuned and accurate training data sets in several geographical areas optimized for training on detecting and segmenting buildings.\nIn several large scale experiments, a multitude of existing models, newer models and own models have been training and validated. Additionally we have included LIDAR-height data to enhance the precision of segmenting between the likes of roofs and terraces. Training the models on the existing data yields good results. However, when finetuning with the high accurate data \u2013 the models show impressing results.\nSpatial Ai projects like KartAi are at the mercy of volumes of good training data. Our experience show that even more accurate data sets improve the models even further. Therefore, the project has made efforts that have resulted in the release of the training data sets publicly \u2013 as well as all of the results data for the different models and approaches that have been developed. This is an effort into developing a more open living lab for Spatial Ai in Norway. Our hope is that sharing the knowledge and data created can ensure that other Ai-models have easier access to high resolution and high accuracy data \u2013 to train models in the open living lab \u2013 and apply the models internationally where data is scarcer.\\n\\nAlexander Salveson Nossum\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/RGYMR3/\\n\\n#foss4g2022\\n#generaltrack\\n#AI4EOChallenges&Opportunities"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Verde/1 Francois Prunayre.mp4", "persons": "Florent Gravin, Jody Garnett, Jose Garc\u00eda, Jeroen Ticheler, Francois Prunayre", "pretalx_id": "XNSHYD", "title": "FOSS4G 2022 | State of GeoNetwork", "description": "The GeoNetwork-opensource project is a catalog application facilitating the discovery of resources within any local, regional, national or global \"Spatial Data Infrastructure\" (SDI). GeoNetwork is an established technology - recognized as an OSGeo Project and a member of the foss4g community for over a decade.\n\nThe GeoNetwork team would love to share what we have been up to in 2022!\n\nThe GeoNetwork team is excited to talk about the different projects that have contributed with the new features added to the software during the last twelve months. Our rich ecosystem of schema plugins continues to improve; with national teams pouring fixes, improvements and new features into the core application.\n\nWe will also talk a bit about the health and happiness of the GeoNetwork opensource team. Progress of our main branches (3.12.x and 4.0.x), and release schedule.\n\nAttend this presentation for the latest from the GeoNetwork community and this vibrant technology platform.\\n\\nFlorent Gravin\\nJody Garnett\\nJose Garc\u00eda\\nJeroen Ticheler\\nFrancois Prunayre\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/XNSHYD/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Verde/2 Alessio Fabiani - Giovanni Allegri.mp4", "persons": "Alessio Fabiani, Giovanni Allegri", "pretalx_id": "KCPKTX", "title": "FOSS4G 2022 | State of GeoNode", "description": "GeoNode is a Web Spatial Content Management System based entirely on Open Source tools whose purpose is to promote the sharing of data and their management in a simple environment where even non-expert users of GIS technologies can view, edit, manage, and share spatial data, maps, prints and documents attached.\n\nThis presentation provides a summary of new features added to GeoNode in the year  up to the latest releases of GeoNode together with a glimpse of what we have planned for next year and beyond, straight from the core developers.\n\nThe purpose of this presentation is to introduce the attendees to those which are the GeoNode current capabilities and to some practical use cases of particular interest in order to also highlight the possibility of customization and integration. Finally,  we will provide a summary of new features added to GeoNode in the last  release up to the latest releases of GeoNode together with a glimpse of what we have planned for next year and beyond, straight from the core developers.\\n\\nAlessio Fabiani\\nGiovanni Allegri\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/KCPKTX/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Verde/3 Torsten Friebe .mp4", "persons": "Torsten Friebe", "pretalx_id": "7Z9ERN", "title": "FOSS4G 2022 | State of deegree: What's new in 2022", "description": "This presentation provides a summary of new features added to deegree in the latest releases of deegree webservices and deegree OGC API together with a glimpse of what we have planned for next year and beyond.\nInitiated in 2002 the OSGeo project deegree has developed over the last 20 years to an important building block for Spatial Data Infrastructures (SDI). As the implementation of the INSPIRE directive is fully underway it requires stable and mature software solutions based on OGC standards such as GML, WFS and WMS. One of the goals of the deegree project is to provide implementation of those standards.\nIn this talk we will focus on the recent improvements available in deegree webservices and our updated roadmap for full Java 11 support comming with version 3.5. We will show how the support for OGC API - Features Core, part 1 and 2 has been implemented and can be used with existing configurations.\n\nFinally we will show the directions for the project and what future developments are currently planned.\\n\\nTorsten Friebe\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/7Z9ERN/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Verde/4 Tim Schaub.mp4", "persons": "Tim Schaub, Andreas Hocevar", "pretalx_id": "WZRGKK", "title": "FOSS4G 2022 | OpenLayers Feature Frenzy", "description": "A decade ago, OpenLayers was the number one choice for a web mapping library. With the rewrite in 2012 and the rising competition of Leaflet and Mapbox GL JS, there was a phase when the project lost popularity. Today, it has found its niche as a full-featured, flexible, and high-performance geospatial JavaScript library that users can count on for the long haul, especially when their mapping needs get more complex.\n\nThis talk will provide you with a tour of the latest features in the library, including daring live demonstrations. We will present our recent and ongoing work on adding new features and making the library more fun to work with.\n\nWhether you're a developer or decision maker, come to this talk to learn about the current status of OpenLayers.  We\u2019ll provide you with a glimpse into the future of the library and leave you motivated to get mapping with OpenLayers.\\n\\nTim Schaub\\nAndreas Hocevar\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/WZRGKK/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Verde/5 Martin Zdila - Wladimir Szczerban .mp4", "persons": "Wladimir Szczerban, Petr Pridal, Martin Zdila", "pretalx_id": "NBSPX9", "title": "FOSS4G 2022 | MapLibre GL 2.x - JavaScript maps with React, Vue.js, Svelte or Angular", "description": "What's new in MapLibre version 2? We'll explore all the latest features of the library, including its new 3D capabilities. We'll also show you get started with MapLibre in whichever frameworks you choose to work in. This talk will be useful for beginners through to experienced web mappers interested in MapLibre.\nAlong with the 3D capabilities, there are new styling functions and also the move from JavaScript to Typescript to discuss. We'll show you some snippets of these new features and demonstrate the power of MapLibre.\nFor those getting started with web mapping or learning new frameworks, we will show you how to use MapLibre in your own application. We will introduce practical code examples in React, Vue.js, Angular or Svelte, creating a simple map component.\nBy the end of this talk, you should have all you need to get started building apps with MapLibre and the main JavaScript frameworks.\\n\\nWladimir Szczerban\\nPetr Pridal\\nMartin Zdila\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/NBSPX9/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Verde/6 Lorenzo Natali.mp4", "persons": "Lorenzo Natali, Emanuele Geri", "pretalx_id": "G7DJ79", "title": "FOSS4G 2022 | MapStore, a year in review", "description": "*MapStore* is an open source product developed for creating, saving and sharing in a simple and intuitive way maps, dashboards, charts and geostories directly online in your browser. MapStore is cross-browser and mobile ready, it allows users to:\n\n - _Search_ and load geospatial content served using widely used protocols (WMS, WFS, WMTS, TMS, CSW) and formats (GML, Shapefile, GeoJSON, KML/KMZ etc..)\n - _Manage maps_ (create, modify, share, delete, search), charts, dashboard and stories directly online\n - _Manage users_, groups and their permissions over the various resources MapStore can manage\n - _Edit data online_ via WFS-T with advanced filtering capabilities\n - _Deeply customize the look&feel_ to follow strict corporate guidelines\n - _Manage different application contexts_ through an advanced wizard to have customized WebGIS MapStore viewers for different use cases (custom plugins set, map and theme)\n\nYou can use *MapStore* as a product to deploy simple geoportals by using the standard functionalities it provides but you can also use MapStore as a framework to develop sophisticated WebGIS portals by reusing and extending its core building blocks.\n\n*MapStore* is built on top of React and Redux and its core does not explicitly depend on any mapping engine but it can support both OpenLayers, Leaflet and Cesium; additional mapping engines could be also supported (MapBox GL is in the working) to avoid any tight dependency on a single engine.\n\nThe presentation will give the audience an extensive overview of the MapStore  functionalities for the creation of mapping portals, covering both previous work as well work for the future releases.  Eventually, a range of MapStore case studies will be presented to demonstrate what our clients (like City of Genova, City of Florence, Halliburton, Austrocontrol and more) and partners are achieving with it.\\n\\nLorenzo Natali\\nEmanuele Geri\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/G7DJ79/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Verde/7 Andrea Aime.mp4", "persons": "Andrea Aime", "pretalx_id": "8CCEVH", "title": "FOSS4G 2022 | State of GeoWebCache", "description": "GeoWebCache is a popular open source tile cache server written in Java. GeoWebCache that can be used stand alone, working off a remote WMS or local tile layers, such as MBTiles. However, it's also integrated inside GeoServer, allowing simple and quick configuration, as well as transparent caching of WMS requests that happen to match a cached tile.  This presentation will provide information on the latest development for the project, including:\n\n - Performance and scalability improvements\n - OGC TileMatrixSet built-in definitions\n - Storage of tiles in more blob stores (Swift)\n - MBTiles support\n - Integration of tile caching in OGC API - Tiles (with GeoServer integration)\n - Serving vector tiles and integration with the Mapbox ecosystem (e.g., style editing with Maputnik)\n - Continued codebase QA efforts (code clean up, dependency upgrades and the like)\n\nAttend this talk for a cheerful update on what is happening with this project, whether you are an expert user, a developer, or simply curious what it can do for you.\\n\\nAndrea Aime\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/8CCEVH/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Verde/8 Michel Gabri\u00ebl.mp4", "persons": "Michel Gabri\u00ebl", "pretalx_id": "GMQWPY", "title": "FOSS4G 2022 | GeoNetwork and a11y: Introducing accessibility in OSGeo applications", "description": "When websites and web tools are properly designed and coded, people with disabilities can use them. However, currently many sites and tools are developed with accessibility barriers that make them difficult or impossible for some people to use [W3C - Introduction to Web Accessibility].\n\nThe European accessibility requirements present a new and welcome challenge for OSGeo applications. Accessibility (a11y) goes far beyond ease-of-use, with strict guidance on making web applications easily accessible to screen readers and assistive technologies.\n\nThis talk provides an overview of implementing the accessibility guidelines WCAG 2.1, WAI-ARIA, and EN 301 549 (Harmonised European Standard). GeoNetwork is used as a case study here, with \u201chands-on\u201d illustrations of successful guideline implementations and their technical and organisational challenges.\n\nMaking OSGeo Software accessible is a rewarding task that requires broad community engagement and support. Attend this talk to learn more about meeting the a11y requirements and the impact they will have on your organisation and your software solution.\\n\\nMichel Gabri\u00ebl\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/GMQWPY/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Verde/9 Tom Kralidis.mp4", "persons": "Tom Kralidis, Just van den Broecke", "pretalx_id": "XMAYMU", "title": "FOSS4G 2022 | GeoHealthCheck - QoS Monitor for Geospatial Web Services", "description": "Keeping (OGC) Geospatial Web Services up-and-running is best accommodated by continuous monitoring: not only downtime needs to be guarded,\nbut also whether the services are functioning correctly and do not suffer from performance and/or other Quality of Service (QoS) issues.\nGeoHealthCheck (GHC) is an Open Source Python application for monitoring uptime and availability of OGC Web Services.\nIn this talk we will explain GHC basics, how it works, how you can use and even extend GHC (plugins).\n\nThere is an abundance of standard (HTTP) monitoring tools that may guard for general status and uptime of web services.\nBut OGC web services often have their own error, \"Exception\", reporting not caught by generic HTTP uptime\ncheckers. For example, an OGC Web Mapping Service (WMS) may provide an Exception as a valid XML response or\nin a error message written \"in-image\", or an error may render a blank image.\nA generic uptime checker may assume the service is functioning as from those requests and an HTTP status \"200\" is returned.\n\nOther OGC services may have specific QoS issues that are not directly obvious. A successful and valid \"OWS GetCapabilities\" response may not\nguarantee that individual services are functioning correctly. For example an OGC Web Feature Service (WFS) based on a dynamic database may\nreturn zero Features on a GetFeature response caused by issues in an underlying database. Even standard HTTP checkers supporting \"keywords\"\nmay not detect all failure cases in OGC web services. Many OGC services will have multiple \"layers\" or feature types, how to check them all?\n\nWhat is needed is a form of semantic checking and reporting specific to OGC services!\n\nGeoHealthCheck (GHC) is an Open Source (MIT) web-based framework through which OGC-based web services can be monitored. GHC is written in\nPython (with Flask) under the umbrella of the GeoPython GitHub Organization. It is currently an OSGeo Community Project.\n\nGHC consists of two parts: (1) a web-UI app (using Flask) through which OGC service endpoint\nURLs and their checks can be managed, plus for visualising monitoring-results and (2) a monitoring engine that executes scheduled\n\"health-checks\" on the OGC service endpoints. Both parts share a common database (via SQLAlchemy, usually SQLite or PostgreSQL).\nThe database also stores all historic results, allowing for various forms of reporting.\n\nGHC is extensible: at this moment of writing a plugin-system is developed for \"Probes\" in order to support an expanding number of\ncases for OGC specific requests and -checks. Work is in progress to provide a GHC API for various integrations.\n\nLinks:\n\n - Website: http://geohealthcheck.org\n - Sources: https://github.com/geopython/GeoHealthCheck\n - Demo: http://geohealthcheck.osgeo.org\\n\\nTom Kralidis\\nJust van den Broecke\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/XMAYMU/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Limonaia/1 EVREN PAYUZ.mp4", "persons": "Evren Payuz-Charrier, Jean Felder", "pretalx_id": "MMNCZQ", "title": "FOSS4G 2022 | OpenLog - Open Source drillhole data visualization in QGIS", "description": "Mining industry professionals are in a constant need of simple and efficient software solutions for drillhole visualization, management, and edition. Although several Open Source solutions are offered to partially fulfill the need, none has propagated into common professional use.\nIn partnership with a team of mining industry leaders including Orano, Evolution Mining, Sandfire Resources, Kenex, the University of Western Australia, NordGold, GoldSpot and the CEA, Oslandia has formed a consortium in 2021 to answer the demand.\nOslandia has since then been developing a high performance drillhole data visualization QGIS plugin that combines 3D, cross-section, map, and log views into a fully synchronous system. Moreover, users are able to connect OpenLog directly to their existing drillhole databases such as Acquire, Datashed or Geotic.\nThis talk will succinctly present the functionalities of OpenLog as well as its primary use cases, contribution to QGIS 3D data visualization technology, development roadmap, and future prospects.\\n\\nEvren Payuz-Charrier\\nJean Felder\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/MMNCZQ/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Limonaia/2 LAURI KAJAN.mp4", "persons": "Lauri Kajan", "pretalx_id": "XAFBUK", "title": "FOSS4G 2022 | Streamlining QGIS workflows with PostgreSQL editable views and triggers", "description": "When using QGIS as a user interface for a PostgreSQL- & PostGIS-based registry database, user experience plays a high role. The data schemas of a registry database can hold a complex set of relations and database objects which can be hard to set up within QGIS. This was the case with a waste soil transportation registry that we developed for the City of Tampere, Finland. The main goal of the registry is to optimize soil transportation from construction sites by communicating and making it visible what soil categories are available and needed where and when. The registry enables significant savings in transportation costs as well as substantial reductions in climate emissions.\n\nWhen the relational data model gets complex, you can deploy different strategies for setting up the workflows within QGIS. One possible solution is to use editable views and triggers for enabling user-friendly workflows in QGIS. This was the case in our soil registry project. The data model, as it was, would have forced the user to create multiple new features to the database tables when he/she just wanted to add a single soil transfer from one construction site to another. This was seen as too tedious when repeated constantly. The solution was to make a database view that the user could edit in QGIS, in addition to deploying database triggers for creating the right database features, with the proper data into the correct database tables.\n\nThis presentation seeks to show how the strategy was deployed and what challenges we met during the development.\\n\\nLauri Kajan\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/XAFBUK/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Limonaia/3 ARIEL ANTHIENI.mp4", "persons": "Ariel Anthieni", "pretalx_id": "NSLFQ9", "title": "FOSS4G 2022 | Generation of 3D geometries with Artificial Intelligence for the prediction of volumetry of the Urban Code of the City of Buenos Aires", "description": "To make the Platform possible and meet the objectives set, it was necessary to work with different areas of the government involved in urban planning and systems, promoting the opening of data to generate a sustainable process over time for the automatic and dynamic system of interpretation of the Urban Code that governs the constructive and urban behavior of the city of Buenos Aires, which is the basis of this technological solution.\nThe platform is based on the \u201cDigital Twin\u201d concept, that is, a virtual and digital replica of a city's urban plan. The objective is to test any initiative on this virtual model before its real implementation, in order to reduce costs and risks.\nThe tool was developed entirely with open source resources and technologies so that other organizations can study, modify and improve its design through the availability of its source code.\nRegarding its architecture, the platform works from the information extracted from the datasets of the areas referred to the urban fabric and parcels. Then, from a set of processing algorithms that works with systematized rules generated from the text of the urban code regulations, this information is processed, allowing the generation of 3D graphics of each of the city parcels. The volumetry of each parcel allows to know the buildability, the maximum allowed height and the allowed construction alternatives for each parcel, which integrate the platform's viewer.\\n\\nAriel Anthieni\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/NSLFQ9/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Limonaia/4 JARIS VAN DEN BOSSCHE.mp4", "persons": "Joris van den Bossche", "pretalx_id": "7WJNCB", "title": "FOSS4G 2022 | State of GeoPandas and friends", "description": "GeoPandas is one of the core packages in the Python ecosystem to work with geospatial vector data. By combining the power of several open source geo tools (GEOS/Shapely, GDAL/fiona, PROJ/pyproj) and extending the pandas data analysis library to work with geographic objects, it is designed to make working with geospatial data in Python easier. GeoPandas enables you to easily do operations in Python that would otherwise require desktop applications like QGIS or a spatial database such as PostGIS.\n\nThis talk will give an overview of recent developments in the GeoPandas community, both in the project itself as in the broader ecosystem of packages on which GeoPandas depends or that extend GeoPandas. We will highlight some changes and new features in recent GeoPandas versions, such as the new interactive explore() visualisation method, improvements in joining based on proximity, better IO options for PostGIS and Apache Parquet and Feather files, and others. But some of the important improvements coming to GeoPandas are happening in other packages. The Shapely 2.0 release is nearing completion, and will provide fast vectorized versions of all its geospatial functionalities. This will help to substantially improve the performance of GeoPandas. In the area of reading and writing traditional GIS files using GDAL, the pyogrio package is being developed to provide a speed-up on that front. Another new project is dask-geopandas, which is merging the geospatial capabilities of GeoPandas with the scalability of Dask. This way, we can achieve parallel and distributed geospatial operations.\\n\\nJoris van den Bossche\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/7WJNCB/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Limonaia/5 ANITA GRASER.mp4", "persons": "Anita Graser", "pretalx_id": "XP3YS3", "title": "FOSS4G 2022 | State of MovingPandas: analyze all those tracks (not just GPS)", "description": "This talk presents the current state of MovingPandas (http://movingpandas.org) and related movement data analysis tools. MovingPandas has been growing steadily since its first publication in 2018 (with more than 24 contributors to date). Building on GeoPandas and GeoViews, MovingPandas provides movement data analysis tools that support efficient exploratory data analysis through interactive (visual) analysis. Early functionality and demos were focused on dealing with GPS tracking data (including vehicle and animal tracks). This talk presents recent developments towards supporting other track data, including examples from sports tracking (movement in real space, extracted from video footage) and eye or mouse tracking (movement in virtual space). Among many other details, this includes support for local coordinate systems, integration of context beyond geographic base maps, as well as trajectory generalization, segmentation, and distance measures. Finally, we revisit the origins of MovingPandas: the QGIS plugin Trajectools; and review the steps necessary to bring MovingPandas' trajectory analysis tools to QGIS.\\n\\nAnita Graser\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/XP3YS3/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Limonaia/6 BORJA MUNOZ.mp4", "persons": "Borja Mu\u00f1oz", "pretalx_id": "CAPMXK", "title": "FOSS4G 2022 | An introduction to deck.gl for data visualization", "description": "deck.gl is one of the most advanced open-source libraries for data visualization. In this session we will discuss how its WebGL-powered engine can be used to perform visual exploratory data analysis of large datasets. This library is quickly becoming one of the most used in the FOSS4G world due to its open governance model and compatibility with other mapping libraries like MapLibre GL JS.\n\nWe will learn how a deck.gl visualization is structured and what the main concepts are: views, layers and accessors. We will discuss its reactive architecture and how it can be used to build simple scripting prototypes and complex applications with modern JavaScript frameworks like React, Angular or Vue.js.\n\nWe will present different examples ranging from simple layer visualizations to thematic and choropleth maps to advanced interactive 3D visualizations including animations.\n\nFinally we will focus on specific use cases for large data visualization, from datasets with hundreds of thousands of features with data formats like GeoJSON to datasets with billions of features using advanced tiling schemes.\\n\\nBorja Mu\u00f1oz\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/CAPMXK/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Limonaia/7 JOHANNES KROGER.mp4", "persons": "Johannes Kr\u00f6ger", "pretalx_id": "GPC8U8", "title": "FOSS4G 2022 | LERC, an innovative compression algorithm for raster data", "description": "Although in use for about 10 years in various Esri products and services, the LERC (Limited Error Raster Compression) raster compression algorithm has only just recently made its way into the free and open-source GIS scene by its inclusion in GDAL (3.3).\n\nLERC can perform both lossless and lossy raster data compression. To achieve its impressive compression ratios and speed LERC employs two major basic tricks:\n\n - The raster is processed and compressed in small two-dimensional blocks, taking advantage of spatial autocorrelation (neighboring values usually being more alike than others).\n - The raster values are quantized (absolute values are replaced by differences between neighbors) and bitstuffed to minimize the number of bits required to store them, this is especially useful for high bit depth data.\n\nFor lossy compression LERC will follow a user-configurable maximum error threshold (the \"limited error\" in its name). Want to compress your DEM and allow up to one centimeter of error? No problemo!\n\nLERC is patented by Esri but thanks to the choice of the permissive Apache License it is freely usable by anyone.\n\nThe talk will try explain the algorithm on a basic level, understandable by non-experts, and show its performance with some examples.\\n\\nJohannes Kr\u00f6ger\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/GPC8U8/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Limonaia/8 TIMO AARNIO.mp4", "persons": "Timo Aarnio", "pretalx_id": "M7J7YN", "title": "FOSS4G 2022 | State of Oskari (for end-users)", "description": "Oskari (www.oskari.org) is used around the world to provide map applications with integrations to spatial and statistical data and service APIs. Oskari can be utilized as a Web GIS with a regular browser or via embedded maps controllable with a simple API. The embedded maps are created in a easy-to-use WYSIWYG-tool enabling users to add a map component to their websites/services without any programming skills. The additional API can be used to integrate to existing APIs and services for richer functionality.\n\nThis presentation will cover the basics of Oskari and new features introduced during 2021-2022. The focus will be on functionalities for end-users and administrators, such as: new styling tools, map layer analytics and diagnostics tool, metadata supported automation to statistical data visualisation, enhanced support for theming and mobile use. There will be a separate presentation about technical developments in Oskari focusing on developer experience. You can try the features of vanilla Oskari in our demo environment (demo.oskari.org), it has the newest stable version without any customisation.\\n\\nTimo Aarnio\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/M7J7YN/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Limonaia/9 Sami Makinen.mp4", "persons": "Sami M\u00e4kinen", "pretalx_id": "CC93KV", "title": "FOSS4G 2022 | State of Oskari (for developers)", "description": "Oskari is used world wide to provide web based map applications that are built on top of existing spatial data infrastructures. Oskari offers building blocks for creating and customizing your own geoportals and allows embedding maps to other sites that can be controlled with a simple API. In addition to showing data from spatial services, Oskari offers hooks for things like using your own search backend and fetching/presenting statistical data.\n\nThis presentation will go through the improvements to existing functionalities and new features introduced in Oskari during the last year. The focus will be on functionalities from developer perspective like:\n\n - Improvements for working with vector features\n - API-improvements for embedded maps.\n - Rewrite of service capabilities parsing and handling\n - Planned developments for better theming support and mobile-device friendliness for the geoportal\n\nYou can try some of the functionalities Oskari offers out-of-the-box on our sample application: https://demo.oskari.org.\n\nLink: https://oskari.org\\n\\nSami M\u00e4kinen\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/CC93KV/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Limonaia/10 Victoria Neema.mp4", "persons": "Victoria Neema", "pretalx_id": "EK7KL8", "title": "FOSS4G 2022 | The Open Source GIS Stack (OSGS)", "description": "In the last few years, open source GIS has been developing relatively rapidly with an increase in the number of open-source GIS software available for performing various specialty functions. With this increase came the problem of managing the dependencies of different software when installing them on the same machine or getting them to work together to accomplish a task.  How was the setting up process the last time you needed to make a map, share it and write about how you made the map? This is where the docker-based Open Source GIS Stack (OSGS) comes in.\n\nOSGS is a rich, integrated, and opinionated GIS Stack with a focus on configurability and ease of use built from open source components. The primary objective of the OSGS stack is to provide simple and effective end-to-end solutions based on open source geospatial technologies. Some of the key services offered by the OSGS platform are Nginx and Hugo for web publishing using static web pages, File Browser for file management, QGIS-Server for publishing web maps, PostgreSQL and PostGIS for database management, and Metabase for visualizing your data. We\u2019ll take a look at how easy and painless making, sharing and writing about maps can be.\n\nThe Open Source GIS Stack by Kartoza is maintained in the Kartoza OSGS repository https://github.com/kartoza/osgs.\\n\\nVictoria Neema\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/EK7KL8/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Limonaia/11 Nick Forbes-Smith.mp4", "persons": "Nick Forbes-Smith", "pretalx_id": "BBJNWQ", "title": "FOSS4G 2022 | State of TerriaJS", "description": "TerriaJS is an open-source framework for web-based geospatial catalogue explorers.\n\nIt uses Cesium and Leaflet to visualise 2D and 3D geospatial data, and it supports over 50 different Web APIs, file formats and open data portals.\n\nIt is almost entirely JavaScript in the browser, meaning it can even be deployed as a static website, making it simple and cheap to host.\n\nTerriaJS is used across the globe to create next-generation Digital Twin Platforms for open geospatial data discovery, visualisation and sharing - it is used to drive\n\n - National Map (https://nationalmap.gov.au/) (Australian Gov)\n - Digital Earth Australia Map (https://maps.dea.ga.gov.au/)\n - Digital Earth Africa Map (https://maps.digitalearth.africa/)\n - Pacific Map (https://map.pacificdata.org/)\n - NSW Spatial Digital Twin (https://nsw.digitaltwin.terria.io/) (Australian State Gov)\n - and many others\n\nIn this talk, I will give:\n\n - Background information about TerriaJS and how it is used by the community\n - Current state of the project for users, developers and wider community\n - New features\n - Future plans!\n\nhttps://terria.io/\n\nhttps://github.com/TerriaJS/terriajs\\n\\nNick Forbes-Smith\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/BBJNWQ/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Limonaia/12 Marco Montanari.mp4", "persons": "Marco Montanari", "pretalx_id": "KTDUZE", "title": "FOSS4G 2022 | Realtime multi-user mapping with MUDraw", "description": "Mapping is a private operations. It is done with several different local tools and usually by one person at a time. Yet we are used to have realtime multiuser editing of spreadsheets, documents and presentations. MUDraw tries to define a protocol to enable multiuser editing of features on a map and make it available as a library for both Leaflet as well as Maplibre (and enabling cross-library data editing) in order to make map editing a group activity. It relies on the client(s) and a server part written in Python/FastAPI that can be used independently from the infrastructure in which the communication is used and can set up a persistence layer taht is connected directly to github or other storage facilities.The idea of this tool is to be able to integrate it into UMap in order to make it  a more fun to use tool, but also in a longer perspective, part of the Public History Toolkit OpenHistoryMap is developing.\\n\\nMarco Montanari\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/KTDUZE/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Limonaia/13 Erik Meerburg.mp4", "persons": "Erik Meerburg", "pretalx_id": "TSUFJ8", "title": "FOSS4G 2022 | From a national map publication platform to infinity. And beyond, of course.", "description": "For over a decade, there has been an open source map publication platform in the Netherlands, known as Tailormap (formerly Flamingo). That project is maintained largely by one company, B3Partners. Currently, Tailormap is being overhauled. Nah, not overhauled, I\u2019d say completely rebuild. And this rebuild comes with a new approach on how to distribute this software project, and how to make it accessible to other developers to contribute, to organizations to roll out independently, and to other companies to use in their customer solutions.\n\nWhat we aim for in the long run is an online geospatial platform that is easy to use for all. For now, we publish an easy to install online GIS and mapviewing application, with features like mobile editing capabilities so that it can be used for maintenance purposes as well as for data dissemination. And here, at the FOSS4G in Firenze, we will celebrate this with our international launch presentation (and party in a not yet disclosed bar).\n\nWe\u2019d like to invite you to join us in this journey. We\u2019re extremely happy to have been able to start this development without outside funding, and we\u2019re looking for partners to grow Tailormap together. We\u2019re currently looking into the OSGeo Community project program, to see if we can join. We\u2019ll be at the B2B meeting as well, but this presentation is where we\u2019ll show the goodies.\\n\\nErik Meerburg\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/TSUFJ8/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Onice/1 Matthew Hanson.mp4", "persons": "Matthew Hanson, \ufeffPete Gadomski", "pretalx_id": "9RRYZM", "title": "FOSS4G 2022 | STAC Best Practices and Tools", "description": "The SpatioTemporal Asset Catalog (STAC) specification is a common language for describing geospatial information that is flexible enough to extend across domains and use cases. In this talk, we walk through best practices for building STAC catalogs and using STAC extensions, using real world examples. These best practices are informed by documentation, conversations with STAC contributors, and discussions within the wider community. We survey the ecosystem of open-source STAC software, which includes libraries and tools written in Python, Node.js, and more. We show examples of reading, modifying, and writing STAC catalogs with a selection of software, including PySTAC and stactools, and we show which metadata to include in your STAC objects to ensure interoperability with powerful tools like xarray and pandas. Whether you are new to the STAC ecosystem or an experienced contributor, this talk will provide you with the context and tools you need to build your best STAC!\\n\\nMatthew Hanson\\n\ufeffPete Gadomski\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/9RRYZM/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Onice/2 Daniel J. Dufour.mp4", "persons": "Daniel J. Dufour, Matthias Mohr", "pretalx_id": "MNLFUG", "title": "FOSS4G 2022 | Cloud-Native Geospatial with JavaScript", "description": "The amount of Earth Observation data we have available nowadays is exceeding the capabilities for data processing. Therefore, a lot of data is now made available in the cloud. To make digesting the data easier and more-lightweight, it is getting more and more popular to store the data in so-called \u201ccloud-native\u201d file formats while data processing is also moving towards the data, i.e., into the cloud. This way you only need to retrieve the actual subset of the data you are actually interested in instead of the full data set, which can be in the magnitude of gigabytes or even larger. This technology of cloud-native file formats is usually best used with Browsers, which is the users\u2019 main interface to the internet and the cloud. There the main language is JavaScript. Therefore, this talk will give a high-level introduction about the relevant cloud-native file formats and show whether and how you can make use of these files in client-side JavaScript:\n\n - COG: Cloud-Optimized GeoTiff ( https://www.cogeo.org )\n - COPC: Cloud-Optimized Point Clouds ( https://copc.io )\n - Flatgeobuff ( https://flatgeobuf.org )\n - GeoParquet ( https://github.com/opengeospatial/geoparquet )\n - STAC: SpatioTemporal Asset Catalog ( https://stacspec.org )\n - Zarr ( https://zarr.readthedocs.io )\n\nThis talk will dig into the available open-source libraries and, if JavaScript implementations are available, show their functionality based on examples. If multiple options are available, a high-level comparison will show the main differences in functionality. For COGs for example, we\u2019ll compare the capabilities of the popular mapping libraries Leaflet, OpenLayers and MapLibre GL.\\n\\nDaniel J. Dufour\\nMatthias Mohr\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/MNLFUG/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Onice/3 Matthew Hanson.mp4", "persons": "Matthew Hanson", "pretalx_id": "FSK8U3", "title": "FOSS4G 2022 | The State of Cloud-Native Geospatial", "description": "The vision of \u201cCloud-Native Geospatial\u201d is a new paradigm of performing efficient computing and data access in the cloud in an interoperable way in order to achieve scalable and repeatable analysis of geospatial data. The last few years have seen major developments in open standards and open software that are helping make this vision possible, supporting full end to end interoperable workflows on remote sensing data, from data discovery to publishing of interoperable derived products.\n\nThis talk will present the current state of the Spatio Temporal Asset Catalog (STAC) specifications (stac-spec and stac-api-spec), updates in the published STAC extensions, and the latest community developments around Analysis Ready Data (ARD). We will cover the landscape of current recommended cloud-optimized file formats, for raster, vector, and point-cloud data formats (COG, Zarr, GeoParquet, COPC). Finally, we will provide recommendations for open-source client software to use to take advantage of the emerging geospatial clouds.\\n\\nMatthew Hanson\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/FSK8U3/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Onice/4 Andrea Aime.mp4", "persons": "Andrea Aime", "pretalx_id": "CK89KG", "title": "FOSS4G 2022 | Serving earth observation data with GeoServer: COG, STAC, OpenSearch and more...", "description": "Never before have we had such a rich collection of satellite imagery available to both companies and the general public. Between missions such as Landsat 8 and Sentinels and the explosion of cubesats, as well as the free availability of worldwide data from the European Copernicus program and from Drones, a veritable flood of data is made available for everyday usage.\n\nManaging, locating and displaying such a large volume of satellite images can be challenging. Join this presentation to learn how GeoServer can help with with that job, with real world examples, including:\n\n - Indexing and locating images using The OpenSearch for EO and STAC protocols.\n - Managing large volumes of satellite images, in an efficient and cost effective way, using Cloud Optimized GeoTIFFs.\n - Visualize mosaics of images, creating composite with the right set of views (filtering), in the desired stacking order (color on top, most recent on top, less cloudy on top, your choice).\n - Perform both small and large extractions of imagery using the WCS and WPS protocols.\n - Generate and view time based animations of the above mosaics, in a period of interest.\n - Perform band algebra operations using Jiffle.\n\nAttend this talk to get a good update on the latest GeoServer capabilities in the Earth Observation field.\\n\\nAndrea Aime\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/CK89KG/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Onice/5 Asger Skovba Petersen.mp4", "persons": "Asger Skovbo Petersen", "pretalx_id": "SQYE9A", "title": "FOSS4G 2022 | Serving oblique aerial imagery using STAC and Cloud Optimized Geotiffs", "description": "In this talk we are going to present how the Danish Agency for Data Supply and Efficiency (SDFE) transitioned from a purely proprietary system to an open source system based on SpatioTemporal Asset Catalog (STAC) API and Cloud Optimized GeoTiffs (COGs) for servingservicing its open data collection of 5 million oblique aerial images. The new system is built partly using existing open source components and partly on newly built open source components. It uses significantly less resources and lets third party users access the data in a standardized way.\n\nAn important part of the process has been to develop and propose a community STAC extension for perspective imagery. This extends the STAC base metadata with parameters which are needed to do photogrammetric calculations and measurements using the images. The potential of this extension is that it enables the community to build generic perspective imagery clients in which the user can do advanced photogrammetric measurements.\n\nTo  ensure support for existing clients and to lower the barrier to entry the system also supports clients without COG reading abilities. Using open source components we have built \"CogTiler\" a high performance tile server which serves jpeg tiles directly from the COGs. Most of the time this is accomplished without decompressing the jpeg data.\n\nSDFE required that all code written for this project be open source and easily available to anyone. Therefore, all the code is available on GitHub.\\n\\nAsger Skovbo Petersen\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/SQYE9A/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Onice/6 Markus Neteler.mp4", "persons": "Markus Neteler, Carmen Tawalika, Jorge Herrera, Anika Weinmann", "pretalx_id": "TD3HNC", "title": "FOSS4G 2022 | News from actinia - let's STAC!", "description": "\u201eHello again, my name is actinia. Still new to OSGeo and a Community Project since 2019, you might have heard about me already. In short I am a REST API on top of GRASS GIS to allow location, mapset and geodata management and visualization as well as execution of the many GRASS GIS modules and addons. Processing with other tools like GDAL and snappy is supported as well. I can be installed in a cloud environment, helping to prepare, analyse and provide a large amount of geoinformation. Besides these facts about me there is also a lot to tell about what happened last year! Besides vector upload, citable DOI, QGIS and python client implementations and more, I can be a Spatio Temporal Asset Catalog myself with the actinia-stac-plugin, am able to use data registered in a STAC for processing and after processing register the resulting data. With the ongoing development of the openeo-grassgis-driver, you can use this new functionality either in my native language or via openEO API. To learn about the details, come on over!\u201c\\n\\nMarkus Neteler\\nCarmen Tawalika\\nJorge Herrera\\nAnika Weinmann\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/TD3HNC/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Onice/7 Dave Bianco.mp4", "persons": "Dave Bianco", "pretalx_id": "P9TKKA", "title": "FOSS4G 2022 | Serverless Geospatial", "description": "More and more geospatial operations are happening in the cloud and often these processes are serverless.  Whether your focus is on transportation logistics, agriculture, climate change analytics, or real estate; it is now possible to do geospatial computing in the cloud for both small and large projects.\n\nWith serverless cloud compute options for data storage, compute, and desktop; we can now host our entire infrastructure completely serverless. Let's review the current state of geospatial serverless cloud infrastructure by exploring a stack consisting of OGC publishing, QGIS Desktop for cartography and client-side processing, TiTiler tile server, STAC data catalog, and a combination of data storage options.\n\nFor OGC publishing, we'll review MapServer and Koop using Lambda plus API Gateway.  Similarly TiTiler can also be built with Lambda and API Gateway.   QGIS Desktop can now be run in the cloud through AWS Workspaces or AppStream.  For our data storage, we can use a combination of S3, Aurora PostGIS, and Redshift.\\n\\nDave Bianco\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/P9TKKA/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Onice/8 Samweli Mwakisambwe.mp4", "persons": "Samweli Mwakisambwe", "pretalx_id": "LQLAPC", "title": "FOSS4G 2022 | Introduction to STAC API plugin in QGIS", "description": "STAC or SpatialTemporal Asset Catalog is now a popular option for providers wishing to create accessible catalogs of spatiotemporal asset data for end users. STAC aims to create a standardized and performant way for providers to expose their spatiotemporal asset data, and for users to ingest that data.\nA 'spatiotemporal asset' is any file that represents information about the earth captured in a certain space and time.\nSince the development of STAC started in 2007, the STAC ecosystem was not able to use the STAC data in desktop softwares. Recently through collaboration between Kartoza and Microsoft, a QGIS (a desktop GIS application) plugin called \u201cSTAC API Browser\u201d was developed to bridge the gap between QGIS users and STAC data.\nNow using \u201cSTAC API Browser\u201d users can access, download, analyze and use a vast amount of imagery data offered by various STAC specification providers, such as Microsoft Planetary Computer.\nThe aim of this talk is to introduce the \u201cSTAC API Browser\u201d plugin, give a guide on how to use the plugin inside QGIS, showcase cool things that the plugin supports and how users/developers can collaborate on the plugin project. On top of all, we will also look at how to use the QGIS temporal controller feature with the added STAC data from the plugin.\\n\\nSamweli Mwakisambwe\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/LQLAPC/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Onice/9 Darren Wiens.mp4", "persons": "Darren Wiens", "pretalx_id": "SBVBVU", "title": "FOSS4G 2022 | Maps in Motion: Introduction to the STAC Video Extension", "description": "This talk will introduce a new Spatiotemporal Asset Catalog (STAC) extension for geospatial video assets. The extension is designed to standardize the metadata for all types of overhead geospatial video assets, including those collected by satellite, UAV, or airborne sensors, while accommodating situations in which the sensor moves throughout the video. The talk will include a brief overview of the STAC ecosystem (elements and extensions), and explain the Video extension\u2019s schema. In addition, there will be a complete end-to-end demonstration including data preprocessing and STAC item creation (entirely using FOSS tools), and a FOSS method for displaying STAC Video extension-enabled items on an interactive map. The audience need not prepare in any way for this introductory presentation, although some background in STAC and geospatial video might be beneficial. Otherwise, this talk has a broad appeal for data professionals through to frontend developers who are keen to add some motion to their maps!\\n\\nDarren Wiens\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/SBVBVU/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_4/1 Eduard Rosert.mp4", "persons": "Eduard Rosert", "pretalx_id": "B7WFKK", "title": "FOSS4G 2022 | SkinnyWMS Meteorological Web Map Service", "description": "The European Centre for Medium-Range Weather Forecasts (ECMWF) is an intergovernmental organisation that produces global numerical weather predictions and other data for its Member and Cooperating States and the broader community. It hosts one of the largest meteorological data archives in the world. ECMWF supports the open data community by providing data through its Public Datasets program and Open Charts. Additionally, the Centre has a long history of and extensive expertise in developing and providing software to process and visualize meteorological data.\n\nIn concert with these efforts, we developed SkinnyWMS \u2013 a lightweight Web Map Service for meteorological data. SkinnyWMS is currently used in the Copernicus Climate Data Store (CDS) and Germany\u2019s Meteorological Service (DWD) Geoportal. It provides out-of-the-box interactive visualisation for a large set of meteorological parameters. It offers built-in support for data stored in GRIB (WMO standard) and NetCDF (OGC standard) formats, which are commonly used in meteorology, climatology, and oceanography.\n\nSkinnyWMS is written in Python and is based on ECMWF\u2019s existing free and open source software ecCodes and Magics. It is free and open source software available under the Apache License 2.0. SkinnyWMS\u2019 code is hosted on GitHub and it's available as an Anaconda package, from PyPi and as a Docker image from Docker Hub.\\n\\nEduard Rosert\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/B7WFKK/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_4/2 Simon Kassel - Aaron Su.mp4", "persons": "Aaron Su, Adeel Hassan, Simon Kassel", "pretalx_id": "ZZGNXV", "title": "FOSS4G 2022 | Human-in-the-loop Machine Learning with Realtime Model Predictions using GroundWork and Raster Vision", "description": "Acquiring and labeling geospatial data for training machine learning models is a time-consuming and expensive process. It is made even more difficult by the lack of specialized open-source tools for dealing with the idiosyncrasies of geospatial data. At Azavea, we have encountered both of these problems before. In this talk, we will present a solution that incorporates our geospatial annotation platform, GroundWork (https://groundwork.azavea.com), with our open-source deep learning framework, Raster Vision (https://rastervision.io), to provide a human-in-the-loop active learning workflow. This workflow allows labelers to immediately see the effect of their created labels on the model\u2019s performance, thus speeding up the labeling-training-labeling cycle and making the connection between the AI and human GIS data labelers easy and seamless.\n\nThis talk will extend the hands-on experience introduced in last year\u2019s \u201cHuman-in-the-loop Machine Learning with GroundWork and STAC'' FOSS4G workshop. We will present an enhanced active-learning workflow that allows labelers to train a model and see predictions on-the-fly as they create labels in GroundWork. The model-training and predictions will be handled by Raster Vision. This workflow will give the labelers a clear view of the model\u2019s current strength and weaknesses at all times, and thus allow them to direct their labeling efforts more efficiently. Newly created labels will propagate back to the AI model in real time, and an asynchronous job will continue to refine the model and predictions. This loop is backed by the open-source Raster Foundry (https://rasterfoundry.azavea.com) and Franklin (https://azavea.github.io/franklin) APIs, and is compliant with the STAC (https://stacspec.org) and OGC Features (https://www.ogc.org/standards/ogcapi-features) open standards.\\n\\nAaron Su\\nAdeel Hassan\\nSimon Kassel\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ZZGNXV/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_4/3 Dennis Bauszus.mp4", "persons": "Dennis Bauszus", "pretalx_id": "NUZYVC", "title": "FOSS4G 2022 | Composing Software: Spatial for the JAMstack generation", "description": "In the words of Eric Elliot; All software development is composition: The act of breaking a complex problem down to smaller parts, and then composing those smaller solutions together to form your application.\n\nInspired by Eric\u2019s work we have begun to modularize all the things and combine your mapping libraries (Openlayers, Maplibre, et al.) with other open source libraries (Tabulator, ChartJS) for data visualizations.\n\nHaving finally broken the shackles imposed on us by the restrictions of the Internet Explorer age we can finally facilitate Javascript (ES6+) to its functional best and deliver the applications we dream of.\n\nESBuild has revolutionized the way we compile script, and dynamic imports which have long been touted as the future are finally available to us with a little help from Skypack.\n\nIn addition to tried and tested server side rendering we now have powerful vanilla Web APIs to build application views on the fly and with little reflow, and repaint.\n\nThis is a talk for the opinionated JS enthusiast.\\n\\nDennis Bauszus\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/NUZYVC/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_4/4 James Banting.mp4", "persons": "James Banting", "pretalx_id": "JVD7YW", "title": "FOSS4G 2022 | Cleaning and processing global resource data for game development", "description": "This talk will describe some of the tools and tricks used by the team at Sparkgeo to gather, clean, and represent global resource data (minerals, wood, and water) for use in video game development.  One of the resources collected by the team used the STAC package for the Joint Research Centre - Global Surface Water data product to deliver water occurrence as part of the end product.\n\nThis talk will describe how to use a STAC package like JRC to access and transform cloud datasets before moving on to additional datasets such as limestone, gold, and forest cover.  These other datasets required a different geospatial approach to ensure that the resources were appropriately represented in the video game.  Nevertheless, each dataset required gathering from the internet and performing an Extract-Transform-Load (ETL) task.\n\nThe use of open-source geoprocessing tools, data science methods, and data delivery formats helped ensure real-world data is used in video games.  Community standards\\n\\nJames Banting\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/JVD7YW/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_4/5 Pete Gadomski.mp4", "persons": "\ufeffPete Gadomski", "pretalx_id": "L3KNY8", "title": "FOSS4G 2022 | Exploring Data Interoperability with STAC and the Microsoft Planetary Computer", "description": "As a part of its AI4Earth initiative, Microsoft has created a Planetary Computer (PC) for hosting and processing open geospatial data. In addition to publishing a wide range of datasets, including Sentinel-2, MODIS, and more, the PC provides a powerful API and compute system based on open-source geospatial tools and using STAC metadata for data query, discovery, and access. In this talk, we present the latest in open geospatial data access, discovery, processing, and visualization using a variety of datasets from the Planetary Computer. We demonstrate use of the odc-stac package, which leverages the power of the OpenDataCube computing platform without the need for a database backend, and how odc-stac can load, mosaic, and transform geospatial assets into xarray datasets. We dive into other data interoperability tasks, including scaling processing with Dask and leveraging a variety of cloud-native formats. Along the way, we provide recommendations for data providers and curators on how to ensure their data can be used in a rich, interoperable way by the latest in geospatial processing tools.\\n\\n\ufeffPete Gadomski\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/L3KNY8/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_4/6 Markus Neteler.mp4", "persons": "Markus Neteler, Carmen Tawalika, Marc Jansen, Markus Metz, Anika Weinmann", "pretalx_id": "EFDUYY", "title": "FOSS4G 2022 | Connecting tribes: how we connected the GRASS GIS database natively to GeoServer", "description": "All of us involved in the creation and publication of large amounts of geodata are familiar with the complexities of data management. In the case of geodata created with GRASS GIS, we asked ourselves how they could be made accessible to GeoServer without duplication. To overcome the previous limitation of GRASS GIS having its own data format, we connected the tribes and let Java and C/Python communicate with each other. So the challenge was to be able to efficiently read the GRASS GIS database directly with GeoServer. And why is that? Because this directly links the analytical capabilities of GRASS GIS with the exceptional geo service & publishing capabilities of GeoServer.\n\nOur approach is to use the existing GDAL-GRASS bridge, and add this bridge as a new extension to GeoServer. To this we add two new GRASS GIS addons (r.geoserver.style + r.geoserver.publish) to easily publish the data from a GRASS GIS session as an OGC service. The new GeoServer GRASS raster datastore allows to use GRASS raster data directly in a GeoServer instance. In this way it is now very easy to publish GRASS data as a web service via GeoServer without having to export the data from GRASS GIS to GeoTIFF or COG files. This works for both classic raster data and also for timeseries which can e.g. be inspected as a WMS Time.\\n\\nMarkus Neteler\\nCarmen Tawalika\\nMarc Jansen\\nMarkus Metz\\nAnika Weinmann\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/EFDUYY/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_4/7 Irene Pleizier.mp4", "persons": "Irene Pleizier", "pretalx_id": "E8BBBU", "title": "FOSS4G 2022 | The challenges and benefits of implementing OS geo within a large contracting company", "description": "Within large construction companies GIS is widely used to store, analyse and visualise spatial data. GIS is just one of the components of an information infrastructure and has to be an integral part that can provide data and information to other departments and subcontractors as well. Van Oord as a marine contractor deals with spatial data on a daily basis. Existing disciplines like the design team and Survey team already have their way of dealing with spatial data to fulfil their task. What is it that the organisation needs additionally to work with GIS?\nVan Oord has chosen to use FOSS4g software as a GIS backbone. This choice has its benefits but also poses challenges. Most competitors in the business use proprietary software. Clients do not necessarily follow standards and the IT department has to support our requirements.\nWe are very proud of our GIS backbone and definitely see the benefits of using FOSS4G. Come and listen to the solution we have chosen; the changes we make in the business and challenges we face.\\n\\nIrene Pleizier\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/E8BBBU/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_4/8 Marco Bernasocchi.mp4", "persons": "Marco Bernasocchi", "pretalx_id": "RXW9SZ", "title": "FOSS4G 2022 | Professional field data management with QField", "description": "PostGIS represents the de-facto standard for managing your spatial data, while QField is the state-of-the-art application for their management in the field.\nSince QField 2.0 release in spring 22, the seamless data synchronisation experience is complete. QFieldCloud closes the loop between your company's fieldworkers and the GIS analysts.\n\nIn this talk, we'll share _features_, _best practices_ and _pro-tips_ for managing your projects, remote teams, and permissions in a professional setting.\n\n## About QField\n\nQField is an open-source app developed for efficient fieldwork in real-time in urban areas, with a 5G connection or with offline data. The mobile GIS app combines a minimal design with sophisticated technology to conveniently bring data from the field to the office. Seamless QGIS integration, GPS-centred, offline functionality, synchronisation capabilities, desktop configurable: \u201cQField\u201d is designed for fieldwork \u2013 simple but uncompromising. Link: https://qfield.org\n\n## About QFieldCloud\n\nQFieldCloud is a spatial cloud service integrated into \u201cQField\u201d that allows remote provisioning and synchronisation of geodata and projects. Although \u201cQFieldCloud\u201d is still in an advanced beta stage, it is already being used by many groups to improve their workflows significantly. Link: https://qfield.cloud\\n\\nMarco Bernasocchi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/RXW9SZ/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_4/9 Antonello Andrea.mp4", "persons": "Andrea Antonello, Silvia Franceschi", "pretalx_id": "EBANJZ", "title": "FOSS4G 2022 | SMASH, state of the art of the digital field mapping project.", "description": "SMASH, the smart mobile app for surveyor\u2019s happiness, is a slick app dedicated to digital field mapping.\nThe open source flutter app for Android, IOS (and upon request Linux, Macos and Windows) is packed with features, as for example: Geopackage and PostGIS editing support, Kalman filter on gps logs, geo-fences, native geotiff and shapefile visualization support, SLD styling for vector datasets.\n\nSMASH\u2019s web counterpart is the Survey Server, a web application that allows groups of surveyors to centralize data collection. Users can synchronize the data from the app, but also download dedicated forms and projects, as well as basemaps and datasets. The server is built upon the same technology as the mobile app and visualizes the data with the same look and feel. Notes serverside-versioning has been introduced to enhance synchronization of data by teams. A redmine plugin is being developed by community members to create a geo-ticketing system.\n\nThis presentations gives an insight about the state of the art of the SMASH ecosystem and its current roadmap.\\n\\nAndrea Antonello\\nSilvia Franceschi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/EBANJZ/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_4/10 Andrew Bailey.mp4", "persons": "Andrew Bailey", "pretalx_id": "UNJEXC", "title": "FOSS4G 2022 | From the field to the desk - end to end mobile data capture in an enterprise environment.", "description": "A demonstration of how to deploy a mobile data capture platform in an enterprise setting. In this example an environmental survey has been developed for a large organisation with a team of surveyors. Consideration is made to authentication, version control and synchronisation to an enterprise spatial database for wider consumption.\n\nQGIS is used to define base mapping, context layers and the data capture layers for the mobile application. In this project it is demonstrated how QGIS can be used to define survey forms to reduce input error. In this case a tree survey layer has been defined that adheres to the Individual Tree Standard from the UK\u2019s Forest Research, the Open University and Treework Environmental Practice.\n\nThe QGIS project is then deployed to a dockerised Mergin service. Authenticated access is then granted to users of Lutra Consulting\u2019s Input Android application. Field collected data can be created and synchronised with the Mergin service. Version control & merging allows multiple users to make asynchronous changes with the ability to rollback if required.\n\nThe Mergin service internal database is synchronised with an enterprise PostGIS database to allow other users to access and edit data via desktop. Media captured in the survey such as images is extracted through Mergin\u2019s API and made available together with the survey data through a web GIS interface.\\n\\nAndrew Bailey\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/UNJEXC/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_4/11 Jakko lehto.mp4", "persons": "Jaakko Lehto", "pretalx_id": "JNECGN", "title": "FOSS4G 2022 | Using QField to manage traffic sign inventory", "description": "The new Road Traffic Act of Finland (effective since 2020) requires\nthe road management authorities to provide information about the existing road\nsigns, along with other similar infrastructure such as traffic lights and road paintings, to Traficom,\nthe Finnish Transport Infrastructure Agency. The data is stored in Digiroad, the national database of open\nstreet and road data, also hosted by Traficom. To help the different actors in public sector and elsewhere fulfill this legal obligation,\nas well as providing tools for infrastructure management and maintenance more generally, FOSS4G software can play an important role.\n\nIn this talk, we present results from our recent project related to this effort. In the project, we developed a\ntraffic sign inventory process using QField mobile data collection app and studied its suitability for the task.\nThere was a pre-existing conceptual data model for the road signs from Traficom, which was used as the basis for the\nphysical PostGIS database implementation. In addition, the data collection workflow was designed to make the\ndata collection as efficient as possible. This included configuring the data input forms and the traffic sign visualizations in the  related QGIS project file, as well as other aspects of usability of the app, such as further development of the geocoding functionality.\n\nThe process was then tested out in the field and improved upon in cooperation with employees from a few different-sized municipalities around Finland. The finished project report, along with the files needed to set up the data collection project are freely available in  the Github repository of the project: https://github.com/finnishtransportagency/digiroad-QField\\n\\nJaakko Lehto\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/JNECGN/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_4/12 Ant Scott.mp4", "persons": "Ant Scott", "pretalx_id": "7URVYD", "title": "FOSS4G 2022 | Analysing access to UK public rights of way with the QGIS Graphical Modeler", "description": "The UK national walking organisation, Ramblers, are working to improve the public rights of way network, and in particular improve access to it for people who are less advantaged, and may not have access to vehicles. The research project described in this talk undertook an analysis of the national paths network using publicly available data supplied by hundreds of individual local authorities across the UK. This was done by setting up a series of models in the QGIS Graphical Modeler to generate six key indicators aggregated to census area level, including distance to nearest continuous path from each small area unit of population,  length of available path within a series of buffers, and access to paths of specific types \u2013 for example those passing through protected or designated areas. The talk will look at some of the challenges of the project, including scaling the modeller to work with millions of path features and tens of thousands of point locations, and building processes to combine path segments and then disaggregate them to an appropriate level.\n\nThe main goal of the project was to inform and support specific policy proposals, but it is also intended that the QGIS models should be passed on to Ramblers and used in the longer term, to monitor the impact of changes to the paths network and of population patterns over time, and also to support analysis of how additions to the network, for example by the inclusion of historic paths which are not yet official rights of way, could improve access. The intention is that these models could be run on smaller areas, and on hypothetical paths networks, to help build a case for extensions and rationalisation of the paths network at both national and local levels. Use of the Graphical Modeler rather than scripts or database processing will make it easier for Ramblers staff to run the models themselves in the future using inputs of their choice.\\n\\nAnt Scott\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/7URVYD/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_4/13. Marco Bernasocchi.mp4", "persons": "Marco Bernasocchi", "pretalx_id": "QWEF8P", "title": "FOSS4G 2022 | Seamless fieldwork thanks to QFieldCloud", "description": "QFieldCloud's unique technology allows your team to focus on what's important, making sure you efficiently get the best field data possible.\n\nThanks to the tight integration with the leading GIS fieldwork app QField, your team will be able to start surveying and digitising data in no time.\n\nDiscover what QFieldCloud has to offer and how, thanks to seamless integration with your SDI, it can help make your teams' fieldwork sessions pleasant and efficient. And if you want to roll out your own customized version, nothing will stop you, QFieldCloud is open source!\n\nQFieldCloud is a SaaS (software as a service) solution built by OPENGIS.ch that allows your team to seamlessly integrate field data to your SDI.\n\nQFieldCloud is written in python using the Django Web framework that encourages rapid development and clean, pragmatic designs.\n\nQField is the mobile data collection app for QGIS with more than 120K active monthly users and 500K downloads. Discover how the seamless synchronisation with QFieldCloud can help make your teams' fieldwork sessions pleasant and efficient.\\n\\nMarco Bernasocchi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/QWEF8P/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_9/1 Jody Garnett.mp4", "persons": "Tom Kralidis, Jody Garnett", "pretalx_id": "GK8T9L", "title": "FOSS4G 2022 | How to join OSGeo (for projects)", "description": "Welcome to the Open Source Geospatial Foundation, proud hosts of FOSS4G, and advocate for free and open source geospatial software everywhere. This is a call out to open source software developers; please join OSGeo and help us help you!\n\nJoin OSGeo today:\n\n - Even just listing your project on the osgeo.org website is a great first step. Help us promote your technology so users can discover and enjoy your software.\n\n - The OSGeo \u201ccommunity program\u201d gives project teams a chance to join the foundation with an emphasis on supporting innovation and new projects. The foundation provides some direct support, assistance along with endorsement and recognition from our board.\n\n - For established projects please join our \u201cincubation program\u201d to be recognized for excellence and as a full OSGeo committee.\n\nUnlike other foundations, OSGeo does not require that you give up or transfer any Intellectual Property; we simply ask that you be spatial, open-source, and open to participation.\n\nThis presentation gives clear instructions on how to join OSGeo, and representatives from recent successful projects will be on hand to answer your questions.\\n\\nTom Kralidis\\nJody Garnett\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/GK8T9L/\\n\\n#foss4g2022\\n#generaltrack\\n#TransitiontoFOSS4G"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_9/2 Vicky Vergara.mp4", "persons": "Vicky Vergara", "pretalx_id": "KWJEGF", "title": "FOSS4G 2022 | OSGeo community interactions", "description": "OSGeo is an international organization, and the members are people from everywhere in the world .\n\nOSGeo is cares and loves the community. When you move from \"other\" G software to FOSS4G you become part of the community.\n\nThis community has a range of roles like users of the geo-spacial software, conference organizers, geo-spacial software developers, committee members, and some many more.\n\nWe are a complex organization.\n\nAs the second objective of this talk I would like to explain our organization.\n\nThe preface of the main objective:\n\nThese last two years have been hard times for everyone, we have been locked down, working remotely and unable to interact in person with our colleagues, and probably on this FOSS4G some members will not be able to be face to face during this FOSS4G 2022 in Florence, Italy.\n\nThe main objective:\n\nI would like to share the \"autographs & good wishes\" from the OSGeo community members that I've meet along these 7 years that I've been participating on the organization.\\n\\nVicky Vergara\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/KWJEGF/\\n\\n#foss4g2022\\n#generaltrack\\n#TransitiontoFOSS4G"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_9/3 Ashish Kumar.mp4", "persons": "Ashish Kumar, Rajat Shinde, Rahul Chauhan", "pretalx_id": "NA7E9U", "title": "FOSS4G 2022 | Google Summer of Code with OSGeo", "description": "OSGeo's *Google Summer of Code * Initiative has been an inspiring and motivating platform for new contributors to join the OSGeo projects, community projects, guest projects, and incubating projects. In 2022, OSGeo is participating for the *_16th year_* in the Google Summer of Code, and it itself is a great achievement. With this talk, the OSGeo GSoC Administrators shall try to put forth the importance of GSoC with respect to the students and participating projects. The admins would focus on the development of projects with GSoC and encourage projects to be a part of the upcoming GSoC. \n\n\nOver the years, OSGeo's Google Summer of Code initiative has transformed into an initiative full of contributions towards geospatial software development. In the last 16 years, many OSGeo projects comprising incubating projects, community projects, and guest projects have progressed attributed to the contributions of student developers. Some of these contributors continue to participate as contributors for the projects and went on to take mentoring and organizing responsibilities. This is a true sense of FOSS4G in terms of the individual and collective growth of the developers and the OSGeo community. *In this talk, the OSGeo GSoC Admins team would try to appreciate the efforts of all the mentors and students involved till now and present the state of the GSoC 2022. The Admins would also present possibilities for new projects to be part of the GSoC with OSGeo as an umbrella organization.*\\n\\nAshish Kumar\\nRajat Shinde\\nRahul Chauhan\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/NA7E9U/\\n\\n#foss4g2022\\n#generaltrack\\n#TransitiontoFOSS4G"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_9/4 astrid emde Angelos Tzotsosmp4.mp4", "persons": "Astrid Emde, Angelos Tzotsos", "pretalx_id": "PVRWZY", "title": "FOSS4G 2022 | OSGeoLive project report", "description": "OSGeoLive is a self-contained bootable DVD, USB thumb drive or Virtual Machine based on Lubuntu, that allows you to try a wide variety of open source geospatial software without installing anything. It is composed entirely of free software, allowing it to be freely distributed, duplicated and passed around. It provides pre-configured applications for a range of geospatial use cases, including storage, publishing, viewing, analysis and manipulation of data. It also contains sample datasets and documentation. OSGeoLive is an OSGeo project used in several workshops at FOSS4Gs around\nthe world.\nThe OSGeoLive project has consistently and sustainably been attracting contributions from ~ 50 projects for over a decade. Why has it been successful? What has attracted hundreds of diverse people to contribute to this project? How are technology changes affecting OSGeoLive, and by extension, the greater OSGeo ecosystem? Where is OSGeoLive heading and what are the challenges and opportunities for the future? How is the project steering committee operating? In this presentation we will cover current roadmap, opportunities and challenges, and why people are using OSGeoLive.\\n\\nAstrid Emde\\nAngelos Tzotsos\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/PVRWZY/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_9/5 Jani kylmaaho.mp4", "persons": "Jani Kylm\u00e4aho", "pretalx_id": "TJ3GWK", "title": "FOSS4G 2022 | Openness - a Strategic Choice", "description": "The National Land Survey of Finland has made a strategic decision to pursue increased use of open source solutions in its activities. We\u2019ve been an active user of FOSS4G solutions for more than a decade. Further, we created an open source mapping framework Oskari, which has an active user and developer community.\n\nIn autumn 2020, the National Land Survey of Finland made a major decision to build our new topographic data production system on open source components, such as QGIS and PostgreSQL/PostGIS. The decision has raised a few eyebrows and a lot of interest among other national mapping agencies as well as other institutions using geospatial software. This talk will discuss\n\n - on what grounds we made such a decision\n - how we are progressing with the implementation\n - how we are looking at engaging in collaboration with open source communities\n - and most importantly, why every public sector organization should consider the benefits that can be gained by using and investing in open solutions.\\n\\nJani Kylm\u00e4aho\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/TJ3GWK/\\n\\n#foss4g2022\\n#generaltrack\\n#TransitiontoFOSS4G"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_9/6 Andrius Balciunas.mp4", "persons": "Andrius Balciunas", "pretalx_id": "TCL9SW", "title": "FOSS4G 2022 | Implementation of INSPIRE in Lithuania: experience with the transition to FOSS4G", "description": "Since entering into force in May 2007, the Directive 2007/2/EC of the European Parliament and of the Council establishing Infrastructure for Spatial Information in Europe (INSPIRE directive) has been playing very important role in building spatial information infrastructures \u2013 both pan-European and at national level. Technical specifications and guidelines describe the key components of data content and of implementation of web services. However, each country decides individually how technically it will implement these requirements, what architecture and software it will choose to use. The roadmap of directive implementation has reached the last milestone in 21/10/2020 \u2013 all spatial data sets had to be provided to the INSPIRE geoportal ((https://inspire-geoportal.ec.europa.eu/). Now is the best time to share the experience how Lithuania started INSPIRE implementation path using commercial software but successfully ended with using only FOSS4G.\n\nImplementation of INSPIRE directive in Lithuania is centralized and state enterprise GIS-Centras is responsible for technical work. INSPIRE directive was implemented in 2 stages. The first stage started back in 2012 and it was dedicated to cover data sets from Annex I and Annex II (only orthophoto imagery). Back then the INSPIRE directive implementation was a new and little-known technical challenge. The decision to call a tender and use the commercial software for which there were not many viable alternatives at the time seemed quite logical.\n\nThe second stage of INSPIRE directive implementation started in 2018 and ended up in 2021. This stage was dedicated to cover data sets from Annex III and part of Annex II. Instead of just calling a tender to implement the requirements with commercial software we already had we decided to implement everything by ourselves and change the commercial software to FOSS4G. At the end of the project, we have not only prepared and published all the datasets and services, but also had a team of in-house specialists who were able to work with the FOSS4G. Even the results from the first stage was quickly changed to FOSS4G in order to unify the implementation architecture.\n\nWe have set three goals for the transition from commercial software to FOSS4G:\n\n 1. Create a system that we can administer and develop ourselves;\n 2. Create infrastructure that is cost-effective in the long run;\n 3. Automate the workflow as much as possible.\n\nIn this presentation we will share our experience of transition from commercial software to FOSS4G both from technological and company/team perspectives. We will present the technological architecture we use to implement INSPIRE requirements. It consist of PostGIS, Geoserver, QGIS, Hale studio, GDAL and Geonetwork. Finally we will explain what we have learn as a company and GIS specialists during the transition process.\\n\\nAndrius Balciunas\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/TCL9SW/\\n\\n#foss4g2022\\n#generaltrack\\n#TransitiontoFOSS4G"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_9/7 Micheael Terner.mp4", "persons": "Michael Terner", "pretalx_id": "NMBNLT", "title": "FOSS4G 2022 | Is it wrong to make money with FOSS4G technology?", "description": "Spoiler alert, I believe the answer to the question posed in the title is a firm \u201cno\u201d. As such, this presentation will describe why a healthy commerce ecosystem is an essential component of the broader FOSS4G community. The presentation will describe several commerce models that both support open source initiatives and generate work and revenue for businesses. The commerce models presented will be complimented by real world examples of these models in action. The presentation will also describe the trend of large companies open sourcing some of the tools that they use to run their business and/or that support their products. The presentation will also describe the business importance of open source frameworks for both the broader Javascript development space (e.g., React, Angular, etc.) and the more specialized geospatial development arena (e.g., Deck.gl, etc.). Finally, while making money is appropriate within open source communities, it is always important that businesses contribute back to the open source ecosystem and best practices for being a good open source citizen will be discussed.\\n\\nMichael Terner\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/NMBNLT/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_9/8 Federico Mensio.mp4", "persons": "Federico Mensio", "pretalx_id": "WEY8CW", "title": "FOSS4G 2022 | Pedological Information System of Piedmont Region in Italy", "description": "Over the last 35 years, the IPLA has collected data on soils, both soil samples and cartographic data, to create a database (physical and digital) that represents knowledge for all stakeholders, public and private, of the composition and state of soils. Piedmontese.\nin the last 25 years the SIP (Pedological Information System) has been changed several times, to meet the new needs in terms of data collection but above all to update it to the new FOSS technologies.\nin fact, in the last 5 years we have gone from non-connected proprietary systems (DB FoxPro and Esri geoDB personal) to a single integrated system with FOSS tools: PostgreSQL / PostGIS and QGIS.\nAn information system has therefore been created that allows technicians on the one hand to be able to collect the field data by inserting them, with a web interface in the database, and to be able to see in real time, the cartographic themes in QGIS, based on the data.just inserted and taking advantage of the geographical component of the database.\nAlso the implementation of the survey points can be done, using in this case internal functions of the DB, both in alphanumeric way and in QGIS in a geographic way, with real-time modification of the points based on the coordinates entered by one of the two tools.\nAnd new implementations for field survey (QFiled) are under development, for the survey of the points and their visualization on the DB in real time.\nThe pedological observations are characterized by different levels of information among which more than 5000 soil profiles are the basic and fundamental data, subdivided into field data (descriptions and photos) and analytical data (physical-chemical determinations in laboratory). The elaboration of these data provides the main structure of the Pedological Information System, that is the description of more than 1200 Soil Types, used to build up the characterization of 7000 Geographical Units.\\n\\nFederico Mensio\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/WEY8CW/\\n\\n#foss4g2022\\n#generaltrack\\n#TransitiontoFOSS4G"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_9/9 Julien Moura.mp4", "persons": "Vincent Picavet, Julien Moura", "pretalx_id": "YU8XVH", "title": "FOSS4G 2022 | Geo-commons in France : review of current initiatives", "description": "*\"G\u00e9ocommun\"* `[\u0292eok\u0254m\u025b\u0303]` : is it the latest buzzword in France or a large movement towards more openness in the geospatial realm ?\n\nThe French National Geographical Institute (IGNF) recently started communicating its vision towards the development of Geo-commons. This sounds like a strategical change in the way the institute apprehends geo-data and geo-software production.\n\nIn this presentation, we first try to give a definition of what a \"geocommon\" is. Then we review the initiatives currently being deployed by various actors in France to transform this word into a reality.\n\nWe study the roots of these actions and their links to opendata, opensource and opengov movements.\n\nWe also try to provide a mindmap of involved actors, and how they interact together : administrations, data-oriented communities or software-oriented communities.\n\nThen we anticipate the impact on free and opensource software for geomatics, and how it could affect technologies and communities in this area.\\n\\nVincent Picavet\\nJulien Moura\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/YU8XVH/\\n\\n#foss4g2022\\n#generaltrack\\n#TransitiontoFOSS4G"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_9/10 Taro Matsuzawa.mp4", "persons": "Taro Matsuzawa", "pretalx_id": "JYCARU", "title": "FOSS4G 2022 | 10 years in Georepublic and OSGeo", "description": "Taro Matsuzawa has been working for Georepublic for 10 years now. He has had experience in many open source communities since his student days, but had not yet joined the OSGeo community until he joined Georepublic. He is now a FOSS4G specialist and has presented at FOSS4G conferences in Japan.\n\nFor a ten years he has been a committer for OpenMapTiles and several OpenSource projects, and has contributed more than 20 projects to Japanese companies and municipalities. In this issue, he would like to share some of the insights he has gained from his work and the OSS community.\n\nI will mainly talk about the basics and applications of Game Tile[1] technology, a small-scale map solution using pgRouting[2], and Python3 support for the ckanext-spatial plugin[3].\n\n 1. https://leafletjs.com/SlavaUkraini/examples/crs-simple/crs-simple.html\n 2. https://pgrouting.org/\n 3. https://github.com/ckan/ckanext-spatial/pull/249\\n\\nTaro Matsuzawa\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/JYCARU/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_9/11 Waddle Julien.mp4", "persons": "Julien Waddle", "pretalx_id": "KKQWHV", "title": "FOSS4G 2022 | Favoring Opensource Technologies for French Fire Brigades", "description": "The NexSIS project aims to create a digital rescue platform providing all civil protection actors in France with a complete set of cloud operational services. Open Source GIS solutions were chosen for this national project with strong technical requirements.\n\nThis has a direct impact on the way data will be exploited. Each Fire Department will have to adapt and create data that will be directly used by the NexSIS software (areas that require special equipment or specialized teams for example).\n\nCurrently in France each fire department has a budget depending on the size / number of people in the department. This budget is used to buy new fire extinguishers, computers, but also to hire new people, etc... Most departments currently use many different proprietary softwares for all GIS aspects. Historically, each department has made their own choices on what software they use.\n\nThis talk will show how we are helping fire brigades to make the switch to Open Source without losing any functionalities and without any extra work load.\n\nUsing the power of both QGIS and PostgreSQL, we will show how these tools can be used to share and publish common workflows (qgis expressions, model builders) that are often used in fire emergencies, build a common atlas (report module), edit spatial data (forms, and constraints) and so forth.\\n\\nJulien Waddle\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/KKQWHV/\\n\\n#foss4g2022\\n#generaltrack\\n#TransitiontoFOSS4G"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_9/12 Johannes Schielein.mp4", "persons": "Johannes Schielein, Darius Andreas G\u00f6rgen", "pretalx_id": "38XHEC", "title": "FOSS4G 2022 | The MAPME Initiative: Leveraging the power of open data and FOSS GIS to improve public expenditure in the development aid sector.", "description": "MAps for Planning, Monitoring and Evaluation (MAPME) is an initiative founded by Geo-geeks and FOSS enthusiasts from KfW Development Bank (KfW), French Development Agency (AFD) and MapTailor Geospatial Consultants.\nAid agencies such as KfW and AFD financially assist developing countries in fighting hunger, poverty, disease, illiteracy and environmental degradation around the world. Together with our partner countries we are key decision makers in the allocation of the so-called Official Development Assistance (ODA). KfW, for example, allocated 12.4 bn. EUR to assist developing countries achieving the Sustainable Development Goals (SDGs) in 2020.\nGeodata and geospatial technologies help us to take informed decisions to allocate funds responsibly and maximize public goods and benefits. Nevertheless, the uptake of open data and geospatial technologies within our institutions and decision-making processes is still relatively low. We think that one of the main reasons for this is missing openness in the way that we deal with data-analytic questions in our institutions.\nIn response we founded MAPME, an open community and open-source initiative to upscale and democratize the usage of geodata and geo-spatial technologies within our own institutions as well as our partners. With this initiative we promote cultural change in our institutions by prototyping small FOSS and open-data pilot projects that illustrate the power and usefulness of these technologies to improve development aid projects. One of our outputs is the mapme.biodiversity package, which offers R-users the possibility to automatically download and process several important open-data sources for conservation science using a parallelization approach to deal with large AOIs or global conservation portfolios (https://github.com/mapme-initiative/mapme.biodiversity).\nWe will offer a talk where we share our approach to FOSS application and development, what we see as barriers in our institutional and IT contexts and first successes stories that leveraged the power of geospatial data for learning about our projects and taking more informed decisions.\\n\\nJohannes Schielein\\nDarius Andreas G\u00f6rgen\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/38XHEC/\\n\\n#foss4g2022\\n#generaltrack\\n#TransitiontoFOSS4G"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_9/13 Ariel Anthieni.mp4", "persons": "Ariel Anthieni, Julia Martinuzzi", "pretalx_id": "KFVAPC", "title": "FOSS4G 2022 | Development of plugins in QGIS for the management of the Multipurpose Cadastre in the Government of Mexico City", "description": "Migration of the current tools that maintain the Cadastre of Mexico City to Open Source and free licensing technologies.\n\nThe objective of the project was the development of a plugin in QGIS that optimizes the functionalities of the licensed software and allows the maintenance and management of cadastral data.\n\nStages of the development process:\n\na. Requirements analysis: Based on the information provided by the client, the feasibility of integrating the database engine,  the API of workflow services with the transactional systems of the municipality is evaluated.\n\nb. Definition and implementation of PostGIS and QGIS: together with the client, for the integration of the tools and subsequent development.\n\nc. Design of Python and QT tools: carry out the design and development of plugin components in QGIS.\n\nd. Design of Postgres security interfaces:  coordination with the permissions, automation routines with the plugin components.\n\ne. Development of functional tools from Bentley to QGIS: development of the previously detailed functionalities in the analysis and design stages of the project in order to replace the existing functionalities, accompanied by redesign.\n\nf. Test and implementation in Quality Assurance  (QA) environment\n\ng. Training and  technology transfer.\n\nh. Documentation of all strage of the process of the project, in order to carry out the complete transfer to our client.\\n\\nAriel Anthieni\\nJulia Martinuzzi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/KFVAPC/\\n\\n#foss4g2022\\n#generaltrack\\n#TransitiontoFOSS4G"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_6/1 John Duncan.mp4", "persons": "John Duncan", "pretalx_id": "TERMMU", "title": "FOSS4G 2022 | Maplandscape - an open-source geospatial workflow for agricultural landscape monitoring", "description": "Maplandscape is a stack of open-source geospatial applications designed to enable mapping of agricultural landscapes and farm systems. It supports large team in-the-field mobile data collection, provides tools for data syncing and management, and easy visualisation and querying of spatial information for decision making and reporting. The workflow has been developed and deployed in Tonga through a collaboration between universities in Australia and the South Pacific, and Tonga\u2019s Ministry of Agriculture, Food, Forests and Fisheries (MAFF). Maplandscape is currently being used in Tonga to map crop, livestock, agroforestry systems, and farm management practices; over 11,000 farms and four island groups have been mapped so far. This information has been used to inform agricultural planning and resource allocation, disaster response, land utilisation assessment, tracking land use changes, and monitoring of the condition of key commercial crops.\n\nThe Maplandscape workflow is based on QField for in-the-field data collection and QFieldCloud for data syncing, storage, and user authentication and management. Using QField mobile GIS, key agricultural landscape features (e.g. crop parcels, paddocks, fallow land) can be spatially mapped, and rich attribute information can be captured through various widgets and flexible and complex form logic, with support of reference geospatial layers. Three cloud-based applications have been developed that build on top of the QFieldCloud API to provide geospatial data visualisation and analytics tools. These applications provide differing and complementary functionalities, and facilitate quick analysis, publishing, and reporting of data collected using QField and stored using QFieldCloud. The apps are built using Shiny, Leaflet, ggplot, and DataTables software, and are deployed using ShinyProxy and docker containers in swarm mode. These applications use the QFieldCloud API to authenticate users and retrieve data and an R package has been developed to handle this interaction within Shiny apps. The goal of these applications is to speed up the process of data collected using QField informing agricultural monitoring, planning, and decision making activities. A summary of these geospatial data visualisation and analytics applications is provided below.\n\nmaplandscape-view is a web app that allows users to query and view spatial data on interactive maps and data tables and generate reports comprising cartographic outputs, charts, and summary tables directly from QFieldCloud data. maplandscape is a web app that allows users to specify and apply custom geospatial data querying, analysis, and visualisation tasks to their QFieldCloud data in a web browser and with a simple UI interface. This application enables users without a GIS background to extract information from, and analyse, rich datasets collected in-the-field using QField; for example, agricultural officials in Tonga used this application to generate village- and district-level crop area summary tables for their annual report. Finally, maplandscape-admin provides tools for users to manage their QFieldCloud projects and accounts.\\n\\nJohn Duncan\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/TERMMU/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_6/2 James O'Connor.mp4", "persons": "James O'Connor", "pretalx_id": "HG7RLR", "title": "FOSS4G 2022 | Early use of FOSS4G in a space start up", "description": "As a small but scaling new space company, Satellite Vu relies heavily on open source tooling for our image production pipeline, as well as storing our image assets and conducting experiments using thermal data sources. The company prides itself on being early adopters of emerging technologies, particularly as standardization of satellite imagery access and reproducible science are at the core of what we stand for.\n\nIn this talk, we\u2019ll give an overview of the main projects we lean on for all of data engineering, data science and thermal science as well as outline the vision for Satellite Vu\u2019s evolving role within the open source community. Specific tools we\u2019ll comment on our use include:\n\n 1. STAC, and the related stac-fastapi, for storing and serving image collections\n 2. rioxarray and stackstac for scaling our use of both internal and external cloud native imagery datastores\n 3. The pangeo stack for running experiments and scaling data processing\n 4. pygeoapi, as a vector data server\n\nI\u2019ll introduce the Satellite Vu public STAC, and talk through how we\u2019re using FOSS4G tools to shorten the development time of new products as well as prepare for the first satellite launch in Q1 2023.\\n\\nJames O'Connor\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/HG7RLR/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_6/3 Amit Wadhwa.mp4", "persons": "Amit Wadhwa, Jorge Martinez", "pretalx_id": "EXUCF7", "title": "FOSS4G 2022 | Visualizing climate risks for disaster reduction and climate resilience programs \u2013 Interactive open-source tools for analysts and decision makers to utilize Earth observation data", "description": "Climate and vegetation indicators created from Earth observation data provide timely information to analysts and decision makers implementing disaster risk reduction and climate risk mitigation programs. The United Nations World Food Programme\u2019s (WFP) Climate and Earth Observation unit (ClEO) works with a number of Earth observation datasets to measure and monitor climate risks across all of the regions where we work, including 90+ countries globally.\n\nThe end users of this information include government institutions such as the meteorological and disaster management agencies, implementers of humanitarian assistance programs, as well as WFP field staff working on programs which build climate resilience through the development of community assets and livelihood support.\n\nTo enable the creation and dissemination of monitoring indicators, WFP is in the process of deploying an instance of Open Data Cube with nearly global coverage. Leveraging the power of data cubes to measure key climate and vegetation indicators over space and time, WFP\u2019s Open Data Cube instance will provide free and open access to a wide range of analysis-ready data products. Utilization of this data requires user-facing applications with easy to use and intuitive interfaces. One of the tools developed by WFP to provide more direct access to climate and Earth observation data is PRISM \u2013 an open-source software solution which greatly simplifies the integration of geospatial data from various systems. PRISM has been developed to easily integrate data from Open Data Cube deployments using OGC standards \u2013 providing a quick tool to display time-series raster data in an interactive dashboard.\n\nDuring this talk, WFP will present a brief overview of the use cases we address with Earth observation data, the role of our Open Data Cube instance in the organization, and the development of tools and processes to disseminate data for visualization using OGC standards \u2013 including the PRISM platform.\\n\\nAmit Wadhwa\\nJorge Martinez\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/EXUCF7/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_6/4 Stefano Bovio.mp4", "persons": "Stefano Bovio", "pretalx_id": "UEU7BR", "title": "FOSS4G 2022 | Developing with MapStore; creating a custom dashboard to map crime data", "description": "MapStore is an open source product developed for creating, saving and sharing in a simple and intuitive way maps, dashboards, charts and geostories directly online in your browser. You can use MapStore as a product to deploy simple geoportals by using the standard functionalities it provides but you can also use MapStore as a framework to develop sophisticated web gis portals by reusing and extending its core building blocks. MapStore is also integrated inside geOrchestra as well as GeoNode open source project.\n\nThe presentation will focus on the use of MapStore as web gis framework to create a modular, reproducible, simple yet powerful dashboard to visualize crime data (but in reality many different types of location based data) leveraging on GeoServer and PostGIS advanced functionalities. We will describe the main steps for creating such an infrastructure leveraging on the MapStore components and framework then we will cover how the existing dashboard template can be configured to work with your own data sources (eventually touching the needed processing steps for the data itself) including GeoServer and PostGIS advanced functionalities.\nWe will eventually discuss further improvements and  new features to evolve the current capabilities to capture new and emerging requirements.\n\nThe goal of this presentation is twofold, on one side we are addressing developers in order to show them advanced usage of MapStore to develop compelling applications on the other side we will be addressing power users and system administrators willing to deploy the Crime Mapping dashboard to make their own data available without writing code.\\n\\nStefano Bovio\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/UEU7BR/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_6/5 Andrea Aime - Nuno Oliveira.mp4", "persons": "Andrea Aime, Nuno Oliveira", "pretalx_id": "RREDPC", "title": "FOSS4G 2022 | Mastering Security with GeoServer and GeoFence", "description": "The presentation will provide a comprehensive introduction to GeoServer's own authentication and authorization subsystems.\nThe authentication part will cover the various supported authentication protocols (e.g. basic/digest authentication, CAS, OAuth2) and identity providers (such as local config files, database tables and LDAP servers).\nIt will explain how to combine various authentication mechanisms in a single comprehensive authentication tool, as well as providing examples of custom authentication plugins for GeoServer, integrating it in a home-grown security architecture.\n\nWe\u2019ll then move on to authorization, describing the GeoServer pluggable authorization mechanism, and comparing it with proxy based solution. We will explain the default service and data security system, reviewing its benefits and limitations.\n\nFinally we\u2019ll explore the advanced authorization provider, GeoFence. The different levels of integration with GeoServer will be presented, from the simple and seamless direct integration to the more sophisticated external setup. Finally we\u2019ll explore GeoFence\u2019s complex authorization rules using:\n\n - The current user and its roles.\n - The OGC services, workspaces, layers, layer groups.\n - CQL read and write filters.\n - Attribute selection.\n - Cropping raster and vector data to areas of interest.\\n\\nAndrea Aime\\nNuno Oliveira\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/RREDPC/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_6/6 andrea aime-.mp4", "persons": "Andrea Aime", "pretalx_id": "J8AEGR", "title": "FOSS4G 2022 | Creating Maps in GeoServer using CSS and SLD", "description": "The presentation aims to provide attendees with enough information to master GeoServer styling documents and most of GeoServer extensions to generate appealing, informative, readable maps that can be quickly rendered on screen. Examples will be provided from GeoSolutions training material (https://docs.geoserver.geo-solutions.it/edu/en/), as well as from the OSM data directory (https://github.com/geosolutions-it/osm-styles) we shared with the community.\n\nSeveral topics will be covered, providing examples in CSS and SLD, including:\n\n - Mastering common symbolization, filtering, multi-scale styling.\n - Using GeoServer extensions to build common hatch patterns,  line styling beyond the basics, cased lines, controlling symbols along a line and the way they repeat.\n - Leveraging TTF symbol fonts and SVGs to generate good looking point thematic maps.\n - Using the full power of GeoServer label lay-outing tools to build pleasant, informative maps on both point, polygon and line layers, including adding road plates around labels, leverage the labeling subsystem conflict resolution engine to avoid overlaps in stand alone point symbology.\n - Dynamically transform data during rendering to get more explicative maps without the need to pre-process a large amount of views.\n - Generating styles with external tools.\\n\\nAndrea Aime\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/J8AEGR/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_6/7 Ramya Ragupathy.mp4", "persons": "Ramya Ragupathy", "pretalx_id": "BNA8YX", "title": "FOSS4G 2022 | Introduction to Spatial Data Outputs Platform - OpenStreetMap Galaxy", "description": "OpenStreetMap (OSM) Galaxy is a project that the HOT Tech Team launched in mid-April 2021 to optimise and improve availability and accessibility of OSM Data outputs for different user groups within the ecosystem. Through this project, we strive to address all the OSM data needs under one umbrella and ensure OSM data is available, accessible and ready to use for all kinds of users. We are trying to solve the high dependency on different data sources and uncontrolled platforms while focusing on fast queries and process optimisation by accessing data from HOT administered and controlled environment.\n\nAs a one-liner, the vision for OSM Galaxy is to provide a single platform to address all OSM Data Needs.\nIn OSM context, a data need is a broad term covering a variety of topics:\nRaw data exports\nAnalysing completeness of Data\nChecking the data quality in your neighbourhood\nUnderstanding your contribution to a mapathon, to name a few\n\nThrough this project we strive to:\nBring together all the data needs under one umbrella\nEnsure OSM data is available, accessible and ready to use for all kinds of users\\n\\nRamya Ragupathy\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/BNA8YX/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_6/8 Koko Alberti.mp4", "persons": "Koko Alberti", "pretalx_id": "XTCZDP", "title": "FOSS4G 2022 | Geofolio: Making Environmental Data Understandable and Accessible for Everyone", "description": "Geofolio is a project aiming to make environmental data understandable and accessible for everyone. Geodata is notoriously difficult to use for non-experts. It often gets hidden away in confusing data portals, and at least some GIS expertise is a common prerequisite to find and download data, extract your area of interest and to do some simple analysis. Geofolio lowers these adoption thresholds by letting users draw an area of interest, and then a factsheet with text summaries, maps, and charts is generated automatically from various open access geodatasets. The factsheets contain information on various environmental themes such as topography, land use, hydrology, climate, and agriculture. Users can download the source data, thereby providing an easy step up for further investigation and learning using open source GIS applications such as QGIS.\n\nGeofolio makes extensive use of open source software for geospatial applications. The front-end and factsheets use the Leaflet mapping library, and the back-end and processing framework depends on GDAL and Shapely. Geodata is stored for analysis and visualization using PostGIS and Cloud-Optimized GeoTIFF files. The actual data processing takes place \"on-the-fly\" using GDAL-enabled AWS Lambda functions.\\n\\nKoko Alberti\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/XTCZDP/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_6/9 Adela Sobotkova.mp4", "persons": "Adela Sobotkova, Steve Cassidy", "pretalx_id": "CQCGUA", "title": "FOSS4G 2022 | Just Enough GIS: Plugging Lightweight Mobile GIS into an Offline Field Data Collection Platform", "description": "In 2012, FAIMS project developed FAIMS Mobile, an open-source platform for minting Android applications for offline human-mediated data collection on multiple tablets. Originally intended for archaeology, this platform saw cross-disciplinary adoption including disciplines such as oral tradition, linguistics, ecology and geochemistry.  Mobile GIS (provided by Nutiteq, Estonia) was built into the core software from the start providing the most essential geospatial functionality from management and rendering user-owned raster and vector data, to manual data creation, editing, retrieval, and rendering. Automated data collection via onboard and bluetooth sensors was also implemented to support unique identifier generation and printing, and other key tasks for field sample tracking.  Navigation and spatial query facility existed. The simplified interface isolated end-users from administrators, with only the latter needing geospatial skills and domain knowledge, a division that facilitated data entry by unskilled volunteers. Many of the geospatial functions, however, required programming to customize. Given this barrier to entry, only clients with access to a programmer could create customisations for geospatially-tailored field data entry. Others had to run existing customisations, published on Github. Despite this bottleneck, FAIMS 2.6 clients created a variety of spatial data collection workflows, from simple offline shape mapping to manual map data digitisation.\nIn 2022, FAIMS project is rebuilding the FAIMS Mobile platform to equip it with a graphic user interface for customisation, to allow cross-platform deployment, and to implement \u2018round trip\u2019 data transfer to and from  existing desktop tools. We hope to retain a robust geospatial data creation capability but aim to strip away functionality that saw little use over the 10 previous years, taking a 'just-enough-GIS' approach. As the architecture of FAIMS Mobile is changing from sqlite with spatialite extension to CouchDB/ PouchDB supporting geojson, technical elaboration pointed to OpenLayers as the most appropriate and complete library for geospatial data collection and management. This paper will examine the challenges and considerations of \u2018just enough GIS\u2019 implemented with OpenLayers in a comprehensive mobile data capture application.\\n\\nAdela Sobotkova\\nSteve Cassidy\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/CQCGUA/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_6/10 Nathan McEachen.mp4", "persons": "Nathan McEachen", "pretalx_id": "CQCHJZ", "title": "FOSS4G 2022 | GeoPrism Registry - Using Spatial Knowledge Graphs for Managing and Integrating Geographic Data Over Time Across Multiple Information Systems", "description": "A knowledge graph is a network that interconnects concepts, objects, or events according to domain specific relationships and terminology. Spatial knowledge graphs model locations and how they are spatially related to each other according to semantic properties and are useful for helping to automate the integration of geographic data across silos. Information systems used to make decisions often have different pictures of the geographies (i.e. people, places, and infrastructures) they respectively cover. Within a single area, different programs collect and store different geographic data in siloed systems at different times, leading to discrepancies and duplication of effort. This also results in decisions based on incomplete and out-of-date geographic data (e.g., spatial distribution of population and resources).\n\nGeoPrism Registry is an open-source Common Geo-Registry (CGR) implementation that utilizes spatial knowledge graphs to provide a single source of truth for managing geographic data over time across multiple information systems and data sources. It is used to publish, access, and manage changes over time to hierarchies and geospatial data for geographic objects such as administrative divisions, infrastructure and other relevant physical features.\n\nGeoPrism Registry uses geo-ontologies to define semantic properties and relationships that implement spatial knowledge graphs using a graph database. Changes to attribute values, relationships, and geographies are managed for different time periods. Historical views of data can be generated for any time period. The application has been released under the Lesser General Public License (LGPL) and was developed using only open-source components including OpenJDK, MapboxGL, PostgreSQL, OrientDB, Solr, GDAL, and GeoServer.\n\nThis talk will demonstrate how spatial knowledge graphs defined in GeoPrism Registry using FOSS4G tools can:\n\n 1. contextualize data from different sources in both time and space,\n 2. use geographic objects as the common link between data sources,\n 3. facilitate trend analysis, and\n 4. aggregate data according to different hierarchies\n\nSupport for the development of GeoPrism Registry was provided by the Bill and Melinda Gates Foundation via the Digital Solutions for Malaria Elimination (DSME) Project and the DSME Community. The DSME project uses geo-enabled information systems to improve the efficiency and effectiveness of malaria surveillance, program planning, and intervention.\\n\\nNathan McEachen\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/CQCHJZ/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_6/11 Julien Osman.mp4", "persons": "JulienOsman, Arthur VINCENT", "pretalx_id": "SDG9K7", "title": "FOSS4G 2022 | IOTA2: large scale land cover mapping operational chain", "description": "The use of remote sensing data operating in different observation domains is an undeniable asset for the realization of quality land cover products.\nIndeed, satellites allow to cover large areas of interest in a regular way with a durable quality.\nSatellite data can be of different but often complementary natures, which makes it possible to broaden the possible fields of application (water management, snow cover, crop yield, urbanization, etc.).\nIn addition to these new data, there are recent technological developments (or old but now usable due to the evolution of computing capacities, such as the use of neural networks), and means of service provision and dissemination that allow these applications to be carried out over a longer period of time (long time series that are computed more rapidly) and in a larger space at different scales, sometimes simultaneously (stationary, local, national, continental, global scale).\niota2, developed by CESBIO and CNES with the support of CS GROUP, is a response to the growing demand for the creation of an Open Source tool, allowing the production of land cover maps at a national scale that is sufficiently generic to be adapted to the different objectives of users.\nIn addition, this project ensures the production of an annual land use map of metropolitan France [REF https://doi.org/10.3390/rs9010095], with a satisfactory level of quality, thus proving its operational capacities.\n\niota2 integrates several families of supervised algorithms used for the production of land use maps. Supervised algorithms (e.g.,  Random Forests or Support Vector Machine) that process pixels that can be parameterised by the users through a simple configuration file. iota2 also offers the user the option of using a deep learning model.\nIn addition to the pixel approaches, contextual approaches are also proposed, with Autocontext [1] and OBIA (Object Based Image Analysis). Autocontext, based on RF, takes into account the context of a pixel in a window around its position. The OBIA approach exploits an input segmentation to classify objects directly.\n\nIn addition to the supervised classification approaches, iota2 is also able to produce indicator maps (biophysical variables) either by supervised regression or by using user-provided processors, diversifying the possibilities of using iota2.\n\nOne major interest in iota2 is it's ablility to deal with a huge amount a data, for instance the OSO product (https://theia.cnes.fr/atdistrib/rocket/#/collections/OSO/2327b748-a82c-5933-afb0-087bbfeff4cd) is generated using a stack of all available Sentinel-2 data over the France without any landscape discontinuity due to the Sentinel-2 grid. Another point of interest is its capability to produce a landcover map everywhere a Sentinel-2 data and a groundtruth are available (ie : https://agritrop.cirad.fr/597991/1/Rapport_Intercomparaison_iota2Moringa.pdf).\n\n 1. Derksen, D., Inglada, J., & Michel, J. (2020). Geometry aware evaluation of handcrafted superpixel-based features and convolutional neural networks for land cover mapping using satellite imagery. Remote Sensing, 12(3), 513. http://dx.doi.org/10.3390/rs12030513\\n\\nJulienOsman\\nArthur VINCENT\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/SDG9K7/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_6/12 Frederic Jacon.mp4", "persons": "Frederic Jacon, Philippe Belais", "pretalx_id": "D7GSXV", "title": "FOSS4G 2022 | The Carto 2 Project", "description": "The Carto 2 project is part of the Geo-IDE program of the Ministries of Ecology and Agriculture in France. The objective of Geo-IDE is to provide stakeholders in the ministries with common data and tools in the field of geographic information.\n\nSince 2019, the Ministry of the Ecology and Camptocamp have been collaborating to create a new module, Carto2, that would allow data administrators to compose, publish and consult maps online and other users to search, consult or download published maps at the same time.\n\nCarto2 also had to offer a more modern and ergonomic platform, as well as possibilities to evolve the module and its functionalities in order to better meet the needs and expectations of the decentralized services.\n\nThe project is developed using free solutions such as Geoserver, QGIS Server and Openlayers. This is an example of the development of a large departmental spatial data infrastructure used by about 150 services in France.\n\nWe will present the software architecture and the strategies put in place to develop Carto 2 and we will describe the technical challenges we have faced during the development.\\n\\nFrederic Jacon\\nPhilippe Belais\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/D7GSXV/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Auditorium/01 - Thomas Gageik.mp4", "persons": "Gijs Hillenius, Thomas Gageik", "pretalx_id": "QHNCVZ", "title": "FOSS4G 2022 | Open source at the European Commission", "description": "This talk by Thomas Gageik, Director Digital Business Solutions (DIGIT.B) at the European Commission will get you up to speed on the most recent actions to encourage free and open source in and around the Commission. This is an introduction to the session organised by the EC, and we will show you what has changed since the adoption of the reinvigorated open source strategy in October 2020.\nOur topics include: what have we done to make it easier for the Commission to share software as open source, and how can we contribute to existing free/open source software tools. We will show you how the Commission is helping to strengthen the security of open source software, and how we are networking with other organisations to help open source to progress in public services across the EU.\n\nThe talk will also introduce you to the open source programme office. The EC OSPO, created in 2020, is here to help Commission projects with free/open source.\\n\\nGijs Hillenius\\nThomas Gageik\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/QHNCVZ/\\n\\n#foss4g2022\\n#generaltrack\\n#AEuropeanapproachtogeospatialopensource"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Auditorium/02 - Hannes Reute.mp4", "persons": "Hannes I. Reuter", "pretalx_id": "QDYYBB", "title": "FOSS4G 2022 | Usage and contribution of FOSS at GISCO", "description": "GISCO, the \u2018Geographical Information System of the COmmission\u2019, is a permanent service of Eurostat that fulfils the requirements of both Eurostat and the European Commission for geographic information and related services at European Union (EU), Member State and regional levels. These services are also provided to European citizens at large. GISCO\u2019s goal is to promote and stimulate the use of geographic information within the European Statistical System and the European Commission.\nOne of the main lessons learned over the last years is not only to provide \u2018conventional\u2019 GIS datasets, but add a variety of distribution channels like Application Programming Interfaces (APIs), Linked Open Data (LOD) plus Human Friendly Interfaces on top. API\u2019s for example simplify software development and innovation by enabling applications to exchange data and functionality easily and securely into a digital ecosystem. Additionally, the implementation of API\u2019s contributes to: a) an open government approach to modernise public administration b) a modernised use of the European Interoperability framework or c) the application of the Once Only Principle. The talk will describe some of GISCOs API\u2019s supporting European Institutions in their daily work as well as the public. For that, we are using FOSS tools in production environments. Besides, GISCO team members develop or contribute to a wide variety of software tools (e.g. eurostat-map.js, gridviz, IMAGE tool, diff and generalization tool) which will be presented for further use by the FOSS4G community.\\n\\nHannes I. Reuter\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/QDYYBB/\\n\\n#foss4g2022\\n#generaltrack\\n#AEuropeanapproachtogeospatialopensource"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Auditorium/03 - Marco Minghini.mp4", "persons": "Marco Minghini", "pretalx_id": "HSU3RK", "title": "FOSS4G 2022 | A vision for INSPIRE: from a traditional SDI to a self-sustainable data ecosystem", "description": "Published in 2007, the INSPIRE Directive has established a pan-European Spatial Data Infrastructure (SDI) to support European Union (EU) policies related to or having an impact on the environment. The Directive requires Member States public organisations to make geospatial datasets in scope (i.e. belonging to 34 cross-sector categories known as data themes) interoperable, discoverable and accessible through view and download services. Fifteen years after the entry into force of the Directive, we assess the state of play, reflect on the lessons learned and, leveraging on these while also considering the current policy and technological context, elaborate a vision for the future evolution.\nThrough its Geoportal, which regularly harvests the EU Member States national catalogues, the INSPIRE infrastructure currently provides access to approximately 90 thousand datasets. The amount and update of those datasets is steadily increasing as is the fraction of datasets whose metadata, data models and view/download services are compliant to the legal requirements of the Directive. The INSPIRE infrastructure is currently based on three so-called central components, which in turn are implementations of reusable and mature open source software solutions: the INSPIRE Reference Validator makes use of the ETF testing framework, the INSPIRE Registry is based on the Re3gistry software (included in the OSGeo Live since 2021) and the INSPIRE Geoportal is currently being migrated to GeoNetwork  . INSPIRE has also played a key standardisation role in Europe by fully promoting and relying on open standards, mainly by ISO and OGC. Finally, an active and engaged community of stakeholders, meeting at the annual INSPIRE Conference and other related ad-hoc events, has highly favoured the policy and technological development.\nDespite many pros, lessons learned from INSPIRE also show some cons. These include e.g. overspecification in legislation (often leading to extensions to existing standards) which still limit implementation, and the lack of a common approach to data licensing. In addition, the current technological landscape is very different from the one from the INSPIRE dawn. New data sources (Internet of Things, citizen-generated and Earth Observation data, research data and data owned by businesses), new agile standards (e.g. OGC APIs for data sharing and modern standards for data encoding) and novel architectures (cloud, edge and fog computing) are creating an opportunity that INSPIRE shall leverage to remain relevant and fit-for-purpose. In parallel, driven by the recent European Strategy for Data, the current European policy context and related legislative instruments are strongly pushing for an increased, better and fairer use of all available data for the benefit of European economy and society.\nWithin this context, the talk will illustrate our vision to streamline and simplify the technological and organisational structure of INSPIRE towards a data-driven and self-sustainable ecosystem. We will mainly reflect on the key role played by open source software, open standards and open licenses, and on the need to redefine the governance of the infrastructure through the increasing involvement of open source communities, including OSGeo as a strategic partner.\\n\\nMarco Minghini\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/HSU3RK/\\n\\n#foss4g2022\\n#generaltrack\\n#AEuropeanapproachtogeospatialopensource"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Auditorium/04 -Kyoung-Soo Eom.mp4", "persons": "Kyoung-Soo Eom", "pretalx_id": "CZHZKH", "title": "FOSS4G 2022 | UN Open GIS Initiative", "description": "UN Open GIS Initiative, established in March 2016, is to identify and develop an Open Source GIS bundle that meets the requirements of UN operations, taking full advantage of the expertise of contributing partners (Member States, international organizations, academia, NGO\u2019s and private sector).\n\nGeospatial Information Systems (GIS) has been played a substantial role in providing timely and effective geospatial information products (maps and dynamic tools) to ensure the United Nations operations are equipped with suitable information to support the UN mandates through informed planning and decision-making processes. The UN has been using proprietary GIS software for the past two decades. The rapid growth and development of open-source GIS solutions present the technological potential, operational flexibility and financial benefits as well as easy to access for UN operational partners and host nations.\n\nIn view of complexity and variety of UN operational demands and the outcome and lessons learned from the UN Open GIS Initiative, it is identified to develop a hybrid GIS platform that the users should be able to access the most suitable solutions to fulfil the operational demands in flexible and cost effective manner whether the solutions are open source or proprietary, combination of both and/or complement each other. The hybrid model lets coexist two software stacks, one open source based, the other proprietary, which renders different services to end users and applications.\n\nSignificant progress has been made so far in developing open source-based GIS solutions such as Hybrid Geospatial Database, GeoPortal, Analytical models/ applications, Data collection and Optimized/innovated applications for harmonizing open source technology with proprietary as well as open GIS trainings to the UN staff for smooth transition from proprietary to hybrid GIS platform technology.\n\nIn particular, it will provide an overall update on what has been achieved by the UN Open GIS Initiative during the past year, such as hybrid GIS architecture, mobile GIS solution, story map project, field application of OpenDroneMap and UN Vector Tile toolkit as well as the capacity building activities.\\n\\nKyoung-Soo Eom\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/CZHZKH/\\n\\n#foss4g2022\\n#generaltrack\\n#TransitiontoFOSS4G"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Auditorium/05 - Jordi Escriu.mp4", "persons": "Jordi Escriu, Jeroen Ticheler", "pretalx_id": "MBDB3W", "title": "FOSS4G 2022 | Revamped INSPIRE Geoportal - Cooking the next generation of spatial data catalogues", "description": "In force since 2007, the INSPIRE Directive has established a European Spatial Data Infrastructure to support European Union (EU) policies relevant to the environment. The INSPIRE Geoportal (https://inspire-geoportal.ec.europa.eu) constitutes its main component, being the central point of access to all datasets published by EU Member States falling under the scope of the Directive. Using the INSPIRE Geoportal, users can search for, access, visualize and download datasets published by more than 7000 data providers from across Europe.\nIn line with the open source strategy of the European Commission and the ambition towards a sustainable evolution of the INSPIRE infrastructure based on open source components, since 2021 the INSPIRE Geoportal is has been revamped by using cutting-edge, open source applications and open standards, while redesigning the way in which information and services are offered to users.\nThe process comprises deep changes in the Geoportal backend, totally renovating the underlying catalogue application: management interface, powerful harvesting engine, set of metadata, data and service linking tests, search engine, automatic metadata translation capabilities, containerization and deployment in a cloud environment. In addition, a new frontend (user interface) is integrated with the mentioned backend using APIs, making both layers more independent in terms of technological stack and update cycles.\nThe application selected for achieving these goals is GeoNetwork opensource, currently constituting the catalogue choice of around 80% of Member States national geospatial data portals in the EU. Since its inception in 2001, it has been developed with a strong focus on international standards and many new features have been added over the years.\nDuring the last year, the GeoCat staff and the INSPIRE team at the European Commission\u2019s Joint Research Centre have closely collaborated in the development of a new powerful and versatile system for delivering the revamped INSPIRE Geoportal, contributing the improvements \u2013 to the maximum possible extent \u2013 to the core of GeoNetwork to maximize their exploitation by the geospatial community.\nMore in detail, the system encompasses a high-performance harvesting system based on a microservices, including link validation and reporting functionality. All these pieces have been developed as separate components, which can be scaled independently from other components within a GeoNetwork-based infrastructure. Performance and compliance to the INSPIRE Technical Guidelines formed part of the key requirements of the work. As a result, GeoNetwork capabilities for supporting the INSPIRE Directive will be substantially improved and completed in the toolkit. This, in turn, will also improve the transparency and collaboration between the national authorities and the European level.\nAt the end of this transitional phase for the INSPIRE Geoportal, foreseen by mid-2022, the project will deliver tangible benefits. Firstly, by providing EU Member States with an up-to-date and transparent toolkit for managing their geospatial metadata, data and services in compliance to the INSPIRE Directive monitoring and reporting obligations. Secondly, by making a direct valuable contribution to the core of GeoNetwork and to the whole open source geospatial community.\\n\\nJordi Escriu\\nJeroen Ticheler\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/MBDB3W/\\n\\n#foss4g2022\\n#generaltrack\\n#AEuropeanapproachtogeospatialopensource"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Auditorium/06 - Celine Vilain.mp4", "persons": "C\u00e9line Vilain", "pretalx_id": "ZYC7RM", "title": "FOSS4G 2022 | FAIR-ization of INSPIRE datasets", "description": "Belgian federal authorities are working on PSI/INSPIRE conversion tool. We have produced an enhanced DCAT AP 2.0 profile. We have proposed to use ATOMFeed to instantiate dcat:Distribution classes because of their semantic completeness. We have tried to keep most of the INSPIRE metadata elements in order to keep the work that has been done for some years..\n\nNow we are working on its implementation through GeoNetwork 4.x microservices that would provide a consistent DCAT AP RDF/XML with many languages. By doing this we consider that our datasets will be more accessible through many platforms and open data portals and will become real FAIR data.\n\nThis work is the result of the strong collaboration between federal belgian authorities (e.g. Cadaster, National Mapping Agency, Office of federal statistics, ...).Moreover we are involving regional authorities in order to reach a certain harmonization. Now we would like to share these developments with the opensource community. You can find more information here https://github.com/belgif/inspire-dcat.\\n\\nC\u00e9line Vilain\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ZYC7RM/\\n\\n#foss4g2022\\n#generaltrack\\n#AEuropeanapproachtogeospatialopensource"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Auditorium/07 - Johannes Lauer.mp4", "persons": "Johannes Lauer", "pretalx_id": "VQ7NF9", "title": "FOSS4G 2022 | MobiDataLab - Labs for prototyping future mobility data sharing solutions", "description": "MobiDataLab is the EU-funded lab for prototyping new mobility data sharing solutions.\nOur aim is to foster data sharing in the transport sector, providing mobility organising authorities with recommendations on how to improve the value of their data, contributing to the development of open tools in the cloud, and organising hackathons aiming to find innovative solutions to concrete mobility problems.\n\nThe project consists of following main pillars:\n\n 1. Open Knowledge Base\n    ... a portal about open mobility data which provides informations about about\n    practices and solutions related to legal and regulatory (s.a. licenses), governance,\n    data privacy, technical standards (for data interoperability and accessibility),\n    and challenges for actors in the mobility domain.\n\n 2. Transport Cloud\n    ... a cloud-based prototype platform for sharing mobility data. It facilitate users by\n    several tool components to find, use and interact with mobility data in an open, interoperable\n    and privacy-preserving way.\n\n 3. Living and Virtual Labs\n    ... are the environments for the project to interact with the reference group (mobility data providers and users),\n    b2b and endusers (s.a. data innovators, solution providers and further stakeholders in the mobility domain) to get\n    feedback on challenges and missing pieces in the mobility data and services assets. A set of mobility use-cases,\n    set-up by the project stakeholders and the reference group will help to trigger practical execution, innovation,\n    and further ideas within the labs.\n\n 4. Socio-economic impact\n    ... identifies the the current best practices in data sharing, analyses the market potential and elaborates new\n    data sharing services and business models on that.\n\nWith the heterogeneous experts project group, we are facing the challenge of mobility data sharing from different perspectives - research, privacy, data, mobility solutions, open data, services, ... .\nA close work with a large reference group (which is representing several mobility data providers - e.g. from the public and private sector and actors, s.a. start-up communities) and the implementation of virtual and living labs allows to get early real world feedback and help to identify challenges in interoperability and missing standards as well as findable and available data, conflicting licenses, accessibility and usability of data and services.\n\nSince the project started in February 2022, we will present the mid-term achievments and\nprovide an outlook on the second part of the project.\n\nFurther information on the project is available via https://mobidatalab.eu\n\nMobiDataLab is funded by the EU under the H2020 Research and Innovation Programme (grant agreement No 101006879).\\n\\nJohannes Lauer\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/VQ7NF9/\\n\\n#foss4g2022\\n#generaltrack\\n#AEuropeanapproachtogeospatialopensource"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Auditorium/08 - Luca Battistella.mp4", "persons": "Luca Battistella", "pretalx_id": "ZH98CF", "title": "FOSS4G 2022 | Identifying new conservation areas: a web multi-criteria approach using Earth Observation and other spatial information", "description": "Today Protected Areas only partly cover important sites for biodiversity and are not yet fully ecologically representative and effectively or equitably managed. Improvement of the existing networks and further expansion of conservation areas will therefore require well-defined baselines that are comparable across countries for actions prioritisation.\nIn recent years the availability of new earth observation imagery and advances in analysis and processing have significantly improved our capabilities in terms of mapping and monitoring\u202fbiodiversity variables\u202fand ecosystem services. This event\u202fwill\u202fintroduce\u202fthe Biodiversity Analyst, a web GIS tool, developed by the European Commission - Joint Research Centre, for\u202fidentifying\u202fareas of potentially high conservation value based on the available datasets such as species distribution, ecosystems services and natural state.\nThe aim of the Biodiversity Analyst is to provide decision-makers with means to visualise and interact with the above datasets which are considered key for biodiversity conservation while allowing them at the same time to test different weighting schemes in terms of prioritisation to identify so-called \"biodiversity hot-spots\".\\n\\nLuca Battistella\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ZH98CF/\\n\\n#foss4g2022\\n#generaltrack\\n#AEuropeanapproachtogeospatialopensource"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Auditorium/09 - Edzer Pebesma.mp4", "persons": "Edzer Pebesma, Matthias Mohr", "pretalx_id": "ELXNEB", "title": "FOSS4G 2022 | openEO: Open Science for Earth Observation Research", "description": "The open standards, open source geospatial and open science communities still have a very limited answer to the question how researchers active in applied domains such as agriculture, ecology, hydrology, oceanography or land use planning can benefit from the large amounts of open Earth Observation (EO) data currently available. Solutions are very much tied to platforms operated and controlled by big tech (Earth Engine, Planetary Computer), particular programming languages, software stacks and/or file formats (xarray, Pangeo, ODC, GeoPySpark/GeoTrellis). The openEO initiative provides an API and a set of processes that separate the \u201cwhat\u201d from the \u201chow\u201d: users specify what they want to compute, and back-end processing engines decide how to do this. The openEO API is OpenAPI compliant, and has client interfaces for Python, R, and JavaScript, and in addition graphical user interfaces running in the browser or in QGIS. The underlying data model is that of a data cube view: image collections or vector data may be stored as they are, but are analysed as if they were laid out as a raster or vector data cube, e.g. for raster with dimensions x, y, band and time, or for vector with dimensions geometry, band and time. Because openEO assumes that imagery is described as STAC collections and the implementation is composed of open source components, it is relatively easy to set it up and compute on infrastructure where imagery is available through a STAC interface. Having a single interface to carry out computations on back-ends with different architecture makes it possible to compare results across implementations, to verify that EO processing is reproducible. So far, over 100 processes have been defined, and user-defined functions written in Python or R extend this ad infinitum. openEO was initially developed during a H2020 project (2017-2020). It is currently continued with ESA funding that has resulted in the \u201copenEO Platform\u201d, an implementation run by VITO and EODC where the general public can use the openEO interface for large scale computations. Several upcoming Horizon Europe projects will further support continued development of the API and openEO software ecosystem of clients and back-ends. Since the initiative is designed to be an open science, all users and developers are invited to engage. We will present the current state of the openEO ecosystem and give an outlook to forthcoming developments.\\n\\nEdzer Pebesma\\nMatthias Mohr\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ELXNEB/\\n\\n#foss4g2022\\n#generaltrack\\n#AEuropeanapproachtogeospatialopensource"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Auditorium/10 - Fabian Schindler, Anca Anghelea.mp4", "persons": "Anca Anghelea, Stephan Mei\u00dfl, Fabian Schindler-Strauss", "pretalx_id": "JDGNJD", "title": "FOSS4G 2022 | EO Open Science Catalogue initiative by ESA", "description": "To enable sustainable and impactful Open Science in the long-term, ESA Earth Observation looks to design and implement a comprehensive Open Science framework, which includes a dedicated set of integrated tools and common practices for effective scientific data management, seeking to support Open Innovation, advance Science and increase community participation. The framework will build on and advance existing Open Science elements and will develop new capabilities to achieve the ambitions and vision set forth in the 2025 Agenda, supporting the European Green Deal. The four main pillars of the initiative are: i) EO Digital Platforms, interoperability and standardisation, ii) Accessible and Reproducible EO Science, iii) Inclusive and collaborative research and iv) Strategic Partnerships. Contributing to the second pillar, ESA is developing an EO Open Science Catalogue tool to enhance the discoverability and use of products, data and knowledge resulting from Scientific Earth Observation exploitation studies. Adhering by design to the \"FAIR\" (findable, accessible, interoperable, reproducible/reusable) principles, the Open Science Catalogue aims to support better knowledge discovery and innovation, and facilitate data and knowledge integration and reuse by the scientific community.\n\nThe Open Science Catalogue is based upon the EO Exploitation Platform Common Architecture (https://eo4society.esa.int/2022/01/26/interoperability-sharing-your-application-where-the-data-sit/) (EOEPCA) and shares its basic Open Source components, but extends it with additional functionalities:\n\n - The Static Catalogue is a hosted STAC Catalogue, comprised of static Catalogue, Collection, and Items that represent the Themes, Variables, Projects, and Products\n - The Open Science Catalogue Frontend is a Vue.js based client application, that allows the efficient browsing of the Open Science Catalogue\n - The Backend API allows users to make submissions to create, update, and delete Themes, Variables, Projects, and Products. These submissions are then handled as GitHub Pull Requests, where they can be further reviewed, discussed, and finally accepted or denied.\n\nThe Open Science Catalog makes use of various geospatial Open Source technologies such as pycsw, PySTAC, and OpenLayers.\n\nIn this presentation we will review the EO Open Science Catalogue architecture, technology stack, and how this tool can be used to discover and publish Earth System Science products from ESA activities. We'll also look at future evolutions of the product and how it contributes to the overall ESA EO Open Science Framework.\\n\\nAnca Anghelea\\nStephan Mei\u00dfl\\nFabian Schindler-Strauss\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/JDGNJD/\\n\\n#foss4g2022\\n#generaltrack\\n#AEuropeanapproachtogeospatialopensource"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Auditorium/11 - Alessandro Frigeri.mp4", "persons": "Alessandro Frigeri", "pretalx_id": "9RXQFF", "title": "FOSS4G 2022 | FOSS4G in the Solar System", "description": "It is well-known that Free Open Source Software is part of Space and Planetary Exploration, and the latest generation of rovers and drones on Mars embed FOSS components and frameworks.  But what about Free Open Source for Geospatial software and data access and availability?  We will travel the timeline of planetary cartography, from the first steps of remote and direct observation of the bodies of our Solar System to the era when Geographic Information Systems spread in Planetary Science and  FOSS4G starts to play an essential role in studies and missions to environments beyond planet Earth.\\n\\nAlessandro Frigeri\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/9RXQFF/\\n\\n#foss4g2022\\n#generaltrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Auditorium/12 - James Varndell.mp4", "persons": "Edward Comyn-Platt, James Varndell", "pretalx_id": "BZZ78F", "title": "FOSS4G 2022 | The Copernicus Data Store (CopDS) - a reimagining of the Copernicus Climate Change Service (C3S) Climate Data Store (CDS)", "description": "The Copernicus Climate Change Service (C3S) Climate Data Store (CDS) is a single point of access to a wide range of free, quality-assured climate data, along with a suite of tools for performing cloud-based analysis and visualisation of very large datasets. Launched in 2018, the CDS provides over 100 datasets and 30 interactive applications for a global, interdisciplinary and intersectoral audience of over 100,000 users.\n\nThe Copernicus Data Store (CopDS) project aims to reimagine the CDS, making use of modern technologies and knowledge gained during the development of the existing system to expand and streamline its functionalities and improve its performance and scalability. We present a high-level blueprint of the in-development CopDS, with an emphasis on how we plan to overcome the limitations of the original CDS. We explore our plans for the development of a new suite of open-source Python tools for performing retrieval, analysis and visualisation of climate and atmospheric data under the CopDS project, along with our plans for offering free cloud-based infrastructure for processing and visualising very large datasets through an easy-to-use Python web interface. We also discuss the development of tools for transforming simple Python code into high-quality web applications for exploring CopDS climate and atmospheric datasets, providing tools for interactive mapping, graphical user interfaces and a results cache for responsiveness.\\n\\nEdward Comyn-Platt\\nJames Varndell\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/BZZ78F/\\n\\n#foss4g2022\\n#generaltrack\\n#AEuropeanapproachtogeospatialopensource"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Auditorium/13 - Milana Vuckovic.mp4", "persons": "Milana Vuckovic", "pretalx_id": "ELA8HN", "title": "FOSS4G 2022 | Towards open and accessible weather forecast data", "description": "The European Centre for Medium-Range Weather Forecasts (ECMWF) is an independent intergovernmental organisation which is producing and disseminating numerical weather and environmental predictions to its users in national meteorological services as well as commercial customers. As of recently, ECMWF started the move towards serving data to users beyond operational forecasters in Member states and commercial customers for a charge, by adopting an open data policy which will be implemented in phases from 2020 to 2025. The first phase included opening hundreds of web forecast charts (https://apps.ecmwf.int/webapps/opencharts) and making archived data available under a Creative Commons (CC BY 4.0) open licence in 2020. The next step was in January 2022 when the production of open subset of real time medium range forecast (https://www.ecmwf.int/en/forecasts/datasets/open-data) began.\n\nThis phased move towards free and open data aims to support creativity and innovation in the field of scientific research as well as weather applications. It also represents a step towards more reproducible open science. However this can not be achieved by only opening the real time data. The users need to be able to find and easily use the data and integrate it into their own research work or application workflows. Reliable access to the data is achieved by making it available both through ECMWF https service and via the Microsoft Azure cloud, where the archived data is kept as well.\n\nIn order for the data to be more FAIR (Findable, Accessible, Interoperable and Reusable), additional development work is being done. This work includes the design of an API (https://github.com/ecmwf/ecmwf-opendata) to easily download the geospatial data, and the development of open source Python libraries to process (https://github.com/ecmwf/ecmwf-data) and visualise (https://github.com/ecmwf/magpye) it. These open source libraries make use of open geospatial software, such as proj to deal with different projections. To present these new tools and help users understand how to retrieve and process ECMWF data, a set of Jupyter notebooks (https://github.com/ecmwf/notebook-examples/tree/master/opencharts) was created, each of them reproducing one open weather forecast chart from the downloading the data to the visualisation.\n\nThis talk will give a short overview of which data is available in the open data set, and will then focus on the software and Jupyter notebooks development.\\n\\nMilana Vuckovic\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ELA8HN/\\n\\n#foss4g2022\\n#generaltrack\\n#AEuropeanapproachtogeospatialopensource"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Auditorium/14 - Dimitar Tasev.mp4", "persons": "Dimitar Tasev, Paolo Battino", "pretalx_id": "GZACL9", "title": "FOSS4G 2022 | 10 years of open-source software in emergency management: the case of the European Flood Awareness Service", "description": "The European Flood Awareness System and the Global Flood Awareness System (EFAS and GloFAS), are the two Early Warning Service for floods part of the Copernicus Emergency Management Service (CEMS), operated by the EU Joint Research Centre (JRC). EFAS and GloFAS aims to complement national and regional service by providing medium-range flood forecasts and hydrological outlooks for large, transboundary rivers. Data and products are accessible to eligible users through the Climate Data Store and dedicated web interfaces. ECMWF, having the role of the computational centre within CEMS, is responsible for running the forecasts and the post-processing, on top of co-developing and hosting the EFAS and GloFAS information systems.\n\nThese two information systems consist on back-end/front-end web services based on OGC standards and open-source software. As it is often the case, a web-based mapviewer allows to display different layers, produced by a WMS back-end. These layers are the graphical representation of the output of the hydrological models and meteorological observations, like flood probability, soil moisture, return period, observed precipitation etc. For most layers a new forecast is produced every 12 hours for EFAS and every 24 hours for GloFAS.\n\nUnlike many similar services, however, the aim of EFAS and GloFAS is not only to offer the latest forecasts or the latest observations but also to browse through data from previous days, so that older forecasts can be compared with actual observed events. This inherently means supporting the time dimension within the WMS standard, and managing large quantity of data that accumulates every day. In the case of EFAS, for example, an additional 1.5 Gb of data is produced twice a day.\n\nIt also means handling the inevitable changes in data formats and structures that arise as the service grows and new features are added, without breaking backward compatibility. New layers are added, old layers are removed, changes in the geographical domain or the projection for a certain layer must be supported from a certain date onward, etc. Not to mention increasing the number of forecast cycles from one per day to two or more.\n\nTo make matters worse, data access must be restricted on both front-end and back-end based on a matrix of user privileges, requested product and requested date. For example some layers are offered to all users with no time restrictions, while others are restricted to some users for the latest 30 days, and freely accessible to all users for dates older than 30 days ago.\n\nIn this talk we describe the challenges of developing and operating an authentication-aware web service heavily based on large geospatial datasets with a strong diachronic component.\\n\\nDimitar Tasev\\nPaolo Battino\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/GZACL9/\\n\\n#foss4g2022\\n#generaltrack\\n#AEuropeanapproachtogeospatialopensource"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Verde/1 markus neteler.mp4", "persons": "Anna Petrasova, Vaclav Petras, Veronica Andreo, Markus Neteler", "pretalx_id": "RU7PYN", "title": "FOSS4G 2022 | State of GRASS GIS", "description": "The new GRASS GIS version 8.2 is a special edition including all new features developed during Google Summer of Code 2021. One of the enhancements is the parallelization of several raster modules by means of OpenMP, an implementation of multithreading to speed up massive data processing. Another exciting new feature is much improved, the Jupyter notebook support. Here, a new python package (grass.jupyter) is available which allows to interactively visualise maps and time series given the integration with folium (https://github.com/python-visualization/folium).\nThe graphical user interface in version 8.0 introduced faster and more streamlined startup without a need for a welcome screen. For even more convenience, version 8.2 adds an experimental single window layout with familiar look-and-feel.\nRelated to raster data, a new metadata class called semantic labels can now be added to raster maps. Examples of semantic labels are aerial or satellite spectral bands, dataset names in remote sensing products (ndvi, evi, lst, etc), or any custom names.\nAt community level, we have developed a student grant program and, thanks to the move to GitHub, we have welcomed numerous new contributors.\\n\\nAnna Petrasova\\nVaclav Petras\\nVeronica Andreo\\nMarkus Neteler\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/RU7PYN/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Verde/2 linda kladivova.mp4", "persons": "Linda Kladivova", "pretalx_id": "TREFCV", "title": "FOSS4G 2022 | Redesigning GRASS GIS graphical user interface in a community-driven way", "description": "Aside from many new features, GRASS GIS 8 brings an improved graphical user interface focused on better user experience. Based on a broad community discussion involving several surveys and test sessions, we developed a new startup mechanism helping the users understand the data hierarchy and guiding them in their first steps. In addition, our surveys helped to identify a number of opportunities for improvements, including a need for a Single-Window mode that could fully replace the traditional Multi-Window GUI that has been in GRASS since the first GUI version in 1999. Therefore, during the GSoC 2021 project, the first steps towards the Single-Window GUI were established, eventually leading to the friedlier GRASS GUI in version 8.2. Come and listen to the presentation describing how a community-driven approach helped to steer the development direction of the GRASS graphical user interface to satisfy both GIS beginners and advanced users. You can also look forward to the brand-new screenshots of the GUI in version 8.2 that might eventually inspire you to try GRASS on your own.\\n\\nLinda Kladivova\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/TREFCV/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Verde/3 vraclav petras .mp4", "persons": "Vaclav Petras", "pretalx_id": "DQPT8L", "title": "FOSS4G 2022 | Take-Home Messages from Adding Code Quality Measures to GRASS GIS", "description": "The message is not surprising: You should quality check your code, too, even if you are writing a small script for your own needs! However, maybe you wondered if all the warning messages are relevant to you or got discouraged after getting a flood of messages from tools like Pylint. Perhaps you were even annoyed by it. This talk will help you get motivated and get started and how to automate that with continuous integration tools such as GitHub Actions.\n\nIn this talk, I will share my experience with adding various code and non-code checks to GRASS GIS which is primarily written in C, C++, and Python. Checking a mixed code base with over 30 years of development is not easy, but not impossible. The talk will cover code quality measures in GRASS GIS such as tests, Pylint, Black, GCC, CodeQL, and Super-Linter and how this compares to my experience with new and small organizational repositories.\\n\\nVaclav Petras\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/DQPT8L/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Verde/4 julien osman.mp4", "persons": "JulienOsman", "pretalx_id": "DWHZKD", "title": "FOSS4G 2022 | Orfeo ToolBox: open source processing of remote sensing images", "description": "Orfeo Toolbox (OTB) is a free and open-source remote sensing software. It is available on multiple platforms, Linux, Windows and MacOs, and was developed primarily by CNES (French Space Agency) and CS Group in the frame of the development of the ORFEO program (French and Italian support program for Pleiades and Cosmo-Skymed).\n\nOTB can process large images thanks to its built-in streaming and multithreading mechanisms. Its data processing schema is primarily based on ITK pipelines, and uses GDAL dependency to read and write raster and vector data. Many formats are supported by the library (at least those supported by GDAL) as CosmoSkyMed, Formosat, Ikonos, Pleiades, QuickBird,  Radarsat 2, Sentinel 1, Spot5, Spot 6/7, TerraSarX or WorldView 2.\n\nOTB provides a lot of applications to process optical and SAR products: ortho-rectification, calibration, pansharpening, classification, large-scale segmentation and more. The library is written in C++ but all the applications can also be accessed from Python, command line launcher, QGIS and Monterverdi, a powerful satellite image visualization tool bundled in the OTB packages capable of manipulating large images efficiently.\n\nThe library also facilitates external contributions thanks to the remote module functionality: users can add new applications without modifying the core of the library. If this new remote module is relevant, it could be added as an official remote module, like DiapOTB (differential SAR interferometric processing chain) and OTBTensorflow (multi-purpose deep learning framework, targeting remote sensing images processing).\n\nMoreover, several operational image processing chains are based on OTB: their algorithms use the framework of OTB Applications while the orchestration is written in python. Some of the chains are also open source: Let It Snow (Snow cover detection), iota2 (Large Scale Land Surface Classification), WASP (Multitemp images fusion), S1Tiling (Sentinel-1 calibration and MAJA (Maccs-Atcor Joint Algorithm). The Orfeo Toolbox is also a part of the Sentinel 2 ground segment, being integrated in the S2 Instrument Processing Facility (IPF) module where it is used for radiometric corrections and resampling.\n\nIn the latest releases (from 7.x to 8.0), several features have been added as new SAR sensor models and new applications, and the OSSIM dependency - used for geometric sensor modelling and metadata parsing \u2013 has been removed in favor of functionalities available in GDAL. The aim of the presentation is to present the major features of OTB, the latest updates, the future features and architecture of the library and how OTB is used at CNES and CS Group to process data from scientific and developer points of view.\\n\\nJulienOsman\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/DWHZKD/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Verde/5 julien osman.mp4", "persons": "JulienOsman, Julie Brossard", "pretalx_id": "DZZCTY", "title": "FOSS4G 2022 | OTB integration in operational processing chains", "description": "The Orfeo ToolBox is used as development framework for satellite image processing over large dataset in several operational projects. Indeed, its image processing functionalities (multithreading, streaming, ram configuration) allow to process big images quite fast. The operational processing chains use OTB from the Python API and C++ API.\n\nAmong the optical chain processing using OTB, we can list: MAJA, WASP, BIOPHY and IOTA2. MAJA (Maccs-Atcor Joint Algorithm) is an atmospheric correction and cloud screening software, based on multi temporal and multi-spectral processing. This chain uses L1C products to generate high quality L2A surface reflectance time series for Landsat8, Venus, and Sentinel 2 missions, it is mainly used by THEIA distribution center. The core algorithms of Maja are based on the Orfeo Toolbox. To process a product, the chain uses aerosol contents, cloud and shadow detection and various atmospheric effects to estimate accurate surface reflectance values. The main problem of the L2A products is the presence of clouds in time series which is why WASP was created. Indeed WASP (Weighted Average Synthesis Processor) delivers L3 products which provide monthly syntheses of cloud-free reflectance for Sentinel2 and Venus L2A products distributed by THEIA. This processor mainly includes a directional correction to normalize data and a weighted average of surface reflectance. Two other operational chains which uses OTB are BIOPHY - the goal of this processing chain is to create L2A products containing biophysical variables (FAPAR, FCOVER, LAI) related to the presence of vegetation in the image over a year \u2013 and IOTA2 - a soil occupation processor over a year of Sentinel1 and Sentinel2 data, the algorithms use the classification toolbox provided by OTB to process large areas, to determine the areas covered by buildings.\n\nOrfeoToolBox is also used for radar processing chain, like diapOTB or S1Tiling. S1TIling is a generic processing chain for Sentinel-1 time series developed with open-source software. Its main goal is to produce time series of Analysis ready data S1 images for large areas. The algorithms are using the SAR processing toolbox from OTB to take profit of its in-memory pipelining capabilities. DiapOTB is a differential SAR interferometry processing. It uses two SAR images of the same portion of the Earth\u2019s surface taken at different time as input and aims to analyze potential events (earthquake, destruction \u2026) by highlighting differences between SAR images.\n\nTo conclude, OTB is the central framework for a large scale of operational chains in remote sensing. Its genericity permits to cover a lot of use cases in one single tool. Note that it is also distributed in other projects like WorldCereal, SNAP, AI4GEO as toolbox or RUS as training and formation aim.\\n\\nJulienOsman\\nJulie Brossard\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/DZZCTY/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Verde/6 remi cresson .mp4", "persons": "remi.cresson@inrae.fr", "pretalx_id": "RK9QUW", "title": "FOSS4G 2022 | Status of OTBTF, the Orfeo ToolBox extension for deep learning", "description": "OTBTF is a remote module of the Orfeo ToolBox enabling deep learning with remote sensing images.\nCreated in 2018, it aimed to provide a generic framework for various kind of raster-oriented deep-learning based applications.\nOriginally, OTBTF included user-oriented applications for patches sampling, model training, and inference on real world remote sensing images, and a few python scripts to help users with no coding skills to generate some ready-to-use models.\nA few years later, it has been used for a wide range of applications, like landcover mapping at country scale, super-resolution, optical image cloud removal, etc.\nThis talk will present a few selected IA based applications powered by OTBTF in the framework of research projects, public policies support, or teaching.\nWe will present the recent features added in OTBTF and we are very happy to introduce what is next!\nMore details on the project on the github repository: github.com/remicres/otbtf\\n\\nremi.cresson@inrae.fr\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/RK9QUW/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Verde/7 piero toffanin.mp4", "persons": "Piero Toffanin", "pretalx_id": "LJWMZW", "title": "FOSS4G 2022 | Aerial Images to Maps: Technological Advancements with OpenDroneMap", "description": "OpenDroneMap is an ecosystem of free and open source software to collect, process, analyze and display aerial data. In this talk we will present an exciting overview of what's new in the ecosystem, where the project is headed and how you can benefit from using it. In particular, will first provide a brief overview of the ecosystem, what the tools are and how you can start making maps in minutes. A short introduction to the \"magic\" of the processing pipeline will be presented. We will then touch on state-of-the-art advancements in photogrammetry technology within ODM, how we benefit from a global team of researchers and how that has allowed us to match (and often times exceed) proprietary software results. After a presentation of the technological advancements, we will discuss the importance of people, or how prioritizing people over code and investing into the community has affected both participation and adoption.\\n\\nPiero Toffanin\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/LJWMZW/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Verde/8 luca di leo .mp4", "persons": "Piero Toffanin, Luca Di Leo", "pretalx_id": "RAAYEE", "title": "FOSS4G 2022 | Effortless Aerial Data Management and Sharing: The DroneDB Ecosystem", "description": "DroneDB is free and open source software for geospatial data storage. It provides a novel approach to store point clouds, textured models, aerial images, orthophotos and elevation models via a dynamic filesystem index. In this talk we will present DroneDB's storage approach and how you can start using it right away. We will discuss the project's architecture and roadmap. We will also perform a showcase of the project and demonstrate its most effective use cases.\n\nWe will cover how DroneDB's dynamic index can be published on the web using Registry, a cross-platform open source application which provides both a friendly user interface and a RESTful API. This enables users and GIS developers alike to access and manage the underlying data. We will showcase the ddb client, a command-line interface that enables power users to manage the index and can be used to sync, share and download remote datasets in a manner inspired by git workflows.\n\nWe will show how WebODM and Registry can integrate together to create a powerful and versatile workflow for 3D reconstruction using a full opensource stack.\\n\\nPiero Toffanin\\nLuca Di Leo\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/RAAYEE/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Verde/9 dk benjamin.mp4", "persons": "Cristiano Giovando, DK Benjamin, Ekaterina Grudinskaya", "pretalx_id": "PFADT9", "title": "FOSS4G 2022 | OpenAerialMap V2 Design and Development", "description": "OpenAerialMap.org (OAM) was built in 2015 to serve as a platform and tools for sharing openly licensed satellite and aerial imagery. For Humanitarian OpenStreetMap Team (HOT) and its partners, open imagery has been critical for disaster response and preparedness mapping projects. Those images have traditionally been difficult to share and access because of the large file sizes and technical skills required to publish them online. Since its inception, OAM provides an easy means of contributing to and accessing a large repository of open imagery, with over 11,000 images added. The OAM browser is designed to easily index, visualize and filter images, while the data itself is stored in Cloud Optimized GeoTIFF (COG) format in the Open Imagery Network, a federated network of highly available imagery buckets from different cloud providers.\n\nOpenAerialMap is the only platform built on open-source software that allows anyone to upload and share aerial imagery of anywhere on Earth. With advances in drone mapping technologies and their proliferation in places where cost and access used to be a limiting factor, there are now massive amounts of images that can be easily made available through OAM. Once uploaded, all imagery becomes instantly accessible via scalable TMS and WMTS services for mapping in OpenStreetMap or for any other use. Since its creation, OAM has been democratizing high resolution Earth observation and promoting the sharing of aerial imagery through open data licenses.\n\nThis year HOT joined with Kontur to take a fresh look at OAM and redesign the platform. Using modern, equitable, human-centered design principles, we evaluated how this tool could be used to better support HOT\u2019s vision that everyone has access to high quality map data and can use that data responsibly to improve their lives and their communities. The development will build on and integrate emerging standards for geospatial data such as the Spatio-Temporal Asset Catalog (STAC) specification. A broad range of users and stakeholders will be involved in the design process, to ensure that OAM v2 will result in a modern and accessible platform. In this talk we will present an update on the development of OAM as informed by the results of that design work and share a preview of its implementation using open-source geospatial software.\n\nThe need for access to open imagery has never been greater, with advances in UAS imaging and processing technologies and their proliferation in places where cost and access are a major factor. This year HOTOSM joined with Kontur to take a fresh look at OAM and redesign the tool with modern, equitable, human-centered design principles to better support HOTOSM\u2019s vision that everyone has access to high quality map data and can use that data responsibly to improve their lives and their communities. In this talk we will present an update on the development of OAM as informed by the results of that design work.\\n\\nCristiano Giovando\\nDK Benjamin\\nEkaterina Grudinskaya\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/PFADT9/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Verde/10 michael smith.mp4", "persons": "Michael Smith", "pretalx_id": "333STX", "title": "FOSS4G 2022 | State of PDAL", "description": "PDAL is Point Data Abstraction Library. It is a C/C++ open source library and applications for translating and processing point cloud data. It is not limited to LiDAR data, although the focus and impetus for many of the tools in the library have their origins in LiDAR.  PDAL allows you to compose operations on point clouds into pipelines of stages. These pipelines can be written in a declarative JSON syntax or constructed using the available API. This talk will focus on the current state of the PDAL Pointcloud processing library and related projects such as COPC and Entwine, for pointcloud processing. Coverage of the most common filters, readers and writers along with some general introduction on the library, coverage of  processing models, language bindings and command line based batch processing. First part will be covering new features for current users. Some discussion of installation method including Docker, binaries from package repositories, and Conda packaging. For more info see https://pdal.io\\n\\nMichael Smith\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/333STX/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Verde/11 saber razmjooei.mp4", "persons": "Saber Razmjooei", "pretalx_id": "8EWA8W", "title": "FOSS4G 2022 | MDAL: mesh data in QGIS", "description": "Mesh Abstraction Library (MDAL) has become an integral part of QGIS over the recent years. MDAL is used in QGIS to parse meteorological and hydrological data. MDAL is an open source library and recently has joined the OSGeo family as a Community project.\nMDAL data can be 1-dimensional, 2D or stacked 3D data. QGIS has been extended to render all those types of data in 2D and 3D map canvases. Once data are loaded in QGIS, users can easily style and explore temporal dimension of the data using QGIS generic tool. Additional plugins have been developed to leverage on mesh data in QGIS to slice and dice the mesh data.\nIn addition to visualising the data, new tools have been developed to directly edit the unstructured mesh data in QGIS. Users can edit geometries and values of the faces and vertices of the mesh data. The built-in validation tools for mesh editing, ensure the resulting mesh is topologically correct during and after mesh editing operations.\\n\\nSaber Razmjooei\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/8EWA8W/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Verde/12 christofer nuth.mp4", "persons": "Christopher Nuth", "pretalx_id": "JSC7EV", "title": "FOSS4G 2022 | Lidar classification, accuracy and change detection using the Norwegian open lidar data archive.", "description": "Three dimensional representations of surface terrain and structure is essential for a range of widespread applications and forms a base dataset that underlies many decision making processes. A few examples include land use planning, areal overview, operational analysis, emergency handling, route and transport planning, geographical and meteorological modelling etc. Recently, the Norwegian Government and the Norwegian Mapping Authority tasked the acquisition of high resolution Light Detection and Ranging (LIDAR) data covering the entire mainland with a minimum of 2 point measurements per meter. In addition, all aerial lidar acquisitions that were tasked by the government since the early 2000s are also publically available for download. In this work using FOSS, we discuss the height accuracy of ground classified datasets (i.e. Digital Terrain Models, Digital Surface Models) with varying original acquisition ground point densities. We create classification pipelines that allow us to calculate derivative products such as a \u201cnormalized\u201d vegetation density and further compare these over time. This work in progress discusses our experience with open source tools on open source data and some of the challenges we encountered scaling our methods for big data.\\n\\nChristopher Nuth\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/JSC7EV/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/1 ETIENNE TRIMAILLE.mp4", "persons": "Etienne Trimaille", "pretalx_id": "9ARVQD", "title": "FOSS4G 2022 | State of OSM in QGIS", "description": "QGIS is one of the most used Open-Source GIS Software. It is possible to display, edit, analyse, process different kind of data such as vector, raster, mesh, point clouds etc.\n\nQGIS has some native functionalities to work with OSM data. Either with raster layer as a basemap, or with vector, QGIS can deal with OSM data. Depending on the amount of data to work with, the need to \"refresh\" the data (from the main OSM database), the extent of the coverage, different plugins or technologies are possible.\n\nThis presentation will try to give an overview how it's possible to use OpenStreetMap data within QGIS according to different situations (Geocoding, TMS/WMS, Overpass-API, Docker, PostgreSQL\u2026).\nThe presentation will show how you can contribute to QuickOSM to add some default \u00ab\u00a0map preset\u00a0\u00bb to QuickOSM core on GitHub. This feature in QuickOSM allows users to have a set of vector layer with styles in QGIS which are ready to be used, with a symbology.\\n\\nEtienne Trimaille\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/9ARVQD/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/2 ILYA ZVEREV.mp4", "persons": "Ilya Zverev", "pretalx_id": "DTJSU3", "title": "FOSS4G 2022 | Surveying amenities for OSM at scale", "description": "OpenStreetMap editing transitions to mobile devices. There are few editing apps, and the best ones are thematical. This year I've published \"Every Door\": an app specifically designed to collect hundreds of shops and amenities. I've made it with the experience of mapping in OSM, making a Telegram bot of a similar purpose, and studying geospatial UX design. I've surveyed half a thousand amenities with the bot, and even more \u2014\u00a0with this new app.\n\nIn this talk we'll briefly touch on the app itself and the OSM tagging model. The main attraction would be map UX design: why you should remove the most interactivity from your maps. These are hard to use even on desktop, and a small screen provides an even bigger challenge. Can we get rid of them altogether? Let's see how working with maps can be made efficient, and how the ideas behind this app can make geodata collection apps better.\\n\\nIlya Zverev\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/DTJSU3/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/3 JOHN HOLDEN.mp4", "persons": "John Holden, Blake Esselstyn", "pretalx_id": "EDYALU", "title": "FOSS4G 2022 | Political Reapportionment: Drawing Boundaries with QGIS", "description": "The process of drawing new political boundaries in representative democracies has generally been done with closed source software. However, a number of open source products are changing the way governments draw their jurisdictions. The QGIS Redistricting Plugin has been used to redistrict communities in the United States, Canada, and Australia, and other open source software such as DistrictR has been used to redistrict the United States in their previous cycle, significantly cutting the cost needed to participate in this activity and allowing individuals to make better contributions. At its core, the software is simple but powerful: it allows users to change attributes in an attribute column using selection tools and displays aggregate statistics for other selected columns. Join John Holden, the plugin's developer, and Blake Esselstyn, a geographic and political consultant, for a plugin demonstration and a discussion of how governments and citizen groups have transitioned to using open source software in this important political area.\\n\\nJohn Holden\\nBlake Esselstyn\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/EDYALU/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/4 VINCENT PICAVET.mp4", "persons": "Vincent Picavet", "pretalx_id": "QEHLM7", "title": "FOSS4G 2022 | Manipulating text with PostgreSQL - lesser known PG jewels", "description": "PostgreSQL is the most advanced opensource RDBMS. As GIS folks, you most probably use it in combination with PostGIS, its Geospatial plugin.\n\nWhen dealing with Geospatial data, we usually focus on geometries. But most of feature attributes are text data. Of course, filtering on these text data with standard SQL capabilities is a day-to-day operation for database users.\n\nBut PostgreSQL provides much more capabilities when it comes down to text data management. In this presentation, we will go through a few of them.\n\nAfter a quick look at standard text functions in PostgreSQL, we will discover the lesser known fuzzy matching modules :\n\n - `pg_trgm` extension allows for string searches using trigraphs to determine a similarity rank between text items\n - `fuzzystrmatch` extension provides fuzzy matching functions like soundex, Levenshtein, metaphone\n\nThen, we will explore *Full Text Search ( FTS )* PostgreSQL capabilities.\n\nLast but not least, we will peek inside PostgreSQL collation concept, which has nothing to do with your lunch. Collations are a powerful feature in PostgreSQL allowing to adapt the way you deal with text data according to the localization. Like trying to answer this - apparently - obvious question : is '12' before or after '2' ?\n\nAnd, because we can, display all of this on a map :-)\\n\\nVincent Picavet\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/QEHLM7/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/5 LARS OPSAHL & SANDRO SANTINELLI.mp4", "persons": "Lars Opsahl, sandro santilli, Mattia Natali", "pretalx_id": "H7ZEBF", "title": "FOSS4G 2022 | Postgis Topology to secure data integrity, simple API and clean up messy simple feature datasets.", "description": "In Postgis Topology a merge of two surfaces does not involve spatial operations, since\nthe surface to border relation has foreign key structures in the database. This means that the border of the new object is spatially not touched/changed when two surfaces are merged. With simple feature the common border must be computed on the fly, which again may involve snapTo and cause tiny overlaps and gaps.\n\nWith Postgis Topology you can easily make an API where the client only sends new borders which is a key issue to secure data integrity. This secures that old border are not are not moved by a client error or the by simple transport format, because existing points are never not passed back to the server. Postgis Topology makes it easy for the server to work with those new borders(delta), because there are standard methods for this in Postgis Topology and all relations between border and surfaces are stored in the database. Postgis Topology also has validation routines in addition to using standard database constraints to secure a healthy system.\n\nThe principles that Postgis Topology is based on was used in spatial system many years ago, but one problem was to keep the border line work nice and clean and not end up in a spaghetti.  So one of the first things we did together with Sandro Santilli was to create methods on top of Postgis Topology to avoid this, by throwing away any border parts that does not contribute to a new \u201cvalid\u201d surface.\n\nPostgis Topology is built on a relational database model that is based on SQL-MM part 3. Your own domain data are easily linked to border, surface objects with more. For instance to check domain attributes on a surface on the other side of a border is not spatial query but a standard relational query.\n\nThe following projects will also be touched in this talk:\n\nhttps://gitlab.com/nibioopensource/pgtopo_update_sql (Functions using Postgis Topology to make it easy to create spatial update clients.)\n\nhttps://github.com/strk/qgis_pgis_topoedit (Postgis Topology is very well integrated with QGIS.)\n\nhttps://github.com/larsop/resolve-overlap-and-gap (Show how we clean up,  simplify, generalize  simple feature tables with millions of rows using Postgis Topology)\n\nIs relational database structure a good choice for Postgis Topology? Yes I will mean and since it\u2019s also linked up SQL-MM part3 and not a random private structure and with all great Postgis functions available this is very good combination. You may take take glance at https://www.ibm.com/ibm/history/ibm100/us/en/icons/reldb/ and other articles about relational databases.\n\nThe plan now is to build a full ecosystem around Postgis Topology with a generic client to support declarative rules, where you can define attributes, rules for attribute handling and how to deal with overlap and gap.\n\nAll the work NIBIO has done/is doing here would not have been possible with out the great support from Sandro Santilli.\\n\\nLars Opsahl\\nsandro santilli\\nMattia Natali\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/H7ZEBF/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/6 JASHANPREED SINGH.mp4", "persons": "Jashanpreet Singh", "pretalx_id": "YJPU9S", "title": "FOSS4G 2022 | Spatio-temporal Database - Creating a high availability easily scalable Spatio-temporal database cluster with Postgres, PostGIS, and timescaleDB!", "description": "I am working as the Technical Lead at Blue Sky Analytics, a climate-tech startup empowering the world\u2019s decision-makers with accurate, real-time, and standardized climate data.\n\nAll datasets that we are building here at Blue Sky Analytics, technically have one similarity - they all have a space and time component. We tried to build solutions like filling empty values in inconsistent temporal data, and dividing the data in specified time period chunks for faster queries, while these worked as POC, they were not easy to scale up. Working with structured data was much easier to understand, working on postgres with the addition of timescale and PostGIS gave us exactly what was needed. Building the solution at the database level with the existing open-source technologies has been an exhilarating experience.\n\nImagine a dataset with hourly frequency going back years on a global level, with frequent inconsistencies, that not only you have to efficiently store but that should also be highly accessible in combination with other such datasets. If not for the open-source, we would not have been able to answer questions like:\n\n - How much have the lakes shrunk between the years 2010-2020 on a yearly basis?\n - Finding GHG emissions from biomass burning of \"*all US states, for the last 10 years on a monthly, weekly, daily basis***\".**\n   Leveraging other open source solutions like h3-pg indexing also helped us to reduce the query time by an exponential factor for global level queries!\n\nWhile the database sounds pretty amazing, another challenge was putting it all together and deploying it on the cloud, which was a whole another challenge. The most intuitive solution was to deploy a bunch of Postgres instances. While it was not so hard to implement the basics, it became almost impossible to scale up or down, install rolling updates, account for failures.\n\nKeeping up with the tech, Kubernetes seemed like a great solution for building a high availability cluster service, and finding the postgres-operator (PGO) by crunchydata was exactly what we needed. It combined all the right tools like pgBouncer, pgBackRest, and monitoring solution using grafana and Prometheus all in one packaged easily to deploy service. While the learning curve with Kubernetes was a little steep, it lead to building a highly scalable and resilient database cluster.\n\nThe PostgreSQL + PostGIS + Timescale + H3 stack helped us simulate the temporal and spatial nature of the world at the database level and gave a universal approach to store and query all our datasets. It can handle textual data like fires with time (recorded time) and spatial information (lat -long) or shapes of counties, water bodies, etc., and combine them with each other using few joins giving us a very powerful geospatial-temporal query engine.\n\nWithout FOSS it would have been impossible to even imagine any of this but as of now, we are quantifying climate change!\\n\\nJashanpreet Singh\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/YJPU9S/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/7 BRANDON LIU.mp4", "persons": "Brandon Liu", "pretalx_id": "WXJKDM", "title": "FOSS4G 2022 | Web mapping at any scale: Bite-size, full-stack cartography with Protomaps + PMTiles open source tools", "description": "Protomaps is a new, open source set of tools for vector cartography on the web. It\u2019s designed to enable projects of any scale - from hobby projects of a neighborhood, to dense datasets covering the entire planet. It finally makes it simple to both host tiles and render them using web standards, and accomplishes it in the most affordable way possible.\n\nThis talk will be an overview of the entire mapping stack, driven by an ethos of simplicity. Component projects include:\n\n - The OSM Express database for syncing and querying fresh OpenStreetMap data\n - The PMTiles cloud-optimized archive format for serverless hosting on platforms like S3\n - The Protomaps JS renderer for custom cartography on the web using Canvas 2D\n - The relationship to complementary projects like GDAL, Leaflet, MapLibre, Tippecanoe and FlatGeobuf\n\nI\u2019ll also describe successes and failures in adoption among users over the past two years, as well as future development plans.\\n\\nBrandon Liu\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/WXJKDM/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/8 IVAN SANCHEZ.mp4", "persons": "ivansanchez", "pretalx_id": "KV3XUW", "title": "FOSS4G 2022 | Gleo: Reinventing WebGL maps", "description": "WebGL has enabled fast rendering of maps on the web (including MapLibreGL and OpenLayers renderers), but from the software development point of view, is a notoriously cumbersome technology to work with.\n\nThis session introduces Gleo, a JavaScript+WebGL map display library aiming to cover similar use cases than Leaflet, OpenLayers, MapZen and MapLibreGL.\n\nA few architectural features of Gleo will be outlined, including:\n\n - \"One GL shader per type of cartographic symbol\" rendering & framebuffer compositing approach\n - Object-oriented design: symbols as instances; allocation/deallocation of GPU resources for each symbol\n - ES6 javascript features: classes, modules, private fields; symbol as DOM EventTarget; deprecation of mouse/touch events in favour of pointer events\n - Sliding window algorithm in a wrapped WebGL texture for tile caching\n - On-the-fly reprojection enabled by updating just one WebGL data structure\n - On-the-fly CRS offsetting to prevent floating-point precision artifacts\n - Coordinate wrapping and display tessellation to avoid antimeridian artifacts\\n\\nivansanchez\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/KV3XUW/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/9 Astrid Emde.mp4", "persons": "Astrid Emde", "pretalx_id": "YFJNLU", "title": "FOSS4G 2022 | MapComponents, a new component framework for developing web map applications", "description": "MapComponents is a new component framework to quickly and easily build dynamic geospatial web apps. It includes React front-end components for all kinds of projects, from small apps with a narrow and specific focus up to complex geospatial suites for the web. Server-side components are also planned to aid the development of flexible backend services.\n\nMapComponents\n\n - is a modular framework to create tailored geospatial web apps built upon modern webbrowser technology\n - can be used to visualise and analyse geo data\n - can be used for desktop and mobile applications (online and offline; progressive web apps (PWA))\n - provides independent components which can be combined into full-fledged geospatial web applications (e.g. dashboards, WebGIS, ...)\n - provides a catalog of components and example applications\n - uses a flexible core which theoretically supports any kind of mapping library (currently supported are MapLibre, Mapbox GL JS and OpenLayers)\n - is easily integrated into existing stacks\n - makes it easy to rapidly design and deploy a map centric web app\n\nMapComponents is developed by WhereGroup GmbH and is available under the MIT license.\n\nhttps://www.mapcomponents.org/\n\nWe will present the project, with its current state and goals, and will show practical examples.\\n\\nAstrid Emde\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/YFJNLU/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/10 Eleni Valtopoulou.mp4", "persons": "Eleni Valtopoulou", "pretalx_id": "Q9G7EH", "title": "FOSS4G 2022 | EVRYMAP - An extensible web mapping framework based on Angular, NodeJS, Leaflet and Mapserver.", "description": "It started as a way to help us publish geospatial data. It quickly morphed to something quite different. You can call it scope creep. And despite this term being close to a swear word in ICT, it turned out to be very good thing. And that's because while still serving its main purpose, which is to provide an out-of-the-box web based mapping app with all the trimmings (navigation, measure, layer control and search tools), EVRYMAP also:\n\n - Provides client-side editing tools\n\n - Provides a modular design that allows you to implement custom business logic by simply writing your own apis. EVRYMAP will consume these APIs automatically by defining them in configuration as 'modules'\n\n - Implements 1-n relationships between your spatial data and other related data. Which may come from the same or external databases\n\n - Can be run as standalone or within an iframe to spatially enable third party applications (and provides the communication mechanism)\n\nUsing EVRYMAP at the core, we have also deployed a few systems in production environments as commercial apps, namely:\n-Landify, a mini-cadastre for organizations with a real-estate portfolio. It allows users to easily review, catalogue, and manage real estate data (land parcels and buildings).\n-MapTheYA, a map-based information system for the management of water networks including topology checks.\n-Building permits/Expropriations Management\nExamples of not \"map-first\" systems, meaning that while the bulk of their functionality are text/form based (applying for electronic copies of documents) they also include embedded maps to improve user experience.\n\nThis presentation will provide a brief introduction to EVRYMAP, the way it works, how you can configure and extend its functionality and what we plan for the future. And being the new kid on the block, ask the community for input and feedback!\\n\\nEleni Valtopoulou\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/Q9G7EH/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/11 Luis Calisto.mp4", "persons": "Luis Calisto, Lu\u00eds M. de Sousa", "pretalx_id": "ZAB3FH", "title": "FOSS4G 2022 | Web Mapping with Global Map Projections", "description": "Web Mapping as a technology and a method is now twenty years old. Within the\nOSGeo Community, it has been fostered by projects such as OpenLayers\nand Leaflet. They evolved tightly intertwined with the framework imposed by\nfree data providers, initially around commercial efforts like Google and later\nOpenStreetMap. While useful in providing an easy entry to web mapping, and\nconvenient background layers, these data providers also triggered a regression\ntowards centuries-old cartography techniques, in particular the Mercator projection.\nThis has become a major hurdle to web mapping, particularly concerning global\ndata.\n\nThe Mercator map projection was created to aid sea faring in the XVI century and\nwas rendered useless with the advent of global positioning systems. Its use in\ncartography may still be acceptable at large scales, neighbourhood or city\nlevel, but at smaller scales it imposes severe distortion to distances and areas.\nFor global datasets in particular, the Mercator projection is unusable, for it\ncannot represent the full surface of the planet.\n\nWeb mapping developers may work around this framework with libraries such as D3\nor proj4js, and by setting up bespoke base layer services. But in doing so they\nface a different problem: the deep dependence on the CRS index created by the\nEuropean Petroleum Survey Group (EPSG). Primarily concerned with the survey and\nextraction of fossil fuels, the EPSG leans heavily on local or regional CRSs,\nlargely ignoring global CRSs.  Hardly any of the more than 100 map projections\nand coordinate systems developed since the beginning of the XX century feature\nin the EPSG index.  Landmark projections such as the Eckert series, the\nHomolosine, Eumorphic, Dymaxion or the Snyder series were never included in the\nEPSG index.  Not even the classical Mollweide projection (one of the turning\npoints towards modern cartography) appears in the EPSG index. With a FOSS4G\nstapple such as MapServer, this forces the leveraging of map (re-)projections to\nthe client, which is not always possible.\n\nWeb mapping with global data thus remains a technical challenge with FOSS4G.\nThis address reviews several techniques and work-arounds making global web\nmapping possible with familiar FOSS4G technologies. Starting with the\nappropriate configuration of CRS managing software, going through the set-up of\ndata servers and finally providing examples with web mapping clients.\\n\\nLuis Calisto\\nLu\u00eds M. de Sousa\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ZAB3FH/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/12 John Wika Haakseth.mp4", "persons": "John Wika Haakseth", "pretalx_id": "ZH8WAJ", "title": "FOSS4G 2022 | Liven up your webmaps with custom microanimations", "description": "Micro animations are\u00a0small animations on a website that support the user by attracting focus to where we want their attention. They can also be used to support relationships between elements in a web application, for example a list element and a map feature, or simply to spark a little joy. Users today have come to expect these animations in their online experiences. How can we provide these features in a web map? Map libraries gives you some animations out of the box today, but what if you want something custom?\n\nThis presentation will give examples on how small animations can be used in web maps to support interactivity. We will walk through building our own, custom animation that can be used as a starting point for many types of animations in web maps. The technique is library-agnostic, so we\u2019ll show examples in both MapLibre GL JS, Leaflet and OpenLayers.\\n\\nJohn Wika Haakseth\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ZH8WAJ/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/13 Gerald Guala.mp4", "persons": "Gerald \"Stinger\" Guala, Cl\u00e9ment Albinet", "pretalx_id": "EBYEUP", "title": "FOSS4G 2022 | Joint ESA-NASA Multi-Mission Algorithm and Analysis Platform (MAAP)", "description": "The scientific community is faced with a need for greatly improved data sharing, analysis, visualization and advanced collaboration based firmly on open science principles. Recent and upcoming launches of new satellite missions with more complex and voluminous data, as well as the ever more urgent need to better understand the global carbon budget and related ecological processes, provided the immediate rational for the ESA-NASA Multi-mission Algorithm and Analysis Platform (MAAP).\n\nThis highly collaborative joint project of ESA and NASA established a framework between ESA and NASA to share data, science algorithms and compute resources in order to foster and accelerate scientific research conducted by ESA and NASA EO data users. Presented to the public in October 2021, the current version of MAAP provides a common cloud-based platform with computing capabilities co-located with the data, a collaborative coding and analysis environment, and a set of interoperable tools and algorithms developed to support the estimation and visualization of global above-ground biomass.\n\nData from the Global Ecosystem Dynamics Investigation (GEDI) mission on the International Space Station and the Ice, Cloud, and Land Elevation Satellite-2 (ICESat-2) have been instrumental in the first products of MAAP including the first comprehensive map of Boreal above-ground Biomass and a current Global Biomass Harmonization Activity, but the platform is also being specifically designed to support the forthcoming ESA Biomass mission and incorporate data from the upcoming NASA-ISRO SAR (NISAR) mission. While these missions and the corresponding research which includes airborne, field, and calibration/validation data collection and analyses, provide a wealth of data and information relating to global biomass estimation, they also present data storing, processing and sharing challenges. The NISAR mission alone will produce about 80TB/day. These large data volumes present a challenge that would otherwise place accessibility limits on the scientific community and impact scientific progress.\n\nOther challenges being addressed by MAAP include: 1) Enabling researchers to easily discover, process, visualize and analyze large volumes of data from both agencies; 2) Providing a wide variety of data in the same coordinate reference frame to enable comparison, analysis, data evaluation, and data generation; 3) Providing a version-controlled science algorithm development environment that supports tools, co-located data and processing resources; and 4) Addressing intellectual property and sharing challenges related to collaborative algorithm development and sharing of data and algorithms.\n\nMAAP products can be explored on the MAAP Dashboard at https://earthdata.nasa.gov/maap-biomass or the joint platform entrance at scimaap.net. MAAP also can be accessed through individual NASA (https://maap-project.org) and ESA (https://esa-maap.org/) landing pages.\\n\\nGerald \"Stinger\" Guala\\nCl\u00e9ment Albinet\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/EBYEUP/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/14 STUART LYNN.mp4", "persons": "Stuart Lynn", "pretalx_id": "XV87XB", "title": "FOSS4G 2022 | Write once, run anywhere: safe and reusable analytic modules for WebAssembly, Javascript, or more!", "description": "The proliferation of client-side analytics and on-going vulnerabilities with shared code libraries have fueled the need for better safety standards for running executables from potentially unknown sources. WebAssembly (WASM), a compilation target that allows lower-level languages like Rust, C, and Go to run in the browser or server-side at near-native speeds. Much like Docker changed the way we run virtualized workflows, WASM runtimes create safe virtual environments where access to the host system is limited.\n\nIn combination with a new free and open source full-stack geospatial platform, Matico, efforts are underway to enable portability across workflows and applications to more easily use WASM modules. WASM implementations of GDAL are in the works, and powerful open source Rust geospatial libraries are easily packaged for web usage through Wasm-Pack. Additional geo WASM libraries like jsgeoda provide spatial indices, binning, and autocorrelation functions. Shareable code can be a recipe for security vulnerabilities and attack vectors, potentially exposing personal or critical information, particularly if there is the opportunity to run code server-side. WASM implementation alleviates this by requiring access from the Virtual Machine (VM) to be limited and explicit, and for Javascript developers the lightweight AssemblyScript language is relatively familiar.\n\nAn upcoming Javascript feature called ShadowRealms may enable even simpler and more familiar implementations to safely run Javascript code shared between module authors. These developments lay the groundwork for a hybrid front- and backend geospatial ecosystem of shareable code snippets and analytic functions, much like have emerged in the UI component Javascript ecosystem. The combination of emerging features positions web geospatial analytics and This talk explores the implementation and performance of running geospatial analytic modules through a WebAssembly virtual machine and through the upcoming Javascript ShadowRealm specification.\\n\\nStuart Lynn\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/XV87XB/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/15 COREY WHITE.mp4", "persons": "Corey White", "pretalx_id": "BHVKEZ", "title": "FOSS4G 2022 | OpenPlains - Is it the new web GRASS?", "description": "OpenPlains - Is it the new web GRASS?\\n\\nCorey White\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/BHVKEZ/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/16 Mauro Bartolomeoli.mp4", "persons": "Mauro Bartolomeoli", "pretalx_id": "JUKEPT", "title": "FOSS4G 2022 | Scaling down web maps for the final user", "description": "WebGIS publishing platforms like MapStore, are usually very feature-rich, to cover a lot of different  scenarios, from the QGIS-like do-it-all web application, to a simple interactive map for a company website.\n\nThis comes with an important trade-off: even when removing most of the unneeded functionalities for the simplest use case, the cost of the platform needed to run your maps can be overwhelming.\n\nThe problem here is that a single platform is not always the best choice for every kind of usage.\n\nThis talk shows how to use the popular MapStore platform as an application builder, to publish interactive maps that can run on a very light engine, de facto scaling down a quite heavy platform to the needs of performance and simplicity that better suit a lot of general user oriented applications and websites.\n\nWe will start by creating a map from different data sources, using MapStore, then we will export the map and publish it to our alternative light engine.\n\nWe will then highlight all the advantages this approach can offer.\n\nFinally we will give some insights on the technical aspects of this project.\\n\\nMauro Bartolomeoli\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/JUKEPT/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/17 Michele Tobias.mp4", "persons": "Michele Tobias", "pretalx_id": "DAST9N", "title": "FOSS4G 2022 | Automating Generating a Web Map from Online Tabular Data: UC Davis Potential Worksite Exposure Interactive Web Map", "description": "Tables are a great way to store data and this format is often used to make data available for the public on websites. While these tables technically meet their intended goal of sharing data, they do not make it easy to understand the spatial and temporal patterns in the data they contain. In this talk, I will demonstrate how an automated toolchain of web scraping and text processing in R, and interactive visualization in Leaflet is automated with GitHub Actions and applied to aid data interpretation and generate new insights from a daily-updated online tabular dataset using a case study of the University of California Davis\u2019 Potential Worksite Exposure Reporting data for COVID-19.\nIn the United States, California Assembly Bill 685 (AB685) requires employers in the state of California to notify employees of potential worksite exposures to COVID-19 to the geographic scale of individual buildings. The University of California Davis meets this requirement by listing any potential exposures on a website, giving the date reported, the dates of the potential exposure, and the building name as reported by the employee. To make a map from this data, the dates and building names had to be standardized and joined to a vector layer of campus buildings before they can be added to an interactive Leaflet map. Because the data updates daily, the whole process needed to be automated so no one had to run the scripts every day to update the map. The result is a map that gives uses a much clearer understanding of the spatial and temporal distribution of potential exposures to COVID-19 on campus.\\n\\nMichele Tobias\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/DAST9N/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/18 Lorenzo Natali.mp4", "persons": "Lorenzo Natali, Tobia Di Pisa", "pretalx_id": "XPCXBQ", "title": "FOSS4G 2022 | MapStore and geOrchestra, a match made in heaven", "description": "Work started at the end of 2019 to integrate MapStore (https://mapstore.readthedocs.io/en/latest/) as a WebGIS viewer (https://mapstore.geosolutionsgroup.com/mapstore/#/) for the geOrchestra SDI (https://www.georchestra.org/) (a free, open source, modular and interoperable Spatial Data Infrastructure software born in 2009 to meet the requirements of the INSPIRE directive in Europe). The work, led by GeoSolutions (https://www.geosolutionsgroup.com/), was funded by Rennes M\u00e8tropole (https://metropole.rennes.fr/) with the  goal to meet the expectations of the large geOrchestra community for a new, more ergonomic, modular and customizable WebGIS based on updated technologies.\n\nThe project also triggered a significant evolution of the MapStore product by developing several interesting new tools and enhancements to the MapStore framework. Thanks also to this powerful integration MapStore significantly increases its strengths by opening the door to further and more advanced developments and evolutions. Below is a list of main enhancements and new features that have been part of the integration:\n\n - Application Context Manager: an administrative tool designed to build and configure MapStore's viewers\n - General evolutions of common existing tools in MapStore to enrich the user experience: Map viewport enhancements, CRSs management, TOC, translations, styling of layers, advanced measure tool, layer metadata, various catalog tool extensions to support additional data sources (like TMS, WFS etc), Attribute Table enhancements for the editing mode and more\n - Enhancements on the MapStore security tier aimed to the integration\n - Extension Manager: extensions are plugins that can be distributed as a separate package (a zip file), and be installed, activated and used at runtime in an existing MapStore installation\n - MapStore Data Directory: to make more portable and manageable the MapStore configuration and installed extensions\n\nThe first integration received positive feedback from the geOrchestra community but also from those who were already using MapStore as a standalone application as well as from GeoNode users. Thanks to MapStore, some application flows have also been strengthened and consolidated in geOrchestra; further developments made after the first integration work also had the aim of migrating other custom tools (such as Cadastrapp and Urbanisme) leveraging on the MapStore Extensions system and also the geOrchestra community has taken its own steps in this direction with the inclusion of further custom extensions for MapStore.\n\nThis great collaboration is progressing fruitfully even today where further evolutions and developments are expected for 2022, including new features and functionalities for MapStore.\\n\\nLorenzo Natali\\nTobia Di Pisa\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/XPCXBQ/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Limonaia/19 Andrea Aime.mp4", "persons": "Andrea Aime", "pretalx_id": "TLCX97", "title": "FOSS4G 2022 | Styling Natural Earth with GeoServer and GeoCSS", "description": "Natural Earth is a public domain map dataset available at 1:10m, 1:50m, and 1:110 million scales. Featuring tightly integrated vector and raster data, with Natural Earth one can build a variety of visually pleasing, well-crafted maps with cartography or GIS software.\n\nGeoServer GeoCSS is a CSS inspired language allowing you to build maps without consuming fingertips in the process, while providing all the same abilities as SLD.\n\nIn this presentation we\u2019ll show how we have built a world political map and a world geographic map based on Natural Earth, using CSS, and shared the results on GitHub. We\u2019ll share with you how simple, compact styles can be used to prepare a multiscale map, including:\n\n - Leveraging CSS cascading.\n - Building styles that respond to scales in ways that go beyond simple scale dependencies.\n - Various types of labeling tricks (conflict resolution and label priority, controlling label density, label placement, typography, labels in various scripts, label shields and more).\n - Quickly controlling colors with LessCSS inspired functions.\n - Building symbology using GeoServer large set of well known marks.\n\nJoin this presentation for a relaxing introduction to simple and informative maps.\\n\\nAndrea Aime\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/TLCX97/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Onice/1 Tom Kralidis - Angelos Tzotsos.mp4", "persons": "Tom Kralidis, Angelos Tzotsos", "pretalx_id": "3DTFSV", "title": "FOSS4G 2022 | pycsw project status 2022", "description": "pycsw is an OGC CSW server implementation written in Python and is an official OSGeo Project. pycsw implements clause 10 HTTP protocol binding - Catalogue Services for the Web, CSW of the OpenGIS Catalogue Service Implementation Specification, version 3.0.0 and 2.0.2. pycsw allows for the publishing and discovery of geospatial metadata, providing a standards-based metadata and catalogue component of spatial data infrastructures. The project is certified OGC Compliant, and is an OGC Reference Implementation.\n\nThe project currently powers numerous high profile catalogues such as IOOS, NGDS, NOAA, US Department of State, US Department of Interior, geodata.gov.gr, Met Norway and WMO WOUDC. This session starts with a status report of the project, followed by an open question answer session to give a chance to users to interact with members of the pycsw project team. This session will cover how the project PSC operates, the current project roadmap, and recent enhancements focused on ESA's EOEPCA, Open Science Data Catalogue and OGC API - Records.\\n\\nTom Kralidis\\nAngelos Tzotsos\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/3DTFSV/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Onice/2 Tom Kralidis - Francesco Bartoli.mp4", "persons": "Tom Kralidis, Francesco Bartoli, Angelos Tzotsos, Just van den Broecke", "pretalx_id": "KABLGQ", "title": "FOSS4G 2022 | pygeoapi project status 2022", "description": "pygeoapi is an OGC API Reference Implementation. Implemented in Python, pygeoapi supports numerous OGC APIs via a core agnostic API, different web frameworks (Flask, Starlette, Django) and a fully integrated OpenAPI capability. Lightweight, easy to deploy and cloud-ready, pygeoapi's architecture facilitates publishing datasets and processes from multiple sources. The project also provides an extensible plugin framework, enabling developers to implement custom data adapters, filters and processes to meet their specific requirements and workflows. pygeoapi also supports the STAC specification in support of static data publishing.\n\npygeoapi has a significant install base around the world, with numerous projects in academia, government and industry deployments. The project is also an OGC API Reference Implementation, lowering the barrier to publishing geospatial data for all users.\n\nThis presentation will provide an update on the current status, latest developments in the project, including new core features and plugins. In addition, the presentation will highlight key projects using pygeoapi for geospatial data discovery, access and visualization.\\n\\nTom Kralidis\\nFrancesco Bartoli\\nAngelos Tzotsos\\nJust van den Broecke\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/KABLGQ/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Onice/3 Fabian Schindler-Strauss.mp4", "persons": "Fabian Schindler-Strauss", "pretalx_id": "GPPKXW", "title": "FOSS4G 2022 | pygeofilter: geospatial filtering made easy", "description": "## Abstract\n\npygeofilter (https://github.com/geopython/pygeofilter/) is a library to support the integration of geospatial filters. It is split into frontend language parsers (CQL 1 + 2 text/JSON, JFE, FES) , a common Abstract Syntax Tree (AST) representation and several backends (database systems) where the parsed filters can be integrated into queries.\n\n## Parsers\n\nCurrently pygeofilter supports CQL 1, CQL 2 in both text and JSON encoding, OGC filter encoding specification (FES) and JSON filter expressions (JFE) as input languages. Additionally pygeofilter provides utilities to help create parsers for new filter languages.\nThe filters are parsed to an AST representation, which is a common denominator across all filter capabilities including logical and arithmetic operators, geospatial comparisons, temporal filters and property lookups. An AST can also be easily created via the API, if necessary.\n\n## Backends\n\npygeofilter provides several backends and helpers to roll your own. Built-in backends are for Django, SQLAlchemy, raw SQL, (Geo)Pandas dataframes, and native Python lists of dicts or objects.\n\n## Usage\n\npygeofilter is used in several applications, such as PyCSW (https://pycsw.org/), EOxServer (https://github.com/EOxServer/eoxserver/) and ogc-api-fast-features (https://github.com/microsoft/ogc-api-fast-features/)\\n\\nFabian Schindler-Strauss\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/GPPKXW/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Onice/4 Micha\u00ebl Douchin.mp4", "persons": "Etienne Trimaille, Ren\u00e9-Luc Dhont", "pretalx_id": "VC8WX9", "title": "FOSS4G 2022 | QGIS Server into the wild", "description": "With our Lizmap hosting service, we provide and monitor several hundred of QGIS servers. These QGIS Servers receive and process 3.5 million requests per week, including 3 million WMS GetMap requests.\n\nWe do not control the content of these QGIS projects, which are sent by our customers on our servers. Therefore, we need to deal with projects having some various kind of issues. Some QGIS projects can have very heavy SQL views which are slow to load. Our infrastructure may host projects having hundreds of layers with complex symbology. Users can publish QGIS PDF layouts (A4 and A3) with custom logos etc. This can lead to memory problems.\n\nGIS technicians can add different data sources : vector and raster files, PostgreSQL / PostGIS database, OGC WMS, WFS and WMTS web services into these QGIS projects. We need to ensure that QGIS Server is working properly, for all customers, to execute incoming requests when some external Web Services providers are too slow to respond or are temporarily offline.\n\nWe need to take care of possible errors propagated by these projects. In some circumstances, we have about 10 thousand errors per week coming from QGIS server.\n\nThe goal of this presentation is to give an overview of what QGIS Server can experience into the wild and what we need to do to make the Lizmap user experience the best possible: monitoring, proxy, caching.\\n\\nEtienne Trimaille\\nRen\u00e9-Luc Dhont\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/VC8WX9/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Onice/5 Micha\u00ebl Douchin.mp4", "persons": "Etienne Trimaille", "pretalx_id": "A3TBBA", "title": "FOSS4G 2022 | PgMetadata - A QGIS plugin to store the metadata of PostgreSQL layers inside the database, and use them inside QGIS", "description": "PgMetadata is made for people using QGIS as their main GIS application, and PostgreSQL as their main vector data storage.\n\nThe layers metadata are stored inside your PostgreSQL database, in a dedicated schema. Classical fields are supported, such as the title, description, categories, themes, links, and the spatial properties of your data.\n\nPgMetadata is not designed as a catalog application which lets you search among datasets and then download the data. It is designed to ease the use of the metadata inside QGIS, allowing to search for a data and open the corresponding layer, or to view the metadata of the already loaded PostgreSQL layers.\n\nBy storing the metadata of the vector and raster tables inside the database:\n\n - QGIS can read the metadata easily by using the layer PostgreSQL connection: a dock panel shows the metadata for the active layer when the plugin detects metadata exists for this QGIS layer.\n - QGIS can run SQL queries: you can use the QGIS locator search bar to search for a layer, and load it easily in your project.\n\nThe administrator in charge of editing the metadata will also benefit from the PostgreSQL storage:\n\n - PostgreSQL/PostGIS functions are used to automatically update some fields based on the table data (the layer extent, geometry type, feature count, projection, etc.).\n - The metadata is saved with your data anytime you backup the database\n - You do not need to share XML files across the network or install a new catalog application to manage your metadata and allow the users to get it.\n\nThe plugin contains some processing algorithms to help the administrator. For example:\n\n - a script helps to create or update the needed \"pgmetadata\" PostgreSQL schema and tables in your database\n - a algorithm creates a QGIS project suitable for the metadata editing. This project uses the power of QGIS to create a rich user interface allowing to edit your metadata easily (forms, relations). Why use another interface when QGIS rocks ?\n\nMore PgMetadata features will be shown during the presentation:\n\n - Modification of the template to tune the displayed metadata\n - Export a metadata dataset to PDF, HTML or DCAT\n - Publish the metadata as a DCAT catalog with Lizmap Web Client module for PgMetadata. It can then be harvested by external applications (Geonetwork, CKAN)\n - The data model is very close to the QGIS metadata storage and the DCAT vocabulary for compatibility.\n\nWe will also show the last features such as the new support of the PostgreSQL rasters\\n\\nEtienne Trimaille\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/A3TBBA/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Onice/6 Adam Laza.mp4", "persons": "Adam Laza", "pretalx_id": "PEXWC9", "title": "FOSS4G 2022 | QGIS MapTiler plugin v3- vector basemaps & global DEM for 3D terrain", "description": "The MapTiler plugin is the easiest way to load styled vector tiles into QGIS. The plugin allows anybody to easily load map data of the entire planet (from OpenStreetMap project), with details down to the street level from Cloud or any other URL.\n\nThe version 3.0 of MapTiler plugin brings several new features, maps and datasets.\nA new global DEM of the entire planet is ideal for terrain spatial analysis. New maps - both in vector and raster - OpenStreetMap (popular OSM Carto finally in vectors!) and a Winter map for all wintertime activities. A new Satellite map based on our new 2021 cloudless satellite imagery with 10m resolution for the entire planet.\n\nThe plugin offers maps of the entire world in vector or raster tiles, but can also open maps from any other URL. You can load high-resolution aerial imagery, hillshading, global terrain data and contour lines for outdoor maps or official government open data from various countries.\n\nA ready-to-use list of beautiful map styles is available to QGIS users. Those who prefer customized maps can make their own map design in a few clicks using the Customize tool. Users can set their own colors, fonts, or choose the language of map labels.\n\nUse the power of QGIS and reproject, rotate and export vector tiles to various formats (including PDF, SVG or DWG) or use Print Composer to create beautiful high-detailed maps to fit your needs.\n\nThe plugin is an open-source project with code available at GitHub repository and open to any contribution from developers and users.\\n\\nAdam Laza\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/PEXWC9/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Onice/7 Ian Turton.mp4", "persons": "Ian Turton", "pretalx_id": "TNMMMF", "title": "FOSS4G 2022 | How to get a good response on stackexchange", "description": "I often hear complaints that the stackexchange sites are too mean to new users, that moderators are too quick  to close a question that doesn't fit the guidelines or nitpick the questions to death. Also, that they didn't get a good answer anyway so what is the point.\nThis talk will give you an introduction on how to ask a \u201cgood\u201d question on gis.stackexchange.com from an experienced moderator of the site. As a bonus, you will also find out how to file a useful bug report (either internally or to an external project). This talk will cover the things that you might not think are useful but are in fact vital to someone who is trying to help you.\nI will discuss how the site works and how to make it work well for you, what sort of questions are \u201cgood\u201d questions and which ones are better asked somewhere else. I will also cover what the difference between closing and deleting a question is and how to get your question reopened if it is closed. How the review queues work and how you can help improve the site for other users.\\n\\nIan Turton\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/TNMMMF/\\n\\n#foss4g2022\\n#generaltrack\\n#Education"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Onice/8 Zoltan Siki.mp4", "persons": "Zoltan Siki", "pretalx_id": "CQFH3J", "title": "FOSS4G 2022 | A Moodle based complex system to teaching spatial data processing", "description": "Open-source solutions in geoinformatics have gradually come into the focus of attention over the past decades, becoming of the most well-promising opportunities in tertiary education. It is  indubitable that students have to develop their skills to find, apply and contribute to the existing open-source opportunities, besides developing skills regarding coding and programming logic.\u00a0\nAt the Budapest University of Technology and Economics, a complex system has been developed to support students on this matter. This system is fully based on open-source software and free cloud services. Consequently, all  the teaching materials have creative common licenses supported by the use of open source software.\u00a0\nThe main entry point of the educational materials is Moodle, considered as one of the most popular learning management systems. The majority of the source codes and explanation texts/notes used for teaching are published in Jupyter notebooks, stored on personalized GitHub pages. For opening and testing the Jupyter notebooks, the students can use Google Colab.\u00a0\nAnother challenge worth mentioning is the continuous assessment evaluation format. Moodle supports the creation of tests based upon a wide variety of question types (e.g. multiple choice, true/false, drag and drop markers, etc), which are stored in a question bank. The test is generated by randomly selecting a given number of questions; therefore, taking the test a couple of times is highly recommended. As stated by many, this way of self-studying is popular among students these days and efficient in achieving remarkable progress.\u00a0\nOur presentation shares either the developed system or the gained experience over the recent years.\\n\\nZoltan Siki\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/CQFH3J/\\n\\n#foss4g2022\\n#generaltrack\\n#Education"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Onice/9 Cody D Smith.mp4", "persons": "Cody D Smith, Kasra Manavi", "pretalx_id": "VCPPNM", "title": "FOSS4G 2022 | Teaching GIS Through Geospatially Aware Agent-Based Modeling", "description": "Teaching GIS Through Geospatially Aware Agent-Based Modeling.\n\nAgentScriptGIS is a web-based platform that provides a geospatially aware agent-based modeling programming environment. The goal is to enable programmers to generate geo-agent-based models with minimal barriers to entry. The platform provides a programming environment that includes an agent-based modeling library (agentscript.org), a geo-aware programming context, and a map display (leafletjs.com).\n\nThe platform was designed to reduce the overhead needed for programmers to begin modeling. We want to empower modelers who come from a wide array of backgrounds with the ability to write and animate geospatial models with minimal time and effort. The intended audience of this platform are users who want to explore geospatial and agent-based modeling but may have little to no experience interacting with these types of models.\n\nWe use agent-based modeling as a basis for our platform since it is a popular way to teach programming and can model a wide spectrum of problems. Popularized by NetLogo and StarLogo, agent-based modeling is used in a variety of educational contexts from elementary school studies to graduate level research. To maximize deployability, our agent-based modeling library AgentScript was written in JavaScript and built to be leveraged by the web browser.\n\nGIS software is typically professional in nature and leans on being sophisticated and precise, but is often overburdened with complexity. The hobbyist GIS programmer faces a steep learning curve when starting, including choosing appropriate tools and information sources, deciding on data formats and understanding projections. Our platform intends on removing these burdens on the user by trading versatility for simplicity and ease of use.\n\nWe are preparing our platform to be used initially in academia, but can see it being applied in a variety of settings. AgentScriptGIS focuses on facilitating new ways to engage students, teachers and modelers with geospatial issues. This platform provides a low barrier of entry to users and promotes the modeling of local and regional problems by leveraging real-world data and empowering low skill users with the ability to model various geospatial phenomena.\\n\\nCody D Smith\\nKasra Manavi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/VCPPNM/\\n\\n#foss4g2022\\n#generaltrack\\n#Education"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Onice/10 Caitlin Haedrich.mp4", "persons": "Caitlin Haedrich, Vaclav Petras", "pretalx_id": "GV7AJG", "title": "FOSS4G 2022 | Using GRASS GIS in Jupyter Notebooks: An Introduction to grass.jupyter", "description": "Although integration of GRASS GIS with Python has been well supported for several years, using GRASS with computational notebooks such as Jupyter Notebooks was inconvenient up until recently. Computational notebooks allow users to share live code with in-line visualizations and narrative text, making them a powerful interactive teaching and collaboration tool for geospatial analytics. In this talk, we\u2019ll introduce a new GRASS GIS package, grass.jupyter, that enhances the existing GRASS Python API to allow Jupyter Notebook users to easily manage GRASS data, visualize data including spatio-temporal datasets and 3D visualizations, and explore vector attributes with Pandas. We\u2019ll demonstrate how to create interactive maps through integration with folium, a leaflet library for Python, and we\u2019ll look at an example use case: using notebooks to teach an advanced geospatial modeling course for graduate students at NC State University.\nGrass.jupyter is still under active development but is available experimentally in GRASS version 8.0 and officially with GRASS version 8.2.\\n\\nCaitlin Haedrich\\nVaclav Petras\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/GV7AJG/\\n\\n#foss4g2022\\n#generaltrack\\n#Education"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Onice/11 Amelie A. Gagnon.mp4", "persons": "Riku Oja, Amelie A. Gagnon", "pretalx_id": "SGCHCK", "title": "FOSS4G 2022 | Geospatial data science for planning education systems", "description": "The presentation will share how UNESCO\u2019s International Institute for Educational Planning (IIEP) applies FOSS4G technologies to advance Ministries of Education\u2019s use of geospatial data in planning better educational results among school children. Our work here at the IIEP-UNESCO is to design tools for educational planners all around the world, and FOSS4G has been the cornerstone of our work.\n\nEducational planners are the professionals who work in Ministries of Education \u2013in district offices or in the central office-- that are tasked with designing the best possible strategies and interventions to make sure that all learners will get good quality access to relevant and efficient educational services. For decades, planners have been using geospatial insights with minimal computing capacity and- to be honest- very little spatial data.\n\nOver the last few years, we have been completely refurbishing the methods and the data that we use as planners, and working with the FOSS4G community has been instrumental in fulfilling our mission.\nThis talk is about sharing concrete applications and use cases of geospatial data in educational planning. For example, we spatialize the number of students that will enrol in each grade in different communities, we plan for the training, recruitment, deployment, and retention of the teaching staff, we lead suitability analyses to check where to best build a new school or where to refurbish existing ones.\n\nSo in this presentation we will show you examples of application of tools and methodologies all built on FOSS:\n\n - Spatialized school-age populations in Jamaica\n - Routing optimization of inspection circuits in Finland\n - Geographically-weighted regressions for improving learning in Colombia\n - School infrastructure and natural hazard risk model in Indonesia\n - Sea level rise and historical floods in Viet Nam\n - School catchment areas based on travel time (check out the presentation submitted by Riku Oja from GISPO, it\u2019s our joint work!)\n\nAs an institution here at IIEP we have sought to advance this line of work by (1) making a complete switch to free and open source software (FOSS) and open access documentation and data sources (OpenScience), (2) bringing geospatial approaches and big, small, and thick data, to update EDplanning processes, (3) creating technical partnerships with instances such as GISPO, UNOSAT, among others, and (4) collaborating on informing education policy-making with geospatial insights.\n\nThis talk is an invitation to all geospatial data geeks to join us in shaping the future of educational planning.\\n\\nRiku Oja\\nAmelie A. Gagnon\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/SGCHCK/\\n\\n#foss4g2022\\n#generaltrack\\n#Education"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Onice/12 Marta Castelli.mp4", "persons": "marta castelli", "pretalx_id": "9SNJEH", "title": "FOSS4G 2022 | Rockfall Quantitative Risk Assessment at a medium-large scale based on FOSS4G tools. An example of applications in the North-Western Alps", "description": "Rockfall risk analysis and mitigation activities are key points in land management in mountain areas and along coastal cliffs, aimed at the protection of population, structures, infrastructures and involved economic activities such as viability, industry and tourism.\nRockfall is a complex landslide phenomenon, widespread over large areas and characterised by high variability. As a function of the amount of available data to describe such variability, the risk analysis can be carried out at different levels of detail, i.e. at different reference scales, each one characterised by specific objectives, procedures, and input data (Fell et al, 2008).\nAt the detailed scale (> 1: 5000), in order to design risk mitigation works, it is necessary to analyse localized rockfall phenomena through specific methodologies requiring a careful identification of danger scenarios, a statistical description of the parameters, and sophisticated probabilistic calculation tools.\nAt the medium-large scale (1: 5000 - 1: 25000), on the contrary, due to the difficulty in finding detailed information over larger slope portions, it is possible to analyse widespread instability sources based on simplified mechanical considerations and several spatial approximations. Such large scale analyses can be used as a management tool for territorial planning and can be easily implemented in GIS software.\nThis work presents a medium-large scale Rockfall Quantitative Risk Assessment procedure fully developed within the QGIS environment. The procedure is based on the IMIRILAND methodology (Castelli and Scavia, 2008), which allows to obtain risk maps through integrated and consequential phases and simple raster calculations. The main steps of IMIRILAND methodology are:\n\u2022\thazard analysis, aimed at defining, for a given rockfall scenario, the potentially involved area, the intensity of the damaging phenomenon and the temporal probability of occurrence;\n\u2022\tidentification of the elements at risk and definition of their value and their exposure with reference to  physical, social, environmental and economic considerations;\n\u2022\tanalysis of the vulnerability of the elements at risk, i.e. the degree of loss of the element as a consequence of the impact with the falling block;\n\u2022\tcalculation of the risk, combining the hazard with value, exposure and vulnerability of the elements at risk.\nThe IMIRILAND QRA procedure was applied to the mountain site of Sorba Valley (VC), North-Western Alps. The site involves an area of about 10 km2 with altitudes ranging from 750 m up to 2035 m a.s.l. The site is prone to rockfall events, which historically involved some hamlets and some sections of the valley main road. However, very little information on such events is available, and no indication can be obtained in terms of rockfall recurrence and involved volumes. Due to this, it was not possible to take into account temporal aspects and relative (spatial) risk maps were produced in this work.\nAll the analysis was carried out using open data available as web services and datasets from the Regione Piemonte GeoPortal:\n\u2022\tDTM with 5 m x 5 m raster resolution \u2013 GeoPortale Piemonte;\n\u2022\tOrthophoto AGEA 2018 \u2013 GeoPortale Piemonte;\n\u2022\tPiemonte Land Cover BDTRE (Base Dati Territoriale di Riferimento degli Enti) \u2013 GeoPortale Piemonte;\n\u2022\tvehicular mobility TGM (Traffico Giornaliero Medio) \u2013 GeoPortale Piemonte.\nThree rockfall design scenarios were identified regarding homogeneous rockfall source areas associated with different design block volumes. Each scenario included more than 3600 source points, extracted through the analysis of the DTM (slope and aspect) and the observation of the orthophoto for the identification of rocky outcrop zones. For each scenario, a quick estimation of a time-independent hazard was performed using the QGIS QPROTO plugin (Castelli et al, 2021). The plugin is based on the Cone Method (Jaboyedoff and Labiouse, 2011) and runs a visibility analysis through the r.viewshed GRASS GIS module, combined with simplified topographic, geomorphological and mechanical considerations. The result of the analysis is a series of raster maps with the distribution of computed values of velocity, energy, and relative spatial hazard.\nThe following step of the IMIRILAND procedure is the analysis of the damage, based on the collection of information on the exposed elements. To this aim:\n\u2022\tthe elements at risk were classified according to various Land Cover categories from BDTRE, associated with relative hierarchical values. Physical and social values were taken into account for each element. Physical value is mainly linked with the type of element and with the reconstruction costs while social value is linked to the presence of persons and the social utility of the asset;\n\u2022\tthe physical exposure of the elements at risk was defined for each hazard scenario with reference to the computed runout area. The social exposure was defined taking into account the time spent by people inside buildings or on the roads.\n\u2022\tthe physical vulnerability of the elements at risk was defined on the basis of the intensity of the phenomenon in terms of rockfall energy and the type of element. The social vulnerability is the same as the physical one inside buildings and is 100% outside buildings.\nPhysical and social damage maps were then obtained for each hazard scenario through the product of the value, the exposure and the vulnerability of the elements located in the involved area. Due to the lack of information on the temporal probability of occurrence of the scenarios, damage maps correspond to relative, time-independent, risk maps.\nThe results show that the highest risk is concentrated in the inhabited areas and some portions of the valley road, according to the few historical information available on the site.\nThe QPROTO plugin is available at the GIT repository of FAUNALIA (gitlab.com/faunalia/QPROTO) and can be easily used by professionals, public administrators, managers of roads, railways or infrastructures for land planning purposes or for preliminary analyses aimed at defining the most critical zone of a wide area, where resources and more in-depth analyses can be focused for mitigation purposes.\\n\\nmarta castelli\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/9SNJEH/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/01- Michael Maurizi.mp4", "persons": "Michael Maurizi, Daniel McGlone", "pretalx_id": "AXTEJZ", "title": "FOSS4G 2022 | DistrictBuilder, or how TopoJSON was the cause of and solution to all of our problems", "description": "DistrictBuilder (districtbuilder.org) is a web-based, open-source tool for collaborative political boundary redistricting or redistribution.\n\nIn order to support creating legally valid districts, DistrictBuilder allows advocates and legislators to define districts using geometries as small as a single census block, which are very numerous \u2013 a medium-sized state will have hundreds of thousands of them. Users can create districts from any combination of geometries, and we need to be able to generate statistics and dissolve them into district geometries in near real-time.\n\nBy reformatting our data as TopoJSON, a file format and Node.js library for working with topological data, we are able to dissolve over half a million census blocks into legislative districts in only a few seconds!\n\nI\u2019ll discuss how we use TopoJSON in DistrictBuilder; the issues we encountered when using it at scale in production and how we were able to overcome them; and the other tools we considered instead of TopoJSON and how they compared in terms of performance.\n\nI\u2019ll also go over our strategy for displaying and calculating metrics in real-time in the browser, using typed arrays and web-workers in combination with Mapbox vector tiles to do real-time aggregation of statistics from hundreds of thousands of features.\\n\\nMichael Maurizi\\nDaniel McGlone\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/AXTEJZ/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/02 - Nicholas Knize.mp4", "persons": "Nicholas Knize, PhD", "pretalx_id": "KPQ97A", "title": "FOSS4G 2022 | Geospatial Indexing with Apache Lucene and OpenSearch", "description": "Come have a look under the covers at the data structures that enable geospatial and multi-dimensional indexing and search at massive scale in Apache Lucene and OpenSearch. This talk will cover not only the indexing structures considered and ultimately implemented in the Apache Lucene Open Source Project but the exceptional performance improvements and centimeter spatial accuracy obtained in the latest release. As a bonus, this talk will cover new and upcoming Spatial Analysis Aggregations and Processing available in the OpenSearch Open Source project.\n\nFrom tessellation to multidimension encoding and block KD trees this talk will cover the algorithms and data structures written and committed to the following open source projects:\n\nApache Lucene (specifically the release of BKD based geo indexing https://issues.apache.org/jira/browse/LUCENE-8396)\nPerformance benchmarks for Lucene Spatial Indexing: https://home.apache.org/~mikemccand/geobench.html\n\nFinally, we will discuss the future of the project including existing and evolving support for custom coordinate reference systems and projections, spatial regression modeling and statistics, and spatial visualizations with OpenSearch Dashboards.\\n\\nNicholas Knize, PhD\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/KPQ97A/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/03 - Joris van den Bossche.mp4", "persons": "Joris van den Bossche", "pretalx_id": "BSY973", "title": "FOSS4G 2022 | Geospatial and Apache Arrow: accelerating geospatial data exchange and compute", "description": "The Apache Arrow (https://arrow.apache.org/) project specifies a standardized language-independent columnar memory format. It enables shared computational libraries, zero-copy shared memory, streaming messaging and interprocess communication without serialization overhead, etc. Nowadays, Apache Arrow is supported by many programming languages.\n\nGeospatial data often comes in tabular format, with one (or multiple) column with feature geometries and additional columns with feature attributes. This is a perfect match for Apache Arrow. Defining a standard and efficient way to store geospatial data in the Arrow memory layout (https://github.com/geopandas/geo-arrow-spec/) can help interoperability between different tools and enables us to tap into the full Apache Arrow ecosystem:\n\n - Efficient, columnar data formats. Apache Arrow contains an implementation of the Apache Parquet file format, and thus gives us access to GeoParquet (https://github.com/opengeospatial/geoparquet) and functionalities to interact with this format in partitioned and/or cloud datasets.\n - The Apache Arrow project includes several mechanisms for fast data exchange (the IPC message format and Arrow Flight for transferring data between processes and machines; the C Data Interface for zero-copy sharing of data between independent runtimes running in the same process). Those mechanisms can make it easier to efficiently share data between GIS tools such as GDAL and QGIS and bindings in Python, R, Rust, with web-based applications, etc.\n - Several projects in the Apache Arrow community are working on high-performance query engines for computing on in-memory and bigger-than-memory data. Being able to store geospatial data in Arrow will make it possible to extend those engines with spatial queries.\\n\\nJoris van den Bossche\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/BSY973/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/04 - Craig Taverner.mp4", "persons": "Jorge Sanz, Nick Peihl, Craig Taverner", "pretalx_id": "8N7RHW", "title": "FOSS4G 2022 | What\u2019s new in geospatial Elasticsearch", "description": "Elasticsearch (https://www.elastic.co/elasticsearch/) is a well-known and mature NoSQL database providing search and analytics services for big datasets. The \u201celasticity\u201d of its name comes from the distributed design and easy scalability capabilities that have made it an industry leader for more than ten years. In this talk we will present two exciting new features that have been added recently to the product related with the geospatial topic: vector tiles support and line and hexagon aggregations.\n\nVector tiles have become an industry standard to encode large amounts of data to be displayed in the browser by web mapping libraries like MapLibre or OpenLayers. Elasticsearch analytics & geo team has added a new API endpoint (https://www.elastic.co/guide/en/elasticsearch/reference/current/search-vector-tile-api.html) that renders search and aggregation queries as zipped protobuffers (https://developers.google.com/protocol-buffers), allowing developers to retrieve right from the datastore assets that are ready to be sent to the user's browser without much further processing. This will speed up the rendering of large datasets by avoiding transferring JSON assets from Elasticsearch to application middleware.\n\nElasticsearch geospatial aggregation capabilities have been extended recently by two new methods, one is to allow combining related points into a new line geometry (https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-metrics-geo-line.html) (think of a vehicle track) and the other is to aggregate geometries into an hexagon grid (https://www.elastic.co/guide/en/elasticsearch/reference/8.1/search-aggregations-bucket-geohexgrid-aggregation.html). The new geo-line aggregation will be very useful for asset tracking use cases where the second enables Elasticsearch to perform powerful analytics combined with the extensive support for metric aggregations.\n\nIn this talk we will present this project, going through the different use cases with some examples and demonstrations using both Kibana Elastic Maps (https://www.elastic.co/maps) and a simple ad-hoc web project that leverages this new feature.\\n\\nJorge Sanz\\nNick Peihl\\nCraig Taverner\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/8N7RHW/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/05 - Pirmin Kalberer.mp4", "persons": "Pirmin Kalberer", "pretalx_id": "US3PDH", "title": "FOSS4G 2022 | Spatial data processing with workflow engines", "description": "Workflow engines like Apache Airflow are commonly used in data engineering nowadays. They provide an infrastructure for setting up, executing and monitoring a defined sequence of tasks, arranged as a workflow application. Tasks and dependencies are defined in a declarative way or in a programming language like Python. Airflow established using directed acyclic graphs (DAGs) to manage workflow orchestration.\n\nThis talk compares a selected subset out of the huge number of available Open Source workflow engines, which are especially suited for workflows containing spatial data processing. It compares the well known Apache Airflow engine with Dagster, an other solution using DAGs and a BPMN-based workflow engine using Celery as distributed task queue.\n\nIn the same space there is the new OGC API - Processes standard which is a modern REST API for wrapping computational tasks into executable processes. This talk gives an overview of the API and shows possible integrations with available workflow engines.\\n\\nPirmin Kalberer\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/US3PDH/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/06 - Borja Mu\u00f1oz.mp4", "persons": "Borja Mu\u00f1oz, Ernesto Mart\u00ednez Becerra", "pretalx_id": "TLJESF", "title": "FOSS4G 2022 | A new SQL library to enable spatial analytics in Spark", "description": "In this talk, we'll review the major milestones that have defined Spatial SQL as the powerful tool for geospatial analytics that it is today.\n\nFrom the early foundations of the JTS Topology Suite and GEOS and its application on the PostGIS extension for PostgreSQL, to the latest implementation in Spark SQL using libraries such as the CARTO Analytics Toolbox for Databricks, Spatial SQL has been a key component of many geospatial analytics products and solutions, leveraging the computing power of different databases with SQL as lingua franca, allowing easy adoption by data scientists, analysts and engineers.\n\nThe CARTO Analytics Toolbox is a comprehensive library that provides advanced geospatial functionality through Spark SQL. It enables Spatial SQL analytics at scale providing the foundational tools for analyzing and visualizing geospatial data.\n\nIn this talk we'll cover the technical aspects of the library implementation using Open Source technologies, as well as demonstrating the installation and practical usage with a real-life example.\n\nOur talk will go through some of the geospatial operations that can be performed directly in Spark and we will demonstrate how users of the Analytics Toolbox can create beautiful map visualizations leveraging the latest Open Source rendering tools; and how to address a wide variety of spatial use cases using other products built on top of open source technologies, like CARTO and Databricks.\\n\\nBorja Mu\u00f1oz\\nErnesto Mart\u00ednez Becerra\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/TLJESF/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/07 - Daniel J. Dufour.mp4", "persons": "Daniel J. Dufour", "pretalx_id": "3JQNXL", "title": "FOSS4G 2022 | State of GeoBlaze: A Blazing Faster Raster Analysis Engine in Pure JavaScript", "description": "*GeoBlaze (https://geoblaze.io)* is a blazing fast raster analysis engine written in pure JavaScript.  With geoblaze, you can run computations ranging from basic statistics (min, max, mean, median, and mode) to band arithmetic and histogram generation in either a web browser or a node application.\n\n### presentation\n\nThis presentation will go over recent updates to GeoBlaze, including the addition of support for Cloud-Optimized GeoTIFFs.  We will also discuss the roadmap for the next couple years.\n\n### use cases\n\nGeoBlaze can be used wherever vectors and rasters meet.  You can use it to calculate the hectares of wheat in a country, the change in daily median earth temperature, and identify wildfires in satellite imagery.\n\n### environment\n\nBecause GeoBlaze is written in pure JavaScript it can be run in various environments, on an EC2 server, Lambda function, Cloudflare worker, or in the browser.  It performs calculations using the CPU, so it is not restricted only to environments where a GPU is available.\n\n### notable dependencies\n\nGeoBlaze is built on top of the following open-source projects: dufour-peyton-intersection (https://github.com/GeoTIFF/dufour-peyton-intersection), georaster (https://github.com/geotiff/georaster), geotiffjs (https://github.com/geotiffjs/geotiff.js),  and calc-image-stats (https://github.com/danieljdufour/calc-image-stats).\n\n### sample notebooks:\n\n - Time Series Analysis with GeoBlaze: Mean Daily Air Temperature for the Month of May: https://observablehq.com/@geosurge/time-series-analysis-with-geoblaze-mean-daily-air-temperat\n - Identifying Carr Wildfire with Landsat 8: https://observablehq.com/@geosurge/identifying-carr-wildfire-with-landsat-8\n - Hectares of Rainfed Wheat in Ukraine: https://observablehq.com/@danieljdufour/hectares-of-rainfed-wheat-in-ukraine\\n\\nDaniel J. Dufour\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/3JQNXL/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/08 Nicolas Rochard.mp4", "persons": "Nicolas Rochard", "pretalx_id": "7MKQK7", "title": "FOSS4G 2022 | The benefits of COG (Cloud Optimized GeoTIFF) outside the cloud", "description": "This is a technical feedback about why the COG (Cloud Optimized GeoTIFF) format is valuable outside the cloud and can speed up productivity in many ways.\n\nDuring first months, remote work and COVID, IT department was overbooked and has to face to many issue such bandwidth limitation. Images display was suffer in GIS client. Of course, webservice was always available but user has to control on band order or radiometry settings. WCS is supposed to be the solution. Unfortunately, it offered degraded performance.\n\nCOG is supposed to be serve from HTTP server or S3. But we\u2019ve simply test from a network drive / mount point and it offer great performance. Depending internet connection, it could be as fast as it is in local !\nCOG advantage must be consider outside of the cloud as remote work tends to develop more and more. It could avoid to deploy heavy webservice infrastructure for only raster visualization.\n\nFrom other side, benchmark between publish some other format compare to COG in GeoServer. From Regional Data Infrastructure, it\u2019s streamline storage data between raster format as input file for webservices and opendata raw downloading services as open archives.\n\nFinally, I will give some feedback and tips and tricks to find best parameters to convert orthophotography, DEM or DSM, etc. to COG.\\n\\nNicolas Rochard\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/7MKQK7/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/09 Jerome St-Louis.mp4", "persons": "Jerome St-Louis", "pretalx_id": "GRNXGG", "title": "FOSS4G 2022 | Update on Modular OGC API Workflows specifications", "description": "Update on the status of OGC API standards and draft specifications enabling client-driven execution of processing workflows, supporting on-demand and ad-hoc selection of data and algorithms. Overview of the capabilities enabled by OGC API - Tiles, OGC API - Coverages and Processes \u2013 Part 3: Workflows and Chaining. Demonstration of both a server and a client implementing these specifications.\n\nThe Workflows and Chaining draft extension specification to OGC API \u2013 Processes enables ad-hoc execution of workflows integrating processes and data available from one or more OGC API instances. The specification allows triggering processing as a result of requesting results for a specific area and resolution of interest, which provides a simple mechanism to chain geospatial data inputs and outputs.\n\nBy referring to a collection of geospatial data irrespective of a particular area, resolution or date/time of interest, workflows can be defined in a generic, re-usable manner, and processing can be performed on-demand rather than (or in addition to) as a batch execution. Such on-demand processing has the advantage of optimizing the use of computing resources and speeding up the availability of the latest available data, such as for continuously captured Earth Observation satellite imagery.\n\nThe initial version of the Workflows and Chaining specification was a result of a GeoConnections 2020-2021 project funded by Natural Resources Canada, which also supported the development of a unified OGC API driver in GDAL allowing to directly visualize the results of such workflows in QGIS.\n\nOGC API \u2013 Tiles is the specification succeeding to WMTS in the OGC API family, leveraging the concept of 2D Tile Matrix Sets. In addition to providing tiles of maps or imagery, Tiles can also be used to distribute raw data tiles, including coverage and vector tiles. Using tiles to deliver results and trigger execution of processing workflows can facilitate caching while allowing to efficiently select an area and resolution of interest.\n\nOGC API \u2013 Coverages is the specification suceeding to WCS in the OGC API family, and provides a simple mechanism to request an optionally down-sampled subset of a coverage. Specific fields (e.g. imagery band) can be selected as needed. The Coverages specification can also be used to request results while triggering execution of a workflow.\\n\\nJerome St-Louis\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/GRNXGG/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/10 Tom Kralidis.mp4", "persons": "Tom Kralidis, Benjamin Webb, David Berry", "pretalx_id": "3WRSHK", "title": "FOSS4G 2022 | Introducing WIS 2.0 in a box: an open source and open standards platform for international weather, climate and water data discovery, access, and visualization", "description": "The World Meteorological Organization (WMO) Information System (WIS) is a coordinated global infrastructure responsible for telecommunications and data management functions and is owned and operated by WMO Members.\n\nWIS 2.0 will provide users with seamless access to diverse information from a wide range of sources and will enable weather, water and climate information to be related to socioeconomic and other contexts. Through an open ecosystem of tools, applications and services, WIS 2.0 will allow all information providers to manage, publish and share their data, products and services, and will allow all users to develop value-added services and new products.\n\nThe WIS 2.0 principles highlight and promote the value of standards, interoperability and the Web/mass market. This will extend the reach of weather/climate/water data for a number of societal benefits.\n\nWIS 2.0 is being designed to have a low barrier to entry for data providers. This will also result in enabling infrastructure and provide great benefit for less developed countries (LDCs). There is a strong motivation to provide LDCs easy to use tools and sustainable workflow for data exchange to 1./ ease the burden of exchanging data 2./ continue to provide valuable weather/climate/water data in WIS 2.0 over time.\n\nThe WIS 2.0 in a box (wis2box) project enables LDCs free and open source onboarding technology to integrate their data holdings and publish them to WIS 2.0 in a manner consistent with the architecture for plug and play capability, supporting discovery, access and visualization.\n\nThis presentation will provide an overview of the project and current capabilities highlighting the use of numerous FOSS4G tools and PubSub driven implementation of OGC API standards.\\n\\nTom Kralidis\\nBenjamin Webb\\nDavid Berry\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/3WRSHK/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/11 Andreas Neumann.mp4", "persons": "Andreas Neumann", "pretalx_id": "XEZ8HX", "title": "FOSS4G 2022 | Designing dynamic forms in QGIS Desktop with expressions", "description": "This presentation will show tips and tricks how to design dynamic and relatively complex forms in QGIS desktop - with the help of the drag and drop form designer, widget configurations, dynamic expressions, data-defined widget visibility, default values, constraints, embedded forms, relations, actions and more. In addition, we will show how you can use spatial joins from other layers to automatically fill in data from independent but spatially related layers.\n\nYou will be walked through an application developed for the management of biodiversity subsidies in the Kanton of Solothurn, Switzerland. The application allows to collect data from eligible areas in the canton's biodiversity programme. Farmers and foresters can apply for separate subsidies for biodiversity support if the areas and their management methods meet certain criteria. The QGIS based application allows to collect data, automatically assigns parcel numbers, place names, community names, etc. and allows to define usage restrictions and record maintenance measures. Interfaces exist for a reporting generator (contract generation) and an SAP based disbursement system for the payment of subsidies.\n\nIn the presentation we will present the result of the development work and show some tips and tricks with forms, widgets, expressions and actions and how we stitched everything together.\\n\\nAndreas Neumann\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/XEZ8HX/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/12 - Sanweli Mwakisambwe.mp4", "persons": "Samweli Mwakisambwe", "pretalx_id": "FCYQXJ", "title": "FOSS4G 2022 | QGIS Temporal Controller with WMS-T layers", "description": "QGIS is a freely downloadable open source GIS software suite that contains a desktop option, mobile, and web component. QGIS is free to download and use, it is released with a GPL v3 license which is a non commercial license allowing users to download and use it without concerns compared to other commercial GIS software.\nUp to QGIS version 3.12 there was no core support for temporal data, users were required to install a plugin called TimeManager in order to visualize temporal data inside QGIS. Through a collaboration between the Canadadian Government, Kartoza and North Road, efforts were made to add core support for temporal data inside QGIS.\nAs a result the QGIS version 3.14 was released with a Temporal Controller feature which was now responsible for handling all the temporal layers inside QGIS. The initial role out of the Temporal Controller contained support for raster, vector and WMS-T layer providers.\nThis session will explore how to use the QGIS Temporal Controller to do animation and visualization of the WMS-T layers, this will include how to setup a standard WMS server that will be serving time based layers.\nIn the session we will also learn about the Temporal Controller API, how to use it through QGIS python bindings and create a simple QGIS plugin that will show the API in action.\\n\\nSamweli Mwakisambwe\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/FCYQXJ/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/13 Stefano Campus.mp4", "persons": "Stefano Campus", "pretalx_id": "MFAVFU", "title": "FOSS4G 2022 | A Python tool for QGIS for gender recognition in street directories", "description": "In the last years the attention for gender equality in all context has increased all over the world.\nNowadays the sensibility of Public Administrations towards the naming of streets, roads, squares and monuments after women has highlighted that, instead, the toponymy has always been oriented to the choice of male figures.\nIn this work we present a Python script for QGIS, that allows to verify if a proper name, contained in a street directory, is of male or female gender.\nThere are other Open Source projects that, starting from an address, verify the gender of the represented person; the most famous is the GeoChicas Project [1]; in Italy it is worth mentioning the \"Toponomastica Femminile\" Association [2] that manually verifies the streets dedicated to women, according to a predefined taxonomy (religious women, artists, etc.).\nThe goal of the present work is to automate the gender reconnaissance starting from a list of names; however, unlike GeoChicas that use as a base parameter a dictionary of names with which to compare the list, we propose to make a query of DBpedia via SPARQL in order to identify the subject and derive its gender.\nIf the address is the attribute of a spatial dataset, then it is possible to add a new attribute (the gender) to the vector layer table as a result of DBpedia query.\nThis approach overcomes language limitations (which would require differentiated dictionaries) and the ambiguities that some names would have (for example the nome \"Andrea\" is used as both a masculine and feminine name).\nThe script is created using the SPARQL language with a very simple structure, in which the triplet of data is constructed in order to obtain the gender from the name of a person through the query of DBpedia.\nThe script can be run in QGIS environment associating the data outputs directly to the geometry or even outside of QGIS and as a result you will have a list of \"genders\".\nThe process of relying on Wikipedia/DBpedia has the twofold advantage that, where the name dedicated to street exists, then the desired information is taken, the gender in our case, while if it missing it can be added or enriched.\nThe script is currently under validation and will be published in the dedicated git repository [3].\n\n[1] https://github.com/geochicasosm\n[2] https://www.toponomasticafemminile.com\n[3] https://github.com/skampus/toponomasticafemminile\\n\\nStefano Campus\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/MFAVFU/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/14 Nicolas Boisteault.mp4", "persons": "Boisteault Nicolas", "pretalx_id": "VVXS3Q", "title": "FOSS4G 2022 | Advanced QGIS forms into the web with Lizmap", "description": "You would like many people from your team or crowdsourcing to fill data in your geodatabase. One way to do that is to make appealing, easy to use and well-constructed forms avoiding wrong inputs. Also, you do not want people to give up filling because the form is too long while in the same time you could automatically fill some entries based on others. With QGIS Desktop, it is possible to make great maps but also advanced forms by using expressions to control field visibility, default values, proposed values, constraints and more. It is very powerful but now how to share those forms to anybody whatever their device or operating system? Could it be possible to share a link for people to open and fill those forms in their web browser?\nLet\u2019s see how you can get most of these features for your forms in web browsers thanks to QGIS Server and Lizmap.\\n\\nBoisteault Nicolas\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/VVXS3Q/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/15 Etienne Trimaille.mp4", "persons": "Matteo Ghetta, Etienne Trimaille", "pretalx_id": "9DWW3N", "title": "FOSS4G 2022 | Dataviz in QGIS and on the web", "description": "#### QGIS and Dataviz\n\nCreating plots is out of the main scopes of QGIS but thanks to the simple Python API, it is easy enough to create additional scripts and plugins. The DataPlotly plugin has been developed for QGIS(the first release was created in 2017 while nowadays the plugin has been downloaded more than 100,000 times). It's today a well maintained Python plugin with a growing community of developers, users and testers.\n\nDataPlotly allows creating D3 like plots from spatial data. It is build on top of Plotly.com, a JavaScript library which offers an easy API for many languages such as Python, R, Matlab etc.\n\nThe plots are completely interactive so that plot elements are directly linked with map items; therefore the user is able to query map items from the main plot canvas. Thanks to a crowdfunding campaign, the functionalities of DataPlotly were extended: a complete refactoring of the code, more plots but especially the creation of plots in the layout composer, also for atlas layouts.\n\nThe plugin is also compatible for QGIS server. Lizmap Web Client is an opensource server application to publish QGIS project on the web without any coding skills needed. It\u2019s using QGIS Server in the backend so users have the same rendering between their QGIS Desktop and the web version of their project.\nThanks to the DataPlotLy plugin installed on QGIS Server and to the Lizmap application, it allows users to print PDF with plots from in their web-browser.\\n\\nMatteo Ghetta\\nEtienne Trimaille\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/9DWW3N/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/16 Amy Burness.mp4", "persons": "Amy Burness", "pretalx_id": "WL9KWS", "title": "FOSS4G 2022 | QGIS and Community: The QGIS Open Day", "description": "The QGIS Open Day are organised on the principle of self-organisation and community participation. The monthly sessions are open to anyone in the opensource community and cover various topics from presenting new developments and releases, tutorial style work-flows and interactive open sessions.\nIn the year the channel has been active, QOD has generated over 50 videos obtained 4000 subscribers and on average QOD channel receives Approximately 5000 views each month. Most QOD viewers are from the United States, Germany, India, France and the UK and 94% of QOD viewers are male. The most popular video on the channel is \u201cA geological map work-flow in QGIS with Chris Lambert with\u201d 5277 views.\nLooking forward, the QOD channel aims to be the official platform to show the functionality of the new QGIS releases, plugins, work-flows, and opensource GIS platforms. The channel aims to increase support, viewership and participation from a wider, more diverse audience and encourage different regions to contribute. Join the QOD community and let\u2019s learn from each other.\\n\\nAmy Burness\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/WL9KWS/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/17 Robert Coup.mp4", "persons": "Robert Coup", "pretalx_id": "W8AY8A", "title": "FOSS4G 2022 | QGIS Data Versioning with Kart", "description": "Maybe you've heard of Kart (https://kartproject.org), the great new geodata versioning tool from the team at Koordinates? But did you know that Kart also has a QGIS plugin so you can do _real_ data versioning without needing to leave QGIS?\n\nIn just 5 minutes we'll demonstrate how to import data into a new Kart repository, make and review some changes, merge a branch, and push everything to a remote server. All from QGIS!\n\n\u2014\n\nWe\u2019re drowning in data, but the geospatial world lags badly behind in versioning tools compared to our software counterparts. Kart (https://kartproject.org) is solving this with a practical open tool for versioning datasets, enabling you to work more efficiently and collaborate better.\n\nKart allows you to quickly and easily manage history, branches, data schemas, and synchronisation for large & small datasets between different working copy formats, operating systems, and software ecosystems.\n\nModern version control unlocks efficient collaboration, both within teams and across organisations meaning everyone stays on the same page, you can review and trace changes easily: ultimately using your time more efficiently.\\n\\nRobert Coup\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/W8AY8A/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/18 - Krishna Lodha.mp4", "persons": "krishna lodha", "pretalx_id": "BJFCHK", "title": "FOSS4G 2022 | Creating GIS Rest APIS using Geodjango under 30 minutes", "description": "We're living in the world of APIs. CRUD operations are base of lot of operations. Many smart frameworks such as Django, Flask, Laravel provides out of the box solutions to filter the data, which covers almost all needs to separate data based on column values.\nWhen it comes to Geospatial data, we expect to filter data based on their location property instead of metadata. This is where things get complicated, if you are using framework that doesn't have package, library built to handle such use cases, you are likely to be dependent on either database or any external package to handle it.\n\nFortunately Geodjango[https://docs.djangoproject.com/en/4.0/ref/contrib/gis/] (Django's extension) allows us to create databases which understands geometry and can process it[https://docs.djangoproject.com/en/4.0/ref/contrib/gis/geoquerysets/#gis-queryset-api-reference]. It also provides support to write APIs using Rest Framework extension [https://pypi.org/project/djangorestframework-gis/] which takes this to next level allowing user to output the data in various formats, creating paginations inside geojson, create TMSTileFilters, etc.\n\nIn this talk we'll scratch the surface of this python package and see how to build basic CRUD APIs to push, pull GIS data along with filtering it to the PostgreSQL database\\n\\nkrishna lodha\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/BJFCHK/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/19- Casper Van der Wel .mp4", "persons": "Casper van der Wel", "pretalx_id": "B8JZTD", "title": "FOSS4G 2022 | Agile Geo-Analytics: Stream processing of raster- and vector data with dask-geomodeling", "description": "We present _dask-geomodeling_: an open source Python library for stream processing of GIS raster and vector data. The core idea is that data is only processed when required, thereby avoiding unnecessary computations. While setting up a dask-geomodeling computation, there is instant feedback of the result. This results in a fast feedback loop in the (geo) data scientist\u2019s\u2019 work. Big datasets can be processed by parallelizing multiple data queries, both on a single machine or on a distributed system.\n\n### Abstract\n\nIn geographical information systems (GIS), we often deal with data pipelines to derive map layers from various datasets. For instance, a water depth map is computed by subtracting the digital elevation map (DEM) from a water level map. These procedures are often done using open source products such as PostGIS and QGIS. However, for medium to large datasets (> 10 GB) the extent of these analyses are costly due to memory restrictions and computational cost. As a rule, these issues are tackled by manually cutting the dataset into smaller parts. However, this is a tedious and time-consuming task. In case one needs to this regularly, this is not feasible.\n\nWe present the open source Python library _dask-geomodeling_ [1] to solve this issue. Instead of a script, dask-geomodeling requires a so-called \u201cgraph\u201d, which is the definition of all operations that are required to compute the derived dataset. This graph is generated by plain Python code, for instance:\n\n```\nplus_one = RasterFileSource('path/to/tiff') + 1 \n```\n\nNote that these operations are lazy: there is no actual computation done and therefore the above line executes fast. Only when actual data is requested:\n\n```\nplus_one.get_data( \n    bbox=(155000, 463000, 156000, 464000), \n    projection='epsg:28992', width=1000, height=1000 \n)\n```\n\nAn array containing the data is computed. No need to load the whole TIFF-file in memory if you only use a small part!\n\nThe computation occurs in two steps. First, a computational graph is generated containing the required functions. While generating the computational graph, the operations may be chunked into smaller parts. Second, this graph is evaluated by _dask_ [2], using any scheduler (single thread, multithreading, multiprocessing, distributed) that is provided dask.\n\nThis library is open source under the name \u201cdask-geomodeling\u201d and is distributed on Github, PyPI, and Anaconda. A hosted cloud version is also available under the name Lizard Geoblocks [3]. Currently, we have implemented a range of operations for rasters, vectors, and combinations. The community is welcome to use our library, benefit from it, and expand it!\n\nReferences\n\n 1. dask-geomodeling, https://github.com/nens/dask-geomodeling, https://dask-geomodeling.readthedocs.io/\n 2. dask, https://dask.org/\n 3. Lizard Geoblocks, https://lizard.net/\\n\\nCasper van der Wel\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/B8JZTD/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/20 Nicolas Nar\u00e7on.mp4", "persons": "Nicolas Nar\u00e7on", "pretalx_id": "YK3V9E", "title": "FOSS4G 2022 | pyotb: a pythonic extension of Orfeo ToolBox", "description": "Orfeo ToolBox (OTB) is an open-source project for state-of-the-art remote sensing, made for large-scale image processing. It is written in C++ and a Python interface is available. However, the use of plain OTB in Python requires a lot of code; more than what a Python user is used to!\n\npyotb aims at making the use of Orfeo ToolBox easy in Python. In this talk, discover:\n\n - how to run any application of OTB in just one line of code\n - how to build complex processing chains containing several applications in an intuitive way.\n - how to interact easily with NumPy and Tensorflow.\n - some pythonic features made for user convenience.\n - some functions written to mimic the behavior of some well-known NumPy functions: `pyotb.where`, `pyotb.clip`, `pyotb.all`, `pyotb.any`... and counting!\n\nOTB has an amazing pool of applications and can run on all types of computers: from resource limited laptops to high performance clusters. With pyotb, unleash the power of OTB in Python!\n\nWe will make you love the way you can use OTB in Python. You can find more info on the project on the pyotb repository: https://gitlab.orfeo-toolbox.org/nicolasnn/pyotb\\n\\nNicolas Nar\u00e7on\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/YK3V9E/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/21 Seth Hosteter.mp4", "persons": "seth hosteter", "pretalx_id": "WY8NQP", "title": "FOSS4G 2022 | Building a data analytics library in Python", "description": "The Data Operations Systems and Analytics team at NYC DOT\u2019s primary mission is to support the data analysis and data product needs relating to transportation safety for the Agency. The team\u2019s work producing safety analysis for projects and programs typically involves merging data from a variety of sources with collision data, asset data, and/or program data. The bulk of the analysis is performed in PostgreSQL databases all with a geospatial component. The work necessitates ingesting input data from other databases, csv/excel files, and various geospatial data formats. It is critical that the analysis be documented and repeatable.\n\nMoving data around, getting external data into the database, transforming it, geocoding it etc., previously occupied the bulk of the team\u2019s time before, reducing capacity for the actual analysis. Additionally the volume of one-off and exploratory analyses resulted in a cluttered database environment with multiple versions of datasets with unclear lineage and state of completeness.\nModeled on the infrastructure as code idea, we began building a python library that would allow us to preserve the entire analysis workflow from data ingestion to analysis and to output generation in a single python file or Jupyter notebook.  The library began as a way to reduce the friction and standardize the process of ingesting external data into the various database environments utilized. It has since grown into the primary method to facilitate reproducible data analysis processes that includes the data ingestion, transformation, analysis, and output generation.\n\nThe library includes basic database connections, and facilitates quick and easy import and export from flat files, geospatial data files, and other databases. It provides both inferred and defined schemas, to allow both quick exploration and more thoroughly defined data pipeline processes.  The library includes standardization of column naming, comments, and permissions. There are built in database cleaning processes, geocoding processes, and we have started building simple geospatial data display functions for exploratory analysis. The code is heavily reliant on numpy, pandas, GDAL/ogr2ogr, pyodbc, psycopg2, shapely, and basic sql and python. The library is not an ORM, but occupies a similar role, but geared towards analytic workflows.\n\nThe talk will discuss how the library has evolved over time, the functionality and use cases in the team\u2019s daily workflows as well as where we would like to extend the functionality and open it up for contributions.  While the library is not currently open source, we are actively working on creating an open version and migrating to Python 3.x. This library has greatly improved the speed and simplicity of conducting exploratory analysis and enhanced the quality and completeness of the documentation of our more substantial data analytics and research.\nThe library should be of interest and utility for anyone working with data without the support of a dedicated data engineering team to facilitate the collection of multiple datasets from a variety of formats, as well as anyone looking to standardize their data analysis workflows from beginning to end.\\n\\nseth hosteter\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/WY8NQP/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_4/22 Sixten Maximillian Thestrup.mp4", "persons": "Sixten Maximillian Thestrup, Elise Stenholt S\u00f8rensen, Erin Stein", "pretalx_id": "HB7QW8", "title": "FOSS4G 2022 | Not too big, not too small: open source geospatial units that are just right", "description": "Publicly available data tends to be spatially aggregated to administrative units, limiting the feasibility of nuanced analyses that reflect the natural state of communities and provide actionable insights for a wide range of stakeholders. While higher resolution data is generally available within government agencies, access for external researchers is limited due to well-established privacy concerns. Inspired by our own use case of developing a regional quality of life metric for neighborhoods in Denmark, our team at Aalborg University\u2019s Department of the Built Environment, in collaboration with data.org\u2019s Growth and Recovery Challenge, and Data Clinic, set out to develop and open source not only foundational granular spatial units and data that adhere to privacy laws, but also the accompanying methodology that has the potential for broad applicability in other countries.\n\nIn this presentation, we will demonstrate the methodology\u2019s generalizability, particularly across common European land use and geographical features, and show how the resulting high-resolution shape files and community data can become crucial tools for government decision-makers, community organizations, and researchers in their efforts to increase transparency and engage in practical, actionable research.\n\nFocused initially on our Denmark use case, we algorithmically create spatial units with minimum household and population counts from country-wide hectare cell level data. Our approach uses data on road networks and administrative boundaries to create socially meaningful component polygons. This is achieved by developing tools based on already existing open source packages available in R and Python. The hectare cells are then mapped onto the polygons and clustered using the max-p regionalization algorithm with constraints on the minimum population and household counts to arrive at the final set of spatial units.\n\nTo improve the accessibility of this data to not just researchers but also administrative decision-makers, community organizations, and the general public, we are developing an online tool to explore and visualize indicators within the resulting fine-grained regions such as disposable income, educational level, housing prices, migration rates, distances to public institutions, and labor market attachments in Denmark. Regional inequality in Denmark has increased over time, and with the help of this tool, we hope to provide the ability to study these key metrics both within and across municipal regions. In the development of the tool, we prioritize user feedback and common use cases to ensure both applicability and longevity.\n\nThis project has been developed with an open-source mindset by: 1) creating flexible open data resources that can adapt to a wide range of public use cases 2) open sourcing the methodology for use in other countries/regions and 3) enabling the use of existing open data and tools such as Open Street Maps, R and Python in the pipeline.\n\nWe firmly believe that the project has the potential to improve knowledge sharing and collaboration between GIS experts, decision-makers, researchers and the general public not only in Denmark, but also in Europe and beyond.\\n\\nSixten Maximillian Thestrup\\nElise Stenholt S\u00f8rensen\\nErin Stein\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/HB7QW8/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/1 Mark Varley.mp4", "persons": "Mark Varley", "pretalx_id": "EBQARM", "title": "FOSS4G 2022 | Aggregating risk with H3 and PostGIS", "description": "In this talk we will look at how PostGIS and Uber's H3 index can be used for aggregating large amounts of data, in our case property insurance risk, in real-time.  We will explore a number of different techniques from the H3 PostGIS extension generating GeoJSON, to generating MVTs from the database to pre-caching the H3 index and painting a vector tile layer client side.  For our client side layer will use a React JS interface, Maplibre and will also look at Deck.GL for more advanced use cases.  We will discuss how the stack can be deployed using a serverless architecture running on AWS Lambda and Aurora Serverless Postgres.\n\nThis talk requires no prior knowledge however some experience with PostGIS and vector tiles will be useful.  You will learn techniques which can be applied to any problem domain where there is the need to work with data volumes where processing individual points would not be practical.\\n\\nMark Varley\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/EBQARM/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/2 Sarah Hoffman.mp4", "persons": "Sarah Hoffmann", "pretalx_id": "NRSLYC", "title": "FOSS4G 2022 | Building a Geocoder on top of PostGIS - a Field Report", "description": "It seems to be conventional wisdom that a search engine for geodata is best implemented with a text search engine like OpenSearch or Solr. Most of available open-source geocoders follow that wisdom. Nominatim is the odd one out. OpenStreetMap's main geocoder was originally developed 12 years ago as a proof of concept that a geocoder can be efficiently implemented on top of a PostgreSQL/PostGIS database. Since then it has grown into mature project. And so have the PostgreSQL database and the OpenStreetMap project.\n\nIn this talk, I will share some of the experiences of working with PostGIS on a growing OpenStreetMap dataset. The talk starts with a quick overview about what the Nominatim database looks like under the hood. It then goes on to present some of the lessons we have learned over the last 10 years on managing a PostGIS database with more than 270 million searchable places. We talk about features that improved performance and about some that are best avoided. The talk concludes with some general observation about implementing search on top of an SQL database.\\n\\nSarah Hoffmann\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/NRSLYC/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/3 Taro Ubukawa.mp4", "persons": "Taro Ubukawa, Gakumin Kato, Akbar Amini", "pretalx_id": "VEXSFH", "title": "FOSS4G 2022 | United Nations Mission in South Sudan GeoStories", "description": "The United Nations Mission in South Sudan (UNMISS) is a United Nations peacekeeping mission for South Sudan, which became independent on 9 July 2011. UNMISS was established on 8 July 2011 by United Nations Security Council Resolution 1996 (2011) and as of March 2021, it is composed of 19,075 total deployed personnel including 14,222 troops; 217 experts on mission; 1,446  police personnel; 2,228 civilians; 387 staff officers and 388 UN Volunteers, where, it is headquartered in the South Sudanese capital of Juba.\n\nUnder Chapter VII of the Charter of the United Nations, UNMISS is therefore authorized to use all necessary means to implement its mandate which includes:\n(a) Protection of civilians\n(b) Creating conditions conducive to the delivery of humanitarian assistance\n(c) Supporting the Implementation of the Revitalized Agreement and the Peace Process\n(d) Monitoring, investigating, and reporting on violations of humanitarian and human rights law\n\nThe mission has decided to extend its public outreach activities in a different method by utilizing geospatial information and using open geospatial tools and data for showcasing some of its important activities in support of above-mentioned mandates, and for this purpose contracted a service provider through bidding exercise and procurement protocols.\n\nIn this general session talk, speaker(s) will give their presentations on below topics:\n\n - UN Open GIS Initiative Background\n - UNMISS GeoStories architecture, FOSS4G tools and data\n - Preventing mis/dis-information by extending public outreach\n - Review selected Geostories in support of UNMISS mandate\\n\\nTaro Ubukawa\\nGakumin Kato\\nAkbar Amini\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/VEXSFH/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/4 Stefan Brand.mp4", "persons": "Stefan Brand", "pretalx_id": "NBAABN", "title": "FOSS4G 2022 | Geo-Infographics created dynamically from PostGIS using ST_AsSVG", "description": "## The Problem\n\nLet's assume you have an attribute-focused table, but you would still like to see a thumbnail of the associated geometry. Or more generally: How to dynamically render polygon geometries in a HTML page without any mapping library. *Enter ST_AsSVG (PostGIS function)!*\n\n## Context\n\nLast year I showed how we display geo data in our webapps using vector tiles (ST_AsMVT) (https://www.youtube.com/watch?v=s_dWBOiuFiY&amp;t=139s). This year I will explain how we apply ST_AsSVG of PostGIS on database records to *create beautiful geo-infographics* in pure HTML. The result is a geo-visualization similar to this one: Comparison maps of Australian Cities (Size, Population) (https://imgur.com/OQClpbc). The trickiest part will be the sizing of the SVG objects (viewport vs. viewBox (https://webdesign.tutsplus.com/tutorials/svg-viewport-and-viewbox-for-beginners--cms-30844)).\n\n## Content\n\nThe talk will contain some theory on SVG. It will then show basic setups for FastAPI, SQLModel, Jinja2 and, of course, PostGIS. All code will be made available via GitHub.\n\n## Aim\n\nAfter the talk you will master sizing of SVG and be capable of creating your own dynamic geo-infographics directly from data stored in your PostGIS database.\\n\\nStefan Brand\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/NBAABN/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/5 Lars Opsahl.mp4", "persons": "Lars Opsahl", "pretalx_id": "9G3YGD", "title": "FOSS4G 2022 | Data integrity risks when using simple feature", "description": "When you care about data integrity of spatial data you need to know about the limitations/weaknesses of using simple feature datatype in your database. For instance https://land.copernicus.eu/pan-european/corine-land-cover/clc2018 contains 2,377,772 simple features among which we find 852 overlaps and 1420 invalid polygons. For this test I used \u201cESRI FGDB\u201d file and gdal for import to postgis.  We find such minor overlaps and gaps quite often, which might not be visible for the human eye. The problem here is that it covers up for real errors and makes difficult to enforce database integrity constraints for this.  Close parallel lines also seems to cause Topology Exception in many spatial libraries.\n\nA core problem with simple features is that they don't contain information about the relation they have with neighbor features, so integrity of such relations is hard to constraint. Another problem is mixing of old and new data in the payload from the client. This makes it hard and expensive to create clients, because you will need a full stack of spatial libraries and maybe a complete locked exact snapshot of your database on the client side. Another thing is that a common line may differ from client to client depending on spatial lib, snapTo usage, tolerance values and transport formats.\n\nIn 2022 many system are depending on live updates also for spatial data.  So it\u2019s big advantage to be able to provide a simple and \u201csecure\u201d API\u2019s with fast server side integrity constraints checks that can be used from a standard web browser. When we have this checks on server side we will secure the equal rules across different clients.\n\nIs there alternatives that can secure data integrity in a better way? Yes, for instance Postgis Topology. The big difference is that Postgis Topology has more open structure that is realized by using standard database relational features. This lower the complexity of the client and secures data integrity. In the talk \u201cUse Postgis Topology to secure data integrity, simple API and clean up messy simple feature datasets.\u201d we will dive more into the details off Postgis Topology\nBuilding an API for clients may be possible using simple features, but it would require expensive computations to ensure topological integrity but to solve problem with mixing of new and old borders parts can not be solved without breaking the polygon up into logical parts. Another thing is attribute handling, like if you place surface partly overlapping with another surface should that have an influence on the attributes on the new surface.\n\nWe need to focus more on data integrity and the complexity and cost of creating clients when using simple feature, because the demands for spatial data updated in real time from many different clients in a secure and consistent way will increase. This will be main focus in this talk.\\n\\nLars Opsahl\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/9G3YGD/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/6 Andre Landwehr.mp4", "persons": "Andre Landwehr", "pretalx_id": "H9WNLQ", "title": "FOSS4G 2022 | FunctionalScope - Interactive real-time simulation tool for neighborhood planning", "description": "The FunctionalScope software builds on the concept of the CityScope, developed by the MIT Media Lab City Science Group. The FunctionalScope supports urban planners in the functional planning phase of new neighborhoods, the phase in which a competition design proposal is refined in preparation for creating a binding land use plan (Bebauungsplan).\u00a0\n\nThe tool offers a 3D view of the new urban design, vector(ized) data of the architectural  designs, embedded into a MapLibre based application in the browser. Several near-to-realtime APIs offer the opportunity to evaluate a neighborhood\u2019s design performance in terms of pedestrian flows, wind-comfort and traffic noise. Each simulation allows the user to set custom scenario criteria to enable to, for example, assess different policy and design strategies for the neighborhood such as pedestrian access to private land, speed limits on city streets, or simulate wind-comfort in for various wind conditions.\nIn addition to the web-interface for detailed planning stages, we have developed a tangible table, which allows users to iteratively generate new spatial configurations using 3D-printed buildings. Simulations are run for the designs created on the table, too.\n\nThe entire stack is built on open-source software.\n\nWe have used this tool in cooperation with the City of Hamburg (HafenCity GmbH) during the planning process of a new waterfront-neighborhood, Grasbrook. The FunctionalScope is designed to in a generic manner and twill be used in the planning of at least one new neighborhood-scale urban development project in Hamburg.\n\nThis talk will present the tech stack behind the tool: starting from the translation of architectural into geospatial data (geojson), covering the 3D neighborhood visualization in MapLibre and presenting our open-source near-to-realtime simulation APIs. Moreover, the technology behind the tangible planning table, based on an infrared camera, ArUco markers and Unity will be explained.\nThe talk concludes with lessons learned when developing and applying such an innovative tool to support a new neighborhood-scale development project.\\n\\nAndre Landwehr\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/H9WNLQ/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/7 Seth Girvin.mp4", "persons": "Seth Girvin", "pretalx_id": "CBVAT9", "title": "FOSS4G 2022 | State of MapServer 2022", "description": "MapServer is one of the founding OSGeo projects, and is used for publishing spatial data and interactive mapping applications to the web [1].\n\nThis talk provides an overview of new developments for existing users, and to show the potential of MapServer for those yet to try the software.\n\nWe'll review migrating to the new MapServer 8.0 release [2], using the new OGC API, highlighting lesser-known features, optimizing performance, and reporting news from the MapServer ecosystem.\nMapScript [3], a scripting interface to MapServer provided in several languages such as Python, PHP, and C#, will also be covered.\n\nThis talk will give an overview of current and planned development for MapServer and its related project MapCache, a tile server that speeds up access to map layers [4].\n\nFinally, we'll look at how to become involved in the MapServer community both as a user and as a developer.\n\n[1] https://mapserver.org/\n\n[2] https://github.com/mapserver/mapserver/wiki/MapServer-8.0-Release-Plan\n\n[3] https://mapserver.org/mapscript/index.html\n\n[4] https://mapserver.org/mapcache/\\n\\nSeth Girvin\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/CBVAT9/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/8 Lars Schylberg.mp4", "persons": "Lars Schylberg", "pretalx_id": "SQMVXH", "title": "FOSS4G 2022 | MapServer - Make beautiful maps", "description": "This talk will be about the art of beautiful digital cartography.  Some of the features in Mapserver can contribute to making maps that stand out a little extra.  We will focus on advanced line symbology, the layer composition pipeline and the newly added GEOMTRANSFORM \"centerline\".\nCreating very complex line symbology can be tricky.  We will go into detail about how to build such symbology. The layer composition pipeline offers many exciting possibilities.  We will show various examples how to achieve some stunning symbology for different feature types.   The geomtransform centerline function can produce beautiful labeling possibilities.  My first experiences and lessons will be shared.  Other things that could come up is possibilities with \u201cNamed Styles\u201d\nTo summarize it will be a talk about some new features and some older features in MapServer that are described in more detail. The talk is based on practical experiments and real problems that the author has experienced.\\n\\nLars Schylberg\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/SQMVXH/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/9 Sander Pukk.mp4", "persons": "Sander Pukk, Kaido Irdt", "pretalx_id": "CXXKVU", "title": "FOSS4G 2022 | Mapserver layer handling, production, and management in larger scale environment", "description": "Managing hundreds of layers from different sources in a Mapserver production is extensive work. Keeping them up to date, scalable and in constant deployment takes time and effort. Not to mention monitoring all of it.\n\nBy combining a configuration management tool (open-source Progress Chef in our case) and Mapserver, we have a continues deployment cycle. Mapserver\u2019s map file is divided into pieces that Chef puts together. All the layer files are separate entities which are easily manageable and changeable. Different map files can be produced combining different layers to keep map files smaller but still all in one place for management. It also enables to switch off or turn on layers easily.\nThis also gives the benefit of keeping development environment different from production.\n\nThrough MapProxy seeding process we also provided our thousands of users with their base map services and serve them WMS, WFS and our own produced Vectortiles.\n\nAll of it is also under constants monitoring and the logs are processed to produce simple statistics to see which applications are requesting, which layers are being accessed the most. We have built a notification system that notifies us immediately through hooks if our services are down or there are errors in any of the Mapserver layers requests.\n\nIt brings us back to the point of how to make your Mapserver layer handling, production, and management smoother and more straightforward. Let us share our insight!\\n\\nSander Pukk\\nKaido Irdt\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/CXXKVU/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/10 Paul van Genuchten.mp4", "persons": "Paul van Genuchten, Luis Calisto", "pretalx_id": "QW3NYC", "title": "FOSS4G 2022 | A crawler for spatial (meta)data as a base for Mapserver configuration", "description": "At our institute we manage a lot of input data and model outcomes of soil data to be shared online. We experienced that updating service configurations and metadata records can be quite a challenge, when managed manually at various locations. We've been working on tooling to help us automate the publication processes. These days data publications are set up as CI-CD processes on Gitlab/Kubernetes.\nThese efforts resulted in a series of tools which we call the Python Data\nCrawler. The crawler spiders a folder of files, extracts and creates metadata records for the spatial files, as well as generates a Mapserver configuration for the data to be published as OGC services. Underneath we're building on the tools provided by the amazing FOSS4G community, such as GDAL, Mapserver, pygeometa, owslib, mappyfile, rasterio and fiona.\nA typical use case for this software is with many organizations maintaining a file structure of project files. The crawler would index all the (spatial) data files, register the metadata records in a catalogue and users would query the catalogue from QGIS Metasearch to find and load relevant data.\nWe will present our findings around the project at the conference and hope to talk to institutes with similar challenges, to see if we can create an open source software project around the Python Geodata Crawler.\\n\\nPaul van Genuchten\\nLuis Calisto\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/QW3NYC/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/11 Alex Orenstein.mp4", "persons": "Alex Orenstein", "pretalx_id": "7Z9CUH", "title": "FOSS4G 2022 | Sharing EO data with farmers and herders in the West African Sahel: Lessons from the GARBAL program", "description": "Farmers and herders in the West African Sahel are critically vulnerable to climate shocks and need access to climate information to secure their livelihoods. Herders use data on pasture and water availability to move their livestock and farmers need weather predictions to plan their planting. While satellite imagery has made much of this information readily accessible to the spatial community, few channels exist to transmit this information to herding communities. As a result, climate data has become more powerful than ever before, yet mostly inaccessible to those who depend on this information for their livelihoods.\n\nThis talk goes over the lessons of a programme that seeks to bridge this gap. GARBAL is a call center that uses Copernicus Earth Observation imagery and field data to provide farmers & herders with information on pasture, water and markets in Mali, Niger and Burkina Faso. GARBAL was first developed in 2015 and this talk will provide lessons from several years of practice.\n\nThe GARBAL interface is built on mapserver and uses automated scripts to download and treat imagery from Sentinel 2 and Meteosat which then display information on pasture conditions and water availability. Field data is routed through a network of local data collectors who provide weekly updates on livestock conditions and market prices. In addition to an interactive map, the interface provides user-friendly textual outputs that summarize all the layers for any area of interest on the map, which allows call center agents to quickly provide data to callers.\n\nThe talk will share lessons from the technical and programmatic aspects of the project. The technical side will go over the architecture of the data treatment, demo the interface, talk about successes and failures and show how you can play with the data yourself. The programmatic side focuses more on how the user needs evolved over the years, techniques for translating GIS data into information useful to farmers and herders, operating in areas of active conflict and how EO data fits into existing centuries-old traditional data collection systems in the Sahel.\\n\\nAlex Orenstein\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/7Z9CUH/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/12 Riku Oja.mp4", "persons": "Riku Oja, Amelie A. Gagnon", "pretalx_id": "HR89PA", "title": "FOSS4G 2022 | Calculating school catchment areas - an open source solution", "description": "In many countries, access to schooling is one of the key measures of performance of the education system. It is not always known how long learners walk to school, even if the buffer distance is set by policy. GISPO teamed up with the UNESCO International Institute of Educational Planning (IIEP) to study the problem.\n\nThe result is a new QGIS plugin (\u201cCatchment\u201d) which allows easily calculating catchment areas based on travel time (isochrones), for all schools across a whole territory. The plugin uses the open source Graphhopper routing server and OpenStreetMap data across the globe. This allows us to easily find out how many people live e.g. 15, 30 or 60 minutes away from education in different parts of a country.\n\nFurther, the development of the plugin triggered a campaign of local OpenStreetMap mapping in Madagascar, which was one of the first countries to pilot the plugin. Having more roads mapped on OpenStreetMap has an impact far beyond educational planning.\n\nNaturally, the same plugin may also be used for calculating all kinds of service catchment areas in QGIS; it was also employed to e.g. calculate access to rail transit across Helsinki metropolitan region.\\n\\nRiku Oja\\nAmelie A. Gagnon\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/HR89PA/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/13 Juiwen Chang.mp4", "persons": "Juiwen Chang, Qasem SAFARIALLAHKHEILI", "pretalx_id": "7H8NH7", "title": "FOSS4G 2022 | TOSCA \u2013 A Novel GIS-Toolkit in Support of Sustainable Urban Development", "description": "TOSCA, also known as Toolkit for Open and Sustainable City planning and Analysis, was implemented by the Digital City Science group at Hafencity University Hamburg (HCU) as a joint venture with the German Association for International Cooperation (GIZ). The project \u2013 which has won the Hamburg Open Science Award in year 2020 \u2013works very closely together with academic and local governments in India and Ecuador in order to develop use cases in the context of urban upgrading, disaster prevention, and participatory planning. The WebGIS application uses modern state-of-the art technologies like Docker, View.js, PyWPS, GrassGIS and Geoserver. The source code of the open source solution is hosted on Git repo. Moreover, user and admin manuals plus several step-by-step video tutorials were uploaded on the Vimeo video portal. In terms of analysis functionalities, TOSCA is equipped with buffer area, time map (service area analysis), query module (filter by categorical and numeric attributes) and volcanic eruption scenario analysis (equivalent with intersect: select features by geolocation).\nThis project has been successfully implemented in India and Ecuador since October 2019. It supports investigations not only in regards to Indian slum upgrading issues, but also volcanic disaster mapping challenges in Ecuador. Further applications of TOSCA in Palestine has been kick-start in May this year. TOSCA can be deployed on multi-touch table or on virtual machine - through cloud hosting, and is designed for usage by non-GIS specialists. It targets diverse user groups ranging from local citizen to experts, the former implying participatory workshops and the later focusing on urban scenarios decision-making processes.\nTOSCA Git Repo: https://github.com/digitalcityscience/TOSCA\nVimeo Tutorial Site: https://vimeo.com/user127753830\nIn order to promote the TOSCA Toolkit further, we encourage developers co-work with us to further develop on modules of the Toolkit.\\n\\nJuiwen Chang\\nQasem SAFARIALLAHKHEILI\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/7H8NH7/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/14 Anna Petrasova.mp4", "persons": "Anna Petrasova, Vaclav Petras", "pretalx_id": "LXQJVU", "title": "FOSS4G 2022 | Tips for parallelization in GRASS GIS in the context of land change modeling", "description": "Although GRASS GIS has been used for big data processing for a while now, you may think that some esoteric knowledge is needed to take full advantage of its computational power. The purpose of this talk is to demonstrate simple ways to parallelize your computations in GRASS GIS, that are applicable whether you are working on your laptop or HPC. I will give an overview of the state of parallelization of individual tools, show benchmarks, and introduce you to other GRASS GIS parallelization tricks. I will use examples relevant to land change modeling and share our experience with simulating urban growth at 30m pixel across the contiguous United States (16 billion cells) using FUTURES simulation implemented in r.futures addon. This talk is for all levels of expertise, although basic Python or GRASS GIS knowledge will be advantageous.\n\nGRASS GIS is a well established, all-in-one geospatial number cruncher with Python interface, command line, and GUI, with new major version 8.0 released in spring 2022.\n\nFUTURES is an open source urban growth model specifically designed to capture the spatial structure of development. It can accommodate the input of a variety of datasets with different spatial extents and can be coupled to other models. FUTURES is implemented in r.futures GRASS GIS addon.\\n\\nAnna Petrasova\\nVaclav Petras\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/LXQJVU/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/15 Nuno Oliveira.mp4", "persons": "Nuno Oliveira, Marco Volpini", "pretalx_id": "CQCHBF", "title": "FOSS4G 2022 | Publishing INSPIRE datasets in GeoServer made easy with Smart Data Loader and Features Templating", "description": "GeoServer is a well-established multiplatform, open-source geospatial server providing a variety of OGC services, including WMS (view services), WFS and WCS (download services) as well as WPS (spatial data processing services). Among the open-source GIS web servers, GeoServer is well known for the ease of setup, the web console helping the administrator to configure data and services, the variety of OGC services available out of the box, as well as the rich set of data sources that it can connect to (open source, such as PostGIS as well as proprietaries, such as ArcSDE, Oracle or ECW rasters). GeoServer also provides several OGC APIs, including the OGC API - Features which recently attracted the interest of the INSPIRE community.\n\nAs far as the INSPIRE scenario is concerned GeoServer has extensive support for implementing view and download services thanks to its core capabilities but also to a number of free and open-source extensions; undoubtedly the most well-known (and dreaded) extension is App-Schema which can be used to publish complex data models (with nested properties and multiple-cardinality relationships) and implement sophisticated download services for vector data. Based on the feedback of App-Schema users collected over the years, a new generation of open-source mapping extensions have been implemented in GeoServer: Smart Data Loader and Features Templating, these extensions are built on top of App-Schema and ease the mapping of the data models by allowing us to act directly on the domain model and target output schema using a what you see is what you get approach.\n\nThis presentation will introduce the new GeoServer Smart Data Loader and Features Templating extensions, covering in detail ongoing and planned work on GeoServer. We will also provide an overview about how those extensions are serving as a foundation for new approaches to publishing complex data: publishing data models directly from MongoDB, embracing the NoSQL nature of it, and supporting new output formats like JSON-LD which allows us to embed well-known semantics in our data. Eventually, real-world use-cases from the organizations that have selected GeoServer and GeoSolutions to support their use cases will be introduced to provide the attendees with references and lessons learned that could put them on the right path when adopting GeoServer.\\n\\nNuno Oliveira\\nMarco Volpini\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/CQCHBF/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/16 Peter Petrik.mp4", "persons": "Peter Petrik", "pretalx_id": "CEWFKZ", "title": "FOSS4G 2022 | Liberate your QGIS projects out of office with Mergin Maps", "description": "Mergin Maps (Mergin synchronization server and the Input app) is a package of free and open-source components developed by Lutra Consulting since 2017. It allows users to seamlessly share QGIS projects with others and keep a history of the geo-data. Moreover, it allows collecting data in the field with the mobile application Input, fully based on the QGIS core engine. No more paper for the collection of vital data in the field! We will briefly present published case studies to show the capabilities and features of the solution.\n\nWe will talk about the recent development of the product.  In the Input app, where we focused on improving the field survey experience by allowance to use of precise external GPS receivers, stake-out navigation mode or attaching multiple photos to a single feature.\n\nOn the server-side, in the Mergin, we will demonstrate the ability to store, version and share your geo-data with your team. You will see the new feature to show a map overview of your Mergin project on the dashboard.  To fully integrate into CDI, the DB-sync tool for two-way synchronization between Mergin and PostgreSQL will be presented. Advanced features for usage in large teams, such as selective synchronization and work packages (subprojects for teams within companies) will be explained.\n\nAt the end of the talk, we will uncover the upcoming roadmap for the new features coming in the second half of 2022.\\n\\nPeter Petrik\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/CEWFKZ/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/17 Robert Coup.mp4", "persons": "Robert Coup", "pretalx_id": "8FEBED", "title": "FOSS4G 2022 | Kart: an introduction to practical data versioning for rasters, vectors, tables, and point clouds", "description": "We\u2019re drowning in data, but the geospatial world lags badly behind in versioning tools compared to our software counterparts. Kart (https://kartproject.org) is solving this with a practical open tool for versioning datasets, enabling you to work more efficiently and collaborate better.\n\nWe will introduce you to Kart and demonstrate some of the key features, including our QGIS plugin. And we'll highlight what\u2019s coming next on our roadmap.\n\nSince 2021 we have added support for Raster and Point Cloud datasets, and we'll be showing how we build on Kart's versioning and spatial filtering techniques to efficiently navigate, access, and use large and small datasets.\n\nKart allows you to quickly and easily manage history, branches, data schemas, and synchronisation for large & small datasets between different working copy formats, operating systems, and software ecosystems.\n\nModern version control unlocks efficient collaboration, both within teams and across organisations meaning everyone stays on the same page, you can review and trace changes easily: ultimately using your time more efficiently.\\n\\nRobert Coup\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/8FEBED/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_9/18 Martin Dobias.mp4", "persons": "Martin Dobias", "pretalx_id": "VUECWC", "title": "FOSS4G 2022 | Elevation data support in QGIS: 3D, profiles, point clouds and more!", "description": "For many years QGIS has been focused on 2D spatial data and support for\n3D data was very limited. This has changed in the last couple of years\nand QGIS is getting a full suite of tools to work with 3D data.\n\nQGIS development team has been actively working on better support for\ndata with elevation - such as point clouds, raster digital elevation models,\n3D vectors or meshes. This has been possible mainly thanks to the successful\ncrowdfunding campaign run in autumn 2021:\nhttps://www.lutraconsulting.co.uk/crowdfunding/elevation-pointcloud-enhancements-qgis/\n\nIn this talk, we will show outcomes of these development efforts including:\n\n - a brand new profile tool for detailed inspection of elevation data\n - new 2D/3D visualization options for data\n - great improvements to the usability of 3D map views\n - support for Cloud Optimized Point Cloud (COPC) format\n\nWe will also discuss the plans for future releases and how QGIS can even\nbetter fit requirements of users with the ever increasing supply of 3D data.\\n\\nMartin Dobias\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/VUECWC/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/1 Vincent Sarago.mp4", "persons": "Vincent Sarago", "pretalx_id": "TSQK8Z", "title": "FOSS4G 2022 | TiTiler: Not just a tile server", "description": "During the last 2 years we've been working on TiTiler (https://developmentseed.org/titiler/), a dynamic raster tile server. Built on top GDAL/Rasterio, TiTiler is written in python and use FastAPI (https://fastapi.tiangolo.com) framework. TiTiler is an application that let you create raster tiles dynamically from raster datasets (e.g Cloud Optimized GeoTIFF) but also from Spatial Temporal Asset Catalog (STAC) or Mosaic (using MosaicJSON). It is also a set of python modules which can be used independently to create custom services.\n\nDuring this talk we'll explain the concept of dynamic tiling, what is TiTiler (and the libraries powering it), how it works and more important how users can customize and built their own dynamic tile server.\n\nWe will also present project like TiTiler-PgSTAC (https://github.com/stac-utils/titiler-pgstac) which enables the creation of Mosaic tiles dynamically from a Spatial Temporal Asset Catalog (STAC) database, or eoAPI (https://github.com/developmentseed/eoAPI) which is a full Earth Observation data service combining STAC database, STAC-FastAPI and a TiTiler in one easily deployable project.\\n\\nVincent Sarago\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/TSQK8Z/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/2 G\u00e9rald Fenoy.mp4", "persons": "Rajat Shinde, G\u00e9rald Fenoy", "pretalx_id": "ZPKH3Y", "title": "FOSS4G 2022 | ZOO-Project: News about the Open WPS Platform", "description": "ZOO-Project is a WPS (Web Processing Service) platform which is implemented as an Open\nSource project and following the OGC standards, it was released under an MIT/X-11 style license and\nis currently in incubation at OSGeo. It provides a WPS compliant developer-friendly framework to\neasily create and chain WPS Web services. This presentation gives a brief overview of the platform\nand summarizes new capabilities and enhancement available in the new version. A brief\nsummary of the Open Source project history with its direct link with FOSS4G will be presented. The new release comes up with a brand new ZOO-Kernel Fast Process Manager and, with the approved standard OGC API - Processes part 1: core. The new functionalities and concepts available in the latest release will be presented and described, also highlight their interests for applications developers and users. Apart from that, various use of OSGeo software, such as GDAL, GEOS, PostGIS, pgRouting, GRASS, OTB, SAGA-GIS, as WPS services through the ZOO-Project will be presented. Then, the ongoing developments and future innovations will be explored.\\n\\nRajat Shinde\\nG\u00e9rald Fenoy\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ZPKH3Y/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/3 G\u00e9rald Fenoy.mp4", "persons": "Rajat Shinde, G\u00e9rald Fenoy", "pretalx_id": "GUNEVQ", "title": "FOSS4G 2022 | MapMint: The service-oriented platform", "description": "MapMint is a comprehensive task manager for publishing web mapping applications. It is a robust\nopen source geospatial platform allowing the user to organize, edit, process and publish spatial data\nto the Internet. MapMint includes a complete administration tool for MapServer and simple user\ninterfaces to create mapfiles visually.\nMapMint is based on the extensive use of OGC standards and automates WMS, WFS, WMT-S, and\nWPS. Most of the MapMint core functions are run through WPS requests which are calling general or\ngeospatial web services: vector and raster operations, mapfiles creation, spatial analysis and queries\nand much more. MapMint server-side is built on top of ZOO-Project, MapServer and GDAL and its\nnumerous WPS services are written in C, Python and JavaScript. MapMint client-side is based on\nOpenLayers and Jquery and provides user-friendly tools to create, publish and view maps.\nMapMint architecture and main features will be introduced in this presentation, and its modules\n(dashboard, distiller, manager, and publisher) will be described with an emphasis on the OGC standards and OSGeo software they are using. Some short but relevant case studies and examples will finally\nillustrate some of the key MapMint functionalities.\\n\\nRajat Shinde\\nG\u00e9rald Fenoy\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/GUNEVQ/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/4 Richard Conway.mp4", "persons": "Richard Conway, Philip Beavis", "pretalx_id": "TKCZFK", "title": "FOSS4G 2022 | EOEPCA - An Open Source Exploitation Platform", "description": "Exploitation platforms offer a cloud-based virtual work environment where expert users can access data, develop algorithms, conduct analysis close to the data and share their value-adding outcomes. We now have a complementary ecosystem of platforms, data sources and cloud services. To fully exploit the potential of these complementary resources we anticipate the need to encourage interoperation amongst the platforms, such that users of one platform may consume the services of another directly platform-to-platform.\n\nThe goal of the EO Exploitation Platform Common Architecture (EOEPCA) project is to define and agree a re-usable exploitation platform architecture by identifying a set of common building blocks that provide their services through open interfaces (e.g. OGC), to encourage interoperation and federation within this Network of Resources. We are also developing an open source Reference Implementation, to validate and refine the architecture, and to provide an implementation to the community.\n\nThe Reference Implementation comprises a set of open source components that are available on GitHub, and provided with helm charts for Kubernetes deployment. The components can be used together as an integrated platform, or individually for specific capabilities - which include:\n\n - Application Deployment and Execution Service (ADES) - processing engine for execution of user defined applications via OGC API Processes interface\n - Processor Development Environment (PDE) - integrated web tooling to develop, test and package apps for ADES execution\n - Resource Catalogue - metadata catalogue for data/applications which provides OGC CSW, API Records, STAC and OpenSearch interfaces\n - Data Access - standards-based access to both platform and user-owned data (OGC WCS, WMS, WMTS)\n - Workspace - centralises the user\u2019s management of owned resources through personal Resource Catalogue and Data Access services, integrated with platform S3 object storage\n - Identity and Access Management - OpenID Connect (OIDC) for authentication (OIDC) and User Managed Access (UMA) for authorization, with integrations for external identity providers\n\nWe provide an introduction to each of the building blocks and the open source projects that underpin their development.\n\nAll of our work is available on GitHub (https://github.com/EOEPCA), via our website (https://eoepca.org/) and through our helm chart repository (https://eoepca.github.io/helm-charts).\\n\\nRichard Conway\\nPhilip Beavis\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/TKCZFK/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/5 Sanghee Shin.mp4", "persons": "Sanghee Shin", "pretalx_id": "898PAZ", "title": "FOSS4G 2022 | Development of Environmental Impact Assessments(EIA) Data Visualization System using FOSS4G - Phase I", "description": "This talk is about the development of an Environmental Impact Assessments(EIA) data visualization system using FOSS4G. The system is being developed by Gaia3D utilizing several open source projects such as PostGIS, GeoServer, Cesium, and mago3D.\n\nAlthough EIA has played an important role for environmental decision-making and sustainable development, most EIA statements are published as a mix of text and tabular data that is not\neasily accessible to or understandable for the public. The system was designed to improve the public\u2019s understanding of stakeholders before and after a construction project by providing visualization of key environmental elements. The final goal of the system is to improve the EIA process so that not only experts but also non-experts, citizens can participate in the EIA process and easily understand the meaning of the EIA statements with help from 3D GIS, Easy Finger real-time simulation technology.\n\nThis system development is 5 years long project funded by Ministry of Environment(MOE-2020002990005), South Korea. This talk will focus on the research outcome of Phase I and future plans. The final system will be opened as an open source with permission from Ministry of Environment.\\n\\nSanghee Shin\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/898PAZ/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/6 Claudio Navacchi.mp4", "persons": "Claudio Navacchi", "pretalx_id": "NAKXRM", "title": "FOSS4G 2022 | yeoda - providing low-level and easy-to-use access to manifold earth observation datasets", "description": "In recent years, several Python packages (e.g. xarray, rasterio) have evolved around more basic software libraries such as netCDF4 or GDAL for accessing geospatial data. These packages allow to work with all kind of data formats (e.g. GeoTIFF, NetCDF, ZARR) providing the data in array format (NumPy, xarray) and constitute a fundamental part of any scientific analysis or operational task. However, they do not offer full flexibility when working with Earth Observation (EO) datasets. The multidimensional complexity of EO data (i.e. space, time, bands) is often resolved by distributing dimensions across many files and thus not always easy to access. An important step forward to streamline EO data access has been the Open Data Cube (ODC) toolbox, which utilizes predefined dataset configurations and file-based indices stored in a database. With this setup, ODC enables an easy and uniform access to multidimensional geospatial datasets. Still, users are often confronted with a great variety of data formats, and files being distributed over different systems. This can pose a hurdle when working with ODC, especially if one wants to process a new stack of geospatial data, where the extra overhead of a database can stall swift progress.\n\nIn order to close this gap, the yeoda (''your earth observation data access'') Python software package aims to resolve this shortcoming by offering a similar interface as ODC, but allowing to interact with geospatial data on a lower level. It relies on two other Python software packages developed by TU Wien: geospade (definition of geospatial properties of a dataset, e.g. geometries), and veranda (read/write access to a variety of raster and vector data formats, e.g. GeoTIFF). This modular setup ensures a clear separation of concerns, specifically between geospatial operations and I/O tasks, yielding a homogenized interface independent from the actual data format. For example, geospatial operations based on tiled EO raster datasets can be easily performed across tile or file boundaries. Data access is then realised in veranda, which combines geometric properties with I/O objects listed in a table. On top of geospade and veranda, yeoda acts as a communication layer between files stored on the file system and data objects by adding additional dimensions to the data table, such as common metadata or file name entries. Thus, one can filter multiple files by their attributes (e.g. time, bands, variable names, satellite platform) before accessing the data.\n\nHence, yeoda guarantees the necessary freedom to apply arbitrary algorithms on manifold data formats, while simultaneously supporting scalability by means of parallelised I/O operations. Despite ODC's tremendous value for accessing EO datasets through large scale operational services, yeoda introduces a new level of data interaction making it an indispensable tool for the EO user community. When taking a look on recent advancements in interoperable cloud-based processing via the openEO API, yeoda could be utilized as a slim back-end library to lower the hurdle of sharing new EO datasets and to foster scientific exchange.\\n\\nClaudio Navacchi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/NAKXRM/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/7 Martin H\u00f8gh.mp4", "persons": "Martin H\u00f8gh", "pretalx_id": "WEUVFZ", "title": "FOSS4G 2022 | GC2/Vidi: What\u2019s new in spatial data infrastructure project", "description": "GC2/Vidi: What\u2019s new in spatial data infrastructure project\n\nThe\u202fGC2/Vidi\u202fplatform helps you build a spatial data infrastructure quickly and easily. Powered using open source components for a scalable solution focused on freedom rather than fees.\n\nGC2/Vidi comprises two software projects:\n\n - GC2\u202f\u2013\u202fmakes it easy to deploy PostGIS, MapServer, QGIS Server, MapCache, Elasticsearch, GDAL/OGR. And offers an easy-to-use browser application to configure the software stack.\n\n - Vidi\u202f\u2013 a modern take on browser GIS. It is the front-end client for GC2.\n\nThe GC2/Vidi project is released under GPL and accepted as an OSGeo Community Project in 2018.\n\nThe talk gives a brief overview of the platform and summarizes the capabilities it has to offer. A new CLI tool (Command Line Tool), which enables administration, import/export of data, starting MapCache seed jobs, running SQLs and more will be introduced.\n\nIn addition, the new \"GC2/Vidi User Group\" will be introduced. It is a non-profit organization whose mission is to promote the adoption of GC2/Vidi and the underlying technologies as well as knowledge sharing. The organization was founded in 2020 and has about 15 members, including municipalities, public transport and private companies.\\n\\nMartin H\u00f8gh\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/WEUVFZ/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/8 Felix Palmer.mp4", "persons": "Felix Palmer", "pretalx_id": "8KUJXV", "title": "FOSS4G 2022 | Fast rendering from vector tiles in deck.gl", "description": "The shift to using vector rendering has enabled maps to take a leap forward compared to using raster data. It is now possible to offer a much richer experience by performing styling, processing and filtering directly in the client. Coupled with tiled rendering, it is now feasible to work with huge datasets directly in the web browser.\n\nThis presentation will look at how applications can be built using the open source deck.gl library, with a focus on displaying vector tilesets, styling and filtering data on the client, with acceleration provided by the GPU. We will look at how deck.gl elegantly works with vector tiles and show how maps and visualisations can be styled using a few lines of code. We will also explore tools provided by the CARTO platform, which bring these features to those without programming experience, via a web-app.\n\nA brand new feature of deck.gl will be presented: the MaskExtension is a powerful tool that allows one dataset to act as a geospatial mask for another. For example this can be used to let the user select features on a map using a lasso tool, or to select map features based on a geospatial bound. All at 60fps on the client.\\n\\nFelix Palmer\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/8KUJXV/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/9 Zulfikar Akbar Muzakki.mp4", "persons": "Zulfikar Akbar Muzakki", "pretalx_id": "7RZH79", "title": "FOSS4G 2022 | geojson-vt for Highly Efficient Geojson Rendering in Open Layers", "description": "GeoJSON is one of the most common geospatial data formats. In simple terms, it is an extension of JSON with geometry property. It is text-based and designed with human readability in mind. For the sake of being eye-convenient, there is a performance trade-off when the browser renders it. GeoJSON consists of features containing redundant property keys, causing the size to be bloated as the feature size goes up. Commonly, drawing GeoJSON with the size of tens megabytes would be slow. Showing a hundred megabytes of GeoJSON data on the browser would most likely crash the browser.\n\nWhen we are in complete control of the system: back end, front end, or anything in between, we could probably change the source format to something more efficient like Vector Tiles. But what if we can only tweak the front end?\n\nWhen we can only tweak the front end, geojson-vt comes to the rescue. Initially designed for Mapbox, we can pair it with OpenLayers to render GeoJSON on the fly as Vector Tiles. We will compare the performance between direct GeoJSON rendering versus geojson-vt for different types of GeoJSON. The usage is straightforward, making it a pretty easy solution to improve our map\u2019s performance. On top of that, we could still use Vector-specific Open Layers function like getFeatures when needed.\\n\\nZulfikar Akbar Muzakki\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/7RZH79/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/10 Xu Cong.mp4", "persons": "xu cong", "pretalx_id": "NWHWED", "title": "FOSS4G 2022 | Vision and Challenge of Re:Earth - an open source WebGIS platform using Cesium", "description": "The Re:Earth project grew from the idea of, \"What would be possible if anyone, anywhere could access the digital Earth's potential?\". To make this a reality, we knew Re:Earth needed to be a no-code solution. But more than that, we needed to make sure hardware and OS requirements wouldn't get in the way, which is why Re:Earth is a fully web-based application.\n\n_*Re:Earth allows you to manage, edit, compute and visualize a multitude of geographic information including 3D data with no coding required.*_\n\nWe knew projects as well as data would need to be shareable so we have both project publishing and data exporting.\n\nPublishing a project is easy and gives users the chance to opt-in or out of SEO, change their URL and setup publishing to their own domain. Exporting data is easy and supports many of the most common file formats seen in GIS.\n\nIt is also the first WebGIS to feature a plug-in system that runs in the browser.\n\nToday, we are focused on solving a problem people face in maintaining, organizing, and managing a wide variety of data, by developing Re:Earth into a general-purpose data management system that can handle all types of data, and one that can be integrated with the user's existing systems.\n\nOur desire has always been to open Re:Earth to the OSS community, to build a global community around the vision of Re:Earth, and to provide and disseminate the value we create with our contributors to the wider society.\n\nThe first step to making this happen was Resium, a popular OSS package that allows developers to use Cesium with React. With Resium we have been able to write Re:Earth's codebase with React and Typescript on the front end. As the main backend language we chose Go. By using these modern languages we have kept Re:Earth highly maintainable and scalable and hope that other developers will find contributing to it easy.\\n\\nxu cong\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/NWHWED/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/11 Yuen Pakhin.mp4", "persons": "Mitsuha Miyake, Yuen Pakhin", "pretalx_id": "HVUKHK", "title": "FOSS4G 2022 | Enrich styles and enhance styling process with OpenMapTiles", "description": "Vector tile map is now industry standard and general-purpose schema is available on OpenMapTiles project. But if the features that people focus on in your own country are different from the default schema? We developed styles to cover and highlight Japanese authentic geographic attributes such as railways, hot springs, and religious facilities with an improved OpenMapTiles schema. The styles are available on MapTiler Cloud as MIERUNE styles globally. In the process, we developed some useful tools for vector tile styling. One is a style-competing tool that makes it cartographers easy to compare two versions of styles interactively. Another is a kind of style management tool using git that visualizes diff of style.json and takes screenshots automatically. Structured approaches of planning and implementation of vector tile styling are not much shared. In this talk, we will speak about how to enrich the styles for your own country and enhance the styling process for vector tile cartographers.\\n\\nMitsuha Miyake\\nYuen Pakhin\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/HVUKHK/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/12 Gravin Florent.mp4", "persons": "Florent Gravin", "pretalx_id": "9YQXW7", "title": "FOSS4G 2022 | Baremaps studio: dynamic vector tiles map rendering", "description": "Baremaps is a blazing fast vector tile server which makes your life easier regarding the publication of OSM data: import, generation and cloud storage.\nBut Baremaps also shines and differentiates from solutions like pg_tileserv in the way you can customize your tileset and merge custom datasets.\nBased on this advantage, we turn Baremaps out to be a vector tiles studio api, allowing the user to easily customize the content of the vector tiles.\nWe adopted the OGC api specification for tileset, layers and styles. Baremaps offers various entry points to manage the datasets and serve them as vector tiles. As an exemple, you can dynamically import different kinds of data sources (geojson, SHP, database) to the server which will expose them as datasets, then you can use any kind of dataset within the same tileset. You can also bring value to your data by doing aggregations (spatial, attribute, hexbin) or computation. It leverages the power of postgis functions and vector tiles specification into one solution. You can attach a style for your dataset and baremaps will serve both Mapbox style file and Vector tiles stream to render the map the way you expect.\nTo illustrate this concept, we will showcase a studio UI which literally provides a tool to quickly create valuable maps and publish them to the web.\n\nBaremaps Studio is the solution to handle dynamic rendering and styling of your vector datas.\\n\\nFlorent Gravin\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/9YQXW7/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/13 Tomas Holderness.mp4", "persons": "Tomas Holderness", "pretalx_id": "P37MWK", "title": "FOSS4G 2022 | Building a scalable tiling service using Amazon API Gateway", "description": "Recent advancements in both raster and vector tile generation mean that TileJSON services can now serve tiles from on-the-fly sources as well as pre-built caches. Currently, Addresscloud uses CloudFront backed by S3 buckets to serve tile caches for its customer-facing applications. Whilst this configuration worked well for pre-built tile caches, it does not readily support on-the-fly generation and is limited by CloudFront's requirement for cookies or signed URLs for private tilesets. In this presentation we will look at the use of Amazon's API Gateway to provide a scalable interface for multiple TileJSON sources. This approach benefits from providing on-the-fly generation tile in a serverless manner and supporting multiple authorization configurations. The presentation will demonstrate the integration of API Gateway with three tile sources: (1) a Lambda function using rio-tiler for on-the-fly generation of raster tiles from a Cloud Optimised GeoTiff. (2) a Lambda function using Amazon Aurora's HTTP API for MVT generation from PostGIS. (3) a proxy interface to a pre-built cache of tile objects stored in an S3 bucket. The presentation will include publication of source code under an open license, which will be available to the community as a reference architecture. This presentation is of interest to anyone developing tiling services in the cloud.\\n\\nTomas Holderness\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/P37MWK/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/14 Ben Kuster.mp4", "persons": "Ben Kuster", "pretalx_id": "LZYESJ", "title": "FOSS4G 2022 | New OS: @vcmap/core", "description": "In the current web GIS ecosystem, 3D is nothing new. It is currently fairly simple to create a 3D web application for rendering geospatial data using open source software, the same can be said for 2D GIS. But in some use cases, you do not wish to have to decide between one or the other. Enter @vcmap/core, a new OS project developed by virtualcitySYSTEMS GmbH of Berlin. With a number of high level abstractions, this slim open source library allows you to create web applications which are able to represent the same data in 2D, 3D and even oblique imagery.\n\nBy abstracting layers, maps, interactions and styling, your data becomes renderer agnostic. Additionally, a parameterized approach to 3D allows you to easily create cuboid 3D representations from simple 2D representations. A feature which has proven useful in urban planning scenarios.\n\nFurthermore, the @vcmap/core comes with a powerful serialization mechanism. All runtime objects can be serialized and stored using JSON. This way, you can easily develop a web gis framework which allows a quick deployment of multiple applications which only differ in data.\n\nAnd this is not all, the @vcmap/core is still not finished, with geometry editors on the roadmap and a further open source project, the @vcmap/ui to follow this year. The @vcmap/ui is an accompanying UI which integrates smoothly with the @vcmap/core and provides a powerful plugin API. This plugin API allows for fast development of custom tools with which to enhance, analyze and use your geospatial data without the need to fully implement an entire web GIS.\\n\\nBen Kuster\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/LZYESJ/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/15 Christopher Beddow.mp4", "persons": "Christopher Beddow", "pretalx_id": "DUB7EE", "title": "FOSS4G 2022 | Open Data in OpenStreetMap\u2019s RapiD Editor", "description": "The MapWithAI RapiD editor for OpenStreetMap offers a variety of open data to improve OpenStreetMap. This web-based map editor presents the user with various sources of open data to validate and add to OpenStreetMap, including MapWithAI roads, Microsoft buildings, and various open datasets shared via Esri.\n\nIn addition to these past data offerings, the user can now validate and add sidewalks and crosswalks derived from both Mapillary street-level imagery, as well as derived from various organizations who provide footway open data. Finally, Mapillary point data derived from imagery can also now be verified and directly converted into map data, thanks to a more efficient and rapid workflow.\n\nWe will explore all that open data available in the RapiD editor, with a specific focus on how footways are generated from Mapillary, validated from open datasets, conflated against existing OpenStreetMap data, and presented to the user for improved maps of pedestrian walkability.\\n\\nChristopher Beddow\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/DUB7EE/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/16 Bryan Housel.mp4", "persons": "Bryan Housel, Benjamin Clark", "pretalx_id": "VSEAKD", "title": "FOSS4G 2022 | Speeding up the RapiD map editor with WebGL and PixiJS", "description": "RapiD is an advanced Open Source map editor for OpenStreetMap built by the MapWithAI team at Meta.  RapiD makes it simple to work with openly licensed geodata and AI-detected road, building, and landform features.\n\nFor years the RapiD editor was based on a SVG rendering engine built with D3.js.  As our users map the world in increasing levels of detail, and as more open data sources become available, our rendering tech has struggled to keep up with the massive amounts of data that we\u2019re asking it to display in a browser-based JavaScript application.\n\nOur team recently converted this legacy rendering engine to instead use WebGL technology by leveraging the popular Open Source PixiJS game engine.  The conversion from SVG to WebGL yielded a considerable performance boost, and the new WebGL-based renderer is up to the task of working with massive world-scale datasets and handling the increasing data density of OpenStreetMap.\n\nIn this talk we share our progress on bringing new datasets into RapiD, tell the story of how we built a modern map editor on top of an Open Source game engine, and share our roadmap for the future of mapping.\\n\\nBryan Housel\\nBenjamin Clark\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/VSEAKD/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/17 Chia Li Juan.mp4", "persons": "Sriram Ravichandran, Chia Li Juan", "pretalx_id": "Z3HJLM", "title": "FOSS4G 2022 | Use of FOSS4G at Gojek to automate map error detection at scale", "description": "Our digital maps are not always up to date with the real world. New road constructions and road blockages could reduce the accuracy of the map data. In a logistics company like Gojek that serves millions of users per day in South East Asia, the core undertaking revolves around routing and ETAs. Any inaccurate local map data can lead to a direct negative impact on business metrics.\n\nSo how do we ensure that map inconsistencies are detected and fixed promptly to minimise interference of our services? When manual detection is labor intensive and not scalable to millions of road networks in vast regions, how can we effectively automate this at scale?\n\nThis talk is a story of how we, at Gojek, built a pipeline that uses bad customer experience as the trigger to identify potentially faulty data in OpenStreetMap. Our solution makes use of noisy GPS traces and Overpass, an open source tool, to automate this detection.\n\nThis solution enabled us to identify 100s of potential issues per day, categorise them, associate business impact to each map issue and allow our map analysts to fix them seamlessly.\\n\\nSriram Ravichandran\\nChia Li Juan\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/Z3HJLM/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/18 Stuart Lynn.mp4", "persons": "Stuart Lynn, Dylan Halpern", "pretalx_id": "ALBXPD", "title": "FOSS4G 2022 | Matico a new federated FOSS platform for spatial analysis, data management, visualization, and app building", "description": "Geospatial data and analysis is more central than ever to data science, research, and policy analyses. This is especially evident in the explosion of tools, both open source and proprietary that have been developed over the past 5 years to help users manage and gather insights from their data. However many of these powerful tools, like geopandas (analysis and modeling) and deck.gl (visualization)\u2014 are technically inaccessible to analysts and researchers without the available time or skills for advanced coding. A number of commercial ventures (Carto, ESRI etc) attempt to overcome this limitation by bringing these tools together as part of polished, graphical user interface driven platforms. While these platforms offer ease of use, they raise concerns about longevity, data ownership, and academic support.\n\nMatico is a new free and open-source platform we are developing at the Spatial Data Science center that seeks to fill the gap between open but technically focused tools and commercial platforms. Consisting of a suite of interoperable components, Matico enables organizations and individuals to manage and visualize their geospatial data while easily maintaining their own infrastructure. A backend server allows users to easily load, clean, analyze, and distribute data through APIs, queries, and in-browser data editing tools while a powerful app builder allows users to develop their own rich applications that target diverse audiences.\n\nThis talk will demonstrate the current features of Matico, our future roadmap , and demonstrate relevant use cases. Matico is now and will forever be open through a permissive MIT open-source license. Learn more at https://matico.app/\\n\\nStuart Lynn\\nDylan Halpern\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ALBXPD/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/19 Mar\u00eda Arias de Reyna Dom\u00ednguez.mp4", "persons": "Mar\u00eda Arias de Reyna Dom\u00ednguez", "pretalx_id": "SCUTFJ", "title": "FOSS4G 2022 | Kaoto: Integrate your Architecture without coding", "description": "Kaoto is an graphical tool to *orchestrate components* in a *visual*, low-code and no-code editor. Once you have your workflows defined, you can deploy them directly to any kubernetes compatible cloud. Kaoto both be deployed as a SaaS platform or used as a standalone application.\n\nThe user interface have both a source code text editor and a drag and drop graphical space. This way users can work both no-code and low-code at the same time, simplifying the learning curve of Apache Camel to create integrations.\n\nKaoto is *highly customizable*. It supports custom views for your specific needs, like showing manuals and helpers for your specific use cases. You can also add *your own domain specific languages* and extensions to use different underlying frameworks with the same user interface. This helps your non tech savvy users adapt to new environments.\n\nKaoto augments your productivity, accelerating new users and helping experienced developers to build complex integrations.\\n\\nMar\u00eda Arias de Reyna Dom\u00ednguez\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/SCUTFJ/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/20 Said Turksever.mp4", "persons": "Christopher Beddow, Said Turksever, Edoardo Neerhut", "pretalx_id": "7UAP8S", "title": "FOSS4G 2022 | The most accurate cameras to generate map data from street-level imagery", "description": "Mapping is time-consuming and requires a high volume of a workforce when it comes to keep maps up to date periodically. This brings the need of finding alternative approaches to keep maps up to date. Mobile mapping is the process of collecting geospatial data from a mobile vehicle using a 360\u00ba camera, laser scanner, GPS/IMU positioning system, and other sensors.\n\nMany devices now include a geotag for every photo captured, and GPS accuracy can\thave major effects on the quality of street-level imagery and derived data. Join us in an exploration of the different accuracy levels of GPS-enabled cameras, where we will take a look at how different devices compare, and what varied levels of GPS accuracy look like both for image location and for data extracted using computer vision and structure from motion.\n\nUnderstanding the differences between devices is an important step in planning street-level imagery capture, as it will align your expectations with the advantages and limitations of the hardware you use. We tested various devices and will share the results of our investigation, with the aim of equipping you to capture street-level imagery with the tools and methods that fit your needs.\\n\\nChristopher Beddow\\nSaid Turksever\\nEdoardo Neerhut\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/7UAP8S/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/21 Matthew Hanson.mp4", "persons": "Matthew Hanson", "pretalx_id": "YPHAZB", "title": "FOSS4G 2022 | Analysis Ready (Meta)Data", "description": "The term Analysis Ready Data started as a way to describe a Landsat product that would efficiently allow time-series based analysis by providing a consistent, grid and pixel-aligned product corrected to surface-based measurements. Since then it has come to mean a wide range of things, but without a clear set of standards on how to characterize ARD there is little to no interoperability among datasets that call themselves ARD.\n\nThe Analysis Ready Metadata initiative uses the SpatioTemporal Asset Catalog (STAC) spec as the vehicle for describing well-characterized data. This goes beyond the basic geospatial and temporal characteristics captured in the core STAC spec and into detail about the processing level of the data, corrections that have been applied, as well as spatial and measurement uncertainties.  Having well-characterized data through it\u2019s STAC metadata enables discovery of usable data, automated processing using interoperable workflows, and tracking of data provenance of derived products.\n\nThe CEOS ARD (previously CARD4L) specifications require certain metadata and processing to be done for it to be compliant and can use this STAC metadata to automatically assess the potential for a dataset to be compliant with the needed requirements. This talk will cover elements of STAC, ARD, and the CARD4L family product specifications.\\n\\nMatthew Hanson\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/YPHAZB/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/22 Markus Tremmel.mp4", "persons": "Markus Tremmel", "pretalx_id": "FVLUDT", "title": "FOSS4G 2022 | Using COMTiles to reduce the hosting costs of large map tilesets in the cloud", "description": "COMTiles (https://github.com/mactrem/com-tiles) is a streamable and read optimized file archive for hosting map tiles at global scale on a cloud object storage. Currently most geospatial data formats (like MBTiles or Shapefiles) were developed only with the POSIX filesystem access in mind. COMTiles in contrast is designed to be hosted on a cloud object storage like AWS S3 or Azure Blob Storage without the need for a database or server on the backend side. The map tiles of a COMTiles archive can be accessed directly from a browser via HTTP range requests. COMTiles are already successfully used in some projects to significantly reduce the hosting costs and simplify the handling of large tilesets in the cloud.\nStructure of the talk:\n\n - Basic concepts of COMTiles like the structure of the streamable index table (pyramids vs space-filling curves vs fragments)\n - Comparison of COMTiles to existing cloud native geospatial formats regarding the visualization of large datasets in the browser\n - Advantages of using a streamable archive format like COMTiles over directly hosting the map tiles in the cloud\\n\\nMarkus Tremmel\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/FVLUDT/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/23 Yves Bolognini.mp4", "persons": "Yves Bolognini", "pretalx_id": "BSG7EL", "title": "FOSS4G 2022 | GeoMapFish status: vector tiles!", "description": "GeoMapFish is an open source WebGIS platform developed in close collaboration with a large user group. It targets a variety of uses in public administrations and private groups, including data publication, geomarketing and facility management. OpenLayers and an OGC architecture allow to use different cartographic engines (MapServer, QGIS Server). Recently new features have been added such as vector tiles integration, from raw data to visualization. In order to get rid of AngularJS dependency, a roadmap has been established for a migration to a web components architecture. Everything has been planned so that our users can continue to develop their projects during this process. K8S support is evolving with the implementation of the necessary tools for Azure environments. Highly integrated platform, large features scope, fine grained security, reporting engine, top performances and excellent quality of service are characteristics of the GeoMapFish solution. In this talk we ll present the key usages, web components migration process and latest developments, including vector tiles support.\\n\\nYves Bolognini\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/BSG7EL/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_6/24 Will Field.mp4", "persons": "Will Field", "pretalx_id": "DCY839", "title": "FOSS4G 2022 | Open Back-End for Vector Tile Based Web Apps", "description": "The Mapping Service at the Center for Urban Research at the City University of New York (CUNY) Graduate Center engages with foundations, government agencies, businesses, nonprofits, and academics to use spatial information and analysis to develop research projects. Our most recent set of web maps focus on the decennial redistricting process in the United States. Redistricting is often a complex and complicated process. Delays in publishing data from the 2020 Census due to COVID-19 shortened the time frame for redrawing legislative lines in many states. Given the often rushed nature of redistricting it was crucial to provide fair district advocates, journalists, and lawmakers with accurate maps and data shortly after the proposed districts became publicly available.\n\nIn previous projects, we relied on proprietary back-end stacks using ArcGIS, Microsoft SQL, and the .NET framework. These products afforded a viable but inflexible solution to our GIS needs. The online mapping platform for ArcGIS is not as elegant as its open source counterparts, Microsoft SQL did not provide a solution for directly serving vector tiles, and each upgrade of Windows, IIS, and Visual Studio presented unique challenges.\n\nLast year we implemented a new back-end stack to connect our spatial databases to our web sites using FOSS solutions: QGIS, PostGres with PostGIS, Mapbox, and Nodejs. The result is a free, fully customizable solution that is easy to update, maintain, and migrate. We are currently using it in about a dozen applications to serve vector tiles and query demographic and other data. With our new workflow we were able to quickly upload dozens of map proposals, calculate metrics to analyze the potential impacts of each one, and present them on our website within hours of the data being made available to us.\\n\\nWill Field\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/DCY839/\\n\\n#foss4g2022\\n#generaltrack\\n#TransitiontoFOSS4G"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Auditorium/01 - Jody Garnett, Andrea Aime.mp4", "persons": "Andrea Aime, Jody Garnett", "pretalx_id": "3CZH8X", "title": "FOSS4G 2022 | State of GeoServer", "description": "GeoServer is a web service for publishing your geospatial data using industry standards for vector, raster and mapping, as well as to process data, either in batch or on the fly.\nGeoServer powers a number of open source projects like GeoNode and geOrchestra and it is widely used throughout the world by organizations to manage, disseminate and analyze data at scale.\n\nThis presentation provides an update on our community as well as reviews of the new and noteworthy features for the latest releases. In particular, we will showcase new features landed in 2.20 and 2.21, as well as a preview of what we have in store for 2.22 (to be released in September 2022).\n\nAttend this talk for a cheerful update on what is happening with this popular OSGeo project, whether you are an expert user, a developer, or simply curious what GeoServer can do for you.\\n\\nAndrea Aime\\nJody Garnett\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/3CZH8X/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Auditorium/02 - Jody Garnett, Andrea Aime.mp4", "persons": "Andrea Aime, Jody Garnett", "pretalx_id": "ULHR8N", "title": "FOSS4G 2022 | GeoServer Feature Frenzy", "description": "GeoServer is a web service for publishing your geospatial data using industry standards for vector, raster and mapping. It powers a number of open source projects like GeoNode and geOrchestra and it is widely used throughout the world by organizations to manage and disseminate data at scale.\n\nWhat can you do with GeoServer? This visual guide introduces some of the best features of GeoServer, to help you publish geospatial data and make it look great!\n\nGeoServer has grown into an amazing, capable and diverse program - attend this presentation for:\n\n - A whirl-wind tour of GeoServer and everything it can do today;\n\n - A visual guide to some of the best features of GeoServer;\n\n - Our favourite tricks we are proud of!\n\nNew to GeoServer - attend this talk and prioritize what you want to look into first. Expert users - attend this talk and see what tricks and optimizations you have been missing out on.\\n\\nAndrea Aime\\nJody Garnett\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ULHR8N/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Auditorium/03 - Andrea Aime.mp4", "persons": "Andrea Aime", "pretalx_id": "JUYKAX", "title": "FOSS4G 2022 | Demystifing OGC APIs with GeoServer: introduction and status of implementation", "description": "The OGC APIs are a fresh take at doing geo-spatial APIs, based on WEB API concepts and modern formats, including:\n\nSmall core with basic functionality, extra functionality provided by extensions\nOpenAPI/RESTful based\nJSON first, while still allowing to provide data in other formats\nNo mandate to publish schemas for data\nImproved support for data tiles (e.g., vector tiles)\nSpecialized APIs in addition to general ones (e.g., DAPA vs OGC API - Processes)\nFull blown services, building blocks, and ease of extensibility\n\nThis presentation will provide an introduction to various OGC APIs and extensions, such as Features, Styles, Maps and Tiles, DAPA, STAC and CQL2 filtering.\nWhile some have reached a final release, most are in draft: we will discuss their trajectory towards official status, as well as how good the GeoServer implementation is tracking them, and show examples based on the GeoServer HTML representation of the various resources.\\n\\nAndrea Aime\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/JUYKAX/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Auditorium/04 - Tom Kralidis Joana Simoes Ilie Codrina Athina Trakas.mp4", "persons": "Tom Kralidis, Joana Simoes, Ilie Codrina, Athina Trakas", "pretalx_id": "B8G9PC", "title": "FOSS4G 2022 | We are Open! OGC and OSGeo Collaboration", "description": "The Open Geospatial Consortium (OGC) and the Open Source Geospatial Foundation (OSGeo) have a long and natural tradition of collaborating. In 2022, the Memorandum of Understanding between both organizations was updated - to pay tribute to ongoing and future activities.\n\nIn the initial MoU (2008), OGC and OSGeo agreed to work closely to coordinate with each other\u2019s memberships regarding new standards developments and standards changes that may be required as a result of open source programs. Another important aspect of the relationship is to keep each other well informed of the respective activities and directions. Both aspects have proven to be of great importance. One goal was and is to coordinate activities in such a way as to maximize the achievement of both organizations\u2019 mission and goals.\nThat includes to identify open source technologies that can be used as reference implementations for and validate compliance tests developed for OGC adopted standards.\nSince the first MOU, there has been an increase in OGC on developer focus and engagement of software communities and activities.  Increased collaboration has also occured by way of the OGC API code sprints. In addition, key opportunities for cross pollination have evolved given shared missions (FAIR data) and the viewpoint that FOSS4G software is beneficial for all software.\n\nThe development of the OGC API suite of standards is an excellent example on how the MoU works in practical terms. The OGC APIs are a family of Web APIs that have been created as extensible specifications designed as modular building blocks that enable access to spatial data that can be used in data APIs. These revolutionary APIs make location information more accessible than ever before through the use of RESTful principles, and the OpenAPI specification for describing interfaces. OGC APIs have been tested in close collaboration with the global developer and end user communities through hackathons, sprints, and workshops to provide a modern solution to tomorrow\u2019s location sharing issues. For example, the 2021 Joint Code Sprint organized by OGC, OSGeo and the Apache Software Foundation (ASF) included open source implementations of OGC APIs - and became a standing sprint activity that was repeated in 2022.\n\nThis presentation provides a deeper dive into the new Memorandum of Understanding and how both open standards and  free and open source software can benefit from one another.\\n\\nTom Kralidis\\nJoana Simoes\\nIlie Codrina\\nAthina Trakas\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/B8G9PC/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Auditorium/05 - Even Rouault.mp4", "persons": "Even Rouault", "pretalx_id": "SB7PQE", "title": "FOSS4G 2022 | State of GDAL", "description": "We will give a status report on the GDAL software, focusing on recent developments and achievements in the 3.4 and 3.5 GDAL versions released during the last year, but also on the general health of the project. In particular, we will present new drivers such as the one handing Zarr datasets (format for the storage of chunked, compressed, N-dimensional arrays) or the Spatio-Temporal Asset Catalog Items driver to create virtual mosaics from STAC items, and potential future additions such as a new JPEG-2000 based driver using the Grok library, a driver for the SAP Hana database or driver for columnar storage format  such as Apache Parquet and Arrow. The topic of coordinate epochs in geospatial datasets and how we\u2019ve addressed it in various formats (GeoTIFF, GeoPackage, FlatGeobuf) will also be mentioned. As well as other improvements such as the JPEG-XL codec for the GeoTIFF format, or support for 64-bit integer data types in rasters. We will present the new CMake build system, the roadmap for its implementation, and its advantages for users and developers.\\n\\nEven Rouault\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/SB7PQE/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Auditorium/06 - Marco Bernasocchi.mp4", "persons": "Marco Bernasocchi", "pretalx_id": "UHRWMX", "title": "FOSS4G 2022 | 20 Years of QGIS [community]", "description": "QGIS turned twenty this year. The first lines of code were written in mid-February of 2002 and the first time the code compiled and ran, it could do one thing:\nConnect to a PostGIS database and draw a vector layer.\n\nQuoting Gary Sherman - \"The mythical man of QGIS that no one has ever met\":\nThis was the humble beginning of one of the most popular open-source GIS applications. GRASS GIS is of course the granddaddy of open source GIS, but the 20th birthday of QGIS is a testament to its longevity and commitment of all those who have made it what it is today.\n\nIn this talk I'll share a walkthrough of the most game-changing features and events that shaped QGIS and its community in the past 20 years making it one of the top ten most important C++ open-source projects [1] and an overall amazing project to represent :)\n\nHappy Birthday QGIS!\n\n[1] https://www.phoronix.com/scan.php?page=news_item&px=OpenSSF-Criticality-Score\\n\\nMarco Bernasocchi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/UHRWMX/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Auditorium/07 - Kurt Menke.mp4", "persons": "Kurt Menke", "pretalx_id": "WNHTN7", "title": "FOSS4G 2022 | QGIS Feature Frenzy - What's New in the Last Year?", "description": "QGIS releases three new versions per year and each spring a new long-term release (LTR) is designated. Each version comes with a long list of new features. This rapid development pace can be difficult to keep up with, and many new features go unnoticed. This presentation will give a visual overview of some of the best new features released over the last calendar year. This will be a mixture of important/popular features along with those which are easily overlooked or missed. Each highlighted feature will not simply be described, but will be demonstrated with real data. The version number for each feature will also be provided. This will let you know which new features are included in the LTR. If you want to learn about the current capabilities of QGIS this talk is for you! Potential topics include: Annotation layers * GUI enhancements * New Expressions * Point cloud support * Print layout enhancements * New renderers and symbology improvements * Mesh data algorithms * 3D * Editing\\n\\nKurt Menke\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/WNHTN7/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Auditorium/08 - Sandro Mani.mp4", "persons": "Sandro Mani", "pretalx_id": "WDPKKP", "title": "FOSS4G 2022 | Easily publish your QGIS projects on the web with QWC2", "description": "QWC2 (QGIS Web Client 2) is the official web application of QGIS, that allows you to publish your projects with the same rendering, thanks to QGIS Server. The environment is composed of a modern responsive front-end written in JavaScript on top of ReactJS and OpenLayers, and several server-side Python/Flask micro-services to enhance the basic functionalities of QWC2 and QGIS Server.\n\nQWC2 is modular and extensible, and provides both an off-the-shelf web application and a development framework: you can start simple and easy with the demo application, and then customize your application at will, based on your needs and development capabilities.\n\nThis talk aims at introducing this application and to show how easy it is to publish your own QGIS projects on the web. An overview of the QWC2 architecture will also be given. It will also be an opportunity to discover the last new features that have been developed in the past year and ideas for future improvements.\\n\\nSandro Mani\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/WDPKKP/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Auditorium/09 - Walter Lorenzetti.mp4", "persons": "Walter Lorenzetti", "pretalx_id": "9NZY8N", "title": "FOSS4G 2022 | G3W-SUITE: an OS framework dedicated to the publication and management of QGIS projects as WebGis services", "description": "G3W-SUITE is a modular, client-server application (based on QGIS-Server) for managing and publishing interactive QGIS cartographic projects of various kinds in a totally independent, simple and fast way.\nThe suite is made up of two main components: G3W-ADMIN (developed through Python, using Django ) as the web administration interface and G3W-CLIENT as the cartographic client., developed using a modular approach and is based on a \u201creactive programming\u201d paradigm using Vue.Js, Javascript framework and OpenLayer3.\nThis components communicate through a series of API REST.\nThe application is compatible with QGIS 3.22 LTR and it is based on strong integration with the QGIS API.\nIt is released on GitHub with Mozilla Public Licence 2.0\nMany graphic/functional aspects of the WebGis publication derive directly from QGIS projects as, first of all, the general and OGC services capabilities.\nThe suite automatically inherits aspects related to the project (themes, 1: N relations, simple and atlas print layout, filter on legend based on map content, layer display order and activation status ...) and related to individual layers (activation scale, interrogability, published attribute fields, join attributes, attribute form, editing widgets ...) .\nOf particular interest is the strong integration with the QGIS DataPlotly plugin.\nQGIS projects can be published as WebGis services via direct upload (no plugins needed) on the Administration component.\nThe granular system of permissions and the subdivision into roles of users (individuals or groups) allows the management of services to be delegated to second and third level administrative users.\nIt is also possible to define consultation permissions on individual WebGis services and editing permissions on individual layers with different editing powers per user.\nFinally, it is possible to define geographic and alphanumeric constraints (both in consultation and in editing) differentiated by individuals or groups of users. Alphanumeric constraints can be based on SQL language or QGIS expressions.\nIt is also possible to define for each layer aspects relating to the preparation of predefined searches, caches and downloads in various formats.\nA particularly advanced function is related to online editing and to the possibility of easily creating web cartographic management systems by defining the various aspects at the level of the QGIS project.\nThis function (operating directly on the data through the QGIS API) allows multi-user editing thanks to a feature-lock system.\nEditing works both at the geometric level (with intra- and inter-layer snap), and at the attributes level (editing form and the widgets included) also connected by joins or 1:N relationships.\nThe call will allow to illustrate the innovations of the current and future versions.\nThese include the implementation of editing functions, user-based filters linked to the visibility of layers and attributes, the possibility of using QGIS projects based on embedded base projects and the integration of the vectorial and raster Temporal Controller of QGIS.\nOnline geographic analysis possible thanks to the integration of Processing algorithms through dedicated APIs.\\n\\nWalter Lorenzetti\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/9NZY8N/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Auditorium/10 - Julien Moura.mp4", "persons": "Julien Moura", "pretalx_id": "MZTDHF", "title": "FOSS4G 2022 | Better productivity for QGIS plugin developers", "description": "Developing a plugin for QGIS is both as simple as one of the countless tutorials and as complicated as a software engineering job facing with the dynamism of the project (maintenance requirements), the size of the APIs and constraints that need to be taken into account (Windows, etc.).\n\nAt Oslandia, we create and maintain many plugins for our clients, which leads us to streamline their development... and especially their maintenance! Historically, many extensions were created using the amazing Plugin Builder and the underlying tool (pb_tool) but it no longer fit our needs.\n\nWe present here our QGIS Plugin Templater (https://oslandia.gitlab.io/qgis/template-qgis-plugin/), based on Cookiecutter (https://cookiecutter.readthedocs.io/) and the related work on developer tools (tests, documentation, code structure, formatting, linter...). We will also mention the other tools we are using or following closely (the 3Liz toolbelt, the other template from Gispo Coding...).\n\nYet Another Plugin Generator? Probably but we think it's worth it!\\n\\nJulien Moura\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/MZTDHF/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Auditorium/11 - Luca Delucchi - Closing Remarks.mp4", "persons": "Luca Delucchi", "pretalx_id": "AYWDJG", "title": "FOSS4G 2022 | Closing Session", "description": "Closing session with Sol Katz 2022 announcement, FOSS4G 2023 presentation an much more\\n\\nLuca Delucchi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/AYWDJG/\\n\\n#foss4g2022\\n#generaltrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Auditorium/12 - OSGeo AGM.mp4", "persons": "", "pretalx_id": "XMJZGY", "title": "FOSS4G 2022 | OSGeo AGM", "description": "The OSGeo Annual General Meeting\\n\\n\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/XMJZGY/\\n\\n#foss4g2022\\n#generaltrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Verde/1 vicky vergara.mp4", "persons": "Vicky Vergara, Ashish Kumar", "pretalx_id": "G9SWET", "title": "FOSS4G 2022 | Are you lost? Get pgRouting to find your way", "description": "pgRouting not only allows to get routes for any kind of transportation, from 0 wheels to 18 wheeler.\nA road is closed? Calculate how can traffic be diverted.\nDon't get a result? Check if your graph is connected.\nNeed to deliver to several clients? Traveling Salesperson problem helps to determine the route.\nFind out what is planned for version 4.0 that is a work in progress.\nLearn about the spin off for vehicle routing problems.\npgRouting extends the PostGIS / PostgreSQL geospatial database to provide geospatial routing functionality.\nAdvantages of the database routing approach are:\n\n - Data and attributes can be modified by many clients, like QGIS through JDBC, ODBC, or directly using Pl/pgSQL. The clients can either be PCs or mobile devices.\n - Data changes can be reflected instantaneously through the routing engine.\n - The \u201ccost\u201d parameter can be dynamically calculated through SQL and its value can come from multiple fields or tables.\\n\\nVicky Vergara\\nAshish Kumar\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/G9SWET/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Verde/2 Laure-H\u00e9l\u00e8ne Bruneton.mp4", "persons": "Laure-H\u00e9l\u00e8ne Bruneton", "pretalx_id": "JKV73V", "title": "FOSS4G 2022 | pgRouting optimization: from technical to functional", "description": "Due to its SQL-based engine, the OpenSource Software pgRouting is the most flexible routing engine available.\nA common misconception is that pgRouting is the least performant routing engine.\n\nSo how to keep both performance and flexibility with pgRouting ?\n\nMany factors should be taken into account.\nTo begin with, the use cases.\nWhat level of precision do you need ?\nWill you be computing short or long routes ?\nWill there be many routes computed at the same time ?\n\nSimplification is the most common way to deal with performance issues.\nHowever, when accuracy is at the core of decision making, a minimum level of precision must be kept.\nReducing the number of rows the routing engine will have to process is the number one tip to enhance performances.\nBut there are many other technical and functional optimizations that can make pgRouting run much faster.\n\nWe will look at some choices we had to make in various projects.\nHow the data is the first key to optimization.\nBut also how to help the routing engine make the best of it.\nWhich algorithms are best used for which use cases, and how fine tuning the database can help too.\\n\\nLaure-H\u00e9l\u00e8ne Bruneton\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/JKV73V/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Verde/3 Christopher Beddow.mp4", "persons": "Christopher Beddow", "pretalx_id": "S99HMM", "title": "FOSS4G 2022 | How to Mapillary - Getting started with Street-level Mapping", "description": "Mapillary is the platform that makes street-level images and map data available to scale and automate mapping. There are many tools available within Mapillary\u2019s ecosystem, as well as many real world use cases where Mapillary can have an impact. In this talk, we will give an overview of the state of the Mapillary platform in 2022. This will include a look at compatible camera devices, upload methods, data and imagery management, download methods, integrations, and stories about users who apply Mapillary to solve a challenge.\n\nYou should walk away from this talk knowing how you want to use Mapillary to improve maps important to you, and what tools you need to get started.\n\nIf you are interested in improving OpenStreetMap, contributing to open data, capturing imagery in your community, or leveraging Mapillary street-level imagery and GIS data into your professional work, this talk is for you. No coding or technical experience is necessary, and the tools and features available can be adapted to any skill level. Join us!\\n\\nChristopher Beddow\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/S99HMM/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Verde/4 Andrea Borghi.mp4", "persons": "Andrea Borghi", "pretalx_id": "Q3VRNT", "title": "FOSS4G 2022 | GeoServer-cloud: Cloud Native GeoServer in production environments", "description": "In this presentation, we show how GeoServer-Cloud has matured into a production ready, cloud-native micro-services application. It has already been successfully deployed in production for three major organizations in their respective kubernetes environments.\n\nGeoServer-Cloud is a spring-boot/spring-cloud based micro services application built on top of GeoServer. The main goal of this implementation is to have an effective and easy way to scale the different services horizontally, splitting GeoServer geospatial services and API offerings into individually deployable components.\n\nAll the services communicate with each other via a messaging queue. There\u2019s no wait-time between configuration changes and their reflection across all services in the cluster, nor the need to reload the applications.\n\nThe last year has not only been spent hardening the code, but also a lot of emphasis has been put on the deployment procedures. In this presentation we will explain how to deploy GeoServer-Cloud in a kubernetes environment. We will showcase the official helm chart that can be used to install it everywhere.\n\nGeoServer-Cloud allows per-service auto scaling and server resource dimensioning, hence optimizing each service based on its performance characteristics. We will discuss how to achieve good load balancing based on service metrics.\\n\\nAndrea Borghi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/Q3VRNT/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Verde/5 Nuno Oliveira.mp4", "persons": "Nuno Oliveira", "pretalx_id": "KZBJ3M", "title": "FOSS4G 2022 | Processing and publishing big data with GeoServer and Azure in the cloud", "description": "The amount of data we have to process and publish keeps growing every day, fortunately, the infrastructure, technologies, and methodologies to handle such streams of data keep improving and maturing. GeoServer is a web service for publishing your geospatial data using industry standards for vector, raster, and mapping. It powers a number of open source projects like GeoNode and geOrchestra and it is widely used throughout the world by organizations to manage and disseminate data at scale. We integrated GeoServer with some well-known big data technologies like Kafka and Databricks, and deployed the systems in Azure cloud, to handle use cases that required near-realtime displaying of the latest received data on a map as well background batch processing of historical data.\n\nThis presentation will describe the architecture put in place, and the challenges that GeoSolutions had to overcome to publish big data through GeoServer OGC services (WMS, WFS, and WPS), finding the correct balance that maximized ingestion performance and visualization performance. We had to integrate with a streaming processing platform that took care of most of the processing and storing of the data in an Azure data lake that allows GeoServer to efficiently query for the latest available features, respecting all the authorization policies that were put in place.  A few custom GeoServer extensions were implemented to handle the authorization complexity, the advanced styling needs, and big data integration needs.\\n\\nNuno Oliveira\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/KZBJ3M/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Verde/6 Alessandro Parma.mp4", "persons": "Alessandro Parma", "pretalx_id": "3RQZ73", "title": "FOSS4G 2022 | Deploying and operating GeoServer: a DevOps perspective", "description": "Cloud computing is revolutionizing the way companies develop, deploy and operate software and GeoSpatial software is no exception. With benefits of cloud based deployments range from cost savings to simplified management, flexibility, lower downtime and scalability of dynamic environments it is easy to understand why more and more companies are migrating their on premise systems to the cloud but cloud based setups have their own set of hurdles and challenges.\nThe migration of the series itself can be challenging. Monitoring, debugging and scaling of applications are very much different than what you are used to.\n\nIn this presentation we will share with you the lessons we have learned at GeoSolutions to tackle these problems and share some common patterns for the migration of on premise GeoServer clusters to the cloud. We'll share with you tips on:\n\n - best practices to migrate your existing GeoServer cluster to the cloud\n - insights on your geoserver cluster using centralized logging and Monitor plugin\n - avoid common bottlenecks to best set up a distributed scalable GeoServer cluster\n - work containers and container orchestrators like Kubernetes\\n\\nAlessandro Parma\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/3RQZ73/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Verde/7 Nicolas Bozon.mp4", "persons": "Nicolas Bozon", "pretalx_id": "3KMLVC", "title": "FOSS4G 2022 | Vector tiles cartography tips and tricks", "description": "Vector tiles are changing the way we create maps. Client-side rendering offers endless possibilities to the cartographer and has introduced new map design tools and techniques. Let\u2019s explore an innovative approach to modern cartography based on simplicity and a comprehensive vector tiles schema.\n\nAfter a short introduction or useful reminder to vector tiles, take a tour of their graphic capabilities through a series of original map design compositions. A variety of cartographic examples will be illustrated during this talk, with a particular focus on map display and performance. Rendering issues and technical limitations will also be put in perspective with pragmatic solutions or design alternatives.\n\nGet an overview of best practices for vector tiles cartography and learn about simple open-source recipes, towards advanced combinations of fills, patterns, fonts, and symbols. Selected layer parameters and style expressions will be discussed in a visual way and explained with basic syntax that you can take away.\\n\\nNicolas Bozon\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/3KMLVC/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Verde/8 Jochen Topf.mp4", "persons": "Jochen Topf", "pretalx_id": "UYJAMC", "title": "FOSS4G 2022 | Creating vector tiles with osm2pgsql", "description": "For over a decade now osm2pgsql has been the standard tool for importing OpenStreetMap data into a PostgreSQL/PostGIS database for rendering of raster tiles and many other use cases. Thanks to several improvements in the last years centered around a flexible configuration language and new geoprocessing capabilities, osm2pgsql is now also a great base for creating a vector tile toolchain. It can easily handle imports of a small country in a few minutes as well as scale to a planet-sized database with minutely updates from OSM.\n\nThe talk will introduce some of the new features that allow you to customize the database table layout and contents. It will outline the few steps needed to create your very own custom vector tiles based on OpenStreetMap data. We'll see how you can use the configuration language to clean up OSM data on import and prepare it for fast access with a vector tile server like T-Rex.\\n\\nJochen Topf\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/UYJAMC/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Verde/9 Pirmin Kalberer.mp4", "persons": "Pirmin Kalberer", "pretalx_id": "KW7SQD", "title": "FOSS4G 2022 | 3D Tiles Next", "description": "\"3D Tiles Next\" is a major update of the \"3D Tiles\" OGC Community Standard 1.0. 3D Tiles are designed by Cesium GS, Inc. for streaming massive heterogeneous 3D geospatial datasets. 3D Tiles Next is a set of extensions in the following areas:\n\n - direct use of glTF models\n - using glTF for point clouds and glTF extensions for texture compression additional 3D tiles functionality\n - semantic metadata stored per tileset, feature, vertex and more\n - implicit spatial indexes (quadtree, octtree, S2 subdivision)\n\nThis presentation gives an overview of the current \"3D Tiles\" format and shows new features in the \"3D Tiles Next\" specification. It also covers other existing 3D OGC (community) standards like CityJSON or \u00abIndexed 3D Scene (I3S)\u00bb.\n\nImportant further topics are :\n\n - overview of viewers for 3D Tiles on the web and in native and mobile applications using game engines\n - data processing tools for producing data in these formats\n - building a community for creating 3D tiles for GIS and OSM data\\n\\nPirmin Kalberer\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/KW7SQD/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Limonaia/1 MARKUS NETELER.mp4", "persons": "Markus Neteler, Marc Jansen, Markus Metz, Anika Weinmann", "pretalx_id": "PCD8VQ", "title": "FOSS4G 2022 | The GreenUr project: creating an application in QGIS to manage the impacts of urban green spaces on human health", "description": "Globally, the population living in urban areas is increasing with a strong impact on land use patterns, particularly on the availability and use of green spaces. The impact of green spaces is beneficial to health, for example, by reducing mortality or improving mental health. These effects are also related to different ecosystem services provided by green spaces, such as regulating temperature, modifying air pollution and noise levels, and offering more opportunities for physical activity.\n\nGreenUr is a plugin for QGIS that aims at putting together knowledge and information on the impacts of green space on health. It is developed as a prototype representing a work in progress coordinated by the World Health Organization (WHO) to provide an educational tool to introduce the relation between green spaces, health, and well-being and raise awareness of the importance of green spaces in cities globally. The tool can also be used as \u2018quickscan\u2019 for urban spatial planners that would like to orientate on possible effects of current and new green space design. The plugin has been tested with different experts and locations, and it will be downloadable via the QGIS Plugin manager from the project website.\n\nThe GreenUr tool allows the users to estimate the impacts of green spaces on health in a given population. The main questions addressed by the current version of the GreenUr prototype are the following:\n\n - How much green space is available for the population of a specific city?\n - Which are the pathways through which green spaces relate to health?\n - Where within a city are health-related benefits of green spaces the largest?\n - Which are hypothetically different land-use scenarios for green spaces?\n - What would be the magnitude of the change in health impacts if future green space would be changed in cities?\n\nAll calculations performed by GreenUr are based on methodologies established by social, environmental, and epidemiological studies identified by WHO. The computational backend used is GRASS GIS and other processing methods available in QGIS. The plugin is running any common operating system and offers a demo database.\\n\\nMarkus Neteler\\nMarc Jansen\\nMarkus Metz\\nAnika Weinmann\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/PCD8VQ/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Limonaia/2 EMMANUEL BELO.mp4", "persons": "Emmanuel Belo", "pretalx_id": "Z8ZFAE", "title": "FOSS4G 2022 | swissgeol.ch - Geology in 3D: new features", "description": "Geological data usually suffer from very low visibility because they are specialized data that are only accessible to a few people and can only be visualized and processed using special software. The swissgeol.ch portal, newly launched by swisstopo (Swiss Federal Office of Topography), aims to change this by making the data accessible on the Internet in a low-threshold and simple way using 3D visualization based and promoted with open-source technology and code.\nswissgeol.ch is a web application for the visualization and analysis of geological sub-surface data.  It has been publicly available at https://viewer.swissgeol.ch since 2020, and the open source code is can be downloaded at https://github.com/swissgeol/ngm.\nIn addition to the geo-portal of the Swiss Confederation (https://map.geo.admin.ch) which focusses on 2D spatial data, swissgeol.ch extents its functionality to 3D data above, on and below the surface. For this, it relies on 3D visualization on the web, which is based on CesiumJS and offers numerous expert tools.\nCesiumJS is the most widespread open source 3D globe library and is used worldwide in many different applications. It not only visualizes large-scale global data, but also very detailed data at the local scale, such as buildings in the 3D view of map.geo.admin.ch.\nWith the development of swissgeol.ch, an underground navigation option was developed in CesiumJS for the first time, which allows the visualization of 3D objects below the terrain. In addition to navigating underground, it is also possible to see through the earth's surface using transparency settings, as well as to slice the 3D-scene vertically.\nWith the use of 3D tiles and precise terrain (2m precision), the data is delivered in an optimized format for the web. At the same time, the download of original data of entire layers or individual objects in the layer is offered.\nAfter the positive echo of last year\u2019s talk, we are going to present this year selected features and data in greater detail and introduce recent developments: A new user experience and a specific user space for projects, as well as new data and formats, e.g. using the new voxel Cesium Next Tiles specs.\\n\\nEmmanuel Belo\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/Z8ZFAE/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Limonaia/3 Fabio Giannetti.mp4", "persons": "Fabio Giannetti", "pretalx_id": "KQJTPH", "title": "FOSS4G 2022 | Use of remote sensing and GIS processing for mapping Chestnut stands decline in Piemonte Region", "description": "Chestnut stands in Piemonte are presently suffering a severe decline due to the concurrence of climatic and silvicultural factors. A project funded by Piemonte region involving the Regional Chestnut Centre and IPLA S.p.A. started in 2018 with the aim of defining technical guidelines for proper interventions in declining stands. The present contribution deals with the activities of spatial monitoring of declining areas through satellite images interpretation and GIS analysis making use of QGIS and Grass tools. Methodological approach was based on the selection of Sentinel 2A e 2B images taken at the beginning and at the end of the summer season in 2017, 2018 e 2019 on a test area. Those images were then processed calculating some indexes with raster functions implemented in QGIS. NDWI Normalized Difference Water Index (B8-B12/B8+B12) resulted the more sensible to the presence of declining stands\nAccurate mapping of areas suffering different degree of damages on the whole Region was then carried out starting from a preliminary analysis of experimental parcels surveyed on the field.\\n\\nFabio Giannetti\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/KQJTPH/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Limonaia/4 Gordon Logie.mp4", "persons": "Gordon Logie", "pretalx_id": "FRAVTT", "title": "FOSS4G 2022 | A tool for mapping fire burn severity and extent in watersheds for flood risk assessment", "description": "As climate change progresses, we are experiencing an increase in the frequency and severity of extreme weather events in many parts of the world. Climate models predict the frequency and severity of these weather events to continue to increase in the future as surface air temperatures rise.\n\nIn 2021, the Canadian province of British Columbia (BC) experienced one of the most severe fire seasons on record which destroyed communities and ecosystems across the province. In the same year, an \u201catmospheric river\u201d precipitation event led to widespread flooding causing severe damage to roads and communities across BC. There is a correlation between severe wildfires and increased runoff following precipitation events in some regions.\n\nThere is a need for better prediction, monitoring, and management of fire and flood events to mitigate the damages caused by post-wildfire flooding. Remote sensing data and analysis techniques play a key role in monitoring climate-related natural disasters and helping understand and mitigate risks to communities, ecosystems, and infrastructure in areas that may be exposed to flooding. Free remote sensing datasets along with free and open source software can greatly reduce the costs and increase availability of this monitoring capability, increasing stakeholder access to geospatial intelligence.\n\nThis talk presents a tool developed at Sparkgeo for automated mapping of burn severity and extent within watersheds of interest. The tool uses multi-source public remote sensing data in a cloud-based workflow, taking advantage of recent open source initiatives including the SpatioTemporal Asset Catalog (STAC). The tool can help assess flood risk from significant rainfall events and may offer essential flood mitigation and risk management knowledge. We present the tool\u2019s deployment to map 2021 wildfires in several British Columbia watersheds.\\n\\nGordon Logie\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/FRAVTT/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Limonaia/5 Andrew Bean.mp4", "persons": "Andrew Bean", "pretalx_id": "DKKUYY", "title": "FOSS4G 2022 | Micronutrient Action Policy Support (MAPS) - A decision support tool for investigating the scale and geographic distribution of micronutrient availability in sub-Saharan Africa", "description": "Micronutrient deficiencies (MNDs), so-called \u2018hidden-hunger\u2019, can have serious ramifications for the health of individuals affected and the economy of the country in which they live. MNDs are a global problem but disproportionately affect populations in low-income countries. Work to alleviate these deficiencies aligns with the UN\u2019s Sustainable Development Goals (SDG), especially SDG2 \u2013 access to adequate safe and nutritious food. Data which can support the understanding of the scale and location of these deficiencies can be fragmented in their availability and accessibility, creating a barrier to their use in planning interventions by stakeholders in the very nations where the impacts of MNDs are most severe.\n\nThe Micronutrient Action Policy Support (MAPS) tool is a web-hosted open access platform providing a unique enabling environment for the wider agriculture-nutrition community and beyond which allows users to view and explore MND risks at various spatial and temporal scales. The tool can provide users with dietary micronutrient supply estimates of all nations in sub Saharan Africa using national-scale and subnational-scale data. Preprocessing steps to clean these data in R language are made available through the open github repository, so that any user can replicate the data used in the tool.\n\nPriorities for the data and functionality have been co-designed with key users from project proposal stage. Stakeholder feedback is used in continued iteration as richer content, supporting material, and functionality is planned, developed and released.\n\nThe platform is built on open-source technologies utilising Postgres and PostGIS to store, combine and interrogate a range of heterogeneous datasets to calculate micronutrient supply estimates, node.js for data APIs and web map services using Geoserver.  Further data processing is conducted using R, with the front-end interface utilising Angular, leaflet.js and chart.js.  Metadata is managed and served via Geonetwork.  The code for the platform, as well as data processing scripts, methods and processes are all open source at https://github.com/micronutrientsupport.\n\nThis talk will provide an overview of the platform along with the datasets and open-source technologies that underpin its functionality, and the UX approaches taken to ensure that this tool meets the currently unmet needs of priority users.\n\n(https://micronutrient.support)\\n\\nAndrew Bean\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/DKKUYY/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Limonaia/6 Marco Corsi.mp4", "persons": "Marco Corsi", "pretalx_id": "EMCDLQ", "title": "FOSS4G 2022 | ARCOS Platform for Monitoring of Arctic Region", "description": "The objective of ARCOS is to design and implement an early-warning system providing continuous monitoring of the Arctic Region. Designed to generate actionable products in the security domain by processing and fusing multi-sensor data, the system integrates available information from space, non-space sources and products available from multiple Copernicus services.\nARCOS generates information at three different levels of scale and user interaction:\n\n 1. Level 1: Automatic Early-warning System. Integration of space and non-space data sources for the triggering of alarms on the region when certain conditions happens. Automatic early-warnings are generated in case anomalous behaviours are detected. For this wide-area monitoring, automatic extraction of analytics and AI techniques are applied.\n 2. Level 2: User-Driven Alert System, where space and non-space data is processed on specific locations provided by the user. The alarms can be configured based contextual information based on the user input.\n 3. Level 3: Geospatial Intelligence Products. Following early-warnings generated in Level 1 or 2, geospatial intelligence products requiring human intervention are provided upon user request.\n    The system is developed using GeoNode (https://geonode.org/) as a Core component and integrates OpenEO services (https://openeo.org/) for the generation of innovative contents from open datasets like Copernicus Sentinels data, Copernicus Services data, AIS data and Social media.\\n\\nMarco Corsi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/EMCDLQ/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Limonaia/7 FRANCESCO BURSI.mp4", "persons": "Francesco Bursi", "pretalx_id": "HE3FHW", "title": "FOSS4G 2022 | From photographic survey to street-level imagery integration in an OpenSource webgis: complete workflow", "description": "For several years Gter has been involved in the development and maintenance of the webGIS related to the management of the road network of the Province of Piacenza. Recently, the client requested the integration of the images, deriving from the photographic survey of about 520 Km of routes, in the existing webGIS (an instance of Lizmap Web Client which public version can be found here https://catastostrade.provincia.pc.it/lizmap/lizmap/www/index.php/view/map/?repository=progettipubblici&project=catasto_strade_pub).\nIn this case, the Public Administration needed the photographic survey in order to update a set of old images sparsely distributed along the network and to have a customized tool similar to services like Google Street View. Therefore, an integration of the Mapillary viewer in Lizmap Web Client has been proposed and developed; hence the survey was performed with a camera that uses front and back optics to have 360-degree photos.\nThe workflow consisted of four main tasks. The first step involved the photographic survey of the road network using a GoProFusion360 mounted on a car that took photos of the surrounding environments. The next step consisted in the processing of the images, stitching the front and the back photos in order to obtain a 360-degree panoramic image. This step has been automated through the development of a Python script together with the use of the available software of the camera from the command line. About 50000 photos were uploaded on the Mapillary platform. Images have been integrated into the Lizmap Web Client webGIS through the Mapillary viewer and utilities. The integration was achieved by developing a new feature  for Lizmap Web Client based on Mapillary JS, an Open Source library provided by Mapillary that helps developers interact with the Mapillary API.\nThe final result is a tool that makes the Public Administration able to navigate and reach the photos uploaded on Mapillary directly from a window in the webGIS.\\n\\nFrancesco Bursi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/HE3FHW/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Limonaia/8 OLLI RANTANEN.mp4", "persons": "Olli Rantanen", "pretalx_id": "TDDGJ9", "title": "FOSS4G 2022 | Developing a topographic data production system based on open source", "description": "The National Land Survey (NLS) of Finland decided in the fall of 2020 to develop a national topographic data production system based on open source technologies and especially on QGIS client. Since then, many significant steps have been taken for us to be able to implement the MVP of the application for the mappers of the NLS at the start of 2024. Later on, we are planning to replace our digital elevation model production system with similar technologies which would enable us to replace the current mapping system by 2026. In this presentation I will talk about our system's architecture, the tools we are developing and furthermore, some insights that we have learned during this project.\n\nThe application's architecture is based heavily on Postgres, where we run the main database from which the national topographic maps are made. The operators can access the main database via Job management-plugin and modify the database objects on the client (QGIS). These modifications (inserts, updates, deletes) are saved in the operators' work database, from which they can register these changes to the main database.\n\nOur first challenge was to design how more than 150 operators of the NLS are able to work using the same main database. We decided to use the client-web service architecture. The benefit of that is that we can use QGIS as such as it is and we can build all of the functions required for job management into the backend application. The job management plugin communicates with the web service and the conflicts between the different work databases are handled by a separate tool. With the tool, an operator can solve conflicts that are created by another operator editing the same objects.\n\nCurrently, we are integrating stereo compilation with QGIS, which will enable the operators to measure objects from 3D aerial stereoscopic photos. The next steps are to develop comprehensive tools for quality assurance and to improve basic QGIS tools for selecting, editing and digitizing objects. The problem is that we have over a hundred different layers, therefore the default way to choose the layer is not sufficient for the operator. We also want to develop tools for real time quality checking so that the mapper would immediately know if a quality error occurs, making the general workflow smoother.\n\nAlthough some of the components are custom-made, our purpose is to publish those components that we recognize to be useful for other QGIS users. In addition, we have seen the value of multiple premade plugins to which we are planning to contribute as well. As a whole, NLS is currently looking for new ways to be a part of the open-source community.\\n\\nOlli Rantanen\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/TDDGJ9/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Limonaia/9 ANDREA AIME.mp4", "persons": "Andrea Aime, Simone Giannecchini", "pretalx_id": "SJTQTK", "title": "FOSS4G 2022 | Supporting precision farming with GeoServer:  past experiences and way forward", "description": "The amount of data available from drones, earth observation as well as machinery itself (i.e. telemetry data) plus the advent of cloud infrastructure has given a huge impulse to innovating the way we used to support farmers and farming in general, democratizing access to data and capabilities like never before through precision (or digital) farming solutions.\n\nPrecision farming (or digital farming) has therefore become one of main use cases for GeoServer deployments over the past years and at GeoSolutions we have worked with many clients, from NGOs to large private companies (like Bayer), from startups to organizations like DLR in helping them to support their client to make sense of data and information through GeoServer and other geospatial open source technologies at scale, in the cloud.\n\nThis presentation will condense 10 years of GeoSolutions in ingesting, managing and disseminate data at scale in the cloud for the precision farming industry covering items like:\n\n - Proper optimizations and organization of raster data\n - Proper optimizations and organization of vector data\n - Modeling data for performance & scalability in GeoServer and PostGIS\n - Deployment guidelines for performance and scaling GeoServer\n - Styling to create NDVI and other visualizations on the fly\n\nAt the end of the presentation the attendees will be able to design and plan properly a GeoServer deployment to serve precision farming data at scale.\\n\\nAndrea Aime\\nSimone Giannecchini\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/SJTQTK/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Limonaia/10 REGIS HAUBOURG.mp4", "persons": "R\u00e9gis Haubourg", "pretalx_id": "3Z3TQY", "title": "FOSS4G 2022 | How to deal with a massive geographic database when surrounded by datascientists ?", "description": "The Scientific and Technical Center for Building (CSTB) built the first French database of buildings and houses to address climate change challenge, helping knowledge and decision making for massive retrofit.\nThe pipeline factory intersects massive datasets (21 Millions buildings, >400 descriptors) and keeps adding new predictions and external datasets all the time. It allows to run analyses and predictions for all the climate change related indicators, such as housing price and energetic performance relation, heat wave impact, solar potential, etc..\nWhile the first versions where a direct image of the classical datascientist\u2019s approach -ie a massive dataframe driven by massive yaml config files and cryptic meta-templated scripts\u2013 ease of use and access performance soon became a limiting factor.  This is a major concern since this dataset will be one long term foundation of derived information systems.\nBetween brute force approach based on scaling resources up, and the old fashioned \u00ab\u00a0data diet\u00a0\u00bb normalization and optimization process, the truth is not easy to find.\nAbusing from cartoonish humor, this talk will try to explore the benefits of normalizing back hugely redundant geographic datasets and making public interfaces (public SQL model, API\u2019s, vector tiles, OGC API\u2019s) so that both end users can analyze efficiently this dataset, and the data manager team can rely on more stability using those good old\u2019 database constraints.\\n\\nR\u00e9gis Haubourg\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/3Z3TQY/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Limonaia/11 PIERGIORGIO CIPRIANO.mp4", "persons": "Piergiorgio Cipriano", "pretalx_id": "SCZWUM", "title": "FOSS4G 2022 | SensorThings API in practice: the AIR-BREAK project in Ferrara", "description": "In the city of Ferrara (Italy) Dedagroup Public Services and other partners are involved in AIR-BREAK project (https://airbreakferrara.net/) to implement a set of geo-ICT tools for supporting an improved identification and monitoring of urban air quality.\nDifferent datasets from heterogeneous sources have been already interconnected and integrated in the Spatial Data Infrastructure of the Municipality of Ferrara, based on (geo)standard protocols for data interchange sourced by:\n\u2022\t173 authoritative AQ monitoring stations from 3 regional environmental agencies, ARPAE Emilia-Romagna (52), ARPA Veneto (33) and ARPA Lombardia (88), for their own whole regional areas;\n\u2022\t2 private AQ monitoring stations managed by private companies located in Ferrara;\n\u2022\t14 new AQ monitoring stations installed by Lab Service Analytica (project partner) in the territory of Ferrara\nFor integrating and sharing dynamic hourly data about air quality and other themes, we adopted the OGC Sensor Things APIs (STA) as the reference standard protocol [1].\nSTA is based on the OGC/ISO 19156:2011 [2] and provides an open and unified framework to interconnect IoT sensing devices, data, and applications over the Web. It is an open standard addressing the syntactic interoperability and semantic interoperability of the Internet of Things. It complements the existing IoT networking protocols such CoAP, MQTT, HTTP, 6LowPAN. While the above-mentioned IoT networking protocols are addressing the ability for different IoT systems to exchange information, STA is addressing the ability for different IoT systems to use and understand the exchanged information.\nIn AIR-BREAK project, FROST solution (FRaunhofer Opensource SensorThings-Server) [3] has been deployed in the GIS server farm of the Municipality of Ferrara to complement Geoserver and other technologies already providing services for viewing/accessing data based on OGC standards.\nIndeed, among the final objectives of the project, the implementation of a standard-based Air Quality Data Infrastructure focuses on:\n\n 1. creating a bi-lateral and cooperative communication systems between authorities and citizens about air quality and its perception;\n 2. defining and implementing a multi-stakeholder Data Infrastructure on Air Quality to integrate existing/heterogeneous/dynamic data from both authoritative sources and crowdsourced by citizens (Rete di Monitoraggio Ambientale Partecipativo [4]);\n 3. providing such dynamic air quality data to local authorities involved monitoring (i.e. Municipality of Ferrara, ARPAE, Regione Emilia-Romagna) and to citizens, through standard APIs (STA) and with open licenses through the upcoming open data portal of Ferrara (June 2022);\n 4. testing and validating innovative solutions for air quality monitoring using in-situ IoT sensors and satellite remote sensing (e.g. Copernicus)\n\nReferences:\n[1] https://en.wikipedia.org/wiki/SensorThings_API\n[2] https://www.iso.org/standard/32574.html\n[3] https://github.com/FraunhoferIOSB/FROST-Server\n[4] https://rmap.cc/\\n\\nPiergiorgio Cipriano\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/SCZWUM/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Limonaia/12 JOANA SIMONES.mp4", "persons": "Joana Simoes, Athina Trakas", "pretalx_id": "8QJZNW", "title": "FOSS4G 2022 | OGC API Standards: Past, Present, and Towards an Exciting Future", "description": "Over the past several decades a significant number of geospatial datasets have been published on the Web. Many of those datasets were published through implementations of classic OGC Web Service standards. As time has gone past, the architecture of web applications has evolved, propelled by new Web and Internet standards. This evolution of web application architecture has led to a revolution in how geospatial datasets are published on the Web. To ensure that the revolution in geospatial data publication has interoperability at its core, the Open Geospatial Consortium (OGC) has developed a series of Web Application Programming Interface (API) standards.\n\nThe OGC API suite of standards is a family of specifications that have been designed as modular building blocks that spatially enable Web APIs that offer access to spatial data and implementations of geospatial algorithms. These revolutionary APIs make location information more accessible than ever before through the use of the OpenAPI specification for describing interfaces. The use of the OpenAPI specification means that implementations of OGC API Standards can describe themselves to levels of detail previously unachievable through the classic OGC Web Service standards. Such an ability to self-describe is significant because it has enabled software developers from a variety of disciplines to implement OGC API Standards to address the needs of their communities.\n\nThis presentation will provide an overview of the background, current status, and future plans for the development of OGC API Standards. The presentation will describe plans for the development of resources that improve the ability of developers to implement OGC API Standards. The presentation will also present a selection of case studies of open source software that has been implemented or enhanced during OGC Innovation activities such as testbeds, hackathons, and sprints (including the 2022 Joint Code Sprint organised by OGC, OSGeo and the Apache Software Foundation (ASF)).\\n\\nJoana Simoes\\nAthina Trakas\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/8QJZNW/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Onice/1 Etienne Trimaille.mp4", "persons": "Boisteault Nicolas, Etienne Trimaille, Ren\u00e9-Luc Dhont", "pretalx_id": "CWGULA", "title": "FOSS4G 2022 | State of Lizmap - Past / Present / Futur", "description": "Lizmap is an opensource server application to publish QGIS project on the web without any coding skills needed.\nIt's using QGIS Server in the backend so users have the same rendering between their QGIS Desktop and the web version of their project.\n\nQGIS Server and Lizmap are reading QGIS project to publish layers with their legend, forms, print layout, layer relationships... Some additional Lizmap configuration can be added to have dataviz capabilities, decide or not to publish the attribute table or to configure the feature filter form. No coding skills are required, all the configuration is done using QGIS Desktop user interface.\nThe QGIS project is adapted for web browsers and have a responsive UI. Lizmap include some Access Control List at different levels such as project, layer or even features.\n\nThe goal of this presentation is to show the state of this opensource project hosted on GitHub and to explain the roadmap.\\n\\nBoisteault Nicolas\\nEtienne Trimaille\\nRen\u00e9-Luc Dhont\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/CWGULA/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Onice/2 Sander Schamin\u00e8e.mp4", "persons": "Sander Schaminee", "pretalx_id": "3R9CQK", "title": "FOSS4G 2022 | State of Bridge for QGIS", "description": "GeoCat Bridge for QGIS is a Python plugin that enables users to publish map layers as OGC data services (WM(T)S/WFS/WCS) to GeoServer or MapServer. It can also publish layer metadata to the GeoNetwork spatial catalog (CSW), linking service to metadata and vice versa, so that users can easily bind to a service from a catalog search result or find the relevant metadata for an exposed dataset.\nBridge can also export metadata, symbology and geodata to local files, so you can modify them and/or upload them manually.\n\nSince its first official release at the FOSS4G in Bucharest (2019), GeoCat has been gradually improving the plugin. One of the most requested and anticipated changes to Bridge for 2022 relates to GeoServer workspace publication. The next upcoming major release involves some major UX changes, which will allow more control over a workspace. For example, users can soon add (or overwrite) single layers to an existing workspace, whereas in older versions all workspace data was removed prior to publication. We would like to take the opportunity to discuss the upcoming release, highlighting this and other new features and improvements.\\n\\nSander Schaminee\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/3R9CQK/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Onice/3 Julien Cabieces.mp4", "persons": "Julien Cabieces", "pretalx_id": "ZGCKEE", "title": "FOSS4G 2022 | QGIS & PostGIS : Tips & Tricks", "description": "QGIS and PostGIS are now renown as one of the best combination to setup a GIS application.\n\nThe support of PostGreSQL and PostGIS in QGIS have grown very mature and offers great features to deal with your database stored geographic data. It allows to create powerful business application easily without any advanced programming language skills, only plain SQL and a well configured QGIS.\n\nThis presentation will showcase some of the interesting features you should be aware of in order to build the perfect GIS user application. I'll explain how to:\n\n - Properly configure relations between layers/tables,\n - Enable transactions (and whether or not you should do it),\n - Communicate from PostGreSQL to QGIS using notifications,\n - Deal with triggers using data dependencies,\n - Store your QGIS project and style information in a PostGIS database,\n - Output your processing result directly to your database,\n - Manage your database directly from the browser.\n\nThese will be some of the key features that will be demonstrated along with a given use case.\\n\\nJulien Cabieces\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ZGCKEE/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Onice/4 Jon Herrmann.mp4", "persons": "Jon Herrmann", "pretalx_id": "Q78RAS", "title": "FOSS4G 2022 | ETF testing framework: past, present and future", "description": "ETF is an open source testing framework for validating data and APIs in Spatial Data Infrastructures (SDIs). It is used by software solutions and data providers to validate the conformity of geospatial data sets, metadata and APIs.\n\nFor example, ETF is the underlying framework used by the INSPIRE Reference Validator to validate INSPIRE metadata, datasets and services against the requirements of the INSPIRE Technical Guidelines. ETF is also used extensively in Germany by the Surveying Authorities of the Laender to validate their datasets. This includes Real Estate Cadastral data, Topographic data, Control Points, 3D Building Models, House Coordinates and Building Polygons. In the test environments of the German Laender, a comprehensive series of attributive, relational, geometric, and topological tests are performed on the data, in addition to interacting with APIs and checking for errors in the interface contracts. Other European Union (EU) Member States are also reusing ETF to allow their data providers to test resources against national requirements. Finally, some software tools such as GeoNetwork open source include validation based on the ETF API in their workflow.\n\nGoals in designing the ETF software were to create test reports that are user-friendly and self-explanatory as well as to be able to validate large amounts of data, which can be several hundred GB in size. In order to cover different validation tasks and present them in a unified report, the architecture is modular and different Test Engines can be used. Currently the following Test Engines are supported: SoapUI for testing web services, BaseX database for testing XML data, Team Engine to validate WFS and OGC Web APIs using the OGC CITE tests, NeoTL Engine for testing WFS, OGC Web APIs and datasets.\n\nAs a horizontal and reusable tool, which could be extended to satisfy the needs of different communities and domains, ETF is currently considered as a component of the so-called Common Services Platform under the new Digital Europe Programme of the European Commission. Within this context, activities are planned in 2022 to: i) include the ETF in the OSGeo Live v.15, and ii) submit the ETF as an OSGeo Community Project.\n\nIn this talk, we will introduce the ETF testing framework, the deployment scenarios and address the current and future technical developments.\\n\\nJon Herrmann\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/Q78RAS/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Onice/5 Jordi Escriu.mp4", "persons": "Jordi Escriu", "pretalx_id": "VGKAVK", "title": "FOSS4G 2022 | Re3gistry: Your interoperable open source tool for managing and sharing reference codes", "description": "The Re3gistry is an open source software for creating, managing and sharing reference codes in a consistent way. Released under the European Union Public License (EUPL) v.1.2 (https://github.com/ec-jrc/re3gistry), it is a key component ensuring interoperability in data infrastructures.\nThe Re3gistry supports organizations in managing and updating \u201creference codes\u201d through unique identifiers. Reference codes can be used for example to define sets of permissible values for a data field or to provide a reference or context for the data being exchanged. Examples are enumerations, controlled vocabularies, taxonomies, thesauri or simply \u2018lists of things\u2019. The Re3gistry provides a means to assign identifiers to such items and their labels, definitions and descriptions in different languages. It provides a user-friendly interface where labels and descriptions for reference codes can be easily browsed by humans and retrieved by machines, including the possibility of downloading them in different formats and exploiting the information using a REST API.\nThe European Commission\u2019s Joint Research Centre (JRC) started the development of the Re3gistry in 2014 to satisfy the interoperability requirements set by the INSPIRE Directive. In 2020, considering the high reusability of the tool beyond INSPIRE, the JRC released the code as open source. So far, the development of the Re3gistry has been supported by the European Commission under the interoperability actions ARE3NA and ELISE and, more recently, by the National Land Survey of Finland.\nIn 2021, a second version of the Re3gistry software was released. This version v2.0, complemented by subsequent minor releases, introduced several new features such as a management interface to add and modify the status of items, and the capability to trace the full lifecycle of items following the workflow defined by ISO 19135 standard. The current stable release is v.2.3.0 released in March 2022. The INSPIRE registry (https://inspire.ec.europa.eu/registry) is currently the most popular implementation of the Re3gistry software. It is the central point of access to (currently) more than 7000 reference codes, available in 23 languages and several formats (HTML, ISO 19135 XML, JSON, RDF/XML, Re3gistry XML, CSV), grouped into different centrally managed INSPIRE registers. The content of these registers is based on the INSPIRE Directive, Implementing Rules and Technical Guidelines (as illustration, used to reference INSPIRE themes, code lists and application schemas).\nThe Re3gistry is currently used by many organizations across European countries (Austria, Finland, France, Italy, Slovakia, Spain, The Netherlands and North Macedonia), different EU-funded projects and private organizations even outside Europe. Since 2021, the Re3gistry v.2.x is included in the OSGeo Live to facilitate discovery and use by the open source geospatial community. In 2022 the software will be also submitted as an OSGeo Community Project.\nSumming up, the Re3gistry is more relevant than ever to ensure semantical and organisational interoperability across any kind of systems, including Spatial Data Infrastructures (SDIs).\\n\\nJordi Escriu\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/VGKAVK/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Onice/6 Cihan Sahin.mp4", "persons": "Cihan Sahin", "pretalx_id": "ZZEGLR", "title": "FOSS4G 2022 | A high performing data retrieval system for large and frequently updated geospatial datasets", "description": "ECMWF is a research institute and a 24/7 operational service, producing global numerical weather predictions and other data for a broad community of users. To achieve this, the centre operates one of the largest supercomputer facilities and data archives within the meteorological community. ECMWF also operates several services for the EU Copernicus programme to provide data for Climate Change, Atmospheric monitoring and Emergency services.\n\nAs part of ECMWF's Open data initiative, more and more meteorological data and web services are freely available to a wider community. ECMWF's web services include an interactive web application to explore and visualize its forecast data, a Web Map Service (WMS) server and many graphical products including geospatial weather diagrams so called Ensemble (ENS) meteograms and vertical profiles.\n\nENS meteograms and vertical profile diagrams are among the ECMWF's most popular web products and presents ECMWF's multi-dimensional real-time ensemble forecast data for a given position globally. They are freely available through various ECMWF web services,  and integrated on ECMWF's GIS based interactive web application. Datasets powering the dynamically generated diagrams are formed from a rolling archive of 10 days data, updated twice a day and each update consists of data around half a Terabyte. An upcoming update on ECMWF's forecasting system will increase the data size by a factor of 3-4 times in the near future.  In addition to ECMWF's forecast data, similar services are requested as part of various Copernicus projects producing different datasets.\n\nThis talk presents migrating legacy data structure used for ENS meteogram datasets to a more flexible, extensible, and high performing one fit to be used by GIS systems by using Free Open Source Software (FOSS). The new data structure uses Python ecosystem. The data preparation workflow as well as the challenges and the solutions that are taken when dealing large and frequently updated geospatial datasets are presented. Talk will also include early experiments and experiences to offer these datasets as part of OGC's Environmental Data Retrieval (EDR) API.\\n\\nCihan Sahin\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ZZEGLR/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Onice/7 Trent Hare.mp4", "persons": "Trent Hare", "pretalx_id": "YF7EPR", "title": "FOSS4G 2022 | Helping to Land a Mars Rover using FOSS4G Tools", "description": "Since landing on Mars in February of 2021, the Mars 2020 Perseverance Rover has been exploring Jezero crater to investigate an ancient delta looking for the evidence of past microbial life and to better understand the geologic history of the region.  In support of Terrain Relative Navigation (TRN), which enables the Mars 2020 spacecraft while landing to autonomously avoid hazards (e.g., rock fields, crater rims), the USGS Astrogeology Science Center generated two precision mosaics: 1) the Lander Vision System (LVS) map generated from three Context Camera (CTX) orthorectified images that was used onboard the spacecraft and was the \u201ctruth\u201d dataset that TRN used to orient itself relative to the surface during Entry, Decent, and Landing; and 2) a High Resolution Imaging Science Experiment (HiRISE) orthomosaic which was used as the basemap onto which surface hazards were mapped. The hazard map was also onboard the spacecraft and used by TRN to help identify the final, hazard-free landing location.\n\nThis talk will present the workflow used by the USGS Astrogeology Science Center to generate these critical data products including the use of FOSS4G tools like GDAL. Other open-source packages used will also be shared.\\n\\nTrent Hare\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/YF7EPR/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Onice/8 Daniel J. Dufour.mp4", "persons": "Daniel J. Dufour", "pretalx_id": "M7PHE7", "title": "FOSS4G 2022 | State of GeoRasterLayer: A LeafletJS Plugin for Visualizing GeoTIFFs (and soon other rasters)", "description": "GeoRasterLayer is a LeafletJS Plugin for visualizing GeoTIFFs.  This presentation will show live demos of new features and discuss the roadmap for the next couple of years.\n\n### Features\n\n - Support for nearly all projections, thanks to proj4-fully-loaded (https://github.com/danieljdufour/proj4-fully-loaded) and epsg.io (https://epsg.io/)\n - Super faster rendering thanks to a simple nearest neighbor interpolation\n - Use of web workers means seamless integration that doesn't block main thread\n - Loads large geotiffs greater than a hundred megabytes\n - Supports custom rendering including custom colors, directional arrows, and context drawing\n - Doesn't depend on WebGL\n\n### Videos\n\n - Edge Compute: Cool Stuff You Can Do With COGs in the Browser (https://www.youtube.com/watch?v=XTkNhGpfmB8&amp;t=4190s)\n - 2019 - Algorithm Walk-through: How to Visualize a Large GeoTIFF on Your Web Map (https://www.youtube.com/watch?v=K47JvCL99w0)\n\n### Examples\n\n - Loading the georaster-layer-for-leaflet library along with GeoBlaze via a script tag. You can view the source code here (https://github.com/GeoTIFF/georaster-layer-for-leaflet-example/blob/master/examples/load-via-script-tag-with-geoblaze.html) and the live demo here (https://geotiff.github.io/georaster-layer-for-leaflet-example/examples/load-via-script-tag-with-geoblaze.html).\n - Combining two Cloud Optimized GeoTIFFs together to create an NDVI map. You can view the source code here (https://github.com/GeoTIFF/georaster-layer-for-leaflet-example/blob/master/examples/ndvi.html) and the live demo here (https://geotiff.github.io/georaster-layer-for-leaflet-example/examples/ndvi.html).\n - Identifying Wildfires from a Landsat 8 Scene. You can view the source code here (https://github.com/GeoTIFF/georaster-layer-for-leaflet-example/blob/master/examples/identifying-wildfires-with-landsat.html) and the live demo here (https://geotiff.github.io/georaster-layer-for-leaflet-example/examples/identifying-wildfires-with-landsat.html).\n - Visualizing Population COG. You can view the source code here (https://github.com/GeoTIFF/georaster-layer-for-leaflet-example/blob/master/examples/population.html) and the live demo here (https://geotiff.github.io/georaster-layer-for-leaflet-example/examples/population.html).\n - Display a COG that represents only one band of a Landsat scene. You can view the source code here (https://github.com/GeoTIFF/georaster-layer-for-leaflet-example/blob/master/examples/cog-with-only-one-band.html) and the live demo here (https://geotiff.github.io/georaster-layer-for-leaflet-example/examples/cog-with-only-one-band.html).\n - Display a COG with YCbCr Photometric Interpretation.  You can view the source code here (https://github.com/GeoTIFF/georaster-layer-for-leaflet-example/blob/master/examples/ycbcr.html) and the live demo here (https://geotiff.github.io/georaster-layer-for-leaflet-example/examples/ycbcr.html).\\n\\nDaniel J. Dufour\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/M7PHE7/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Onice/9 Fabian Schindler-Strauss.mp4", "persons": "Fabian Schindler-Strauss", "pretalx_id": "K8JQMZ", "title": "FOSS4G 2022 | geotiff.js - efficient GeoTIFF exploration in the browser and server", "description": "geotiff.js is a reusable library to abstract remote (Geo)TIFF files. With it, both rich visualization frontends or statistical or data access services can be implemented, as it is possible to inspect the geospatial metadata and the full spectrum raster values of the original data, instead of only 8-bit RGB(A).\n\nDue to its file abstractions, it is possible to only read the relevant portions of a file, thus greatly reducing bandwidth and response times. This effect can be further increased when reading Cloud Optimized GeoTIFF (COG) files.\n\nThe library tries to be as feature complete as possible in terms of file layout, raster cell values, RGB transformation, image data compression and metadata.\n\nThis talk will detail the features of geotiff.js, as well as its most recent additions. Additionally, it will shed light on the greater ecosystem of geospatial libraries and applications where geotiff.js is embedded or building the foundation of.\\n\\nFabian Schindler-Strauss\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/K8JQMZ/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_4/01 - R\u00e9gis Haubourg.mp4", "persons": "R\u00e9gis Haubourg", "pretalx_id": "WWSCVM", "title": "FOSS4G 2022 | Building a common building's(!) open dataset using FOSS4G, open data and open governement.", "description": "Climate change is here. heating, construction, cooling is estimated to contribute to 30% of the C02 emissions for France. And yet, we don't really have a database of those buildings. We have footprints by the French National Geographic institute, tax raising datasets on cadastral parcels, many derived datasets for energy consumption, performance certificates, but all of them are far away from a usable and centralized reference dataset.\n\nThe national adress geolocation (BAN) project unlocked the key pivot database between all them. The Scientific and Technical Center for Building (CSTB) a public industrial and commercial company, decided to dedicated efforts to build a permanent reference dataset, and push it as an open database.\n\nThe full stack is using open source technologies (Pandas / GeoPandas, to PostGIS, Apache Spark, MLflow, QGIS, MapLibre ...), and with massive datasets (21 Millions buildings, >400 descriptors). It allows to run analyses and predictions for all the climate change related indicators, such as housing price and energetic performance relation, heat wave impact, solar potential, etc..\n\nAs the first versions are now published, the next challenges are :\n\n - make the data easier to reuse\n - Push toward a official common identifier of each building, housing and parcels, through the BatID project and Etalab open government initiatives\n - Enrich the dataset with new statistics and predictions twice a year\n - Consolidate its economic rationales to make this viable on the long run\n\nThis talk will also show cool dataviz and geoviz stuff for geonerds audience :)\\n\\nR\u00e9gis Haubourg\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/WWSCVM/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_4/02 - Saheel Ahmed.mp4", "persons": "Saheel Ahmed", "pretalx_id": "R8FHVA", "title": "FOSS4G 2022 | Use of open source tools to estimate global GHG emissions.", "description": "Hey everyone, my name is Saheel Ahmed. I work as a senior data scientist at Blue Sky Analytics. We are a climate tech startup primarily focused on creating environmental datasets for better monitoring and climate risk assessment for various stakeholders across the globe. To achieve this, we are leveraging the potential of geospatial analytics by creating a catalogue of comprehensive and accurate climate data to drive sustainable decision-making. And all this is only possible because of the open-source tools & knowledge made publicly by the good folks organising the event.\n\nGreenhouse gas (GHG) emissions from biomass burning (which includes the combustion of forests, savannas, and croplands) play an important role in regional air quality, global climate change, and human health. In the year 2021, all the continents except Antarctica witnessed major wildfires. These enormous blazes some the size of a small country aren\u2019t just destroying native forests and vulnerable animal species. They\u2019re also releasing billions of tons of greenhouse gases into the atmosphere, potentially accelerating global warming and leading to even more fires. Accurate assessment of biomass burning emissions is paramount to understanding and modelling global climate change.\n\nBy combining open-source tools with geospatial data, we present a global dataset that estimates the total GHG emissions due to biomass burning globally. We achieved this by linking satellite-based fire observations, aerosol optical depth (AOD), and vegetation type (based on land cover classification) to directly estimate how much carbon dioxide (CO2), methane (CH4), and nitrous oxide (N2O) were emitted from each fire. We conducted further analysis of estimated emissions by comparing our estimates with existing datasets from NASA's global fire emissions database and ESA's Copernicus global fire assimilation system. Overall, our estimates agree well against both of these sources with an R2 score of 0.91, 0.71, and MAE score of 9, 14 MtCO2e/yr against GFEDv4.1s and GFASv1.2 respectively across 245 nations between 2015-2020. The dataset includes country-level estimates of gross GHG emissions across different vegetation types such as forest, cropland, shrubland, and grassland for the last 5 years.\n\nThe dataset is currently a work in progress as we aim to add more features such as covering other landcover types, ground truth alternatives. The dataset and its documentation are available at https://github.com/blueskyanalytics/get-started. The dataset is also our contribution to the global coalition Climate Trace (https://www.climatetrace.org/), an independent group for monitoring & publishing GHG emissions across different sectors.\\n\\nSaheel Ahmed\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/R8FHVA/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_4/3 Kshitij Purwar.mp4", "persons": "Kshitij Purwar", "pretalx_id": "EFDYKK", "title": "FOSS4G 2022 | Building the Bloomberg for Climate Data with FOSS", "description": "I am the Founder and CTO of Blue Sky Analytics, a Climate-Tech Startup using satellite-derived climate intelligence to power financial decisions. We provide datasets through API spanning flood, drought, wildfire, heat risk for monitoring, measuring and mitigating climate risk which can be leveraged for various use-cases.\n\nIn 2 years, we have analyzed TBs of data, delivered 5 datasets & built platforms for data visualisation and distribution from scratch using FOSS technology. This has been a rocket-ship of a journey, chasing our mission of building a \u2018Bloomberg for environmental data\u2019.\n\nHowever, the not-so-secret sauce to achieving these milestones has been FOSS. We are often asked how we procure raw geospatial data and how much we spend on it. Thanks to the abundance of open data, our data acquisition cost has been 0. Due to the generous open data policy of amazing organisations like NASA & ESA, we have been able to build a business collecting TBs of data daily & crunching them into useful insights.\n\nThis helped us scale our vision to build a global environmental data stack for tracking climate change in real-time. Moreover, before this data can be applied to climate mitigation, it needs to be analysed. This is true for any big data and today, less than 1% of global data is analysed.\n\nGiven that satellite data is the most significant source of tracking climate variables, it became imperative to tap this source. We discovered that the path to providing environmental datasets was by building a powerful geospatial data refinery along with SpaceTime\u2122 (https://spacetime.blueskyhq.in/)  and our dev portal (http://developer.blueskyhq.in).\n\nThere was limited infrastructure available to support the delivery of geospatial datasets so we built it, leveraging open-source tools like Postgres, QGis, GDAL, k8s etc.\n\nWhile we have proprietary layers to our models, as a team of young developers, data scientists and designers, many self-taught, our cultural ethos stands firmly with FOSS and we plan to be a leading contributor to FOSS for climate action. The most significant step for us in that direction has been providing annual, country-wise data on biomass emissions to the Al Gore-led Climate TRACE (https://www.climatetrace.org/) inventory that can be used by the public via CC-BY-4.0 framework.\n\nAs our business expands, we aim to open-source tools & innovations we have internally developed while building our infrastructure and have started that journey with the Raster Playground. (http://play.blueskyhq.in)\n\nClimate change is the most pressing challenge of our times, throwing at us various questions that need to be answered. This is not possible without data. Data helps us understand the problem and quantify the risk to various assets.\n\nOpen source tools and data have made it possible for 20-year-old data scientists to access sophisticated satellite data to understand the changing planet and answer these questions. BSA is a testament to the fact that fighting climate change is not possible without FOSS.\\n\\nKshitij Purwar\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/EFDYKK/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_4/4 Sophia Parafina.mp4", "persons": "Sophia Parafina", "pretalx_id": "JVFVCS", "title": "FOSS4G 2022 | Where Is Everyone?: The Global Impact of COVID on Road Traffic", "description": "This presentation examines the global impact of COVID-19 on traffic across 40 cities in Europe, South East Asia, Australia, and North America. I analyzed monthly rush hour traffic from 2019 to 2021 with  GeoPandas, leafmap, and  HERE's Traffic Analytics data. In addition, I correlated traffic volume with COVID positivity, mortality,  and vaccination rates to examine how these factors influence the resumption of pre-pandemic traffic patterns.\n\nBecause of the volume of the traffic data (billions of records), desktop GIS software, including spatially enabled databases, could not reliably process it on a desktop computer. Online solutions, such as Google Colab, would have been a costly alternative given the amount of data. However, GeoPandas and Jupyter notebook on notebook computer was able to process the traffic data and enhance the spatial road data and support joining the result to the road network for visualization. The method for processing the data will be discussed in detail. In summary, open source tools give researcher unprecedented abilities to process large amounts of data.\\n\\nSophia Parafina\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/JVFVCS/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_4/5 Antonio Cerciello.mp4", "persons": "Tom Kralidis, Francesco Bartoli, Antonio Cerciello, Joana Simoes", "pretalx_id": "KXSW83", "title": "FOSS4G 2022 | Implementing OGC APIs using Elasticsearch and pygeoapi", "description": "The Open Geospatial Consortium API family of standards (OGC API) are being developed to make it easy for anyone to provide geospatial data to the web, and are the next generation of geospatial web API standards designed with resource-oriented architecture, RESTful principles and OpenAPI. In addition, OGC APIs are being built for cloud capability and agility.\n\npygeoapi is a Python server implementation of the OGC API suite of standards. The project emerged as part of the OGC API efforts started in 2018 and provides the capability for organizations to deploy OGC API endpoints using OpenAPI, GeoJSON, and HTML. pygeoapi is open source and released under an MIT license. pygeoapi is built on an extensible plugin framework in support of clean, adaptive data integration (called \"providers'').\nElasticsearch (ES) is a search engine based on the Lucene library. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents.\nThe Elasticsearch data provider for pygeoapi is one of the most complete in terms of functionalities and it also includes CQL support with the CQL-JSON dialect, which allows you to take extra advantage of the ES backend.\n\nThis presentation will provide an overview of OGC APIs, pygeoapi and Elasticsearch integration, and demonstrate usage in a real-world data dissemination environment.\\n\\nTom Kralidis\\nFrancesco Bartoli\\nAntonio Cerciello\\nJoana Simoes\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/KXSW83/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_4/6 Alexander Salveson Nossum.mp4", "persons": "Alexander Salveson Nossum", "pretalx_id": "ESLMWH", "title": "FOSS4G 2022 | Norwegian National SensorHub - sharing IoT data with open standards and technology", "description": "Sensordata (IoT) is widespread in both private and public sector. However, making use of sensordata across different sectors and applications is challenging - in particular with respect to a geospatial application across different use cases. This encompasses both enviroment/climate sensors, like water-level sensors to smart-building monitoring and water pipe sensors. An interdisciplinary team from diverse sectors is working towards building national standards, an open architecture and implementing proof-of-concepts on a national sensorhub for sharing streams and archives of sensordata in Norway. The team builds upon the very successful open data ecosystems (SDI) that exists in Norway for standardized geospatial data. The project is funded from a range of partners including municipalities, the mapping authority and the maritime ports of Norway. The working group includes open source tech expertise on sensor technology alongside user and demand expertise from the different sectors.\n\nThis talk will focus on the technological advances made from the team both on software and architecture. There will be particular focus on the open architecture and software prototyping that has been developed in the working group. Both of which will be available under an open license.\\n\\nAlexander Salveson Nossum\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ESLMWH/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_4/7 Tom\u00e1\u0161 Pohanka.mp4", "persons": "Tom\u00e1\u0161 Pohanka", "pretalx_id": "RAUZWM", "title": "FOSS4G 2022 | OpenMapTiles 3.14 - vector tiles from OpenStreetMap & Natural Earth Data", "description": "OpenMapTiles is an open-source set of tools for processing OpenStreetMap data into zoomable and web-compatible vector tiles to use as high-detailed basemaps. These vector tiles are ready to use in MapLibre, Mapbox GL, Leaflet, OpenLayers, QGIS as well as in mobile applications.\nDockerized OpenMapTiles tools and OpenMapTiles schema are being continuously upgraded by the community (simplification, performance, robustness). The presentation will be demonstrating the latest changes in OpenMapTiles. The last release of OpenMapTiles greatly enhanced cartography and map styling possibilities, especially for roads such as adding new tags (expressway, access, toll). But also adding concurrent route labels or motorway junctions. Improvements were also done in the countryside by adding important tracks and paths (displaying from zoom 12), cliffs, aretes, and ridges. Another enhancement is the possibility to show mountain heights in customary units (feet in the US). OpenMapTiles is also used for generating vector tiles from government open-data secured by Swisstopo.\\n\\nTom\u00e1\u0161 Pohanka\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/RAUZWM/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_4/8 Yuri Astrakhan.mp4", "persons": "Yuri Astrakhan", "pretalx_id": "KJAEP8", "title": "FOSS4G 2022 | OSM planet data to vector tiles in a few hours: OpenMapTiles & Planetiler", "description": "Converting OpenStreetMap planet data into vector tiles has been a complex and costly process, but now, thanks to the Planetiler project, it has become possible to do on a single powerful machine in just a few hours \u2013 over two orders of magnitude speed up!\n\nOpenMapTiles is a mature customizable tile generation framework and layer specification that can be tailored to specific tile generation needs. It has existed for many years, and allowed users to generate their own layers, optimizing for size or completeness. Over the years it moved to PostGIS-based ST_AsMVT approach, and made numerous small improvements. The biggest downside of OMT was the extensive hardware requirements.\n\nRecently Mike Barry rewrote core functionality of the OMT stack as a single monolithic app, making it possible to generate entire planet data in just a few hours on a single machine. Now the OMT community is actively adapting this new approach, researching if Rust would be even better approach, and experimenting how to make the process customizable and support real-time updates.\\n\\nYuri Astrakhan\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/KJAEP8/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_4/9 Nick Forbes-Smith.mp4", "persons": "Nick Forbes-Smith", "pretalx_id": "GPWMC7", "title": "FOSS4G 2022 | Exploring the World\u2019s Open Data Portals - Discovery, Visualisation and Analysis of Open Data with TerriaJS", "description": "TerriaJS is an open-source framework for web-based geospatial catalogue explorers.\n\nIt uses Cesium and Leaflet to visualise 2D and 3D geospatial data, and it supports over 50 different Web APIs, file formats and open data portals.\n\nIt is almost entirely JavaScript in the browser, meaning it can even be deployed as a static website, making it simple and cheap to host.\n\nTerriaJS is used across the globe to create next-generation Digital Twin Platforms for open geospatial data discovery, visualisation and sharing - it is used to drive\n\n - National Map (https://nationalmap.gov.au/) (Australian Gov)\n - Digital Earth Australia Map (https://maps.dea.ga.gov.au/)\n - Digital Earth Africa Map (https://maps.digitalearth.africa/)\n - Pacific Map (https://map.pacificdata.org/)\n - NSW Spatial Digital Twin (https://nsw.digitaltwin.terria.io/) (Australian State Gov)\n - and many others\n\nSupported formats/protocols include:\n\n - Imagery services like WMS/WMTS and ArcGis Imagery/Map Service\n - Feature/vector services like WFS, ArcGis Feature Service, Mapbox vector tiles, GeoJSON, Shapefile, KMZ, GPX, GeoRSS\n - 3D sources like Cesium 3d-tiles, GLTF and CZML\n - Tabular/sensor data: CSV, SDMX, GTFS, SOS, Socrata and Opendatasoft\n - Open Data portals: CKAN, CSW, Socrata, Opendatasoft, Magda, THREDDS, WMS/WFS Servers, ArcGis Portal and SDMX\n - Geoprocessing with WPS\n - With plans to support new and upcoming services like OGC APIs and STAC in the future.\n\nIn this talk, I will show how TerriaJS can connect to Open Data Portals to\n\n - Discover open datasets\n - Visualise datasets in 2D and 3D\n - Perform aggregation/analysis on datasets\n - Create/share maps with the world!\n\nhttps://terria.io/\n\nhttps://github.com/TerriaJS/terriajs\\n\\nNick Forbes-Smith\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/GPWMC7/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_4/10 Philipe Borba.mp4", "persons": "Philipe Borba", "pretalx_id": "PJDH8K", "title": "FOSS4G 2022 | Building Footprint Extraction in Vector Format Using pytorch_segmentation_models_trainer, QGIS Plugin DeepLearningTools and The Brazilian Army Geographic Service Building Dataset", "description": "Building footprint extraction is a popular and booming research field. Annually, several research papers are published showing deep learning semantic segmentation-based methods to perform this kind of automated feature extraction. Unfortunately, many of those papers do not have open-source implementations for public usage, making it difficult for other researchers to access those implementations.\n\nHaving that in mind, we present DeepLearningTools and pytorch_segmentation_models_trainer. Both are openly available implementations of deep learning-based semantic segmentation. This way, we seek to strengthen the scientific community sharing our implementations.\n\nDeepLearningTools is a QGIS plugin that enables building and visualizing masks from vector data. Moreover, it allows the usage of inference web services published by pytorch_segmentation_models_trainer, creating a more feasible way for QGIS users to train Deep Learning Models.\n\npytorch_segmentation_models_trainer (pytorch-smt) is a Python framework built with PyTorch, PyTorch-Lightning, Hydra, segmentation_models.pytorch, rasterio, and shapely. This implementation enables using YAML files to perform segmentation mask building, model training, and inference. In particular, it ships pre-trained models for building footprint extraction and post-processing implementations to obtain clean geometries. In addition, one can deploy an inference service built using FastAPI and use it in either web-based applications or a QGIS plugin like DeepLearningTools.\n\nResNet-101 U-Net Frame Field, ResNet-101 DeepLabV3+ Frame Field, HRNet W48 OCR Frame Field, Modified PolyMapper (ModPolyMapper), and PolygonRNN are some of the models available in pytorch-smt. These models were trained using the Brazilian Army Geographic Service Building Dataset (BAGS Dataset), a newly available dataset built using aerial imagery from the Brazilian States of Rio Grande do Sul and Santa Catarina. Pytorch-smt also enables training object detection and instance segmentation tasks using concise training configuration.\n\nThis way, considering the aforementioned, this talk presents the usage overview of both technologies and some demonstrations. Using metrics like precision, recall, and F1, we assess the results achieved by the implementations developed as a product of our research, showing that they have the potential to produce vector data more efficiently than manual acquisition methods.\n\nDeepLearningTools is available at the QGIS plugin repository, while pytorch_segmentation_models_trainer is available at Python Package Manager (pip). The Brazilian Army Geographic Service develops both solutions, making their codes available at https://github.com/phborba/DeepLearningTools and https://github.com/phborba/pytorch_segmentation_models_trainer.\\n\\nPhilipe Borba\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/PJDH8K/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_4/11 Epa Utabajimana.mp4", "persons": "Rodwell Chireshe, Epa Utabajimana", "pretalx_id": "ERWRFB", "title": "FOSS4G 2022 | UN Open GIS Initiative: Geopaparazzi Survey Server and SMASH for Mobile Data Collection in a UN Peacekeeping Mission (MONUSCO)", "description": "The project \u201cGeopaparazzi Survey Server (GSS) and SMASH for Mobile Data Collection in a UN Peacekeeping mission (MONUSCO)\u201d aimed to operationalize the use of GSS and SMASH to support field data collection in MONUSCO. This talk will cover the endeavours of this project, introducing the background, user requirements and use cases, the implementation of the online GSS at a UN central data centre as well as the project outcomes and recommendations.\n\nMONUSCO GIS: MONUSCO GIS Unit uses mobile devices, GPS, mini UAV, satellite imagery from commercial providers, to ensure availability of detailed topographic and up-to-date mission operational data for the various GIS end products (cartographic maps, imagery, infographics, interactive web map applications, geodatabases). Having a central server for mobile data collection will ensure constant availability of standardized, quality controlled and up-to-date operational data, which is key for the provision of quality GIS products & services and consequently data-driven decisions and actions for the Mission. From the beginning, there hasn't been a centralised infrastructure readily available to all the geographically dispersed UN Mission users in the DR Congo for field mobile data collection. This project marked the genesis of it.\n\nUN Open GIS Initiative: Established in March 2016, is to identify and develop an Open Source GIS bundle that meets the requirements of UN operations, taking full advantage of the expertise of contributing partners (Member States, international organizations, academia, NGO\u2019s and private sector). Geospatial Information Systems (GIS) have played a substantial role in providing timely and effective geospatial information products (maps and dynamic tools) to ensure the United Nations operations are equipped with suitable information to support the UN mandates through informed planning and decision-making processes. The UN has been using proprietary GIS software for the past two decades. The rapid growth and development of open-source GIS solutions present the technological potential, operational flexibility, and financial benefits as well as ease to access for UN operational partners and host nations.\\n\\nRodwell Chireshe\\nEpa Utabajimana\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ERWRFB/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_4/12 Mikael Vaaltola.mp4", "persons": "Mikael Vaaltola", "pretalx_id": "J3J9D8", "title": "FOSS4G 2022 | Maintaining a national Aerial Image Registry with QGIS", "description": "The National Land Survey (NLS) of Finland maintains a registry of aerial imagery in Finland containing metadata of imagery since 1932. As part of the NLS' strategy of moving towards FOSS software, a novel registry management tool is being developed as a QGIS plugin. This talk describes the process of designing and implementing the new registry management software and explores the suitability of QGIS as a platform for creating highly customised spatial data management tools. While the registry management tool is developed for QGIS, the registry is migrated from Oracle to a PostGIS database, following a redesign of the data model.\n\nIn 2020, the NLS announced it aims to build its technological environment based on open source technologies. As a result, there is an ongoing effort of re-designing and implementing various existing processes and systems using open-source technologies. One such system is the national Aerial Image Registry. The registry is managed by a group of NLS employees and metadata is used in various workflows for publishing new data products from captured images and planning new aerial imaging missions.\n\nThe current registry management software is a technically dated solution based on Visual Basic 6 and an Oracle database. Key features of the new registry management tool include the ability to query the image registry and show the search results on map, editing and archiving existing data in the registry, importing new data to the registry, creating data extracts to PDF maps and spatial formats, and validating plans for aerial imaging missions. QGIS provides an user-friendly platform that is already familiar to many GIS experts that can be easily extended with plugins that provide custom functionality and features.\n\nThe NLS has prior experience of designing and developing tailored QGIS plugins to support their unique workflows, including plugins for maintaining the topographic database of Finland and the national point cloud registry. These projects have been well received by users and developers alike, and the positive feedback has encouraged the NLS to continue developing tailored QGIS plugins for its specific needs.\\n\\nMikael Vaaltola\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/J3J9D8/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_9/1 Zacharia Muindi.mp4", "persons": "Zacharia Muindi", "pretalx_id": "BV7GX8", "title": "FOSS4G 2022 | Mapping impacts of Covid-19 in Nairobi", "description": "The Covid-19 pandemic has had many impacts beyond health - economic, social, etc. The Cities Covid Mitigation and Mapping (C2M2) project, from the US Department of State's MapGive initiative, sought to map and help direct policy around these secondary impacts of Covid in several countries globally. Map Kibera and GroundTruth Initiative worked to track these impacts in Nairobi, focusing on the themes of education, water and sanitation.\n\nThis talk will present the outcomes of the project, which focused on the mapping in OSM of schools, water points, and toilet facilities in the informal settlements of Kibera and Mathare. These updates to existing OSM data help show how the pandemic affected these sectors by looking historically at changes. Additionally, individual surveys about access to water during shortages and impacts of school closings and disruptions help paint a picture of how Nairobi's lower income residents have been particularly impacted by the pandemic. There is also a strong gender component to the impacts which will be highlighted.\n\nThe project used a combination of tools, which will also be presented: Kobo Toolbox for mapping and individual survey collection, OSM for map data, and data analysis in QGIS. The Kenya team was supported by many other team members from the C2M2 project for data analysis. Additionally, participants in Africa included Bukavu in the DRC and Pemba in Mozambique; we will briefly share their map outcomes as well. The \"Africa Hub\" which included Nairobi, Pemba and Bukavu showed that across the continent, economic and social impacts of Covid-19 on vulnerable groups were particularly challenging.\\n\\nZacharia Muindi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/BV7GX8/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_9/2 Olivier Guyot.mp4", "persons": "Olivia Guyot, Florent Gravin", "pretalx_id": "WECPGY", "title": "FOSS4G 2022 | Datahub: the confluence of open data and geo data", "description": "Open data movement has been very active and trendy lately. Many solutions brought fresh air in the metadata ecosystem. Nevertheless, no one really pushed forward the confluence of the open data world and the geo metadata world (often powered by ISO or INSPIRE standards).\n\nActually, many organizations still use both systems, which leads to confusion for the end users: datas are duplicated, metadatas are harvested in both directions, many websites aim to serve the same goal. Overall, this split does not help to easily find your data.\nIt can also give headache to platform administrators, developers and architects who try hard to keep all catalogs synchronized.\n\nBased on this analysis, we are convinced that an ultimate solution could take the advantages of both ecosystems. Complex ISO standards, INSPIRE rules and opendata light schemas can co-exist in the same catalog. All new great ideas like quick data visualization or dataviz widgets can be supplied for any kind of data. The datahub literally came out from the need to centralize any kind of public dataset within the same platform.\n\nThought as a backend API agnostic solution, the datahub first implementation has started based on the GeoNetwork 4 api, with an ElasticSearch backend.\nThe search is fast, accurate, multilingual and customizable. The solution has been designed from use cases: how do you want to help the end users to find, use and value their datas. It brings a new experience to old fashion INSPIRE catalogs and aims to embrace modern challenges like the community, vote, favorites, publishers, usages of the datasets, dataviz and so on.\n\nLeveraging technical challenges to merge open data and metadata, the datahub emphases on a pure, intuitive and fluent user experience.\\n\\nOlivia Guyot\\nFlorent Gravin\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/WECPGY/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_9/3 Ryan Abernathey.mp4", "persons": "Ryan Abernathey, Charles Stern", "pretalx_id": "DABTGG", "title": "FOSS4G 2022 | Pangeo Forge: Crowdsourcing Open Data in the Cloud", "description": "Geospatial datacubes--large, complex, interrelated multidimensional arrays with rich metadata--arise in analysis-ready geopspatial imagery, level 3/4 satellite products, and especially in ocean / weather / climate simulations and [re]analyses, where they can reach Petabytes in size. The scientific python community has developed a powerful stack for flexible, high-performance analytics of databcubes in the cloud. Xarray provides a core data model and API for analysis of such multidimensional array data. Combined with Zarr or TileDB for efficient storage in object stores (e.g. S3) and Dask for scaling out compute, these tools allow organizations to deploy analytics and machine learning solutions for both exploratory research and production in any cloud platform. Within the geosciences, the Pangeo open science community has advanced this architecture as the \u201cPangeo platform\u201d (http://pangeo.io/).\n\nHowever, there is a major barrier preventing the community from easily transitioning to this cloud-native way of working: the difficulty of bringing existing data into the cloud in analysis-ready, cloud-optimized (ARCO) format. Typical workflows for moving data to the cloud currently consist of either bulk transfers of files into object storage (with a major performance penalty on subsequent analytics) or bespoke, case-by-case conversions to cloud optimized formats such as TileDB or Zarr. The high cost of this toil is preventing the scientific community from realizing the full benefits of cloud computing. More generally, the outputs of the toil of preparing scientific data for efficient analysis are rarely shared in an open, collaborative way.\n\nTo address these challenges, we are building Pangeo Forge ( https://pangeo-forge.org/), the first open-source cloud-native ETL (extract / transform / load) platform focused on multidimensional scientific data. Pangeo Forge consists of two main elements. An open-source python package--pangeo_forge_recipes--makes it simple for users to define \u201crecipes\u201d for extracting many individual files, combining them along arbitrary dimensions, and depositing ARCO datasets into object storage. These recipes can be \u201ccompiled\u201d to run on many different distributed execution engines, including Dask, Prefect, and Apache Beam. The second element of Pangeo Forge is an orchestration backend which integrates tightly with GitHub as a continuous-integration-style service.\n\nWe are using Pangeo Forge to populate a multi-petabyte-scale shared library of open-access, analysis-ready, cloud-optimized ocean, weather, and climate data spread across a global federation of public cloud storage\u2013not a \u201cdata lake\u201d but a \u201cdata ocean\u201d. Inspired directly by the success of Conda Forge, we aim to leverage the enthusiasm of the open science community to turn data preparation and cleaning from a private chore into a shared, collaborative activity. By only creating ARCO datasets via version-controlled recipe feedstocks (GitHub repos), we also maintain perfect provenance tracking for all data in the library.\n\nYou will leave this talk with a clear understanding of how to access this data library, craft your own Pangeo Forge recipe, and become a contributor to our growing collection of community-sourced recipes.\\n\\nRyan Abernathey\\nCharles Stern\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/DABTGG/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_9/4 Michael Montani.mp4", "persons": "Michael Montani, Diego Gonzalez Ferreiro", "pretalx_id": "UEHJ8Y", "title": "FOSS4G 2022 | UN Maps: OpenStreetMap supporting Peace and serving Humanity", "description": "UN Maps is a program led by the United Nations Department of Operational Support in support of several peacekeeping and political missions such as UNSOS, MONUSCO, MINUSCA, MINUSMA and UNISFA.\nBy leveraging internal and crowdsourcing capabilities, UN Maps aims not only to enrich topographic and operational data in UN mission areas but also to provide peacekeeping and humanitarian actors with topographic maps, operational geo-information, search and navigation tools, and imagery and street-level base maps, leveraging OpenStreetMap, the Wikipedia of maps.\nIn order to achieve its goals, the UN Maps Initiative is building a thriving community around the collection, validation, usage, and dissemination of open geospatial data. This community is called UN Mappers.\nIt benefits from the established crowdsourcing activities, such as mapathons, training opportunities and other collaborative events involving several stakeholders as the UN staff on the field (peacekeeping and agencies, funds and programs), academia (high schools and universities in Africa, EU and US), local communities and remote volunteers.\nTogether, the UN Mappers community give substantial support not only in the production of maps and web services but also in the development of innovative applications using virtual reality and data analytics. Some of the results obtained with open data to these applications will be presented during the intervention.\nFurthermore UN Mappers are working on translating and updating OSM documentation material in all 6 UN official languages, which is distributed with open license.\\n\\nMichael Montani\\nDiego Gonzalez Ferreiro\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/UEHJ8Y/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_9/6 Yuri Astrakhan.mp4", "persons": "Yuri Astrakhan", "pretalx_id": "SNZWWJ", "title": "FOSS4G 2022 | OpenSource to the rescue: the future of MapLibre", "description": "The story and the future of the MapLibre community - the project that continues to develop various browser and native technologies for map tile visualization ever since Mapbox changed their licensing on the amazing Mapbox gl js technology that sadly became proprietary restricted to Mapbox own service.\n\nThis talk will cover existing lib capabilities, how the project grew to include native, navigation, routing, 3D, and other features. How the project was able to quickly migrate to typescript with lots of additional testing and stabilization efforts. How we became a large non-centralized collective of mapping technologies covering web, android and ios devices. How hundreds of small and large donations from developers and companies have helped with extra incentives.\n\nSome possible future projects and ideas will be presented by individual feature owners, including the possibility of uniting all library efforts using a cross platform compilation from the common Rust code (web assemblies + native libs) and additional styling features.\\n\\nYuri Astrakhan\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/SNZWWJ/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_9/7 Ilie Codrina.mp4", "persons": "Ilie Codrina", "pretalx_id": "BRLCXX", "title": "FOSS4G 2022 | FOSS4G and Open Data to the rescue: a European story!", "description": "Neither the open (geo)data initiative and, needless to say, the open source for geospatial one, are the new kids on the block anymore. Crucial steps have been taken all over the world in establishing the framework of openness, collaborative development and transparency ranging from hands-on events - such as code sprints or collaborative data gathering - mapathons - to funding opportunities and legislative measures. In this context, we present a 3 years-old EU supported initiative founded on open source and open data and that has reached maturity. In our talk, we present the potential support that such initiatives have in the wider framework of environmental monitoring and reporting across Europe - Geo-harmonizer.\n\nGeo-harmonizer stands for EU-wide automated mapping system for harmonization of Open Data based on FOSS4G and Machine Learning. The project unfolded between 2019 and 2022 and was co-financed under Grant Agreement Connecting Europe Facility (CEF) Telecom project 2018-EU-IA-0095 by the European Union.\\n\\nIlie Codrina\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/BRLCXX/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_9/8 Petya Kangalova.mp4", "persons": "Petya Kangalova, Ichchha Moktan", "pretalx_id": "HS3RL9", "title": "FOSS4G 2022 | Open Tech Collective: sharing HOT's journey", "description": "At  the beginning  of  2022, HOT_tech started a collaboration with Kathmandu Living Labs on the Tasking Manager. This followed our ambition to facilitate an open  collaborative process in building and improving our open source technology by forming a  \u2018collective\u2019. The idea of a  \u2018collective\u2019 is to bring people with shared purpose together on shared ground to achieve a shared goal. A lot to be shared! In this context the shared goal is the development of the  Tasking Manager.\n\nOur  vision is for creating with, for, and by the community for making the product more impact-driven and user friendly.  The Tasking Manager has proven itself over the years to be not just a software but  a platform to bring the different individuals, communities, organizations who share a common goal towards not only humanitarian effort and crisis response but identifying local resources and needs through mapping and data. So whether you are a mapper, a validator, a designer or an open source developer with an interest in the Tasking Manager, you can join the collective.\n\nDuring this talk we will share our journey in building the collective. You will hear an open and honest reflection on what worked, what didn\u2019t work, what we have learned and what we hope to do going forward. We want this talk at FOSS4G  to open a conversation with other open source and geospatial communities on best ways for designing, creating and implementing open, diverse and inclusive spaces for thriving and healthy collectives and communities.\\n\\nPetya Kangalova\\nIchchha Moktan\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/HS3RL9/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_9/9 Seabilwe Tilodi.mp4", "persons": "Seabilwe Tilodi", "pretalx_id": "9DLEBU", "title": "FOSS4G 2022 | Classroom GIS in South Africa", "description": "The introduction of technology in the education sphere has brought about improvement regarding the quality of education young and old individuals receive. A country\u2019s development plays a huge factor in the quality of services its people receive, therefore not every country will receive the same quality of services.\nClassroom GIS has changed how Geography as an academic subject is taught. It has sparked interest in the practical component of the subject and gives more understanding to the strong relationship between theory and map work. This leads to the concept of spatial thinking and how it has allowed geography educators around the world, some without basic GIS education, to see the importance of including more GIS concepts in the high school geography curriculum.\nSeveral GIS software packages are available that educators can use to teach their students. But taking into account the availability of resources when focusing on the African continent, it is probable that free software and hardware plays a key role in the development of GIS concepts being included in the geography curriculum. It is affordable, and learning resources are readily available, in terms of tutorials, documentation and more.\n\u201cThis inclination towards GIS textbook lecturing has largely jeopardized the quality of GIS education\u201d. - (Fleischmann and van der Westhuizen, 2020 found in The Journal of Geography Education in Africa)\nAdvocacy to include GIS practices and strategies in geography education across Africa have been documented, but has not received the necessary exposure it needs from its governments. The majority of GIS teaching has been textbook-based, making the introduction of GIS technology and education a frightening phase that educators may not want to engage in.\nTo overcome the fears behind understanding and grasping basic GIS concepts in the classroom, interactive GIS tutorials may help to remove these fears and make the adoption of GIS simple, especially within countries where service delivery (education services) is poor.\nQGIS for example is an open-source GIS software that has been around for 20 years, it has shown tremendous improvements and upgrades throughout its 20 years. Its user-friendly capabilities have improved, making it ideal to introduce more geography educators and learners to the software. It has tutorials and material that is suited for individuals from different walks of the profession.\nThe tutorials are interactive and allow first-time users to readily engage with the material. For both learner and educator to understand the material and not get overwhelmed. The key factors to understand are; GIS can be implemented into the African geography school curriculum, open-source software is key to overcoming limitations such as lack of resources and geography educators are willing to take on GIS with sufficient training. More urgent research is needed on reliable and sustainable methods and practices of teaching GIS in a secondary school classroom.\\n\\nSeabilwe Tilodi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/9DLEBU/\\n\\n#foss4g2022\\n#generaltrack\\n#Education"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_9/10 Sefa Bugra Ozen.mp4", "persons": "ozgenc uslu, sefa bugra ozen", "pretalx_id": "QNBUEC", "title": "FOSS4G 2022 | The best practices of Open Source GIS base applications on T\u00fcrkiye General Directorate of Hihgways", "description": "Traffic Safety Application:\n\nIn the data preprocessing phase, data quality assessment and dirty data were determined on the accident data by using desktop GIS applications such as QGIS,SAGAGIS,JOSM,GeoDa. OpenSource GIS applications and programming languages such as R language and python were used in data cleaning, exploratory analysis and data processing. Statistics for accident data have been extracted. OpenSource map server such as GeoServer is used for sharing, editing and organizing accident maps and base maps produced in GIS applications.\nPython software language was used in the server side of the project. For geospatial data analysis, accident points were verified by using geopandas and shapely libraries. PostgreSQL database was used to store geo-based accident data and the PostGIS extension was used. PostGIS adds spatial capabilities to PostgreSQL so it can store, query, and manipulate spatial data. On the server side scripting, GeoAlchemy(an extension of SQLAlchemy) is used for working with spatial databases and geospatial queries.\nFor the client side, Turf was used for any spatial operations. It is a geospatial engine, and it includes spatial operations and helper functions. MapboxGL-WebGL-powered library is used for interactive vector maps on the web application. To render more than 100k of accidents with high performance, WebGL powered geospatial visualization framework DeckGL was used. NebulaGL provides geospatial drawing and editing tools for lines, polygons etc. It was added for selecting analysis regions from the map. Osm-Nominatim is a geocoding library. It allows users to find accident locations from an address.\n\nOpenSource GIS Tools:\n\n\u25cf\tGIS software for data visualization, processing and analysis:\n\nQGIS, GRASSGIS, JOSM, SAGAGIS, OrbisGIS\n\n\u25cf\tGIS Servers: GeoServer, MapServer, Mapnik,\tMapGuide, QGIS Server\n\n\u25cf\tBackend(Python) :Geopandas, Shapely, Postgis\n\n\u25cf\tClient(Javascript) :Turf, DeckGL, osm-nominatim\n\nAsset Management Application:\n\nWith the \u201cImage-Based Information Management System\u201d Application, it is work to make an information management system and Digital 3D road inventory map for the 91,126km road network under the responsibility of the General Directorate of Highways. With this project, it is possible ensured that images (approximately 21 million) of the highway are taken and the collection, digitization, storage and presentation of the road information of the objects base and the realization of asset management, maintenance services, planning, project design, measurement and evaluation processes determined by the administration through the image.\n\nOpenSource GIS Tools:\n\n\u25cf\tGIS software for data visualization, processing and analysis: QGIS\n\n\u25cf\tGIS Servers: GeoServer\n\n\u25cf\tBackend :Postgis, Turf, @swimlane/ngx-charts\n\n\u25cf\tClient :OpenLayers\n\nResults:\n\n\u2022 Data in semi HD map quality was produced.\n\n\u2022 The entire road network can be monitored and analyzed with panoramic images.\n\n\u2022 The vertical and horizontal profile of the entire highways network has been created.\n\n\u2022 2.995.845 point inventories and 991.820km line inventories in 42  inventory were produced.\n\n\u2022 Detection of inventory deficiencies in the field and maintenance processes can be followed.\n\n\u2022 Road inventory data needed can be shared with other public institutions.\\n\\nozgenc uslu\\nsefa bugra ozen\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/QNBUEC/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_9/11 Luca Battistella.mp4", "persons": "Luca Battistella", "pretalx_id": "SQVEU3", "title": "FOSS4G 2022 | The Africa Knowledge Platform", "description": "The Africa Knowledge Platform is a one-stop-shop for the European Commission (EC)\u2019s scientific knowledge on Africa. Developed by the Joint Research Centre, this open, visual, and interactive platform brings together a wealth of geospatial scientific information on Africa\u2019s social, economic, territorial and environmental development. The Africa Knowledge Platform is developed using open-source geospatial technologies and the whole platform is open to the public, so that its potential value extends to academia and to stakeholders from the public, private and non-profit sectors in both Europe and Africa. The platform brings together information across 62 topics within 10 broad themes: natural resources, sustainable growth and jobs, food and agriculture, climate change, human demography, health, security, economy, energy and digital transformation. This covers all 17 of the United Nations Sustainable Development Goals. We will be taking a tour and in-depth look at the workflow used to develop and publish the platform and the technologies behind it.\\n\\nLuca Battistella\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/SQVEU3/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_9/12 Amour Nyalusi.mp4", "persons": "Amour Nyalusi", "pretalx_id": "R7PQZJ", "title": "FOSS4G 2022 | The Growth of OSM Communities in Tanzania Through Community Microgrants", "description": "The growth of OpenStreetMap communities (OSM) in Tanzania is taking shape as most organizations, institutions, and communities in general, are recognizing the importance of using and contributing to OpenStreetMap data. To support the growth of OSM communities in Tanzania, OpenMap Development Tanzania with her partner the Humanitarian OpenStreetMap Team (HOT) awarded microgrants to seven OSM communities in Tanzania - See the supported communities here.\n\nThe grants provided are supporting these communities to leverage the use of OSM and mapping to help solve different community challenges by facilitating training/workshops, purchasing tools and equipment, supporting staff, and other logistics. Most communities work in peripheral regions with a minimal understanding and use of open data and mapping technologies like OpenStreetMap, OpenDataKit QGIS, etc.\n\nThe first phase of project implementation ended with great successes and lessons learned from these communities. The general success of the microgrants so far include the following:\n\n 1. Transforming communities from using traditional data collection to digital open source tools such as ODK and Kobocollect has greatly improved data management and analysis. For instance, Agri Thamani Foundation and LAVISEHA are among microgrant recipients who are new to OpenStreetMap and other open mapping technologies for generating open data; however, they now use different tools, i.e. Kobotoolbox, OpenDataKit, OSM, and Tasking Manager, to collect data for their interventions in nutrition and gender-based violence.\n\n 2. Connecting OSM communities in Tanzania and encouraging collaboration in various tasks and opportunities. The grant provided an opportunity for local OSM communities in Tanzania to work together; a good example is Hope for Girls and Women in Tanzania, giving training to LAVISEHA on how communities can use open source tools like ODK to report the cases of GBV for rescue.\n\n 3. Creating awareness about OSM and other communities through participating and presenting in conferences and events such as the State of the Map Africa, Community webinars, etc.\n\n 4. Over 16000 building footprints were mapped and 380 km of roads were uploaded to OpenStreetMap by grantees\n\n 5. Supporting the growth of youth mappers chapters - Three grant recipients are youth mappers from three different universities who are using the grants to solidify the chapter and get exposure to projects while also applying for other funding to expand their projects\n\nAlthough the microgrant is expected to end in June 2022, OMDTZ is committed to supporting these communities through training and different engagements to ensure they achieve their goal of using open data for decision-making. Together we can add more people to a map by supporting all communities in mapping.\\n\\nAmour Nyalusi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/R7PQZJ/\\n\\n#foss4g2022\\n#generaltrack\\n#TransitiontoFOSS4G"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_9/13 Edoardo Neerhut.mp4", "persons": "Edoardo Neerhut, Elisa Puccioni", "pretalx_id": "CYU7AW", "title": "FOSS4G 2022 | The story of OSGeo in Oceania", "description": "OSGeo has existed in Oceania in various forms for quite a while now. Some of the major contributors to projects such as QGIS are based in Oceania and open geo events have been organised in the region for many years. It is only in more recent times however that we have started to support these efforts through the creation of a local chapter. When a group of us came together to organise Oceania\u2019s first regional FOSS4G SotM conference in Melbourne, 2018, it became clear structure was needed to sustain the momentum we had created.\n\nStructure was established by forming an entity and completing all the tasks that go along with that. This included creating a constitution, financial policies, forming a board of directors, establishing a membership policy, consulting with the community, working out what the entity\u2019s primary purpose is and so much more. We\u2019ve made plenty of mistakes along the way, but we\u2019ve also learned a lot. There are many successes too, such as the establishment of a Microgrant program to support initiatives across the region, the continuation of annual regional conferences, funding travel so that people without the financial means to do so could attend conferences, and the welcoming of new members from far and wide.\n\nThis talk is an insight into the journey of OSGeo Oceania. It is not meant to be a how to guide or a pat on the back, but rather a chance to facilitate discussion among the FOSS4G community so that we can find ways to support the use and understanding of open geospatial software in our respective regions.\\n\\nEdoardo Neerhut\\nElisa Puccioni\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/CYU7AW/\\n\\n#foss4g2022\\n#generaltrack\\n#TransitiontoFOSS4G"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/1 Xavier Torret  Albert Bofill.mp4", "persons": "XAVIER TORRET, Albert Bofill", "pretalx_id": "KAZNL7", "title": "FOSS4G 2022 | What is new in Giswater 3.5", "description": "Giswater (www.giswater.org) is a open source software aimed at being a corporate tool in water utilities with which to manage network assets in an excellent way and at the same time have the assets ready for hydraulic simulation, a feature that today Today it is known how to have a digital clone of network assets.\n\nTechnologically, it uses a set of Open Source technologies such as EPANET, SWMM, PostgreSQL, PostGIS or QGIS, all of them mature and proven, which give it a very powerful base for growth and consolidation.\n\nIts 'database centric' architecture gives it enormous potential with which maintenance operations (network outages) can be managed in an integrated way, longitudinal profiles can be made, events inventoried, among others.\n\nIt has a data model with dual-face architecture, which allows full integration of inventory and hydraulic model data, both for drinking water networks (https://github.com/Giswater/giswater_dbmodel/wiki/epanet- dual-dbmodel) and for urban drainage and sanitation networks (https://github.com/Giswater/giswater_dbmodel/wiki/swmm-dual-dbmodel) , giving full flexibility to the modeler to work with hydraulic capacities without any impact on inventory data for each asset item.\n\nThe EPA file export module has certain \"on the fly\" transformations to make the two different geometries (remember the dual-face) of the inventory elements compatible for both EPANET (https://github.com/Giswater/giswater_dbmodel/ wiki/epanet-on-the-fly-transformations) how to for SWMM (https://github.com/Giswater/giswater_dbmodel/wiki/swmm-on-the-fly-transformations).\n\nIt allows you to work with different scenarios to create different modeling conditions in order to check the worst case scenario or check how the network will respond in future scenarios. For Water Supply networks it is possible to work with demand scenarios (https://github.com/Giswater/giswater_dbmodel/wiki/epa-demand-scenarios) and for Urban Drainage projects it is possible to work with DWF scenarios (https: //github.com/Giswater/giswater_dbmodel/wiki/epa-dwf-scenarios) and hydrological scenarios (https://github.com/Giswater/giswater_dbmodel/wiki/epa-hydrology-scenarios)\n\nAdditionally, it also allows working with alternatives to plan new elements of the network without interfering with the elements of the asset inventory. By creating an alternative (https://github.com/Giswater/giswater_dbmodel/wiki/masterplan-capabilities) you can modify the physical reality of the network without affecting the real assets at all.\n\nAnother especially interesting feature is that it allows collaborative work. Large hydraulic engineering projects have been worked on to date in a sequential or fractional way, but not collaboratively. Thanks to Giswater it is now possible to work on projects in a real collaborative way, given the inherent multi-user characteristics of the Databases on which the project pivots.\n\nThe project was born seven years ago and in its version 3.5 it incorporates interesting novelties, among which the following stand out: Complete refactor of the python code, new hydraulic model capabilities with the management of multi-scenarios or the improvement of the usability of numerous tools such as dynamic zoning or the info among others.\\n\\nXAVIER TORRET\\nAlbert Bofill\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/KAZNL7/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/2 Larissa Dusabe.mp4", "persons": "Jin Igarashi, IRANKUNDA Moise, Dusabe Larissa", "pretalx_id": "WGLMQ8", "title": "FOSS4G 2022 | Rural water supply mapping by using FOSS4G application in Rwanda", "description": "Water and Sanitation Corporation (WASAC) (https://wasac.rw/) started mapping rural water supply system in Rwanda since 2018. WASAC conducted the data collection by using QGIS, QField and PostGIS all over the country of Rwanda, and now all GIS data is available as open data and visualized in this website (https://rural.water-gis.com/) by using Mapbox Vector Tiles. WASAC is trying to achieve universal access to water in SDGs Goal 6 by keeping updating and utilizing GIS data.\n\nWe are developing GIS system as open source, and all of source code was developed in Github through WASAC organization repositories here (https://github.com/WASAC) under the collaboration with The United Nations Vector Tile Toolkit (https://github.com/unvt/) team. Our approach uses quite low-cost technologies which are more sustainable in low and middle-income countries. All our data is also available in OpenAFRICA (https://africaopendata.org/organization/water-and-sanitation-corporation-ltd-wasac).\n\nOur achievements of the project were presented in previous global conference of FOSS4G 2019 Bucharest (https://media.ccc.de/v/bucharest-30-case-study-of-data-collection-data-sharing-for-rural-water-supply-management-in-rwanda) and FOSS4G 2021 Buenos Aires (https://www.youtube.com/watch?v=1Y2HbWkapDA). In FOSS4G 2022, we would like to update our current situation of the GIS system to the community.\\n\\nJin Igarashi\\nIRANKUNDA Moise\\nDusabe Larissa\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/WGLMQ8/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/3 Dimas Ciputra.mp4", "persons": "Dimas Ciputra", "pretalx_id": "U3KWWY", "title": "FOSS4G 2022 | The Freshwater Biodiversity Information System (FBIS) \u2013 mobilising data for monitoring freshwater ecosystems", "description": "Access to long-term biodiversity datasets is vital for monitoring, managing, and protecting freshwater ecosystems. Detecting critical ecosystem changes, such as losing unique biodiversity and ecosystem services, is dependent on access to data. A wealth of biodiversity data exists for river ecosystems in South Africa, but an operational information system to access these data is currently not available. To address this knowledge gap, the Freshwater Biodiversity Information System (FBIS) has been developed. FBIS is a platform for hosting, visualizing, and sharing freshwater biodiversity information for South African rivers. The project seeks to mobilize and import to the system baseline biodiversity data, identify strategic long-term monitoring sites, and train key organizations on how to use the information system. Using map-based visualizations, user-friendly dashboards and rapid data extraction capabilities, the system will improve knowledge of freshwater biodiversity and long-term river health trends, thereby supporting better-informed river management decisions and conservation planning projects.\\n\\nDimas Ciputra\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/U3KWWY/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/4 Carlos Eduardo Mota.mp4", "persons": "Carlos Eduardo Mota", "pretalx_id": "ZG7CUV", "title": "FOSS4G 2022 | Hardening a GeoNode Project \u2013 Some considerations about container security and optimization", "description": "The GeoNode, according to the project's website, is a platform for managing and publishing geospatial data. It brings together mature and stable open source software projects into a consistent, easy-to-use interface, allowing non-specialist users to share data and create interactive maps. In Brazil there is a growing use of GeoNode, observed mainly in governmental institutions and universities. One of the main ways of installing and configuring GeoNode is the so-called Geonode Project. It consists of a custom Django Project template, which contains, in addition to the main project files, a set of Dockerfiles of GeoNode components, such as GeoServer, Nginx (reverse proxy) and PostGIS. From a detailed analysis of the components of the GeoNode Project created, it was found that the original dockerfiles contain a series of security holes and also unnecessary packages for the execution of the stack, not recommended for production environments. A Dockerfile that follows best practices eliminates the need to run privileged containers (as root), the use of unnecessary packages, leaked credentials, like mail passwords or database DSNs, or anything that could be used for an attack. Removing known risks in advance will reduce security management work and service overhead. The objective of this talk corresponds to discuss the possible security holes found in the Geonode Project and, with the application of best practices in Dockerfiles, to make it leaner and safer for production environments. For demonstration purposes, there will have a project to be used as an example and will be hosted at https://github.com/geonode-br/hardening-geonode-docker.\\n\\nCarlos Eduardo Mota\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/ZG7CUV/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/5 Andreas Jobst.mp4", "persons": "Andreas Jobst", "pretalx_id": "XF9UH3", "title": "FOSS4G 2022 | MapFish Print, the classic printing component, a project update", "description": "MapFish Print is a mature Java-based open source software (BSD-2 license) for printing maps. Opposed to frontend solutions such as inkmap (https://github.com/camptocamp/inkmap), MapFishPrint runs server side and is integrated in several open source GIS frameworks like GeoMapFish ( for creating geoportal applications) or geOrchestra (spatial data infrastructure).\nThe classic approach to deploy MapFish Print is using a WAR-file in a Servlet Container (for example Tomcat), while it can also be integrated into cloud environments with prebuilt Docker images. Alternatively, MapFish Print\u2019s core printing library can also be integrated into other projects programmatically.\nMapFish Print supports the common data formats and standards (WMS, WFS, WMTS, GeoJSON, etc.) and provides access to rich cartographic features like rotations, grids, north-arrow or legends and multi-page printing. The layout is defined by a JasperReports template and a YAML configuration file.  The template allows users  to define the layout, include elements for maps, legends, grids and alphanumeric tables. Clients request a concrete print-out with a JSON-Request, providing along information like bounding-box, map layers and other data. The final report will be rendered by MapFish Print either as PDF or as a raster image and returned to the client.\nWe will present a summary of existing features as well as new (e.g. tiled WMS with buffered tiles for rendering large areas without label conflicts) and planned features of the MapFish Print open source project.\\n\\nAndreas Jobst\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/XF9UH3/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/6 Emmanuel Belo.mp4", "persons": "Emmanuel Belo", "pretalx_id": "G3TA9F", "title": "FOSS4G 2022 | Contributing to Geospatial Cloud Native Solutions", "description": "Over the last years, new architecture arose with the aim of easing the deployment and the usage of geospatial data and software in the cloud. Large accounts are starting to leverage the power of Kubernetes in public clouds such as AWS or Azure associated with traditional OSGEO software such as GeoNetwork and GeoServer.\nIn this talk we'll present our experience and results of working with large institutions in the public sector (civil defence, judiciary) or in the private sector (insurances, telecoms). We'll demonstrate how working the agile way with open-source software and high-level contributors allow to tackle successfully even the most ambitious challenge.\nAs a result of these efforts (multiple 100-man days contributed to the communities), we could participate significantly in developing GeoServer cloud as well as GeoNetwork microservice. Both projects aim to solve the cloud native challenge and are well underway of succeeding.\nAfter such an initial effort, we encourage every party using open-source software to participate in the maintenance and contribute to open-source development. Only with a real open-source engagement can we as a community achieve producing sustainable best of breed open-source software. Finally, we recommend customers to make sure their service providers have a positive impact in the communities.\\n\\nEmmanuel Belo\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/G3TA9F/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/7 Andreas Jobst.mp4", "persons": "Andreas Jobst, Ismail Sunni", "pretalx_id": "GRFEHG", "title": "FOSS4G 2022 | Implementation of the Chinese Postman Problem in the Valhalla Routing Engine", "description": "The Routing Engine Valhalla has been extended with a solution of the Chinese Postman Problem (CPP). This means that the most efficient route to travel all roads and paths in the area can now be calculated within a defined polygon.\nThe CPP is a well-known problem from graph theory, where the goal is to visit every edge in a graph while minimizing the distance traveled. In theory, a graph can be either directed, undirected, or mixed.\nIn this implementation, the CPP has been implemented for directed graphs, as this corresponds to the representation of graphs in Valhalla and the data structure of OpenStreetMap (OSM). The latter forms the data basis for the calculation of the CPP route.\nThe CPP is solved using the following set of algorithms: the Floyd-Warshall algorithm, the Hungarian method, and the Hierholzer method. After successfully implementing the theoretical code base of the CPP, the main challenge was to make the route calculation executable using real-world road networks (OSM).\nA key problem with the implementation of the theoretical CPP is that in real-world graphs, not every edge is always reachable by all other edges. Therefore, various extensions had to be made to allow the computation of a CPP route using OSM data. For example, within a larger area, rarely all road segments are accessible exclusively via the roads located in the area. It is often necessary to leave the area to access these otherwise inaccessible parts of the road network.\nEventually, we were able to create a working prototype of the CPP in Valhalla. In addition to the function of freely selecting the area to be traveled, restricted zones, so called no-go areas,  can also be defined. After selecting the vehicle type (car, bicycle, pedestrian, etc.), the CPP route can be calculated, which also includes turn-by-turn navigation.\\n\\nAndreas Jobst\\nIsmail Sunni\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/GRFEHG/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/8 Esra Cansizoglu.mp4", "persons": "Esra Cansizoglu, Yunzhi Lin", "pretalx_id": "773JU8", "title": "FOSS4G 2022 | A Graph-Based Road Conflation Method Preserving Connectivity", "description": "Connectivity of roads in a map is essential for many use cases including navigation. We present a graph-based solution to the road conflation problem which takes into account the connectivity of the road network. First, we generate a road network graph in both sources based on bifurcation points. Second, we carry out node and edge matching between the graphs where we follow shortest distance as a matching criterion. This is followed by the merging stage where graph edges with matching end nodes get conflated. Newly added roads are connected with the graph based on node and edge matching. We carry out experiments on conflating open source footway datasets from multiple cities with the OSM. The resulting conflated map contains up to 16x map feature improvements per city with geometrically accurate and smooth results around road junctions. Future work involves using different graph matching criteria to improve on the conflated output.\\n\\nEsra Cansizoglu\\nYunzhi Lin\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/773JU8/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/9 Piergiorgio Cipriano.mp4", "persons": "Piergiorgio Cipriano, Beatrice Olivari", "pretalx_id": "GPN87Y", "title": "FOSS4G 2022 | How much \u201c15-minutes\u201d is your city? Using open data to measure walking proximity", "description": "The challenges posed to the current urban mobility model by pollution-related and urbanisation issues have resulted in significantly increasing the importance of urban resilience. Mobility management, pandemics\u2019 spreading, equal access to services and climate crisis are just some of the crucial issues that falls within the definition of urban resilience.\nOne very promising solution aiming to solve many of these issues has been presented in 2016 by Professor Carlos Moreno under the name of \u201c15-minutes city\u201d. The paradigm is based on the idea that every citizen should be able to reach the essential services (supermarkets, shops, parks, etc) walking not more than 15 minutes from their home. The model is being tested in some metropolitan cities around the world (e.g. Paris).\nHowever, reorganizing the city so that it presents a 15-minutes structure is not an easy task. It requires large resources and a careful planning based on data, to make sure that the project undertaken will actually have a positive effect on the urban mobility and no asset is wasted on useless projects.\nThe Business Innovation team of Dedagroup Public Services used Open Street Map data to develop an index to detect the local level of proximity within the city, showing both the areas that already conform to the 15 minutes model and the ones that do not, where taking action would improve the quality of life of the citizens living there.\nThe presentation will be focused on this proximity index, describing the assumptions behind its definition, such as the choice of city services to be considered essential, the nature of the road network used to compute walking distances and the area tiling chosen for the task.\nThe index will be then showcased on the city of Florence, together with an analysis of the city from a proximity point of view and a what if scenario: how would the index change if the municipality (and other relevant stakeholders) decided to make interventions on low proximity areas?\nThe case of Ferrara will be also presented to show that the proximity index can be the basis for further analyses: coupling the index with resident population count can help to spot the areas that are both under-served and highly populated, that are the ones where more people would benefit from improvements.\\n\\nPiergiorgio Cipriano\\nBeatrice Olivari\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/GPN87Y/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/10 Seth Girvin.mp4", "persons": "Seth Girvin", "pretalx_id": "EBJSBX", "title": "FOSS4G 2022 | Introducing Wayfarer - a Python Routing Library", "description": "Compass Informatics [1] is pleased to announce the open sourcing of its routing library Wayfarer [2][3].\n\nWayfarer is a pure Python library that allows spatial features to be loaded into a NetworkX [4] network format. Once in this format the data can be manipulated and analysed using the huge range of graph algorithms in NetworkX.\n\nThe Wayfarer library provides a number of helper functions for example to calculate routes, split edges, find ends of paths, and retrieve features by keys.\n\nThe talk will outline the use cases for the library, and when it may be suitable to use rather than alternatives such as pgRouting. Case studies will be presented including Wayfarer\u2019s use in Ireland's Pavement Management System to help designate works and surveys on the road network. Wayfarer is also currently used for an Environmental Protection Agency project to create fully connected river networks in Ireland.\n\n[1] https://compass.ie/\n[2] https://pypi.org/project/wayfarer/\n[3] https://github.com/compassinformatics/wayfarer\n[4] https://networkx.org/\\n\\nSeth Girvin\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/EBJSBX/\\n\\n#foss4g2022\\n#generaltrack\\n#Stateofsoftware"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/11 Bartlomiej Burkot.mp4", "persons": "Bartlomiej Burkot", "pretalx_id": "E8ELHS", "title": "FOSS4G 2022 | Buses moving on the map - use case of building web mapping portal", "description": "This presentation will be a real story about the process of building webmapping portals with usefull public transport information and the quality of air.\nTwo portals will be shown one from Warsaw and one from Cracow (https://gdziejestautobus.pl/mapa/, https://www.mapakrakow.pl/).\nThis will be an use case of using opensource software and open data for building the web mapping portal. The challenges will be presented by constructing layers with live positions of public transport vehicles and the state of air quality in Poland.\nThe technical details will be presented along with the logistic and an business aspects. Following points will be covered: used development software, user experience challenges, design of project, project organization, effort, cost, legal issues.\nThere will be shown the sources of data from open public API services in Poland. The one is the open API with vehicles location data of public transport office in Warsaw. The second is the data coming from public office responsible for environment protection and monitoring.\nBoth presented portals shows the live position of public transport vehicles in the capital of Poland. The portal for Cracow will also show the live state of air pollution in the city. The pollution data come from sensors located in Poland collection the quality of air.\nBoth portals are the examles of: how to connect opensource Web-GIS tools and open public data to build an interesting web mapping site showing usefull data in the convenient spatial way.\\n\\nBartlomiej Burkot\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/E8ELHS/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/12 Yoni Nachmany.mp4", "persons": "Yoni Nachmany", "pretalx_id": "PT7S3F", "title": "FOSS4G 2022 | Mapping Historical \"Street View\" Images of New York City: Visualizing Geotagged Archival Photos", "description": "Street-level photographs of New York City from the early 1900s show how people used to live, from their clothes and vehicles to their stores and advertisements. Several open source projects have mapped archival \u201cstreet view\u201d images of New York, relying on various collections of photos with locations. These interactives, primarily built with Mapbox GL JS, are instructive when visualizing a newly-digitized archive, in this case a set of over 60,000 photos from the construction of the NYC subway between 1900 and 1950 with approximate coordinates.\n\n 1. \u201cStreet View, Then & Now: New York City's Fifth Avenue\u201d (http://publicdomain.nypl.org/fifth-avenue) compares 1911 wide-angle photographs from the New York Public Library to 2015 Google Street View imagery. A mini-map shows each photo\u2019s location and field of view, and a visitor to the site can \u201cgo south\u201d, \u201cgo north\u201d, or \u201ccross the street\u201d using the arrow keys. The project came out of the NYC Space/Time Directory (http://spacetime.nypl.org), an initiative to communicate the history of the city using historical maps, geodata, and open source tools. Code: https://github.com/nypl-publicdomain/fifth-avenue.\n\n 2. \u201c1940s.NYC\u201d (https://1940s.nyc) places digitized photos of most buildings in the five boroughs of New York City, collected from 1939 to 1941 by the Tax Department with help from the Works Progress Administration, on a map. Zooming in loads georeferenced scans of historical maps, and clicking on a marker opens a panel displaying the historical photos. \u201c80s.NYC\u201d (http://80s.nyc) remixed the site, using more recent images from the Department of Finance. Code: https://github.com/jboolean/1940s.nyc, https://github.com/bdon/80s.nyc.\n\n 3. \u201cA Stroll Down Flatbush Avenue circa 1914\u201d (https://stroll-down-flatbush.chriswhong.com) strings together 65 photographs, captured approximately every 50 feet, from the New-York Historical Society\u2019s \u201cSubway construction photograph collection, 1900-1950.\u201d (https://digitalcollections.nyhistory.org/islandora/object/nyhs%3Asubway) Geometries for the photos, which are often set at nearby intersections, were manually modified, and a mini-map showing those points is navigable with the up and down keys. Code: https://github.com/chriswhong/stroll-down-flatbush.\n\nThe entire subway construction photograph collection contains nearly 100 times as many photos as shown along Flatbush Avenue with associated latitudes and longitudes across New York City. What are the best practices for mapping these geotagged archival photos, with imprecise and duplicate locations, as well as rich text metadata like titles, topics, dates, and descriptions?\\n\\nYoni Nachmany\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/PT7S3F/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/13 Lorenzo Stucchi.mp4", "persons": "Lorenzo Stucchi", "pretalx_id": "3JL9YJ", "title": "FOSS4G 2022 | Open Source geospatial applications for energy and environment integration", "description": "The use of GIS to support energy planning is now widespread and well consolidated, as evidenced by the numerous studies available in the international literature. Many companies and governmental institutions have transferred their data and results into open source web platforms or tools for public access.\n\nWithin the broad topic of the interaction between renewable energy and environment, over the last years RSE S.p.A. has faced the necessity to develop and maintain WebGIS and online platforms related to various aspects of the energy system, in order to characterize the territory and its possible influences on renewable energy sources integration in the energy system, thus supporting the decision-making process towards energy transition.\n\nOne of the most significant products is the Integrated Atlas for the National Energy System and Renewable Sources, a WebGIS platform which represents on a national scale significant variables of the energy sector (resources, demand, installed plants, territorial constraints) under a system view, with the principal aim of supporting energy planning. From a technical point of view the Integrated Atlas is developed on TerriaMap, a catalogue-based web geospatial visualisation platform developed by the Australian research centre CSIRO. TerriaMap uses the JavaScript library TerriaJS together with other open source libraries as React JS, Leaflet and Cesium, for 3D visualization.\n\nBesides standard WebGIS functionalities, the Integrated Atlas provides the access to TOTEM (Territory Overview Tool for Energy Models), an advanced open source tool for the energetical characterization of the territory, essential for supporting multi-energy modelling. Starting from spatial and energy data, the TOTEM tool estimates electrical and heat demand, wind and solar resource and other significant energy variables on hourly and provincial scale. Concerning technical details, the tool and its web interface are developed in Python and use libraries such as Pandas, Flask ad Bokeh. The tool is opensource and it will be release under MIT License, however only a portion of the input data are currently publicly available due to data providers\u2019 restrictions.\n\nThe need to harmonize data and analysis about the relations between energy and environment and provide an access point to the developed tools has inspired the creation of the Energy and Environment Geoportal, based on the Mapstore Open Source web platform developed by GeoSolutions. This platform allows viewing and querying geospatial published data, integrating different remote resources into interactive and immediate representations such as maps, dashboard or geostories.\n\nAs an example, detailed results of above cited multi-energy models, which receive spatialized energy data as inputs, have been synthesized in a geostory, an immersive narration which explains how a multi-energy analysis based on detailed territorial characterization of a region can support the evaluation of the best alternatives for its energy development. The geostory is accessible from the Energy and Environment Geoportal.\n\nIt must be specified that these products are still under development and subject to continuous updates of both data and technology. More details about contents and tools are left to the final presentation.\\n\\nLorenzo Stucchi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/3JL9YJ/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/14bis Sini P\u00f6yt\u00e4niemi un relatore interviene sui buchi di audio.mp4", "persons": "Sini P\u00f6yt\u00e4niemi", "pretalx_id": "L8BQFK", "title": "FOSS4G 2022 | Developing an UI for historical orthophotos timeseries data", "description": "In 2020 National Land Survey of Finland had scanned and digitized over 100.000 historical orthophotos from 1931 to 2020. This unique dataset had been open for a couple of years via a WMS-T API service but was not well known to the public at the time, and not truly available to less technically oriented users. Hence, there was a need to get them findable and easily accessible with a web browser.\n\nInstead of building a completely new service, the images were to be published with the Open Source based national geoportal of Finland - Paikkatietoikkuna. The geoportal is built with Oskari Map Application Platform which was enhanced for this use case to support timeseries data. The historical orthophotos are scattered both in time and in geography. To improve end-user experience and make discovering data easier an OGC API Features service was used for metadata.\n\nThe final result was received with quite a bit of enthusiasm: after publishing the data in Paikkatietoikkuna geoportal in June 2021, the visitor numbers soared to new records. Nearly all of the feedback has been positive, and now it is possible for anybody to benefit from this extremely valuable and fascinating historical data.\n\nThe code is fully open source and can be easily used in any Oskari instance \u2013 all you need is the data, which, obviously, isn\u2019t the easiest part of this all.\\n\\nSini P\u00f6yt\u00e4niemi\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/L8BQFK/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/15 David Blasby.mp4", "persons": "david blasby", "pretalx_id": "QR7XQZ", "title": "FOSS4G 2022 | European (Inspire) Data Tour", "description": "This talk provides concrete tips on how to improve your open data accessibility and discovery.  We use real world analysis of what Europe has today, rather than specifications, guidelines, or theory.\n\nWe recently investigated the linkage between Metadata (CSW Dataset and Service Metadata records) and actual downloadable/viewable data (WFS, WMS, WMTS, and Atom).  We also looked at other linkages between the documents (for example, metadata document links, \"operatesOn\" links,  Inspire \"ExtendedCapabilities\", and other MetadataURL links).\n\nFollowing links isn't as simple as just taking the given URL and resolving it - we will look at \"fixing\" the URL as well as setting request headers.  We will also investigate comparing two different metadata documents (from different URLs) to see if they are \"the same\" even if they aren't really equivalent.\n\nIf you are responsible for an INSPIRE catalogue or web service, attend this talk to learn what works (and does not work) based on real world analysis rather than theory. Or just attend to be sure you did not show up in the examples.\\n\\ndavid blasby\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/QR7XQZ/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/16 DK Benjamin.mp4", "persons": "DK Benjamin, Yogesh Girikumar", "pretalx_id": "NMQQT9", "title": "FOSS4G 2022 | Using Terraform to manage HOTOSM's infrastructure as code", "description": "Humanitarian Openstreetmap Team (HOT) administers several free-software applications with varied deployment architectures on multiple cloud platforms. As an organization that values openness and transparency, we actively seek out open source tools that help us enact our principles of open participation and collaboration. In that vein, we chose Terraform as the tool for managing infrastructure at HOT.\n\nUsing HOT's experience managing OSM Galaxy infrastructure using Terraform, this talk describes our use of Terraform to manage infrastructure at scale in order to improve DevOps processes with  infrastructure reproducibility, security, cost and change management.\n\nWe will present these advantages in the context of our own team's experiences and the challenges we faced trying to build a scaling technology stack and compare Terraform with popular Infrastructure as Code (IaC) alternatives.\n\nThe talk will use OSM Galaxy API (galaxy.hotosm.org) as a case study to describe the process of porting infrastructure to Terraform in order to manage infrastructure continuously at enterprise scale - which is particularly relevant for non-profits and organizations that develop compute-intensive technology.\\n\\nDK Benjamin\\nYogesh Girikumar\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/NMQQT9/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/17 Yunzhi Lin.mp4", "persons": "Yunzhi Lin", "pretalx_id": "DMSDM9", "title": "FOSS4G 2022 | Curated Major Map Features Library", "description": "A team of experienced mappers and language experts at Meta has reviewed a dataset of major map features from OpenStreetMap(OSM), and used the curated results on one of their validation processes to check for quality issues of the Daylight and OSM maps. The dataset of the curated results is considered as a reference library of major map features with their key information. During the validation process, this library is used to compare against Daylight and OSM data to look for suspicious changes on features included in the library.  With such reference library, the Meta Basemap Team is able to keep a stable quality on major map features in an efficient manner. To ensure the data in this library is up-to-date and comprehensive, systematic approaches to continuously improve the library are also developed.  In our talk, we will share more details about this curated library and processes, and how we maintain the freshness of the library.\\n\\nYunzhi Lin\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/DMSDM9/\\n\\n#foss4g2022\\n#generaltrack\\n#OpenData"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_6/18 Crystal Wai.mp4", "persons": "Crystal Wai", "pretalx_id": "VKV8BW", "title": "FOSS4G 2022 | spatialEpisim: an open-source R Shiny app for tracking COVID-19 in low- and middle-income (LMIC) countries", "description": "It is essential to understand what future epidemic trends will be, as well as the effectiveness and potential impact of public health intervention measures. The goal of this research is to provide insight that would support public health officials towards informed, data-driven decision making. We present spatialEpisim, an R Shiny app (https://github.com/ashokkrish/spatialEpisim) that integrates mathematical modelling and open-source tools for tracking the spatial spread of COVID-19 in low- and middle-income (LMIC) countries.\n\nWe present spatial compartmental models of epidemiology (ex: SEIR, SEIRD, SVEIRD) to capture the transmission dynamics of the spread of COVID-19. Our interactive app can be used to output and visualize how COVID-19 spreads across a large geographical area. The rate of spread of the disease is influenced by changing the model parameters and human mobility patterns.\n\nFirst, we run the spatial simulations under the worst-case scenario, in which there are no major public health interventions. Next, we account for mitigation efforts including strict mask wearing and social distancing mandates, targeted lockdowns, and widespread vaccine rollout to vaccinate priority groups.\n\nAs a test case Nigeria is selected and the projected number of newly infected and death cases are estimated and presented. Projections for disease prevalence with and without mitigation efforts are presented via time-series graphs for the epidemic compartments.\n\nPredicting the transmission dynamics of COVID-19 is challenging and comes with a lot of uncertainty. In this research we seek primarily to clarify mathematical ideas, rather than to offer definitive medical answers. Our analyses may shed light more broadly on how COVID-19 spreads in a large geographical area with places where no empirical data is recorded or observed.\\n\\nCrystal Wai\\n\\nhttps://talks.osgeo.org/foss4g-2022/talk/VKV8BW/\\n\\n#foss4g2022\\n#generaltrack\\n#Usecases&applications"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Modulo_3A/1 Jan Stenkamp.mp4", "persons": "Jan Stenkamp, Tom Niers, Nick Jakuschona", "pretalx_id": "DD38UJ", "title": "FOSS4G 2022 | Multi-Sensor Feeder: Automated and Easy-To-Use Animal Monitoring Tool for Citizens", "description": "Environmental changes can have different causes on local level (e.g. soil sealing) as well as on global level (e.g. climate change). To detect these changes and to find patterns in the reasons for them it is necessary to collect broad environmental data, temporally and spatially. Thereto citizens can play an essential role to collect the data (Goodchild, 2007). In particular, we developed a system which enables citizens to monitor the occurrence and distribution of birds and provides the collected data to the public in order that both researchers and citizens can derive conclusions from them. With our automated approach we want to support other citizen science solutions like eBird (Sullivan et al. 2014) where contributors manually report their sightings.\n\nTherefore, we built a prototypical bird feeder equipped with several sensors and the infrastructure to process the data collected by the feeder.\nThe feeder is easy to reproduce at a reasonable price by following an open available manual. This allows anyone to build the feeder on their own, enabling a large distribution at many locations. The feeder automatically detects when a bird is visiting it, takes an image of the bird, determines the species and connects the observation with environmental data like the temperature or light intensity. All the collected data are published on a developed open access platform. Incorporating other surrounding factors like the proximity of the feeder station to the next forest or a large street allows it to pursue various questions regarding the occurrence of birds. One of them might ask, how does the immediate environment affect bird abundance? Or do sealed surfaces have a negative effect compared to a flowering garden?\n\nThe developed weatherproof bird feeder is attached with multiple sensors. Thereby the standard equipment includes a motion sensor to detect if a bird is currently visiting the feeder, a camera to take images of the birds, a balance to weigh the birds and a sensor to measure the environment's temperature and air pressure. In addition to the standard sensors, further sensors were tested with the prototype, which usefully supplement the monitoring but are not absolutely necessary for the operation of the station. Thus, a microphone is suited to record the voice of the birds or generally the surrounding noises. A brightness sensor can be valuable to draw conclusions whether birds visit the feeder in relation to light conditions, or a sensor to measure the air pollution (e.g. PM10) to investigate if the air quality influences the bird occurrence. Besides, the usual camera can be replaced by an infrared camera to capture animals which visit the feeder at night. Thus, the station is expandable and customizable depending on the individual use cases or research questions.\nThe environmental sensor data is continuously logged and sent to the open access platform, whereby the corresponding interval can be set by the user. Once the motion sensor detects a movement, the camera recording starts as well as scale and microphone start to store values. As long as the motion sensor detects movement, camera, microphone and balance are running. After the movement is finished, a light-weighted recognition model is used to check whether a bird is depicted in the images. If this is the case, all data collected during the movement, including the respective environmental data, will be sent as a package to the open access platform.\n\nIn order to process the data collected by the station, we have developed various methods and software for data storage, analysis and sharing. The data processing is done on a centralized server. Communication with this server is enabled through a RESTful API and a website. On the server created entities of the feeders can  receive environmental data as well as movement packages. When movements are sent, the server analyzes the amount of birds and identifies the species with artificial intelligence. In addition to the storage, the server makes the data available to users in two ways. First, the data is downloadable as raw JSON via the API, which enables others to use it for their own research. Second, the data is presented nicely on our website, to make it easily inspectable for everyone. However, not only via our stations a upload to the server is possible, it is also open for the upload of data gathered by other systems. Further, it is also possible to upload images of birds and receive the represented species.\n\nThe feeder is designed so that it can be replicated by anyone. The corresponding instructions will be published shortly. The code to run the station and the server is available via GitHub (https://github.com/CountYourBirds).\n\nMoreover, different options for the validation of the data, especially the species classification, are implemented. One step is the automatic validation by the sensor values or metadata. For instance if a standard camera recognizes a bird but currently it is night (detected by light sensor or time of the day) or the balance detects nothing, the observation is discarded. Further validation can come from actual people. An interface is provided which is used to show people values and especially images recorded with the automatically recognized species. The depicted data can be validated to find corrupt sensors and wipe out mistakes made within the image classification. Additionally, the serverside evaluation of the data is supplemented by a validation of the recognized species. It is checked whether it is possible that the species can occur at that geographic region or at that time of the year.\n\nAs next steps we want to conduct workshops with citizens and experts, both for putting together the stations as well as evaluating the data and the station itself. In general a strength of our implemented approach is that it is easily adaptable to other use cases, especially to detect other animals. For example with small adaptations to the feeder it could be used to detect or count different mammals like squirrels or for insects like butterflies and bees.\\n\\nJan Stenkamp\\nTom Niers\\nNick Jakuschona\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/DD38UJ/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Modulo_3A/2 Cinzia Licciardello.mp4", "persons": "Ing. Cinzia Licciardello", "pretalx_id": "DNPQLN", "title": "FOSS4G 2022 | Environmental monitoring management of waste from large excavations due to infrastructure buildings", "description": "Large infrastructure building like the Florence Railway Station designed for high-speed rails requires a proper management of the huge quantity of waste originating from excavation activities. Such waste amounts require large areas for disposals, making abandoned areas or exhausted quarries and mines ideal sites for hosting the excavated wastes. A rectangular area of 500x70m delimiting the railway station has been excavated in two steps causing the removal of a 10m-thick soil layer per step: the amount of construction waste, as stated in the approved management project by public authorities involved in environmental management plans, would be used for the environmental restoration of an area of 400x350m located near a former exhausted lignite quarry) located in the proximity of the Santa Barbara village near Cavriglia (Arezzo).\nThe Tuscan Regional Environmental Agency (ARPAT) have been involved in monitoring both the terrain transportation and disposals\u2019 operations according to the approved management plan: while the Environmental Evaluation Office (VIA-VAS) was responsible of the waste sampling for further chemical analysis to assess the acceptable waste chemical composition, the Environmental Regional Information System Office (SIRA) was asked to evaluate volume balancing between all the waste management cycle, with included: (a) waste extraction from railway station site building, and (b) waste disposal final destination (exhausted Santa Barbara lignite quarry).\nA phase difference terrestrial LiDAR have been used in acquiring the 3D point cloud at the railway site at the following stages: (a) initial stage, before excavation activities\u2019 starting (b) step 1 stage, after the first 10m-thick layer excavation (c) step 2 stage, after completion of excavation works. Various tests have been performed to assess the optimal number of scans allowing to obtain the required precision of the final 3D model, stating from more than 100 scans for the survey for the initial stage to about 50 scans used for (b) and (c) stage surveys. Each survey was referenced by using a local coordinate system materialized during the survey; each target was then referred to the mail local reference system used in the railway station project by the owner\u2019s topographers with a total station.\nScan alignment and 3D cleaning (point clouds and meshes) was made using proprietary licensed software, while volume differences evaluation was made in QGIS 3.x environment; as for the scan alignment phases (3D point clouds\u2019 alignment), available open-source platforms have been tested and evaluated. Both scan alignment and 3D cleaning, while manually executed, have been proven to be time-consuming operations even using proprietary-licensed sofware.\nAs for Santa Barbara quarry, an initial RTK RPAS was performed before grass and small vegetation removal to evaluate the potential of RPAS over the survey area in speeding survey activities with respect to the terrestrial LiDAR in open areas: the RPAS survey demonstrates that such technology, compared to terrestrial LiDAR surveys in open areas, is much less time consuming in both acquisition and processing time, making it the best choice for surveys in open areas where extreme precision (sub-centimetric) is not required.\nDue to work progresses in filling activities at Santa Barbara site, i.e. the partial cleaning of one of the defined file subareas followed by its filling with excavated wastes, the initial stage of waste filling was surveyed in five times, one for each of the defined subareas. Each subarea survey, due to its limited dimensions (120x50m), instrumentation and personnel availability at the time of vegetation cleaning, have been surveyed with the terrestrial LiDAR, while for the final survey over the whole quarry area the RTK RPAS have been used. LiDAR surveys have been processed according to the tested methods in railway station surveys processing; RPAS RTK survey data, too, have been processed with the same proprietary software. Terrestrial LiDAR surveys were referenced in a local coordinate system by using a local coordinate system materialized during the survey; each target was then referred to the mail local reference system used in the quarry filling project by the owner\u2019s topographers. The RPAS models, in geographic coordinates, were then aligned to the terrestrial LiDAR surveys in order to evaluate the global waste volume disposed onsite.\nComparison operations between excavated volume at the railway station site and the exhausted lignite site showed good agreement, even by taking into account a standard transformation coefficient between compact soil and excavated waste. Terrestrial LiDAR scan alignment and point clouds/mesh cleaning activities have been very time-consuming, so that usage of automatic processing pipelines testing by mean of open source software is in progress: environmental monitoring of waste management over large areas, if properly managed with (semi) automatic processing, would be less time-consuming stating to actual testing. National projects of large processing infrastructure (\u2018Mirror Copernicus\u2019) would see a leading role taken by our office in building a fully-operational prototype of a pipeline for scan alignment and point cloud/mesh processing to evaluate waste extraction in large building sites.\\n\\nIng. Cinzia Licciardello\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/DNPQLN/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Modulo_3A/3 Paolo Zatelli.mp4", "persons": "Paolo Zatelli", "pretalx_id": "E8BXZJ", "title": "FOSS4G 2022 | Modeling of forest landscape evolution at regional level: a FOSS4G approach", "description": "In the last decades the European mountain landscape, and in particular the Alpine landscape, has dramatically changed due to social and economic factors (Tattoni et al. 2017).\nThe most visible impact has been the reduction of the population for mid and high altitude villages and the shrinking of part of the land used for agriculture and grazing. The result is a progressive reduction of pastures and meadows and the expansion of the forested areas. Forest plots become also more compact, with the loss of ecotones.\nThe study of this phenomenon is important not only to assess its current impact on the ecological functionality of forest ecosystems including biodiversity and natural hazards, but also to build future scenarios, taking into account also the climate change issues. The limit of the mountain treeline is gradually shifting upwards and the monitoring and modeling of these changes will be crucial to plan future interventions and try to implement effective mitigation plans.\nFor these reasons, a dataset describing the forest, meadows and pasture coverage for the Trentino region, in the eastern Italian Alps, has been created.\nA set of heterogeneous sources has been selected so that maps and images cover  the longest possible time span on the whole Trentino region  with the same quality, providing the necessary  information to create a LULC (Land Use/Land Cover) map at least for the forest, meadows and pasture classes.\nThe dataset covers a time span of more than 160 years, with automatic or semi-automatic digitization of historical maps and the LULC classification from aerial images.\nThe first set of maps includes historical maps from 1859 to 1936, with an additional map from 1992 which was not available in digital format and has been digitized for this project: Austrian Cadastral (1859, 13297 sheets, scale 1:1440), Cesare Battisti\u2019s map of forest density published in his atlas \u201dIl Trentino. Economic Statistical Illustration\u201d (1915, single sheet, 1: 500 000), Italian Kingdom Forest Map (IKMF) (1936, 47, 1:100 000) and Map of the potential forest area and treeline (1992, 98, 1:50 000). A new procedure has been developed to automatically extract LULC classes from these maps, combining GRASS and R for the segmentation, classification and filtering with the Object Based Image Analysis (OBIA) approach. Two new GRASS modules used in this procedure have been created and made available as add-ons on the official repository (Gobbi et al., 2019)..\nThe second set of maps are aerial images, covering the time span  from 1954 to 2015. The four sets which differ for mean scale, number of bands, resolution and datum: \"Volo GAI\" (1954, 130 images, mean scale 1:35 000, B/W, resolution 2m, Rome40 datum), \"Volo Italia\" (1994, 230, 1:10 000, B/W, 1m, Rome40), \"Volo TerraItaly\" (2006, 250, 1:5 000, RGB+IR, 0.5m, Rome40) and \"Volo AGEA\" (2015, 850, 1:5 000, RGB+IR, 0.2m, ETRS89). The \"Volo GAI\" imagery set has been ortho-rectified using GRASS, images in the other sets were already ortho photos.\nThe aerial images were classified with OBIA to create LULC maps, with particular focus on forest, meadows and pasture classes. The same training segments were used across the 4 sets and the custom classification procedure has been scripted. The number of training segments ranges from 1831 for the 2015 dataset and 2572 for the 1954 imagery set.\nThe evaluation of the results of the classification for all the maps and images has been carried out with a proportional stratified random sampling approach. A procedure has been scripted in GRASS to select 750 sampling points, distributed in each stratum (LULC class) proportionally to the area of the class. The resulting points have been manually labeled and used to assess the classification and filtering (where present) accuracy.[c]\nFor the historical maps, the application of the custom filtering procedure has increased the accuracy from a minimum value of 67% (for the IMF map) to 93% (for the same map), with a maximum of 98% for the cadaster map.\nFor the imagery datasets the accuracy (percentage of points correctly classified) was between 93% and 94%, with the latter value corresponding to the higher resolution 2015 imagery dataset. Higher accuracy, up to 95% was obtained for the forest class, which is the main focus of the study.\nThe analysis of selected landscape metrics provided preliminary results about the forest distribution and pattern of recolonization during the last 180 years.\nA comparison between the capabilities of FOSS4G available systems for  landscape metrics was performed  to evaluate the best analysis  tools (Zatelli et al. 2019).\nFinally, these time series of LULC coverage were used to create future scenarios for the forest evolution in a test area of Trentino in the next 85 years, using both the Markov chain and the Agent Based Modeling approaches with GAMA (Taillandier et al. 2018).\nGiven the large number of maps involved, the great flexibility provided by FOSS for spatial analysis, such as GRASS, R, QGIS and GAMA and the possibility of scripting all the operations have played a pivotal role in the success both in the creation of the dataset and in the extraction and modeling of land use changes.\nThe development of new GRASS add-on modules, based on the scripts created during this study, is planned.\\n\\nPaolo Zatelli\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/E8BXZJ/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Modulo_3A/4 Francesco Pirotti.mp4", "persons": "Francesco Pirotti", "pretalx_id": "EFPDRZ", "title": "FOSS4G 2022 | InforSAT: an online Sentinel-2 multi-temporal analysis toolset using R CRAN", "description": "Remote sensing via orbiting satellite sensors is today a common tool to monitor numerous aspects related to the Earth surface and the atmosphere. The amount of data from imagery have increased tremendously since the past years, due to the increase in space missions and public and private agencies involved in this activity. A lot of these data are open-data, and academics and stakeholders in general can freely download and use it for any type of application. The bottle-neck is often not data availability anymore, but the processing resources and tools to analyse it. In particular multi-temporal analysis requires stacks of images thus digital space for storage and processing workflows that are tested and validated. Processing image by image is often not a viable approach anymore. Several solutions have been created to support centralized and automated processing of multiple images. Software as a service (SaaS) is becoming more common among users. The most popular to this day is probably Google Earth Engine (GEE), which gives users Petabytes of data at their fingertips, access to processing resources and an interface that provides a large number of tools for data processing via Javascript or Python programming environments (Gorelick et al., 2017). What took before days if not months can now be run in a few minutes or hours. GEE is available and free for academics as of today, but it must be noted that it is not to be taken for granted in the future. Other initiatives such as Copernicus RUS project that has closed at the end of 2021 also provided access to data (Copernicus data) and computing resources, to promote uptake of Copernicus data via educational and research activities.\n\nMoving towards SaaS solutions usually requires a provider that puts software on the cloud and a channel, usually a web portal, for accessing data and tools. The R CRAN programming environment has all the \u201cingredients\u201d that are needed to create such SaaS in a local machine or on a server. We propose and discuss here a solution, called InforSAT, that was created ad hoc for centralizing satellite imagery processing, taking advantage of a remote server with multiple processors and thus also parallel processing solutions. The R Shiny package was used for connecting online widgets for user interaction with R tools for specific processing of imagery that is done via other specific packages. To this date only Sentinel-2 Level 2C data are considered, but the system is scalable to other sensors and processing levels. The tools that are available to this day are focused on multi-temporal analysis, to support the academic community involved in particular in vegetation analysis, whose phenology has notable changes inter- and intra-annually. The tools are available via a web portal to reach research teams that are not so familiar to satellite image analysis, to allow simplified extraction of multi-temporal data from Sentinel-2 images. Figure 1 shows the interface and figure 2 the result of extracting a boxplot of vegetation index values over a specific time window.\n\nAll image data are stored in a user-defined folder on the server, and a script checks weekly (or at other user-defined intervals) for new Sentinel-2 images and automatically downloads them and stores metadata in an R list structure. The metadata stores image paths, bands and also histograms of values for each band, to use for defining color-stretching parameters during image rendering on the browser. Regarding visualization, users can render real-color and false-color composites defining their own band combinations, and can also create and raster layer with the values of common vegetation indices or define their own index by providing an equation on the interface (see Figure 1). The images to be rendered on the user browser are processed on-the-fly from the original JPEG2000 format, also for calculating the index raster and the color-composites. Each index raster is calculated every time the user re-draws actively the raster, by sampling the original image with points that correspond to the screen pixels, reprojected from screen coordinates to image coordinates. Depending on the screen size and on the area, these are around one million points, that are then converted to an image and rendered on screen with a fixed scale that depends on the expected minimum and maximum values of the index (e.g. for the normalized vegetation index that would be between -1 and 1) or a scale that automatically stretches between the 10th and 90th percentile of the frequency distribution of the real values. The color-composites are automatically drawn at any scale using the intrinsic overviews for each Sentinel-2 band that are present from the JPEG2000 format. Regarding multi-temporal analysis, users can define one ore more polygons over the area and for each polygon extract single pixel values (digital numbers \u2013 DN) and aggregated zonal statistics for each and all available images in a few seconds, with or without using parallel processing mode. Users can download the multi-temporal data, i.e. the DN values, in table format for further analysis. The table is in long format and has a column with a timestamp, one with polygon ID and one column for each band with values. In both visualization and multi-temporal analysis, users can decide a threshold for masking according to cloud and snow probability, which are available products from the sen2cor processing of Sentinel-2 to level 2C. In the near future this solution will be integrated in an R package, allowing users to easily download, install and replicate their own portal locally or in their own server.  Code is available on Github at https://github.com/fpirotti/inforsat\\n\\nFrancesco Pirotti\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/EFPDRZ/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Modulo_3A/5 Jens Ingensand.mp4", "persons": "Jens Ingensand, Nicolas Blanc", "pretalx_id": "YXFEWL", "title": "FOSS4G 2022 | An open API for 3D-georeferenced historical pictures", "description": "Approach and concepts\n3D-georeferenced historical pictures have a high potential for the analysis of different landscape features such as melting glaciers, the effects of urbanization or natural hazards. Moreover, historical pictures have a higher temporal and spatial resolution than satellite imagery and therefore allow for analyses that go farther back in time. A 3D georeferenced picture can for instance be combined with a digital terrain model (DTM) and other reference data to calculate the exact footprint of the picture and to generate a list of visible toponyms that can be used to find pictures of a specific place or region.\n\nThe utilization of historical pictures is unfortunately still difficult: 1. historical pictures need to be digitized 2. collections are often spread across several places in different archives and collections 3. metadata is often not available. In the ongoing open-source project Smapshot (Produit et al. (2018), https://smapshot.heig-vd.ch/) over 150\u2019000 digitized historical pictures have been georeferenced in 3D by more than 700 participants. In the web-platform Smapshot a participant can georeference a picture using monoplotting (Bozzini et al, 2012): ground-control-points (GCP) are digitized both in the historical picture and in a virtual globe that displays recently updated data. These GCP allow for the calculation of the exact position from where the picture has been taken (3D point) and the three angles that define the direction of view: roll, pitch and yaw. Once the position and the direction of view has been calculated a footprint of the picture is generated using a DTM.\n\nResults\nIn order to make the pictures and the metadata from Smapshot available to the public, an open API for 3D-georeferenced historical pictures has been created. The goal was to offer free access to all the data in the Smapshot database and to allow for different types of queries such as retrieving the footprints of the photos, fetching metadata for a picture (e.g. owner, title, date, x/y/z position and roll, pitch, yaw angles) or retrieving photos that are within a certain range from a specific point.\n\nThis API was built in NodeJS (https://nodejs.org/) with a PostgreSQL/PostGIS (https://www.postgresql.org/, https://postgis.net/) database and python code for the georeferencing algorithm. The API is a REST API fully documented using the OpenAPI specification. The API project has been open-sourced and specific test-suites have been put in place to ensure quality and to allow community contribution with confidence.\n\nOne challenge for the establishment of this API was standardization: Today there are several standards for the definition of metadata in pictures such as the IIIF (https://iiif.io/) or the Dublin-Core (https://www.dublincore.org/) standards. These standards however have limited support for geospatial data. On the other hand, spatial standards poorly support pictures that are oriented in 3D. The glTF standard (https://www.khronos.org/gltf/) is one example and there is also a recent initiative from the OGC called GeoPose (https://www.ogc.org/projects/groups/geoposeswg) which formalizes a standard to define a 6DoF pose everywhere on Earth including a position and orientation in 3D.\n\nReasons why it should be considered\n3D georeferenced images are increasingly used by several projects that document change over time; e.g. within the field of digital humanities even paintings can be considered for 3D georeferencing and differences between the real world and the painted world can give room for analysis and interpretation. Another use-case is the creation of geovisualization-applications that show the contents of historical pictures in 3D and that enable a user to compare its contents to the real world (e.g. augmented or virtual reality applications)\n\nFurthermore in the context of climate change, pictures and paintings document change and deliver evidence. Image processing techniques can be used to automatically detect features (machine learning) and if several pictures are available for one region (but taken from slightly different viewpoints) 3D features can be generated.\n\nThe open API for 3D georeferenced historical pictures makes these types of analyses easier and opens up the data for a larger public. It also becomes possible to implement other solutions that utilize the data directly - e.g. for displaying historical pictures in a 3rd party web page or for implementing machine-learning processes that automatically download pictures and metadata in order to recognize features and places.\n\nThe results of the project are also an important input for standardization activities that aim at establishing standards in the context of georeferenced pictures and their metadata.\n\nAn important perspective of the project is the establishment of an infrastructure for 3D-georeferenced pictures that can be deployed on a national or international level and that also offers the possibility to push new data (e.g. pictures) in the database.\n\nThis work is of interest for researchers who want to utilize and analyze 3D georeferenced historical imagery and for people who want to establish open API\u2019s to give access to data that is relevant for research.\n\nBibliography\nBozzini, C., Conedera, M., Krebs, P., 2012. A new monoplotting tool to extract georeferenced vector data and orthorectified raster data from oblique non-metric photographs. International Journal of Heritage in the Digital Era 1 (3), 499\u2013518.\n\nProduit, T., Blanc, N., Composto, S., Ingensand, J., Furhoff, L, 2018. Crowdsourcing the georeferencing of historical pictures. Proceedings of the Free and Open Source Software for  Geospatial (FOSS4G) Conference. Guimar\u00e3es, Portugal. 2018-07\n\nSource code : https://github.com/MediaComem/smapshot-api\\n\\nJens Ingensand\\nNicolas Blanc\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/YXFEWL/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Modulo_3A/6 Andrea Folini.mp4", "persons": "Andrea Folini", "pretalx_id": "EHNYXK", "title": "FOSS4G 2022 | Cluster Analysis: a comprehensive and versatile QGIS plugin for pattern recognition in geospatial data", "description": "As geospatial data continuously grows in complexity and size, the application of Machine Learning and Data Mining techniques to geospatial analysis is increasingly more essential to solve real-world problems. Although, in the last two decades, the research in this field produced innovative methodologies, they are usually applied to specific situations and not automatized for general use. Therefore, both generalization and integration of these methods with Geographic Information Systems (GIS) are necessary to support researchers and organizations in data exploration, pattern recognition, and prediction in the various applications of geospatial data. The lack of machine learning tools in GIS is especially clear for what concerns unsupervised learning and clustering. The most used clustering plugins in QGIS [1] contain few functionalities beyond the basic application of a clustering algorithm.\n\nIn this work we present Cluster Analysis, a Python plugin that we developed for the open-source software QGIS and offers functionalities for the entire clustering process: from (i) pre-processing, to (ii) feature selection and clustering, and finally (iii) cluster evaluation. Our tool provides different improvements from the current solutions available in QGIS, but also in other widespread GIS software. The expanded features provided by the plugin allow the users to deal with some of the most challenging problems of geospatial data, such as high dimensional space, poor quality of data, and large size of data.\n\nIn particular, the plugin is composed of three main sections:\n\n - feature cleaning: This part aims to provide some options to reduce the dimensionality of the dataset by removing the attributes that are most likely bad for the clustering process. This is important to achieve better results and faster execution time, avoiding the problems of clustering in high dimensionality. The first filter removes the features that are correlated above a user-defined threshold, since highly correlated features usually provide redundant information and can lead to overweight of some characteristics. The other two filters identify the attributes with constant values for all the data points or with few outliers differentiating from them. These types of features don\u2019t provide any valuable information and can worsen the performance of clustering. To identify quasi-constant features, we use two different parameters introduced in the function NearZeroVar() from the Caret package developed for R [2]: the ratio between the two most frequent values and the number of unique values relative to the number of samples.\n\n - clustering: This section is used to perform clustering on the chosen vector layer. First of all, the user needs to select the features to use in the process. It is possible to select the features both manually and automatically. The automatic feature selection is done using an entropy-based algorithm [3] presented in two versions with different computational complexities. The currently available algorithms for clustering are K-Means and Agglomerative Hierarchical, and the users can select the one that best suits their needs. Before performing clustering, the plugin offers the possibility to scale the datasets with standardization or normalization, and to plot two different graphs to facilitate the choice of the number of clusters.\n\n - evaluation: In this section we show all the experiments carried out in the current session, with a recap of the settings and performances of the experiments and the possibility to save and load them with text files. To evaluate the quality of the experiments we calculate two indexes and the comparisons among experiments on the same dataset. The indexes are the internal metrics Silhouette coefficient and Davies-Bouldin index. To directly compare the clusters formed by two or more experiments we compute the score [4], which evaluates how many couples of data points are grouped together in all of the experiments or in none of them. Every experiment completed in the current session can be stored in a text file, and the experiments saved in previous sessions can be loaded in the plugin and are shown in the evaluation section along with the other ones.\n\nOne of the major challenges during development has been allowing most of the functionalities on large datasets as well, both from the point of view of the number of samples and the number of dimensions. To achieve this, we also implemented algorithm options with good time complexities, as in the case of entropy with sampling and K-Means. Moreover, for all the data storage and manipulation done in the system, we use the data structures and functions provided by the libraries pandas and NumPy to guarantee high performance.\n\nAnother important objective of the research is the accessibility and ease of use of the plugin since the general user of GIS is often lacking a machine learning and computer science background. To guarantee this, the User Interface is simple and self-explanatory, and each section contains a brief guide to explain all the functionalities. Furthermore, some algorithm parameters that cannot be modified via the interface are stored in an external configuration file, and can be modified via this. This is done to avoid confusing the less experienced users.\n\nAlong with the implementation, the research is integrated with a considerable experimental phase, both during and after the development phase. This phase is essential to highlight both the potential of the plugin and its limitations in real-world scenarios. The great volume of experiments is conducted on data about the city of Milan, describing social-demographics, urban and climatic characteristics and with different granularities (ranging from less than 100 data points to almost 70000, and with a large number of numerical attributes, up to 109). Overall, the experimental phase shows good and adequate flexibility of the plugin, and outlines the possibilities for future developments that can be provided also by the QGIS community, given the open-source nature of the project.\n\nThe stable version of the plugin is available on the QGIS Python Plugins Repository (https://plugins.qgis.org/plugins/Cluster-Analysis-plugin-main/) while the development version as well as documentation are available on GitHub (https://github.com/folini96/Cluster-Analysis-plugin).\\n\\nAndrea Folini\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/EHNYXK/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Modulo_3A/7 Andrea Folini  Jesus Rodrigo Cedeno Jimenez.mp4", "persons": "Andrea Folini, Jesus Rodrigo Cedeno Jimenez", "pretalx_id": "XDD9JK", "title": "FOSS4G 2022 | Collaborative validation of user-contributed data using a geospatial blockchain approach: the SIMILE case study", "description": "Decentralized applications are a fundamental element for internet development, not only because they are safer but also because they make data accessible to more people than centralized applications. One of the most important architectures of decentralized applications is blockchain, a computing infrastructure capable of sharing data obeying consensus and in an immutable way. The most popular blockchain applications belong to the financial sector, and developments are still missing in other areas that can take advantage of\nthis technology. An area that can benefit from blockchain characteristics is citizen science, which, as its name specifies, is the research activity performed by a community of citizens. Due to the requirements to this extent, this work studies the feasibility to use a blockchain architecture in citizen science, specifically for ecosystem monitoring. Additional to this, this work helped to understand the advantages and disadvantages of using this technology in this area.\n\nCurrent state-of-the-art applications that propose partially a solution to citizen science are FOAM and CryptoSpatial Coordinates. FOAM [1] is a geospatial web application that builds a consensus-driven globe map using the blockchain Ethereum protocol. To achieve network verification, it employs a cryptographic software utility token, where cartographers verify if points added to the network are false or correct. This removes the need for a central authority to regulate and verify the points. The voting mechanism uses FOAM tokens to avoid spamming from the participants. The system works by mapping a blockchain address to a physical location, which can be registered with a spatial resolution of 1m by 1m. CryptoSpatial Coordinates (CSC) [2] is an Ethereum smart-contract library that can be used for developing geospatially enabled decentralized apps. It uses Blockchain technology to store, retrieve, and process vector geographic data.\n\nIn our approach, we were only \u201cinspired\u201d by the previous solutions, but we decided to develop something new and original. The system is developed in Solidity programming language. This allows usage on every blockchain that supports the Ethereum Virtual Machine and guarantees extended flexibility. Moreover, this choice is justified by the expanded ecosystem that Ethereum offers. The architecture of Smart Contracts is completely open-source and developed with a focus on the reusability of the components for other applications in the same field. The two main parts of the architecture are the Cell Smart Contracts and the Registry Smart Contracts. This is based on the mapping of a Discrete Global Grid System (DGGS) [3] with Smart Contracts. As a DGGS we choose S2 [4], which is an open-source library developed by Google that offers good processing functionalities and a grid with a fine-grained resolution. Each Smart Contract representing a Cell is used to keep track of the hash of the observations collected in the application. The hashes are used to locate and retrieve the stored files in the decentralized storage InterPlanetary File System (IPFS). This structure also allows to store metadata about the observations, for example, their quality decided through a peer voting mechanism or with some other system. The Registry Contracts are linked to a resolution of the DGGS and have the duty to keep track of the mapping between the DGGS cells of that resolution and their respective Smart Contract.\n\nThe prototype platform is developed in Velas, a blockchain architecture with a strong focus on fast transaction speed and low costs of fees compared to other blockchains (e.g. Ethereum, Cardano, Solana). The use-case for this work was the Informative System for the Integrated Monitoring of Insubric Lakes and their Ecosystems (SIMILE)  project. SIMILE  is a cross-border Italian-Swiss project with the aim to improve the collaboration between public administrations and stakeholders for the management of the Insubric lakes (Lugano, Como and Maggiore) and their ecosystems, as well as monitoring water resources quality [5]. One of the main sources of data in SIMILE is collected with a Citizen Science approach, meaning that the data is collected from normal citizens through their smartphones. The observations of this type include data about water quality, climatic parameters, and multimedia files such as images can be included. The collected data can be currently validated by the public authorities managing the platform but this requires time which is not always available to technicians. In our system, the observations are instead validated through a mixed rating system that allows both users and admins to evaluate each entry. Furthermore, the use of the proposed blockchain architecture allows access to the collected data without relying on the currently existing Web Application.\n\nThe practical importance of this work is to fill the gaps currently present in citizen science applications, by proposing an innovative system that works with the blockchain infrastructure. The result of this work and the technological development performed, demonstrate that citizen science applications can be, as a matter of fact, developed as a decentralized infrastructure. The main advantages with respect to other systems are data immutability, security and no single point of failure. Future work can include the implementation of a system to further incentivize the collection of data. This will work with a reward system in the form of a Utility Token. This token could be accepted by the public administrations benefitting from the data, in exchange for some form of compensation such as discounts on public services.\\n\\nAndrea Folini\\nJesus Rodrigo Cedeno Jimenez\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/XDD9JK/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Modulo_3A/8 Nicolas Roelandt.mp4", "persons": "Nicolas Roelandt", "pretalx_id": "ELBYL7", "title": "FOSS4G 2022 | Crowdsourced acoustic open data analysis with FOSS4G tools", "description": "## Introduction\n\nNoiseCapture is an Android application developed by the Gustave Eiffel University\nand the CNRS as part of a participatory approach to environmental noise mapping.\nThe application is open-source and all its data are free.\n\nThe study presented here is a first analysis of the first three years of data\ncollection, through the prism of noise sources. The analysis only focused on the\nlabels filled in by the users and not on the sound spectrum of the measurement,\nwhich will be studied later.\n\nThe aim was to determine whether known dynamics in environmental acoustics could\nbe recovered using collaborative data.\n\nThis preparatory work having to be consolidated and extended thereafter, and with\nthe will to include this study within the framework of the Open Science, an\nattention was brought on the reproducibility aspect of the analysis.\nThis one was entirely realized with free software and literate programming techniques.\n\nThe context of the study, the tools and techniques used and the first results\nobtained will be presented as well as the benefits of using literate programming\nin this type of preparatory work.\n\n## Data\n\nAn article presenting this dataset was published in 2021 (Picaut et al. 2021).\nIt details the structure of the database and the data, the profile of the\ncontributors and the contributions but does not analyze the content of the data.\nThis is what this article proposes to begin.\n\nThe data used in this study correspond to contributions made between August 29, 2017\nand August 28, 2020. During this period, nearly 70,000 unique contributors allowed\nthe collection of more than 260,000 tracks for a total of about 60 million seconds\nof measurement. A trace is a collected recording, it contains the sound spectrum\n(1 second, third octave) recorded by the phone coupled with its GPS positioning\n(1 second). This information can be enriched by the contributor with labels.\nThere are 18 labels and the user can select one or more of them for each of the\ntraces made. They are detailed in (Picaut et al. 2021).\nThe preliminary work presented here focuses on the analysis of the proportion of\ncertain labels in the global sample at certain temporalities.\n\nIn addition to data from the collaborative collection, some additional data were\nused to limit the study area. We chose to limit the geographical scope of this\npreliminary study to metropolitan France because this area contains the largest\nnumber of recordings.\nThe climate and sound dynamics are known and documented there.\n\nTo facilitate the reproducibility of spatial filtering, it was decided to use\nopen data sets from recognized sources: the Natural Earth database\n(Patterson and Kelso 2021)  and the Admin Express database from the\nNational Institute of Geographic and Forest Information (Institut G\u00e9ographique National 2021).\n\n## The study\n\n### Tools\n\n#### PostGIS\n\nThe data are provided as a dump from a PostGreSQL/PostGIS database (Ramsey and Blasby 2001).\nSeveral scripts perform much of the attribute and spatial filtering.\nThese filterings are saved in a materialized view whose data will be analyzed\nwith the R language.\n\n#### R\n\nThe R language (R Core Team 2021)\nis a programming language for data processing and statistics with many libraries\ndedicated to geospatial data.\nRmarkdown allows to mix code and text in markdown for the dynamic production of\ngraphs, tables and documents.\nIt is one of the recommended means for literate programming.\n\n#### Git\n\nGit is a Distributed Version Control System (DVCS) (Chacon and Straub 2014).\nIt enables collaborative and decentralized work.\nThe choice of Git was natural as different collaborators are present on several\nsites (Nantes, Lyon, Paris) and Git is already used within the UMRAE laboratory.\n\n### Implementation\n\nThe data are provided in the form of a PostGreSQL/PostGIS dump.\nA server has been set up and the data loaded.\nA materialized view was created in order to provide a stable access to the data\ncorresponding to the defined criteria.\nThese criteria are both attributive (filtering of certain tags, minimum and maximum\ndurations, etc.) and spatial (located in France, reduced trace area, etc.).\nA Rmarkdown document establishes the connection with the view and then performs\nthe operations allowing to analyze the data.\n\nA document mixing narrative, figures and code allowed the resumption and\ncontinuation of the analyses shown here.\n\n## Results\n\nThe study concerns tracks bearing a tag, registered in metropolitan France.\nIt focuses on the proportion of a certain tag in relation to all the tags for a\ngiven period (time of day, season, etc.).\nIn the sample studied, it is possible to note a prevalence of the tags _roads_,\n_chatting_, _animals_ and _wind_. The tags _air_traffic_ and _works_ are also well represented.\n\nA first axis of analysis concerns the time distribution of the tags.\nAnimal noises (tag _animals_) are more frequent in the morning and especially\none hour before sunrise.\nThis is a common dynamic for bird song.\nWe also observed peaks in human activity, especially commuting.\n\nThe next temporal axis was the seasonality, especially those of animal noises,\nwith a more intense activity in European spring and summer.\nThis phenomenon could also be observed in the recordings.\nWe also noticed that music was less present in autumn than in other seasons and\nthat it is mostly present at late hours.\n\n## Conclusion\n\nThe first results are encouraging because road dynamics related to commuting or\nanimal activity can be observed.\nThe main question was to determine if these known dynamics in environmental acoustics\ncan be observed in a crowdsourced dataset.\nThe first elements seem to answer positively to this question.\n\nSome questions still need to be explored, notably those concerning the\nrepresentativeness of samples that are sometimes weak for certain time periods.\n\nThe systematic use of open source software, the provision of documented code files\nand a document mixing narrative, figures and code have allowed the resumption and\ncontinuation of the analyses shown here.\nThis work in progress will complete the final article.\\n\\nNicolas Roelandt\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/ELBYL7/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Modulo_3A/9 Angelica Pianegonda.mp4", "persons": "Angelica Pianegonda", "pretalx_id": "FLDTX8", "title": "FOSS4G 2022 | Multiobjective analysis of open areas invaded by forest with open source software: the case of the SATURN project", "description": "In northern Italian mountainous regions, forests are invading pastures and abandoned cultivated surfaces leading to an important land-use change phenomenon and reducing those open areas that are fundamental for ecological purposes [1].\nThe research here presented, focuses on a multiobjective and contemporary assessment methodology of two or more multicriteria analyses applied in the identification of the most suitable areas for agricultural purposes between those surfaces that have been invaded by forests carried out using Free and Open Source Software for Geospatial (FOSS4G) software. The analysis of the areas was determined by taking into account their intrinsic characteristics and their spatial location in relation to the territory and started from previous studies on land use in the Autonomous Province of Trento (Italy). The pilot areas are three municipalities that are part of Trento\u2019s Province: the municipality of Trento - the Province\u2019s capital, the municipality of Pergine Valsugana and seven municipalities that are part of the Piana Rotaliana region. Almost 88% of the Municipalities are located at an altitude of more than 600 m above sea level reflecting the peculiar topography of the province made up of valleys and high mountains with high percentages of steep slopes [2].  In Trento, the overall density is 742 inhabitants per square kilometers and the pressure on urban and peri-urban areas is nine times higher than the rest of the province [51]. 20% of Trento\u2019s territory is classified as agricultural and 50% as forest or pasture land. About 70% of the territory is covered by silvopastoral -agricultural areas, the remaining 30% is categorized as urban. The repartition of the province\u2019s surface is similar to the one of the city of Trento: 61% of the territory is covered by forests, 33.6% by agricultural areas, and only 5% by other types of land use. Collective bodies and public actors manage most of these silvopastoral -agro-forestal areas whose ownership is collective and is managed following the \u201cuso civico\u201d rights, a customary right embedded within the properties of communities and villages [52]. Therefore, profit is not their main aim.\nThis study has been part of the SATURN European project [3] funded by EIT Climate-KIC (November 2018-December 2021). Three city-regions have been involved: the Trentino region in Italy, Birmingham in the United Kingdom, and Gotheborg in Sweden. The project aimed to reintegrate natural resources into cities' climate change adaptation strategies and to expand and nurture its model by creating a broader initiative involving an increasing number of stakeholders. Geospatial data set was georeferenced and managed with GRASS and QGIS and the files were collected combining data freely available at the Autonomous Province of Trento as well as self produced during the project.\nThe comparative analysis and methodology were carried out by means of QGIS 3.8 Geographic Information System that has been used to complete the analysis in order to develop a methodology that can be widely used by territorial operators and Public Administrations.\nThrough a series of multi-criteria analyses [4] of the agricultural and ecological vocation of a given region, and more specifically of abandoned agricultural areas, it was possible to create initial maps assigning values according to specific considered aspects. To lead these analyses, it was necessary to collect and select a significant amount of georeferenced data and then standardise them. Synthesis analyses have been useful to compare the ecological and agricultural aspects and to integrate them in synthesis maps, which can be used in the future for land management and planning.\nIn order to validate the model and to verify the results, on-site inspections were carried out both in Valsugana and in Val d'Adige.\nTechnicians and experts have been involved in the research through focus groups, organised within the SATURN project, which allowed some general criticalities of the territory to emerge, and through the completion of a questionnaire proposed within the thesis work. Through these questionnaires, it has been possible to identify the most important criteria for assessing a plot of land from an ecological and agricultural point of view.\nThe obtained results showed how the classical approach, based on single criteria analysis, differ from the multicriteria approach for its potential to produce a more precise and clearer classification output of the aspects considered, showing the two multi-criteria analyses and their dependence on a single final map. Significant advantages have been taken from the use of this method in terms of data and information exchange between the stakeholders and in terms of a deepen understanding of the characteristics of the areas that have been analysed.\nThe proposed methodology and the script that has been developed can be used in order to better plan forest management and as a basis for future territorial plans.\nMoreover, the multicriteria approach, which initially provides for a separate analysis of the research layers and then integrates them into a single final output, may represent a starting point for ecosystem evaluations. Preserving the ecosystem of an area, or rather the mosaic of ecosystems that make it up, is in fact of fundamental importance, as is succeeding in creating an eco-sustainable environment. In order to achieve this, it is necessary to have a spatial planning process that is as accurate as possible and that evaluates all the ecological criteria in a diversified manner with respect to the criteria of the object of research, so as to be able to identify key elements.\nThe model presented can be replicated by changing the current research object, i.e. agricultural assessment, and keeping the ecological assessment instead.\nFuture development will foresee the transformation of the Python script into a plug-in for Qgis, guaranteeing greater functionality for those who wish to use it.\\n\\nAngelica Pianegonda\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/FLDTX8/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/1 Paolo Dabove.mp4", "persons": "Paolo Dabove", "pretalx_id": "WMUGYQ", "title": "FOSS4G 2022 | The use of open source software for monitoring bee diversity in natural systems: the BEEMS project", "description": "This work wants to highlight the results obtained during the BEEMS (Monitoring Bee Diversity in Natural System) project, which the main goal was to answer the following question: Which biotic and abiotic indicators of floral and nesting resources best reflect the diversity of bee species and community composition in the Israeli natural environment? To this end, the research was oriented towards the cost-effectiveness analysis of new aerial geomatics techniques and classical ground-based methods for collecting the indicators described above, based only on open-source software for data analysis.\nThe study involved the Israeli and Italian teams, focusing the attention on two complementary study systems in central Israel, the Alexander Stream National Park, an area undergoing an ecological restoration project in a sandy ecosystem, and the Judean foothills area, to the South of Tel Aviv. In each study system, different surveys of bees, flowers, nesting substrates and soil, using classical field measurement methods have been conducted. Simultaneously, an integrated aerophotogrammetric survey, acquiring different spectral responses of the land surface by means of Uncrewed Aerial Vehicle (UAV) imaging systems have been performed. The multispectral sensors have provided surface spectral response out of the visible spectrum, while the photogrammetric reconstruction has provided three-dimensional information. Thanks to Artificial Intelligence (AI) algorithms and the richness of the data acquired, a methodology for Land Cover Classification has been developed. The results obtained by ground surveys and advanced geomatics tools have been compared and overlapped. The results are promising and show a good fit between the two approaches, and high performance of the geomatics tools in providing valuable ecological data.\nThe acquisition of the indicators identified in the planning phase took place through several measurement campaigns conducted in the period between February 2020 and April 2020 located in two areas of interest in the Israeli territory. A total of 934 and 543 wild bees were collected in the two systems under study, respectively. From a geomatics point of view, 8 flights were carried out in the Alexander Stream National Park on 24 February 2020, acquiring approximately 65 GB of 8-bit multi-band images in tiff format. In the Judean foothills area, 11 flights were carried out on 26 February 2020, obtaining approximately 77 GB of tiff images. In addition, in order to obtain a correctly geo-referenced 3D model, a total of 54 Ground Control Points (GCPs) were acquired, of which 27 in Alexander Stream National Park and 27 in the Judean foothills, with a multi-frequency, multi-constellation GNSS geodetic receiver in RTK mode.\nOn the basis of the technical requirements necessary to carry out this project, very high-resolution digital maps (orthophotos, digital terrain models - DTM) were produced through the application and optimisation of photogrammetric and structure from motion (SfM) processes performed on data from different imaging sensors (RGB, multispectral), considering only open-source software. Therefore, considering all the previously defined aspects, in order to plan the data acquisition, the research group defined the flight parameters and instruments, both in terms of aircraft and sensors to be installed onboard, necessary to achieve the project objectives. All the digital cartography generated has been defined in the Israeli reference system, i.e. in WGS84 with UTM 36N cartographic projection. The results are shown in Tables 2 and 3 for the Alexander Stream National Park and the Judean foothills, respectively.\nThe production of very high scale digital cartography allowed the extraction of the necessary data for training the proposed Artificial Intelligence model. These data were applied to two different approaches for automatic land cover classification. The first approach was based on unsupervised classification at the pixel level, while the second approach is based on object classification, i.e. vector polygons describing the boundaries of a real object. The algorithms operate differently on these two types of data, in fact in the pixel-based approach they are applied at the level of the single pixel, while in the object-oriented approach they are applied to groups of homogenous pixels for a given feature. The implementation of all the training and validation phases of the proposed models was based on Python programming language using open libraries for data management (shapely, raster) and learning (sk-learn). The segmentation of the input data is fundamental in the approach in order to define the objects to be classified, therefore the Orpheo Toolbox library was applied. The object-oriented approach was applied for the Alexander Stream National Park site while the pixel-based approach was applied on the Judean Foothills area.\nFor pixel-based classification, a clusterization algorithm, KMeans, was used in an unsupervised manner. The KMeans algorithm clusters the data by attempting to separate the samples into n groups of equal variances, minimising a criterion known as within-cluster sum-of-squares. The algorithm was optimised through a trial-and-error procedure that led to the identification of initialisation parameters. For the object-oriented classification, we proceeded to apply automatic segmentation algorithms based on the analysis of multi-band spectral variability. In particular, the algorithm used is the Large-Scale Mean-Shift segmentation algorithm, which produces a clustered image in which the pixels around a target pixel that present similar behaviour from both the spatial and spectral points of view are grouped together. Then, the procedure vectorizes these clusters and the operator associates a label to each of them for the generation of the dataset. After subdividing the data into training and testing elements, the Random Forest algorithm was used for both approaches and proved to be the most effective in performing the assigned task. The classification results were carried out using different validation metrics such as Precision, Recall, F1 score, etc. that will be presented.\\n\\nPaolo Dabove\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/WMUGYQ/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/2 Bianca Federici.mp4", "persons": "Bianca Federici, Stefania Magr\u00ec", "pretalx_id": "BALEWA", "title": "FOSS4G 2022 | Sea water turbidity analysis from Sentinel-2 images: atmospheric correction and bands correlation", "description": "Sea water turbidity is a measure of the amount of light scattered by particles in water. It is due to the presence of suspended particles, which it is operationally defined as the fraction in water with less than 2 \u00b5m in diameter. Plankton can also generate turbidity, but high turbidity events are dominated by high concentrations of inanimate inorganic particles. High levels of suspended sediments in coastal regions can occur as consequence of high sediment load from rivers, from bottom sediment resuspension due to wave actions or due to anthropogenic activities, such as dredging operations or bottom resuspension from ship propellants. The increase of turbidity can determine negative environmental effects both on the biotic and abiotic marine ecosystem. In highly anthropized coastal marine systems, like harbours, sediments represent a sink for contaminants and resuspension can contribute to propagate pollution to unpolluted areas (Lisi et al., 2019).\n\nMany marine water quality monitoring programmes measure turbidity. Traditional methods (e.g., in situ monitoring) offer high accuracy but provide sparse information in space and time. Earth Observation (EO) techniques, on the other hand, have a potential to provide a comprehensive, fast and inexpensive monitoring system to observe the biophysical and biochemical conditions of water bodies (Caballero et al., 2018; Saberioon et al., 2020; Sagan et al., 2020). Hence, some of the authors are developing a semi-empirical model for predicting water turbidity by combining Sentinel-2A data and machine learning methods using samples collected along the North Tyrrhenian Sea (Italy). Field data collected at the study site from April 2015 to December 2020 were made available by ARPAL, even though most of these data refer to low turbidity events.\n\nIn the framework of this research activity, Sentinel-2A multispectral optical images, freely available within the EU Copernicus programme, are elaborated. It\u2019s well known that such products are provided at Level-1C (L1C) Top of Atmosphere (TOA) and at Level-2A (L2A) Bottom-Of-Atmosphere (BOA). L2A BOA reflectance products are preferred as they are already corrected for effects of the atmosphere. However, the official L2A data are available for wider Europe from March 2018 onwards.\n\nThe necessity to use the complete on-site dataset to calibrate the predicting model, and not only data after March 2018, required the identification of the most appropriate algorithm for atmospheric correction of L1C images relative to study area between 2015 and 2018.\n\nHence, a comparison between the available L2A BOA product ant the corresponding L1C image corrected in different open source environment was performed. In particular, the free and open source QGIS and GRASS GIS, and the Sentinel Application Platform (SNAP), provided by ESA/ESRIN free of charge to the Earth Observation Community, published under the GPL license and with its sources code available on GitHub, were used.\n\nBoth image-based method, i.e. the Dark Object Subtraction (DOS) method in QGIS, and physically-based methods, i.e. the Second Simulation of Satellite Signal in the Solar Spectrum (6S) method in i.atcorr module of GRASS GIS and the Sen2Cor algorithm inside SNAP, were applied (Lantzanakis et al., 2017). The great advantage of the DOS method is that it focuses only on the spectral and radiometric characteristics of the processed image, hence it doesn\u2019t require remote or in-situ atmospheric measurements. But the performed correction doesn\u2019t seem so accurate. Instead, the physically-based approach requires atmospheric measurements and parameters, that are difficult to be identified so to be coherent in space and time with the processed image.\n\nThe most complex physical parameter to set is Aerosol Optical Depth (AOD), which is a dimensionless parameter related to the amount of aerosol in the vertical column of the atmosphere over the target station. It usually range from 0 to 1, with values less than 0,1 that corresponds to a clean atmosphere with high visibility, and values higher than 0,4 that corresponds to hazy atmosphere with very less visibility. AOD is spatially and temporally very variable. It can be estimated from AERONET (AErosol RObotic NETwork), a federation of ground-based remote sensing aerosol networks with more than 25 years of data. A station which measured the Aerosol Optical Depth at 500 nm at Level 2 (quality-assured) at the same time as the scene was taken, is not always available nearby the site under study. Hence the evaluation of AOD variability in time and space was analysed for the area and the events of interest, so to identify the proper values. Expecially i.atcorr seems very sensitive to the set values of AOD.\n\nOnce the proper method for atmospheric correction was identify, it was applied to the L1C images relative to the collected field data from April 2015 to March 2018. Then, the correlation between the in-site dataset and the individual bands known to be most sensitive to water turbidity, i.e. blue (B2), green (B3), red (B4) and near infrared (B8 and B8A) bands, was analysed, finding good results for the visible bands, and a weak correlation with NIR bands. In addition, indexes defined by the ratio between the three visible bands were checked to see which combination could best highlight the turbidity of the water from the Sentinel-2 images. Preliminary results seem to confirm that the identified EO technique could provide a fast and inexpensive monitoring system to observe sea water turbidity along the Northern Tyrrhenian Sea (Italy).\\n\\nBianca Federici\\nStefania Magr\u00ec\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/BALEWA/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/3  Sahil Singh Kapoor.mp4", "persons": "Sahil Singh Kapoor", "pretalx_id": "3MCN3C", "title": "FOSS4G 2022 | Examination of Metro Stations Equal Accessibility for All using Open Data Kit (ODK) Applications: A Case Study of Noida City in India", "description": "Nowadays, the need is felt to create a sustainable and inclusive urban environment accessible to all, which requires a people-centered urban planning approach. Along with alleviating environmental problems and minimizing traffic congestion, the public transit system serves as a means of providing equal access (Rossetti, et al., 2020). This paper attempts to re-evaluate the isochrones prepared to access public transport stops particularly transit nodes across Noida city using a GIS-based approach and Open Data Kit (ODK) approach. The isochrones predict the time to reach any area from a transport node like a transit station based on the shortest path model, however, not all roads and streets offer equal access to all (Lei & Church, 2010). In this study, macro-built-environment attributes responsible to increase pedestrian distance length and time to reach metro stations were identified using a GIS-based approach by integrating land-use and transportation data. However, the micro-built environment attributes like pedestrian behaviour, preference of travel modes, and purpose and frequency of transit trips made by the transit users were gathered by conducting metro station user surveys using the ODK app linked with its ODK aggregate server. The ongoing transport and urban planning methods hardly give any importance to the understanding origin and destination to reach important places with more ease and mobility (Bhatt & Minal, 2022). Urban researchers have not investigated any studies to evaluate equal accessibility to effectively and smoothly use public transit services by easily accessing transit stations (Yang, et al., 2019). The objective of this study is to map the pedestrian permeability and impermeability by categorizing roads and streets around identified transit nodes as public, private, and non-accessible by all. The prime function of accessibility is to link people with activities through linkages (Lei & Church, 2010). In this study, the travel modes particularly considered were on foot, non-motorized (cycle and rickshaw), shared e-rickshaw, bus service, and dropped off by two-wheeler and four-wheeler. A stratified random sampling technique was adopted to calculate the sample size of 12 existing elevated metro stations in Noida on the Blue transit line of DMRC. A self-administered questionnaire was used to conduct metro station surveys using ODK mobile app at identified 12 metro stations in Noida starting from Noida Sector 15 until the last Noida Electronic city (NEC) station. A sample size of 1% of the average transit ridership data, collected from DMRC for each station was taken to achieve a 95% confidence level. However, some stations like the Golf course and stations following Noida city center operational since the year 2019 have low ridership below 5000 persons per day. For these stations, 2% sample size of the average ridership data was considered to achieve a similar confidence level. Following this step, the existing land use encircling individual metro stations within a radius of 800 meters was demarcated from Noida Master Plan (NMP) 2031. Based on static master plan land-use distribution, the stations were categorized as residential, non-residential, mixed-use and transport hubs. The questionnaire contained 31 items which included various aspects including the usual purpose of metro trips made, employment status, availability of the driving license, household size, current city living in, number of cars available in the household, car availability during the transit trip made, building topology of the transit user, and number of floors. Most importantly, the preferred travel mode to reach the nearest metro station, frequency of trips made in a week, metro travel pattern changed in past six months, particularly due to COVID-19 restrictions, and the reason to opt for transit services. Other allied questions were distance and time to reach the metro station using different travel modes. The survey results were downloaded for the ODK aggregate server and converted to an excel sheet from CSV file format for its data analysis. In QGIS, a buffer distance of 800 meters in both directions was marked along the blue line transit corridor with its 12 metro stations in Noida. Initially, typically common walkable pedestrian routes terminating at individual metro stations were identified with their trip origin location in the nearby sector. Based on the farthest location found in all the directions encircling the metro station, walkable sheds were developed for all the 12 metro stations in Noida. However, as the stations are quite close in between 1 to 2 kilometers, the walkable sheds overlap for some consecutive metro stations. Thereafter, using Garmin Etrex 10, all the common routes, most commonly followed by e-rickshaws as an alternative to walking were traced. The photographs of the barriers found that typically increase the walking distance and time to reach the metro stations were clicked. Thereafter, using My Maps an app by Google, the Garmin tracked routes were fed along with photos imported through the Google Photos app. In the case of Noida, there exist both planned and unplanned barriers to equal accessibility for all. While, the gated communities, large super-blocks, and many Government housing societies are planned barriers that impede accessibility for all within TOD station areas. The presence of urban villages with organic street layouts and narrow incomplete streets are hardly accessible and force potential transit riders to shift away from walking or rely on e-rickshaws as short to medium-distance travel modes. Finally, the study proposes a TOD index based on the Space syntax model and distance measurement to categorize roads within the TOD area as public roads, private roads - accessible by only a few residents, non-suitable streets - not fit for use.\\n\\nSahil Singh Kapoor\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/3MCN3C/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/4 Poliyapram Vinajray.mp4", "persons": "Vinayaraj", "pretalx_id": "3SYURF", "title": "FOSS4G 2022 | Multi-branch Deep learning Based Transport Mode Detection using Weakly Supervised Labels", "description": "Mobility data, based on global positioning system (GPS) tracking, have been widely used in many areas.\u00a0 These include analyzing travel patterns, investigating transport safety and efficiency, and evaluating travel impacts. Transport Mode Detection (TMD) is an essential factor in understanding mobility within the transport system.\u00a0 A TMD model assigns a GPS point or a GPS trajectory to a particular transport mode based on the user's activity and medium of travel [1].\u00a0 However, the complexity of the prediction procedure increases with the number of modes that need to be predicted. For example, it is comparatively easy to predict whether a user is 'static' or 'slow moving' or 'fast moving' but it's hard to predict detailed transport modes such as walk, bike, car, bus, train, boat, etc.\u00a0 Therefore, this study proposes a multi-branch deep learning-based TMD model which can predict multi-class transport modes.\u00a0\n\nTwo major challenges need to be addressed in order to generate a state-of-the-art deep learning model.\n\nThe first is to prepare ground-truth data. There are insufficient open-sourced ground-truth data available for transport modes in Japan. Hence, we proposed a transport mode label generation approach using snorkel [2]. Snorkel is a weakly supervised labeling function, a first-of-its-kind system that enables users to train state-of-the-art models without hand labeling any training data. Instead, experts write labeling functions that express arbitrary heuristics based on the logic that can be drawn from understanding the data and the physical actions they represent. In this study, we used snorkel for generating the ground truth data for transport mode. Initially, we considered publicly available road networks, railway networks, bus routes, etc., for creating road, bus, train labels by overlaying GPS points on these transportation networks. However, there are multiple occasions where the road, bus, and train classes overlap each other, especially in a city region. Hence, we introduced a boolean (True/False) based soft-labeling function, where the same GPS point might have multiple True values for road or railway.\u00a0\n\nSecond, we derived mobility-related features from the raw GPS data. Raw GPS raw data is typically composed of latitude, longitude, and timestamps. The raw GPS data were used to generate point-level features such as speed, speed difference, acceleration, acceleration difference, initial bearing, and bearing difference. Apart from that, we also generated trajectory level features such as average speed and average acceleration.\u00a0\u00a0\n\nTransportation network-based soft-labeling and other mobility features are used to define labeling functions in the snorkel. These label functions are used to create true ground truths using a generative machine learning model with a portion of the GPS data. The generated labels (walk, cycle, bus, car, train, boat/ship) were then used to train the proposed deep learning model.\u00a0 To construct the model we opted to use two branches where raw GPS latitude and longitude values were used in one and the derived mobility features are used in the other. We used 3 fully-connected hidden layers for raw GPS data (lat/lon) and 4 fully connected hidden layers for mobility features.\u00a0 Features derived from the two branches are concatenated. Further, 3 fully connected hidden layers and softmax cross-entropy were used as a loss function. The proposed deep learning model has 108,614 trainable parameters and Adam is used as an optimizer. This particular two-branch model structure achieves better accuracy as it combines raw data as well as the derived mobility features in the network.\u00a0 An example of the benefit from this approach benefit can be the network's ability to relate GPS coordinates with road driving classes, thus inherently inferring that location as on a road.\u00a0 Note, many of these inferences that improve classification accuracy are possible via dramatically more advanced pre-processing to build out additional features.\u00a0 However, that approach is more time-consuming and could never catch all the potential inferences that an unbiased set of deep learning layers can inherently extract.\n\n\nWe evaluated the trained model's effectiveness in two ways.\u00a0 We compared the results against the popular XGBoost classifier, with our model producing over 5% higher accuracy for the benchmark Geolife dataset [3].\u00a0 Moreover, we collected smartphone-based GPS trajectories for multiple modes of transportation collected by testers in Bengaluru, India, and Tokyo, Japan.\u00a0 With this new absolute ground truth data, we compared the resulting predicted classes between operating system-provided activity classifications, the above XGBoost model, and our own.\u00a0 Our experiments show promising results with improved accuracy and increases in number of labeled data points.\u00a0 Of key note is that the iOS [4] and android [5]in-built activity recognition tools provide the 'automotive' class as a single class, while our proposed model efficiently distinguishes automotive classes as car, bus, and train with improved accuracy. This work completely depends upon Free and Open Source Solutions (FOSS) for data preparation, mobility feature generation, deep learning model training, and big data computing. That includes various geospatial libraries such as geopandas, shapely, rtree, weakly label generation platform snorkel, deep learning platform tensorflow,\u00a0 keras, big-data computing platforms such as pyspark, hadoop, hive, etc.\\n\\nVinayaraj\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/3SYURF/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/5  Kevin Davies.mp4", "persons": "Kevin Davies", "pretalx_id": "3PT37K", "title": "FOSS4G 2022 | An Open-Source Mobile Geospatial Platform for Agricultural Landscape Mapping: A Case Study Of Wall-to-Wall Farm Systems Mapping in Tonga", "description": "AN OPEN-SOURCE MOBILE GEOSPATIAL PLATFORM FOR AGRICULTURAL LANDSCAPE MAPPING: A CASE STUDY OF WALL-TO-WALL FARM SYSTEMS MAPPING IN TONGA\n\nPacific Island Countries (PICs) such as Tonga rely on landscape services to support communities and livelihoods in particular smallholder and commercial agriculture. However, PICs are increasingly vulnerable to climatic and environmental shocks and stressors such as increasing cyclone occurrence and landscape conversion. Spatially explicit, timely, and accurate datasets on agricultural and other land use at the community scale are an important source of information for land use policy development, landscape management, disaster response and recovery, and climate-smart sustainable development. However, such datasets are not available or readily accessible to stakeholders engaged in landscape management in PICs. Household surveys, participatory GIS (PGIS), and remote sensing are approaches that have previously been used to capture community-scale landscape uses in PICs; however, these approaches are challenged by data collection and management burdens, mismatched scales, timely integration of databases and data streams, aligning system requirements with local needs, and various socio-technical issues associated with developing and deploying applications in new domains. Such data collection approaches only provide single time-steps representations of landscape uses and fail to capture the highly dynamic and spatially diverse nature of PIC landscapes.\n\nWe have addressed these challenges by developing, integrating, and deploying a tool for agricultural landscape monitoring at a local scale. This tool is composed of a stack of open-source geospatial applications and was developed through a collaboration between Tonga\u2019s Ministry of Agriculture, Food, and Forests (MAFF) and researchers from Australian and South Pacific universities. We used a formal, iterative ICT for Development (ICT4D) framework to engage and co-develop the tool with MAFF and other landscape stakeholders including community leaders. The ICT4D framework is based on agile methods and is made up of five components: context analysis; needs assessment; use-case and requirements analysis; sustainability assessment; and development, testing and deploying. The five components provide a framework to ensure that project stakeholders (landscape managers, developers, and end-users) consider the range of technical and non-technical factors that will determine successful implementation of an ICT system in a new domain. Here, the goal was to transition from infrequent paper-based and non-spatial surveying of farms to develop a spatial data infrastructure that supports coordinated large-team farm mapping, data syncing and storage, and geospatial data analysis and reporting that aligns with MAFFs needs, and guides landscape management actions.\n\nHere, we describe our team\u2019s experience in applying the iterative ICT4D framework. We present the development activities associated with successive phases of the project and reflect on the advantages (and constraints) this framework offers for developing open-source geospatial applications for deployment in new domains with a low-resource context. Initially, we introduce the qualitative fact finding, context analysis, and needs assessment to ascertain and distil MAFF\u2019s needs for geospatial data and applications. Then, we present several stages of application design, development, testing, and refinement in various MAFF data collection and reporting campaigns, which enabled analysis and the detailed specification of the requirements for the agricultural landscape monitoring tool. This includes work on developing initial prototype applications, implementing small-scale vanilla and land utilisation surveys, and finally an island-wide wall-to-wall crop survey with a large team of field data collectors.\n\nFinally, we present the system architecture and a case study of the final iteration of the tool deployed for Tonga\u2019s country-wide wall-to-wall farm system survey completed by MAFF in 2021. The final iteration of the tool was composed of a stack of open-source geospatial tools including QField for mobile mapping and data collection, QFieldCloud for user authentication and data syncing, and newly developed, open-source geospatial data visualisation, analysis, and reporting applications. This case study discusses: (1) how a team of over 40 data collectors were able to work collaboratively to build up a database comprising records from over 11,000 farms using QField and QFieldCloud; and (2) how custom applications developed in this project enable visualisation of this data on web maps and automated reporting to inform policy development and landscape decision making by MAFF.  We also illustrate the critical role the tool and the crop survey information collected in 2021 played in assisting MAFF\u2019s recovery efforts in the aftermath of the Hunga Tonga\u2013Hunga Ha'apai submarine volcano explosion and subsequent tsunami which impacted heavily on Tonga\u2019s main island of Tongatapu in January 2022. We also discuss the potential challenges in delivering the tool to other low-resource jurisdictions in the South Pacific including issues related to data dissemination, privacy and security; user management; technical and financial sustainability; scalability; training and knowledge transfer; and creating and fostering a community of open-source developers and users in PICs.  The success of our case study demonstrates the importance of stakeholder engagement in an iterative ICT 4D development framework, and the great potential that open-source geospatial tools such as QGIS, QField, and QFieldSync can play in agricultural landscape management and disaster response in PICs.\\n\\nKevin Davies\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/3PT37K/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/7 Han Sang Hyuck.mp4", "persons": "HAN SANG HYUCK", "pretalx_id": "9CN7WY", "title": "FOSS4G 2022 | Development of Multi-dimensional Array Database Based Massive Satellite Information Processing and Analysis System: KIWI-Sat", "description": "Information and communication technology (ICT) is mainly applied to finance, telecommunications, and public sectors. However, since the early 2010s, there have been efforts to apply ICT to various fields such as aerospace, life science, energy, and automobiles. Recently, artificial intelligence and big data technologies have also been applied in the aerospace field, among others. In the field of aerospace, earth observation attracts the most interest.\n\nRecently, the number of satellites for earth observation is increasing every year. As small satellites can be manufactured at low cost, the number of small satellite constellation for temporal and spatial resolution is increasing. urban change detection, disaster monitoring, and traffic analysis are typical applications. These applications will be increasing more.\n\nWhen performing earth observation using satellite images, it must process a large amount of satellite information in real time and analyze satellite images with artificial intelligence. These studies are being conducted in a variety of ways, and especially, the area of interest in this study is processing technology for storing and retrieving massive satellite images.\n\nAs a technology for handling massive satellite information, a multi-dimensional array database plays an important role. Representative examples based on open source software are Rasdaman and SciDB.\n\nIn 2018, we started developing KIWI-Sat, a system for processing and analyzing massive satellite information for especially supporting Korean satellite images such as KOMPSAT-2, KOMPSAT-3, KOMPSAT-5 etc.\n\nKIWI-Sat supports GeoTiff, HDF 5, and JP2 which are main data types of representative satellite images. It is mainly being developed to support Korean satellite images KOMPSAT-2, KOMPSAT-3, KOMPSAT-3A, KOMPSAT-5, GOCI, etc. also, overseas satellite images such as Sentinel 1A, Sentinel 1B, Sentinel 2B, SPOT, and PlanetScope also be supported. Because KIWI-Sat supports main data type\u2019s satellite images, Other satellite images can be easily supported.\n\nKIWI-Sat is being developed using a number of open source software such as Rasdaman, Pytorch, Django, Mapbox etc. First, it uses Rasdaman to process massive Raster-based satellite information, Pytorch to process AI inference module, and Django and Mapbox for visualizing Satellite images and overlay etc. KIWI-Sat is mainly composed of five subsystems: 1) 'K-SDA(KIWI-Sat Data Access)', which processes satellite information based on Rasdaman, an array database, 2) 'K-SAA(KIWI-Sat AI Analysis)', which is in charge of AI-based satellite image analysis, 3) 'K-SVI(KIWI-Sat Visualization)' that visualizes satellite image based on map, 4) 'K-SUT(KIWI-Sat Utility)' that provides utility functions such as system resource monitoring and upload/download of original satellite image, 5) OpenAPI for satellite information access There is a 'K-SOA(KIWI-Sat OpenApi)' in charge.\n\nIn this paper, KIWI-Sat will be mainly explained focusing on 'K-SDA', which processes massive satellite images, and 'K-SAA', which analyzes satellite images with artificial intelligence.\n\nFirst, K-SDA was developed using Rasdaman. In the early of development K-SDA, SciDB was used as database system, but as SciDB finished its open source policy. We adopted Rasdaman, a representative open source, as alternative database for processing satellite images. For this, function and performance comparison was performed, and Rasdaman has a good performance in the uploading original satellite to storing in Database. The search performance for the selected area was excellent in SciDB. Considering the real-time performance of recent satellite image analysis, it was confirmed that Rasdaman has an advantage. In processing satellite images, the multidimensional array database can handle storage and retrieval of array units with theSQL standard, and has many advantages as it supports massive raster data.\n\nSecond, it is 'K-SAA' that is linked to the satellite image-based AI module. KIWI-Sat has a structure that can be easily linked with the inference code and parameters of the previously developed artificial intelligence module. It works with the 'K-SVI' stage by receiving the satellite image obtained from 'K-SDA' and transmitting the obtained result to the DJango web framework by executing the inference code.\n\nWe installed a demo system at KARI to test and improve Kiwi-sat. KIWI-Sat was installed in Ubunt 20.04 LTS, and it stores KOMPSAT-2, KOMPSAT-3, KOMPSAT-3A, KOMPSAT-5, Planetscope satellite images to search for ROI for optical images and SAR images, AI interlocking, etc. Several tests are being carried out.\n\nIn this paper, we demonstrate the result of interworking of the KIWI-Sat and two AI technologies. First, for the KOMPSAT-3 satellite image, which is an optical image, the object detection result was compared to the object detection result to which the satellite image super-resolution technology was not applied and the object detection result to which the super-resolution technology was applied. This result shows that it is confirmed that the super-resolution technology can improve the object detection performance of satellite images. The test satellite image is KOMPSAT-3, and the area is Hong Kong.\n\nThe second shows the results of detecting the water system in the KOMPSAT-5 satellite image, which is a SAR satellite image.\n\nSo far, we have looked at KIWI-Sat, a large-capacity satellite image processing and analysis system. KIWI-Sat is currently under development. It plans to develop technologies for searching between multiple satellite images and extending satellite images to multiple nodes.\\n\\nHAN SANG HYUCK\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/9CN7WY/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/8 Mark Edwin Tupas.mp4", "persons": "Mark Edwin Tupas", "pretalx_id": "BJNURB", "title": "FOSS4G 2022 | Computing Global Harmonic Parameters for Flood Mapping using TU Wien\u2019s SAR Datacube Software Stack.", "description": "Synthetic Aperture Radar (SAR) backscatter is adept in differentiating standing water, due to its low signal, compared to most non-water surface cover types. However, the temporal transition from non-water to water is critical to identifying floods. Hence objects with permanent or seasonally low backscatter become ambiguous and difficult to classify. TU Wien's flood mapping algorithm utilizes a pixel-wise harmonic model derived from SAR datacube (DC) (Bauer-Marschallinger et al., in review) to account for these patterns. Designed to be applied globally in near real-time, our method applies Bayes inference on SAR data in VV polarization. In this method, the harmonic model generates the non-flooded reference distribution, which we then compare against flooded distribution to delineate floods within incoming Sentinel-1 IW GRDH scenes.\u00a0\n\nIn the harmonic modeling, we estimate each location's expected temporal backscatter variation, explained by a set of Fourier coefficients. Following recommendations in the literature, a seven coefficient formulation was adopted (Schlaffer et al.,2015) and is here on referred to as our harmonic parameters (HPARs). The HPARs include the backscatter mean and three iterations of two sinusoidal coefficients. This model acts as a smoothened proxy for the measurements in the time series, thus allowing for a seasonally varying backscatter reference to be estimated for any given day-of-year\u00a0\n\nHowever, generating the harmonic model at a global scale and with high resolution presents significant logistical and technical challenges. Therefore, harmonic modeling of remotely sensed time series is often performed on specialized infrastructures (Liu et al., 2020), such as Google Earth Engine (GEE) (Gorelick et al., 2017) or other highly customized setups (Zhou et al., 2021), where the pixel-wise analysis of multi-year data requires well-defined I/O, data chunking, and parallelization strategies to generate the HPARs in reasonable time and cost. While harmonic analysis is not new, to our knowledge, production and application at a global scale using dense SAR time series have yet to be implemented, let alone operationally utilized.\n\nTo prepare for global near real-time flood mapping effort, HPARs were systematically computed using a global DC organizing Sentinel-1 IW GRDH datasets. In the DC structure, individual images are stacked, allowing for data abstraction in the spatial and temporal dimensions, making it ideal for time-series analysis. However, for this abstraction to be realized, a rich set of software solutions is needed to implement the 3-dimensional data model.\n\nIn this contribution, we present our SAR DC software stack and its utilization to compute the aforementioned global harmonic parameters. We show a set of portable and loosely coupled Python packages developed by the TU Wien GEO Microwave Remote Sensing (MRS) group capable of forming a global data cube with minimal overhead from individual satellite images. The stack includes, among others, open-source packages for:\n\n```\nhigh-level data cube abstraction - yeoda,\nspatial reference and hierarchical tiling system - Equi7Grid,\nlower-level data access and I/O \u2013 veranda,\nspatial file and folder-based naming and handling \u2013 geopathfinder, and\nproduct tagging and metadata management \u2013 medali.```\n\nThe detailed description of the preprocessing and storage infrastructure used for this global DC is outlined by Wagner et al., 2021. Here, we focus on the software interfaces. Moreover, given the preprocessed datasets, the logical entry point is through yeoda, which abstracts well-structured Earth observation data collections as a DC, making high-level operations such as filtering and data loading possible. This level of abstraction is supported by the other components of the software stack, which addresses the organization and lower-level access to the individual files.\n\nIn a nutshell, the DC is simply a collection of raster datasets in GeoTIFF file format co-registered in the same reference grid. To deploy for large-scale operations, a well-defined grid system is required to deal with high-resolution raster data. A tiling system fulfilling this requirement is the Equi7grid, based on seven equidistant continental projections found to minimize raster image oversampling. Interacting with this tiling system on an abstract level is possible via our in-house developed Equi7Grid package. The tiling system follows a hierarchy of directories to manage the datasets on disk. Moreover, for individual files, a predefined naming convention is applied to indicate spatial, temporal, and ancillary information from product metadata that becomes transparent to yeoda. This setup of customizable file naming schemes is easily managed through the geopathfinder package.\n\nThe actual HPARs processing task was subdivided into multiple High-Performance Computing (HPC) jobs on the Vienna Scientific Cluster (VSC) based on this tiling hierarchy. For the temporal domain modeling to work, data is further split into manageable chunks. Thus only one tile per HPC node was allocated. Hence, yeoda was used to filter the DC down to the tile level, which was further reduced to a two-year period. From there, a three-dimensional array formatted backscatter measurements were generated by veranda from the image stack on disk.\n\nDue to the depth of the DC, further segmentation and parallelization were required at this level. Thus, pixel-based parallelization was done using Numba to handle the core least squares estimation of the measurements versus a day-of-year array derived from image timestamps. Veranda is again used for the output operation to encode and write the HPARs to individual files. Data quality checks, and metadata encoding, done via medali, cap the processing. In this manner, the HPAR product themselves can be abstracted similarly as a DC and simplify subsequent flood mapping computations.\n\nWith the HPAR product, the Sentinel-1 time series is seasonally modeled and condensed to a fraction of the size of the original global DC. While for now, it is exclusively used to allow our flood monitoring workflow to work globally in near-real-time, other potential applications include seasonal water and vegetation analysis. Moreover, with the software stack used to compute and subsequently access, this product can easily be deployed on different platforms with little to no overhead, allowing reproducible DC analysis.\\n\\nMark Edwin Tupas\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/BJNURB/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/9 Daniele Oxoli.mp4", "persons": "Daniele Oxoli", "pretalx_id": "CNHGNH", "title": "FOSS4G 2022 | Geo Collector Bot: A Telegram-based open toolkit to support field data collection", "description": "The collection of georeferenced information on the field has become an established and popular practice allowing professionals, volunteers and citizens to contribute to mapping objects or reporting events. Field data collection is essential to a variety of domains [1] including many scientific and humanistic disciplines, humanitarian and rescues operations, locations reviews and professional engineering surveys, to mention a few.\n\nThe spread of mobile devices that can record location coordinates, media and features while on the go (and share them through the web) is primarily accountable for such diffusion. As a result, a number of mobile apps and software frameworks (both proprietary as well as free and open-source) have been developed and released to perform data collection on the field. Most of these frameworks allow developers or data collection promoters to customize collection forms according to the characteristics of each collection task and manage both users and records through web dashboards or database management systems. From the user perspective, mobile client apps are available to access selectively the collection forms and contribute to the data collection on the field using mainly smartphones or tables. Focusing on general-purpose data collection software frameworks, some of the most popular free and open-source solutions are the Open Data Kit (ODK, https://opendatakit.org), the KoBoToolbox (https://www.kobotoolbox.org) and Epicollect (https://five.epicollect.net). Other relevant examples of free and open-source frameworks implementing a more technical approach to field data collection are e.g. QField (https://docs.qfield.org), Geopaparazzi and SMASH (https://www.geopaparazzi.org). Proprietary or pay-per-use solutions developed by major GIS firms are also available on the market but they were not considered in the benchmark analysis carried out in this work.\n\nThe outlined free and open-source software frameworks provide client and server modules and both web and mobile apps to support the full development of field data collection projects [2]. From the developer (or data collection promoter) perspective, the adoption of such frameworks is facilitated by the availability of open APIs, interfaces and dashboards to generate, deploy and manage collection forms, users and records.  Nevertheless, limitations connected to the final user experience are common to most of them. On one hand, mobile client apps are not always available or optimized for all mobile OS, therefore preventing their use on the field by a significant number of potential contributors [3]. This is the case e.g. of the ODK on iOS devices. On the other hand, each of these frameworks requires the installation of a specific mobile app on the user's device. This operation may not represent a significant obstacle to the contribution to specific data collection projects by very active or committed users. However, it might inhibit the contribution of occasional users who may not be willing to install additional software on their device for sporadic mapping of objects or event reporting [4].\n\nIn view of the above, this work presents the Geo Collector Bot, an alternative free and open-source software toolkit to empower field data collection projects avoiding the development and/or the installation of a specific mobile app on contributors' devices. The Geo Collector Bot is a configurable Telegram-based chatbot enabling the dispatching of data collection forms that can be activated and filled through Telegram chats. It consists of a backend application written in Typescript and running on Node.js. As the supporting mobile client, the Telegram app is exploited thus enabling a large number of users to contribute, even sporadically, to data collection projects (potentially every Telegram user; 550 million monthly active users as of July 2021). The Geo Collector Bot is released under MIT License and source code, documentation and a demo are available on GitLab (https://gitlab.com/geolab.como/geocollectorbot).\n\nThe Geo Collector Bot works as a standard Telegram Bot. To collect the data, the Bot asks a series of questions to the user including location coordinates, media, textual annotations, multiple-choice checkboxes, etc. and persists the answers to a spatial database. The questions flow can be customized by editing a JSON configuration file. Local deployments of the system are facilitated by the provision of a Docker container (https://hub.docker.com/r/geolabpolimi/geo-collector-bot).\n\nThe Geo Collector Bot has been developed in the framework of the  INSUBRI.PARKS project (https://insubriparksturismo.eu), funded by the Interreg Co-operation Programme 2014-2020. This project aims at increasing the tourism attractiveness of the Insubria region (between Northern Italy and Southern Switzerland) through the provision of infrastructure as well as integrated marketing and management strategies for the Insubria natural parks. The Bot represents a component of the virtual infrastructure supporting the project. It was originally designed to allow both parks visitors and managers to easily collect and share geolocated records on parks status and feedback on points of interest. However, the ultimate goal of the presented work is to provide an open and general-purpose data collection software framework suitable for multi-purpose applications.\n\nThe current version of the Geo Collector Bot still does not provide dedicated backend supporting modules for both collection tasks and records management. To that end, the development of a web control dashboard is planned and it will be included in the stack of the Geo Collector Bot Docker container as an auxiliary component. The Bot has been tested using a PostgreSQL-PostGIS database. Additional configuration options to plug other spatial database systems is planned as well in the future development of this work.\\n\\nDaniele Oxoli\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/CNHGNH/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/10 Stefan Jovanovic.mp4", "persons": "StefanJovanovic", "pretalx_id": "7LNNUU", "title": "FOSS4G 2022 | Analysis of Free and open Land Cover maps for agricultural land use planning at the local level", "description": "The area of agricultural land for food production is limited and is constantly decreasing both in the world and in Bosnia and Herzegovina. According to the National Action Plan in Bosnia and Herzegovina (B&H), up to 1,600 ha of land are lost annually (NEAP BiH 2003). The prevention of degradation and sustainably controlled land use should be the most important parts of the land protection policy of every country and the local community. In order for this policy to be implemented properly, relevant indicators of the state of land resources are necessary (Predic et al. 2021). According to the Law on Agricultural Land of the Republic of Srpska, municipalities and cities are obliged to prepare a planning document \u201cGroundwork for Agricultural Land Protection, Use and Restructuring (The groundwork)\u201d. The Groundwork is made according to the FAO (Food and Agriculture Organization) model which consists of an inventory of land and climate resources, agro-ecological zoning, and economic-ecological zoning. With GIS modeling of existing data (pedology, digital elevation model, climate data,...) new relevant data were created (bonity, agro-ecological zoning, suitability of cultivation\u2026). It is intended for municipal authorities in decisions making in the process of land use and protection. GIS layer of the current condition of land cover and land use (hereinafter LC/LU) is one of the most important GIS layers for creating Groundwork.  It is necessary to make a precise GIS layer on a large scale in order to obtain relevant data on agricultural land and land use. The most precise method of making LC/LU is manual mapping of LC/LU classes with orthophotos and high-resolution satellite images combined with field verification. The critical point of this method is that it is time consuming.  On the other hand, \"free\" land cover data is available, such as Corine Land Cover (hereinafter CLC), OpenStreetMap,... In this paper, using free open source programs, a comparison of two sets of data representing land cover was performed: manually vectorized data with an orthophoto image of LC/LU and CLC. The aim of this paper is to determine the relevance of CLC data for the needs of land use planning at the level of administrative units in B&H. The study area is the municipality of Lakta\u0161i with an area of 38807 ha for which the LC/LU was created in 2018 at the same time as the CLC for B&H. The first phase of the comparison is the synchronization of LC/LU-CLC classifications. LC/LU classification is The Land Cover Classification System, (FAO LCCS, 2000) which is modifiable for the conditions of B&H. Both the LC/LU and the CLC classifications consist of classes divided into three levels. The main difference between LC/LU and CLC is that the LC/LU classification is primarily intended for the detailed identification of agricultural land. The LC/LU nomenclature is dominated by classes that represent agricultural land both in terms of land cover and in terms of use (18 out of a total of 36 classes). The smallest mapped area in LC/LU depends on the significance of a LC/LU class. For example, for the arable land class, it is 0.5 ha, and for the permanent crops class, it is 0.1 ha. The main reason is the fragmentation of properties in B&H (85% is dominated by less than 0.5 ha plots). Unlike the CLC classification, which discusses artificial surfaces in great detail and has 11 classes in the third level (111 Continuous urban fabric,.., 121 Industrial or commercial units,\u2026,142 Sport and leisure facilities), LC/LU classification has only 2 classes for artificial surfaces: Built up and Built up dominates. In this class, the minimum mapped area is 0.025 ha because it is necessary to accurately separate land areas that are temporarily or permanently lost to agriculture. Regardless of the above differences, it is possible to synchronize LC/LU and CLC classifications through third level classes. In the study area (Lakta\u0161i municipality) LC/LU GIS layer contains 23 out of 36 LC/LU classes (10707 polygons), and  CLC layer 16 out of 44 classes (177 polygons). In the study area, the CLC classification did not recognize 11 classes of LC/LU, of which 8 classes are precisely characterized by agricultural areas (greenhouses, vineyards, nurseries, meadows\u2026). The entire process of comparing and analyzing data was performed using QGIS with the support of the Python programming language. Using QGIS, the union of LC/LU and CLC polygons (14044 polygons) was performed. Using the Python programming language, an error matrix was created and the parameters of the quality of land cover maps were recalculated (Bratic et al., 2020). The obtained results show the accuracy of CLC with respect to LC/LU reference. Although the overall accuracy is 70%, the class-level results are showing that during the creation of CLC layers, a significant part of non-agricultural areas was marked as agricultural classes. For example, 19.4% LC/LU forest class and 42.4% LC/LU class built up, in CLC were mapped as arable dominated class. From the above example, in the studied area, a significalntly larger area of agricultural land was present in relataion to the actual state. After analyzing the results, it was concluded that the CLC in the studied area is not a sufficiently precise GIS basis for agricultural land use planning at the local level. However, it can be a good starting point for making of LC/LU, which would significantly shorten the time of its creating.\\n\\nStefanJovanovic\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/7LNNUU/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/11 Toshikazu Seto.mp4", "persons": "Toshikazu Seto", "pretalx_id": "9KGNRA", "title": "FOSS4G 2022 | Analysis of the spatiotemporal accumulation process of Mapillary data and its relationship with OSM road data: A case study in Japan", "description": "Japan's open infrastructure map development using OpenStreetMap was triggered by the Great East Japan Earthquake in 2011, which led to a widespread understanding of the activity, and by the end of September 2019, more than 35,000 unique users had made some kind of contribution, and the data is still being updated daily. The data is still being updated daily. In addition, the Mapillary project (Juh\u00e1sz and Hochmair, 2016; Mahabir et al., 2020) which started in April 2014, is a location-based landscape photo-sharing service that, like OSM, is crowdsourced and allows users to post photos of places around the world, not just on roads.\n\nThis activity has started to spread in Asia, especially in Japan, where the number of contributors and the number of photos taken is rapidly increasing (Ma et al., 2020). These voluntary crowdsourcing activities are a great incentive to work on the creation of micro-scale road data, especially those that cannot be maintained or updated by public agencies. On the other hand, most of the research on Mapillary to date has been concerned with technical methodologies, such as the study of ground object extraction based on deep learning of images using Mapillary data, and approaches such as local comparison of data generated by contributors, as is commonly done in OSM research, have not made much progress. This study was conducted in September 2014.\n\nIn this study, we obtained about 41.7 million log data through the Search Images API of Mapillary API ver3 taken in Japan from September 2014 to September 2019. Then, together with the line data of OSM roads at the same point in time, the maintenance status of Mapillary and OSM road data in municipal units in Japan was spatially analyzed mainly with QGIS, considering the time series and user trends. The data for the entire country of Japan to be analyzed is so huge that it is difficult to perform spatial analysis with the basic database (PostGIS), so we tried to add various attributes that can be analyzed spatially in QGIS by converting the data to FlatGeobuf format, which has been attracting attention recently. We also tried to add various attributes that can be analyzed spatially in QGIS. The added attributes include the administrative name of the local government in Japan, and the type, version, last editor, and date of data update of the road in the nearest vicinity of the taking photo  point (maximum search radius set to 50m) from the OSM dump file obtained separately.\n\nSome of the results of the analysis are as follows. The number of unique contributors who participated in the maintenance of Mapillary data for five years across Japan was about 1500, and it was found that the top 20 users generated about 90% of the data. The top three contributors each shared more than 5 million images. The number of contributors involved in the OSM road data as a comparison of user participation is about 4,800, suggesting that Mapillary data is generated by about 1/3 of the users compared to OSM.\n\nWe extracted the major contributors for each of the 1,700 municipalities in Japan and found that about 50 users were involved. Although the Mapillary data in Japan is supported by a smaller number of contributors than the OSM data, we succeeded in bringing to light the image of contributors in each region by analyzing the data on a micro-regional basis.\n\nIn terms of the number of Mapillary images taken and their spatial characteristics, the number of images taken on major roads (equivalent to OSM's highway = trunk or primary) in non-urban areas in the Tohoku region (especially Fukushima Prefecture: approximately 6 million images, Iwate Prefecture: about 4 million images) and Kansai region (Kyoto Prefecture: about 3 million images) is outstanding, while the number of images taken on sidewalks (highway = sidewalk) in the metropolitan areas of Tokyo and Osaka is low. In the metropolitan areas of Tokyo and Osaka, the data developed to supplement the OSM data for sidewalks (highway=path, footway, unclassified) and other road types that exist in reality but are not well-developed in the OSM data. In the paper, we plan to describe the local activities in Fukushima Prefecture and Kyoto City, where Mapillary activities are particularly active, in addition to comparisons at the national and municipal levels. In this paper, we also focus on the temporal transition of data maintenance. In this paper, we also focus on the temporal transition of data maintenance. Specifically, we analyzed the relationship between OSM data and the points where Mapillary images were taken using time series clustering.\n\n\u3000This study is a multifaceted spatial analysis of long-term photography logs through Mapillary and the first study to reveal macro trends across Japan as well as more local trends in combination with attributes of road data from municipalities and OSM. In addition, by using distributed processing methods such as tiling technology and FlatGeobuf to obtain a large dataset of more than 41 million POIs (Points of Interests) from APIs and analyze the data spatially in QGIS, we were able to process the data without requiring a large-scale server. This is also a significant achievement. Finally, since the Mapillary log data used for the analysis is large-scale, we are planning to provide both archived data and spatially aggregated GIS data.\n\nSpatially aggregated from Mapillary POI data (41\u2009765\u2009634) for all of Japan used in the analysis, we are providing both FlatGeobuf format data per municipal-level (232.2 MB; 32 attribute values) and per 1-km grid-level (126.5 MB; 20 attribute values), via a Github repository:\nhttps://github.com/tossetolab/mapillary-analysis-japan.\\n\\nToshikazu Seto\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/9KGNRA/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/12 Daniel Fern\u00e0ndez-.mp4", "persons": "Daniel Fern\u00e1ndez", "pretalx_id": "CA3TGA", "title": "FOSS4G 2022 | Remote mapping of soil erosion risk in Iceland", "description": "Soil erosion is a major global land degradation threat. Improving knowledge of the probable future rates of soil erosion, accelerated by human activity and climate change, is one of the most decisive factors when it comes to making decisions about conservation policies and for earth-system modelers seeking to reduce uncertainty on global predictions [1].\n\nIn this context, the use of remote-sensing based methods for soil erosion assessment has been increasing in recent years thanks to the availability of free access satellite data, and it has repeatedly proven to be successful [2, 3]. Accurate information about it is, however, usually known only at the local scale and based on limited field campaigns. Its application to the Arctic presents a number of challenges, due to peculiar soils with short growing periods, winter storms, wind, and frequent cloud and snow cover. However, the benefits of applying these techniques would be especially valuable in arctic areas, where ground local information can be hard to obtain due to hardly accessible roads and lands.\n\nHere we propose a hybrid solution, which uses ground truth samples to calibrate the processed remote images over a specific area, to then automate the analysis for larger, less accessible areas. This solution is being developed for soil erosion studies of Iceland specifically, using Sentinel 2 satellite data combined with local assessment data from Iceland\u2019s Soil Conservation Services department, Landgr\u00e6\u00f0slan. Their historical data is more extensive than usual, since they are the oldest soil erosion department in the world.\n\nAvailable data includes parameters of bare ground cover, which can be calculated from satellite images alone, after using information from observationally correct areas without vegetation for calibration; Icelandic soil profiles, to be analyzed to find how the profile relates to soil erosion intensity; as well as the parameters of agriculture use and arable land data including plant species in cultivated lands.\n\nFor the training phase we employ a dataset composed of 550 cropped georeferenced and atmospherically corrected Sentinel 2A images [4], combined with a Digital Elevation Model (DEM) of Iceland that allows us to detect slopes which can produce landslides or help erosion to occur. The dataset is labelled by six degrees of erosion severity, using measurement points furnished by Landgr\u00e6\u00f0slan. We split it into 2/3 for model training and 1/3 for model testing.\n\nThese images are in tiles of 10980x10980 pixels (about 600 MB) and cover an area of approximately 100x100 km2. We can crop the images down to preferred size. They contain multispectral data, divided up into 12 bands of varying wavelengths, and a resolution from 10 to 20m. We could add as well some of the 60m bands if necessary. Different band data are combined to create indices which represent or highlight certain features, such as vegetation, soil crusting, bare soil, and red edge indices.\n\nElevation data from the Arctic (north of 60\u00b0N, including Iceland) started to be openly available since 2015 through the ArcticDEM project. The DEMs are derived from satellite sub-meter stereo imagery, particularly from WorldView 1-3 and GeoEye-1. This information can be used to detect to what extent plant growth is reduced at higher heights because of longer snow cover, shorter growing period and stronger winds on one side. By using the variation of DEM and building a slope map, we can see that soil erodes more on steep slopes which leads to a higher likelihood of erosion the steeper they are.\n\nThe tools for geometric and topographic correction include SNAP (Sentinel application platform), Sen2Core, FLAASH (Fast line-of-sight atmospheric analysis of hypercubes), DOS (Dark Object Subtraction) and ATCOR software. This correction reduces effects due to shadows and surface irregularities and corrects the single-date Sentinel-2 Level-1C Top Of Atmosphere (TOA) products from atmospheric effects in order to deliver a Level-2A Bottom-Of-Atmosphere (BOA) reflectance product.\n\nAfter a preprocessing technique based on dimensionality reduction in order to avoid adding too much noise to the algorithm, this labelled data is then used to train a Support Vector Machine (SVM) model for classifying each coordinate. We choose the SVM algorithm as a starting point because it is a fast and reliable algorithm that performs well for classification problems with high-dimensional feature spaces such as ours, and does not require large training sets to achieve high accuracy as other algorithms do (e.g. deep neural networks). The output of the model is a set of coordinates, each with a numeric classification representing soil erosion severity, and used for creating a map of soil erosion severity in a selected area.\n\nThis methodology has been proven to provide good results, achieving an overall land cover classification accuracy of 94% [5], a performance that can be attributed to the spectral complexity of Sentinel-2 data, particularly the red-edge bands which give room for separability of erosion classes. Low separability is a common limitation to the applicability of classification methods. We address this by using ISODATA and minimum distance methods. Two factors that could affect the accuracy of the delineation of eroded soils using spectral images are the intensity of the soil erosion processes and changes in the spectral characteristics of disturbed soils.\n\nThe research described here aims at producing a reliable, widely applicable and cost-effective method to classify Icelandic soils into different categories of erosion risk, a proof of concept which, once engineered, could be straightforwardly expanded and applied to other Arctic areas, such as Greenland and Canada.\\n\\nDaniel Fern\u00e1ndez\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/CA3TGA/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/13 Robert Spang .mp4", "persons": "Robert Spang", "pretalx_id": "CS9MGW", "title": "FOSS4G 2022 | The STAGA-Dataset: Stop and Trip Annotated GPS and Accelerometer Data of Everyday Life", "description": "## Motivation & Contribution\n\nPart of the development of an analysis pipeline for mobility studies using GPS data is benchmarking its performance on both the raw data accuracy and the analysis pipeline itself. When we started to develop our algorithm for stop and trip classification, it became clear that we needed a precisely annotated dataset containing accurate stop and trip labels as a ground truth. Apart from validating our development, we wanted to have a reference point for comparing our analysis methods with existing libraries.\n\nFor the study, we planned to equip participants with a smartphone to collect movement data in form of GPS and acceleration data for several days in a row. To prolong battery time, we chose a lower sample frequency. Our special focus was to create ground truth for stop and trip detection algorithms, hence the annotation focused on this.\n\nThrough this manuscript, we contribute a comprehensive dataset providing accurate start and end timestamps for stops over 126 days. The STAGA dataset is an unprocessed table of GPS coordinates, annotated with a timestamp, altitude, GPS accuracy, and class label (\"stop\" or \"trip\"). Each sample labeled as a \"stop\" further contains the GPS coordinates of the location it's attributed to. The acceleration data is provided as a separate file, but covers the same time frame and contains a triple (x, y, z) of acceleration sensor readings for each given timestamp, sampled at 1 Hz. The STAGA~dataset is provided publicly and free to use. We further provide the iOS app used to create the diary data for simple stop/trip annotation while on the go. All this is made available under CC BY 4.0.\n\n## Method\n\n#### Diary\n\nTo create the dataset, we first tried a traditional diary approach: four researchers were taking notes, writing down addresses and times whenever they stopped. While this provided some first samples, it was a tedious and error-prone process, since taking notes is impractical in everyday life. Furthermore, it required looking up the coordinates belonging to each noted address, which works for clearly defined, urban spaces but can become problematic otherwise, e.g. in a park or a rural, outdoor environment as addresses aren't precise enough here. Because of that, we developed a simple iOS app that helped us annotate our movements. The app contains a map to validate the identified position, one button to start or end a stop, and a list overview of previously recorded stops. It captures the GPS position whenever a new stop is started and stores the current time as the start timestamp. When the button is pressed again, the stop is completed and the current time is stored as the end timestamp. Trips are derived from the intervals between two stops. Even more, the app allows exporting the captured annotations as a CSV file which can be directly used for benchmarking purposes. This way, we were able to create a GPS dataset containing precise stop/trip annotations, together with a reference position of the actual stop location. The diary was recorded using an Apple iPhone XR.\n\n#### Data Collection\n\nThe device we used for the recordings was a ZTE Blade A5 (2019). It was configured to record GPS samples at a minimum accuracy of 25m, so if the device was unable to obtain a position reading within this radius, the data point was omitted. We sampled data with a frequency of 0.1 Hz and used both network and GPS as sources for determining the position (the smartphone supports A-GPS and GLONASS). It runs Android 9 and is equipped with a 2.600 mAh battery; during the recording of the dataset, the battery was always charged before the phone shut down.\n\nWhile the dataset contains mostly everyday life, it also holds small periods of vacation, travel, and hiking. Most trips were carried out by bike. However, the dataset contains long periods of walking, car traffic, and train rides as well. While the data was recorded in two different European countries (mostly urban environments), everything was rotated and projected into the North Atlantic for privacy protection. In the same vein, all timestamps have been shifted to start on January first in the year 2000. However, none of these changes should affect the performance of stop and trip detection algorithms, as the relative temporal and spatial accumulation of GPS records are not changed.\n\n## Dataset Statistics\n\nThe dataset contains 122,808~GPS and 7,813,740~accelerometer records. The recording time spans over 126.65~days.\nThe diary contains 692~stops and 691~trips.\nThe average (mean) duration of a stop is $240.8min$; the average trip duration is $22.7min$.\nOn average, a stop contains $114.0$ GPS samples; a trip contains $63.5$ GPS samples (mean).\n\n## Discussion & Use-Cases\n\nThis dataset enables researchers to validate the performance of their algorithms that are used to predict stops and trips from GPS data. It provides a ground truth through careful annotations over a long period. In particular, the development of algorithms for stop and trip classification should profit from this dataset as it enables accuracy tests in the temporal and spatial domain. Due to free access, researchers can use it in various projects, enabling them to make data-driven decisions in the development of mobility research frameworks.\n\n## Data-Availability\n\nThe described dataset, containing GPS & acceleration records and stop/trip annotations, are publicly available at the Open Science Framework under a CC-By Attribution 4.0 International license: https://osf.io/34sft/\n\nThe annotation companion app we used to annotate the dataset is free software under a BSD 3-Clause license: https://github.com/RGreinacher/GPS-Diary\\n\\nRobert Spang\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/CS9MGW/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/14 Dogus Guler.mp4", "persons": "Dogus Guler", "pretalx_id": "HVSF38", "title": "FOSS4G 2022 | The Role of Open Standards in Digital Building Permitting, 3D Registration of Condominium, and Update of 3D City Models", "description": "Digitalization is being adopted in many public services to increase the efficiencies of the required operations. Regarding this, there is an important interest in digitalizing the current building permit procedures since most of the buildings are designed digitally and as three-dimensional (3D). In addition, several countries are making an effort to realize the transition from two-dimensional (2D) cadastre to 3D cadastre. This is because 2D delineation of the legal rights may remain incapable to reflect the reality with respect to property ownership in multipartite buildings. The 3D city models should also be kept updated to effectively manage the occasions (e.g., natural disasters) and services (e.g., waterworks) in the living areas. In this sense, the open data standards have a vital role to enable interoperability between different domains such as AEC and Land Administration. In this sense, this paper first aims to show the current situation and opportunities on how to efficaciously benefit from open data standards for three significant issues. The issues can be listed as, 1) digitalizing the building permit procedures, 2) registering the condominium as 3D, and 3) updating the 3D city models. It then presents an approach for integrating open standards for 3D registration of condominium rights in Turkey context. The integration of GIS and BIM, GeoBIM, has gained importance in terms of digital building permitting since there are rules to be checked with respect to the built environment; for example, the availability of bicycle parks. Besides, zoning plans that are essential for building permitting are generally formatted with GIS-based data. There are studies in the literature that aim to carry out the building permitting by benefiting from the integrated GIS and BIM approach. This approach is also connected with the update of the 3D city model database because the as-built models of the buildings can be integrated into this database after the necessary conversions (Guler & Yomralioglu, 2021). 3D registration of condominium rights, which is part of the 3D cadastre, is often researched in the literature since 2D-based delineation of ownership rights might be insufficient in detecting who owns or responsible for which parts of the multipartite buildings. The availability of 3D representation of ownership rights will be efficient for various land administration applications, for example, property valuation. Open standards are, of course, pivotal for realizing the 3D registration of condominium rights as they not only provide the integration between different organizations but also enable the interoperability for other processes that are needed the same data. In this connection, Land Administration Domain Model (LADM) is the first standard that comes to mind because it aims to provide a common language for land administration systems and supports 3D representation through boundary face and boundary face strings. Since standards like CityGML focus on 3D modeling of buildings more deeply, there are attempts that integrate the CityGML and LADM by exploiting advantageous features of each of the standards for better depiction of ownership rights as 3D (Li et al., 2016). The \u201cBuilding\u201d and \u201cCadastre\u201d themes that are produced within the context of Turkey National GIS (TNGIS) describe the relationship between related features, namely parcel, building, building blocks, and condominiums. These features are modeled such that they allow for integration with other standards such as CityGML and IndoorGML so as to enable the efficient reuse of spatial data in different applications. To enable better interoperability and 3D depiction of condominium rights, an integrated model is developed. The proposed features that are adapted from LADM permits the 3D representation of ownership rights. The proposed features are linked with the IFC entities, namely \u201cIfcZone\u201d, \u201cIfcRelAssignsToGroup\u201d, and \u201cIfcSpace\u201d to provide integration with IFC. \u201cBuildingUnit\u201d is linked with the \u201cBuildingCondominium3D\u201d feature, and hence the integration with CityGML data is provided. It can be mentioned that \u201cBuildingCondominium3D\u201d corresponds to the \u201cLegalSpaceBuildingUnit\u201d feature of LADM. The proposed model incorporates the integration with IndoorGML by means of the link between \u201cBuildingCondominium3D\u201d and \u201cCellSpace\u201d. Due to fact of the inevitable proliferation of digitalization, the processes related to land and city management need to be accomplished more digitally and fast. There is an important potential to be practiced building permit issuing, as one of the important public services, in the sense of improvement and automation of the process (Noardo et al., 2022). Open data standards have a quite crucial role in realizing this potential. This is because these standards enable the standardization of information flow between designers and organizations that are responsible for compliance checking. In other words, applicants can prepare their submissions according to required information for building permit issuing. There is a strong interrelation between digital building permitting and the update of 3D city models because if the as-built IFC data of buildings are available, these data can be converted to CityGML, and thus the 3D city model database can be kept up-to-date. In addition to this, an up-to-date 3D city model database can be used for digital building permitting as there is a need for built environment data for integrated and comprehensive compliance checking. For example, rules with respect to infrastructure facilities can be checked using 3D city models. Open standards are effective to be successful in practicing the 3D cadastre. With the increasing trend in BIM, there are proposed approaches that use the IFC schema for 3D delineation of apartment rights in multipartite buildings. In parallel, this paper concentrates on a model that provides the integration with IFC data in the 3D representation of condominium rights in Turkey. The misinterpretations regarding who is responsible or owns of which parts of the buildings can be prevented using the IFC-based depiction of ownership rights (Shin et al., 2020). The semantic information pertaining to independent sections can be queried using the produced IFC-based models. These models will also be quite helpful for property valuation applications in Turkey that exploit 3D variables such as size, volume, position, and material quantities since they provide detailed information on indoor parts of the buildings (El Yamani et al., 2021).\\n\\nDogus Guler\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/HVSF38/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/15 Dominik Weckmuller.mp4", "persons": "Dominik Weckm\u00fcller, Dr.-Ing. Alexander Dunkel", "pretalx_id": "CS9HJ3", "title": "FOSS4G 2022 | Developing a privacy-aware map-based cross-platform social media dashboard for municipal decision-making", "description": "# Developing a privacy-aware map-based cross-platform social media  dashboard for municipal decision-making\n\n## Introduction\n\nUsers of location-based social media networks (LBSN), such as Instagram,\nFlickr, or Twitter, have produced an unprecedented base of data over the\npast decade. According to ILIEVA & MCPHEARSON (2018: 553), \"the\nenormous scale and timely observation are unique advantages of [social\nmedia data]\" and therefore hold enormous potential for various\napplication purposes such as urban planning, among others.\n\nMost notably for Instagram, as one of the largest LBSN, encouraging the\nsharing of locations when creating content, offers completely new and\npromising application purposes, through the combination of the spatial\ncomponent with timestamps and the actual content (image & text).\n\nPublic social media (SM) data have shown their potential examining the\nincreasingly relevant social problems of Spatial (In-) Justice, spatial\n(in-) equality and spatial (in-) equity (Cf. SOJA 2013: 47). However,\nfew research attempts were made to make these results available broader\nin practice and accessible to laypersons in an understandable way.\n\nLBSN data could contribute significantly to creating a better\ninformation base for municipal decision-making processes, reaching\nespecially younger target groups. Until now, specifically these groups\nwere difficult to reach in common participation processes (Cf. SELLE\n2004), while bearing consequences of municipal policies for the longest\nperiod of time.\n\nOur stated research goal is therefore to provide citizens, laypersons\nand municipal decision-makers with an unprecedented LBSN Dashboard, as a\nsimple open-source platform for spatial multi-purpose LBSN analysis.\n\n## Problem Statement\n\nSuch an undertaking raises certain ethical and legal questions, since\nthe user data belong to the users themselves, including the right to\nself-determination over their data, on the one hand, and the right to\nprivacy on the other. The far too short-sighted (but frequently used)\nargument that posts have been deliberately published, with all the\nconsequences of their public nature in mind (e.g., BURTON et al. 2012:\n2), is simply not sufficient for an in-depth discussion of privacy. This\nfurther violates the most important aspects of privacy (Cf. BOYD &\nCRAWFORD 2012: 672). In fact, most users are not or only partially aware\nof what can actually be inferred from what they share or disclose about\nthemselves (KESSLER & MCKENZIE 2018: 6f).\n\nYet, privacy is rarely addressed in LBSN research and, worse, often\nnegligently ignored. In this context, many negative examples can be\nfound where data was analyzed and high-resolution results were\npublished, clearly violating users' privacy, for example, in scientific\npublications (Cf. KOUNADI & LEITNER 2014: 140).\n\n## Research Interest\n\nGiven the increasing socio-spatial inequality, the rapid growth of SM,\nand the growing interest of municipalities in SM knowledge, we see a\nsignificant need for such a privacy-aware LBSN dashboard, which is\nentirely new to the geospatial community.\n\nWe develop a privacy-aware LBSN dashboard prototype and propose a data\nprocessing pipeline based on the HyperLogLog (HLL) algorithm by FLAJOLET\net al. (2007). The dashboard is geared towards easy information\nretrieval and making use of the data richness of LBSN -- without\ncompromising user privacy and the need for extensive data retention.\nInstead, we provide a unique, customizable, GDPR-compliant privacy\napproach. The combination of different open-source tools for structuring\nmulti-platform LBSN data, leveraging the capabilities of HyperLogLog and\nsimple Python integration ensure easy reproducibility and active\ncommunity development (Cf. DUNKEL et al. 2021; DUNKEL & L\u00d6CHNER 2021a &\nb).\n\nThe dashboard prototype is tailored for use in municipalities and its\ncitizens, but offers high scalability for other purposes or other\nspatial levels. A limited interactive demo and its GitHub repository are\npermanently publicly available as a result of a Master's thesis and an\nIoT Design Thinking Workshop (Cf. WECKM\u00dcLLER 2021; BUNDESSTADT BONN\n2022).\n\nWe plan on finishing and automatizing the data processing pipeline,\nenabling more sophisticated queries and adding further visualization\nmethods. In the long run, the dashboard is thought to serve as a\nparticipation and open data hub for all citizens and for any city in the\nworld. So far, the city of Bonn and Chemnitz (Germany) are pilot\npartners of this research project.\n\n## References\n\n### Literature\n\nBOYD, D., & CRAWFORD, K. (2012). CRITICAL QUESTIONS FOR BIG DATA.\nInformation, Communication & Society, 15(5), 662--679.\n\nBURTON, S. H., TANNER, K. W., GIRAUD-CARRIER, C.G., WEST,J. H., &\nBARNES, M. D. (2012). \"Right Time, Right Place\" Health Communication\non Twitter: Value and Accuracy of Location Information. Journal of\nmedical Internet research, 14(6), e156.\n\nFISCHER, F. (2008). Location Based Social Media -- Considering the\nImpact of Sharing Geographic Information on Individual Spatial\nExperience. In A. Car, G. Griesebner, & J. Strobl (Eds.) Geospatial\nCrossroads @ GI_Forum '08. Proceedings of the Geoinformatics Forum\nSalzburg (pp. 1-7). Wichmann.\n\nFLAJOLET, P., FUSY, \u00c9., GANDOUET, O., & MEUNIER, F. (2007). Hyperloglog:\nthe analysis of a nearoptimal cardinality estimation algorithm. Analysis\nof Algorithms 2007 (AofA07), 127--146.\n\nILIEVA, R. T., & MCPHEARSON, T. (2018). Social-media data for urban\nsustainability. Nature Sustainability, 1(10), 553-565.\n\nKESSLER, C., & McKenzie, G. (2018). A geoprivacy manifesto. Transactions\nin GIS, 22(1), 3-19.\n\nKOUNADI, O., & LEITNER, M. (2014). Why does geoprivacy matter? The\nscientific publication of confidential data presented on maps. Journal\nof Empirical Research on Human Research Ethics, 9(4), 34-45.\n\nSelle, K. (2004). Kommunikation in der Kritik? In: M\u00fcller B., L\u00f6b S.,\nZimmermann K. (Ed.) Steuerung und Planung im Wandel, VS Verlag f\u00fcr\nSozialwissenschaften.\n\nSOJA, E. W. (2013). Seeking spatial justice (Vol. 16). University of\nMinnesota Press.\n\n### List of Web References\n\nAll links last accessed on February 20, 2022.\n\nBUNDESSTADT BONN (2022). Studierende entwickeln neue Ideen f\u00fcr die\ndigitale Stadt von morgen.\nhttps://www.bonn.de/pressemitteilungen/januar-2022/studierende-entwickeln-neue-ideen-fuer-die-digitale-stadt-von-morgen.php\n\nDUNKEL, A., L\u00d6CHNER, M., KRUMPE, F. & Contributors (2021). LBSN\nStructure. https://lbsn.vgiscience.org/.\n\nDUNKEL, A. & L\u00d6CHNER M. (2021a). LBSN HLL Database - Docker Container.\n\nhttps://gitlab.vgiscience.de/lbsn/databases/hlldb/\n\nDUNKEL, A. & L\u00d6CHNER M. (2021b). Lbsntransform.\nhttps://lbsn.vgiscience.org/lbsntransform/docs/.\n\nWECKM\u00dcLLER, D. (2021). LBSN-Dashboard Prototype for Bonn.\nhttps://geo.rocks/lbsndashboard/\\n\\nDominik Weckm\u00fcller\\nDr.-Ing. Alexander Dunkel\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/CS9HJ3/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/16 Cinzia Licciardello.mp4", "persons": "Ing. Cinzia Licciardello", "pretalx_id": "CY9BMD", "title": "FOSS4G 2022 | 2D/3D soil consumption tracking in a marble quarry district", "description": "Complex quarry districts like Apuan Alps\u2019 marble quarries require remotely sensed high resolution data for soil consumption monitoring over the years: extractive activities lead to environmental challenges that require accurate environmental controls issued by the Tuscan Regional Environmental Agency (ARPAT). The Regional Environmental Information System office (SIRA) over the last 5 and 10 years has developed methods and techniques suitable for both 2D and 3D soil consumption monitoring by using free aerial and satellite images and Open Source Geo-spatial Software for data processing and data dissemination useful in controls\u2019 planning and management. Aerial images and LiDAR acquisition, satellite data, RPAS acquisitions have been tested in order to evaluate their suitability in deriving both 2D and 3D indicators with proper resolution to address required spatial-temporal constraints, i.e. yearly monitoring of high resolution changes (spatial resolution between 50cm and 1m).\nDue to the size of the Area of Interest (AOI) of the Carrara basins, up to 2.5km x 2.5km, stereo satellite and aerial images can be used to obtain precise terrain models by photogrammetric reconstruction useful in 3D soil consumption monitoring, while middle-resolution (10m) multi-spectral satellite images and high-resolution aerial images (50cm-1m) can be used in 2D soil consumption monitoring and quarries\u2019 area regulations by public bodies (natural soil loss, exhausted areas restorations, debris removals and new disposals).\nOpen-access Sentinel-2 multi-spectral satellite images with 10m of spatial resolution have been used to assess coverage changes; the results have been subsequently refined by manual interpretation over 5 years (2016-2021). Both semi-automatic methods based on spectral distances and machine learning techniques have been used to identify areas affected by extraction activities in QGIS 3.x environment over Sentinel-2 images. Free OGC Web Map Services (WMS) made available by the Tuscan Regional Information System have been used to assess changes highlighted by semi-automatic methods: aerial high-resolution images between 2010 and 2019 have been evaluated by visual photointerpretation, allowing to extend to 10 years the 2D soil consumption assessment over the whole area.\nComparison of highlighted 2D changes to regulated areas like mapped debris disposals and quarries\u2019 property limits have been used to check proper developments of extraction activities and proper environmental debris management.\nIn turn, 3D changes have been tracked by comparison of 2009 and 2017 free aerial LiDAR data made available for download by the Tuscan Regional Information System, integrated with two stereo models obtained from 2020 and 2022 Pl\u00e9iades satellite high resolution images (new acquisitions) freely granted by ESA following Project Proposal id 61779 (\u201cQuarry activity monitoring in Apuan Alps\u201d). Stereo satellite B/W images with 50cm of spatial resolution have been processed by using Open Source stereo processing pipelines in Docker virtual environments, obtaining high precision digital surface models (height precision around 1m) after vegetation filtering. 3D changes detected over the years by elevation algebraic comparison, performed in QGIS 3.x environment, highlight quarries characterized by intense extraction activities (extracted marble blocks, characterized by positive quotas differences) and quarry area management (debris disposing and service infrastructure building, characterized by negative quotas differences).\nThe combined usage of both 2D and 3D changes\u2019 indicators can be challenging in term of proper representation of soil consumption dynamics over the years: while decision makers need a quick and easy access to both 2D and 3D data, web technologies suitable for a proper representation have been developed in very different contexts, making their integration quite complex. While a \u2018classical\u2019 2D webgis client Openlayers or Leaflet-based can be enough to highlight 2D changes and \u2013 with some limitations \u2013 3D changes as elevation differences, a \u2018true\u2019 3D visualization environment must be set to track ongoing extraction activities aiming to assess both (a) compliance to authorized extraction plans by public bodies and (b) proper debris management in quarry areas. In addition, 3D web viewers are mainly targeted to represents point clouds or CAD drawings, making very difficult the integration of 2D, 2.5D (Terrain Models) and 3D (extracted volumes) data.\nA dual 2D/3D webgis client have been developed for proper representation of 2D/3D spatial indicators of ongoing extraction activities in the Carrara marble basin: high resolution images have been served as tiled data, while 2D/3D spatial indicators are served as static and/or tiled vector data. Open-Source libraries have used in data processing, serving and representation inside a map interface.\nFor each quarry included in the Carrara basing, both area limitations and authorized areas for extraction activities have been superimposed over the spatial indicator layers, thus allowing users to easily locate areas subjected to intense extraction activities and to evaluate compliance to sustainability plans and environmental management prescriptions issued by public bodies.\n2D and 3D indicators are in progress to be used in prioritizing environmental controls\u2019 planning: this novel application would require a proper scoring system based on the degree of compliance to both environmental management prescriptions and performances mainly in the field of quarry and marble slurry waste management.\\n\\nIng. Cinzia Licciardello\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/CY9BMD/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/17 Mathias Grobe.mp4", "persons": "Mathias Gr\u00f6be", "pretalx_id": "ETS7XY", "title": "FOSS4G 2022 | Mapping Mt. Ushba \u2013 How to create a high-quality topographic map from open data using free software", "description": "Mt. Ushba is situated in the Greater Caucasus in Georgia, next to the Russian border. With its nearly symmetrical double peak appearance, it is iconic and a symbol of the historic Svaneti region in Georgia, famous for its mountains, botany, and century-old defense towers. Svaneti is becoming an increasingly popular tourist destination in summer and winter. Therefore, the German Alpine Club is interested in providing a new map for this region, which will be produced by the Institute of Cartography of the TU Dresden. In the age of open data, it is consequential that OpenStreetMap will be an essential source of the new map. It should make the project more sustainable and inspire people to use free and open-source software for map production.\n\nOne basis of each topographic or touristic map is fieldwork, which means organized mapping and editing with OpenStreetMap aiming to verify and to complement map content and coverage[1], carried out by the Institute of Cartography in Mestia (Georgia) in the summer of 2021. Preparing for this work, a comparison with older maps was conducted to identify possible shortcomings and errors in the data. A draft was created using OpenStreetMap and the SRTM elevation model, preparing for the fieldwork. It helped to evaluate the current state of the data, gave a first impression of the mapping area, and was an ostensive basis for data capturing in field. A field book was produced for each participant, containing the map draft as an atlas and information on which data should be collected and which the specific attributes were required. Finally, the data was contributed to OpenStreetMap, and from there, the draft was updated again.\n\nIn the case of land cover, creating an own classification seemed beneficial in distinguishing between typical vegetation classes in a high mountain area. Showing the vegetation in detail is a feature of Alpine Club map, but using OpenStreetMap data would not detailed enough. In addition, a land cover classification based on remote sensing data is more reliable and ensures better consistent results compared to individual contributions from users with different previous knowledge. Open remote sensing data from the Landsat and Sentinel programs offer good sources for such a task and are also used to monitor the glaciers in this area[II]. R is used as an analysis platform. It is possible to classify rock, glaciers, and specific vegetation types such as alpine rose or open birch stands. For identifying the vegetation, representative examples were collected during the fieldwork by entering them in the atlas and taking sample photographs.\n\nAnother essential part of a topographic map for a high mountain area map is a good terrain visualization. The SRTM model is beneficial but not detailed enough to create rock depictions, which will be automatically derived by the Piotr tool[iii]. Planet Labs Inc provided high-resolution Rapid Eye and their Dove satellites imagery, suitable for creating a digital elevation model with a spatial resolution of approximately ten meters by applying stereo photogrammetry methods using the AMES Stereo Pipeline[iv]. The result enables a much more precise and understandable representation of the terrain. The terrain points were recorded with special standard GPS devices, the Garmin GPSMAP 66sr, which stores the raw observations for two frequencies. Accuracies in the range of around 0.1 meters[v] can be achieved using professional GNSS software.\n\nIn order to produce the final topographic map, it is necessary to combine all data components to represent the area around Mt. Ushba. In a first step, the updated OpenStreetMap data is imported into a PostgreSQL database with PostGIS extension. In a second step, an automated generalization is carried out for the selected target scale of 1:33,000, particularly schema transformation, aggregation, and simplification. For the visualization, QGIS is utilized: one project containing all layers with their visualizations served as WMS. It enables team members to view the current map and access all the data without storing it individually locally on their computer. Additional web mapping services were set up to provide georeferenced scans of other available maps of the region to enable a comparison and evaluation of the new derived topographic map product.\n\nBecause of the wide range of tasks, the work is split into several work packages and ongoing subprojects. Students' master theses within the International Cartography Master program \u2013 a cooperate offer of TU Dresden, TU M\u00fcnchen, TU Wien, and University Twente contributed significantly to the project by implementing and evaluating selected methods required for the map derivation.\n\n[i] Grinberger, A. Yair, Moritz Schott, Martin Raifer, and Alexander Zipf. \u201cAn Analysis of the Spatial and Temporal Distribution of Large\u2010scale Data Production Events in OpenStreetMap.\u201d Transactions in GIS 25, no. 2 (April 2021): 622\u201341. https://doi.org/10.1111/tgis.12746.\n\n[ii] Holob\u00e2c\u0103, Iulian-Horia, Levan G. Tielidze, Kinga Ivan, Mariam Elizbarashvili, Mircea Alexe, Daniel Germain, Sorin Hadrian Petrescu, Olimpiu Traian Pop, and George Gaprindashvili. \u201cMulti-Sensor Remote Sensing to Map Glacier Debris Cover in the Greater Caucasus, Georgia.\u201d Journal of Glaciology 67, no. 264 (August 2021): 685\u201396. https://doi.org/10.1017/jog.2021.47.\n\n[iii] Geisth\u00f6vel, Roman, and Lorenz Hurni. \u201cAutomated Swiss-Style Relief Shading and Rock Hachuring.\u201d The Cartographic Journal 55, no. 4 (October 2, 2018): 341\u201361. https://doi.org/10.1080/00087041.2018.1551955.\n\n[iv] Shean, David E., Oleg Alexandrov, Zachary M. Moratto, Benjamin E. Smith, Ian R. Joughin, Claire Porter, and Paul Morin. \u201cAn Automated, Open-Source Pipeline for Mass Production of Digital Elevation Models (DEMs) from Very-High-Resolution Commercial Stereo Satellite Imagery.\u201d ISPRS Journal of Photogrammetry and Remote Sensing 116 (June 2016): 101\u201317. https://doi.org/10.1016/j.isprsjprs.2016.03.012.\n\n[v] Lachapelle, G\u00e9rard, Paul Gratton, Jamie Horrelt, Erica Lemieux, and Ali Broumandan. \u201cEvaluation of a Low Cost Hand Held Unit with GNSS Raw Data Capability and Comparison with an Android Smartphone.\u201d Sensors 18, no. 12 (November 29, 2018): 4185. https://doi.org/10.3390/s18124185.\\n\\nMathias Gr\u00f6be\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/ETS7XY/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/18 Sara Zollini - Maria Alicandro.mp4", "persons": "Alicandro Maria, Sara Zollini", "pretalx_id": "JW3X9G", "title": "FOSS4G 2022 | Design and implementation of an Open-Source Web-GIS to manage the public works of Abruzzo Region: an example towards the digitalization of the management process of Public Administrations", "description": "According to the goals of the European Communications \"2030 Digital Compass: the European way for the Digital Decade\" and \u201cOpen Source Software Strategy 2020 \u2013 2023\u201d regarding the digitalization and the use of the Open-Source solution inside the Public Administrations, this paper presents the approach followed for the realization of an Open-Source Web-GIS to transfer all the information assets related to the public works, that must be judged by the Regional Technical Administrative Committee (C.R.T.A). The developed Web-GIS consists of a platform to support the \u201cCivil Engineering\u201d authority of the Abruzzo Region in the management of the public works during their whole administrative process.\nIn particular, the main aims of the Web-GIS are:\n\n - to manage in a unique shared geospatial database the public works, that must be judged by the C.R.T.A. of the Abruzzo Region;\n - to monitor the activities and the life-cycle of the public works;\n - to share information related to the public works both with other regional authority offices and with citizens.\n   In general, the creation of a WebGIS starts from a project created on the client side which, in a subsequent phase, will be loaded on a server to allow the visualization, interaction and distribution of the information among multiple users at the same time.\n   In this case, the creation of GIS project for the management of geo-referenced territorial and alphanumeric information for their description required a careful study of the needs of the  \u201cCivil Engineering\u201d authority of the Abruzzo Region and a definition of the contents of the GIS platform, passing through the documentation and the archives to consult and implement in the GIS. Finally, the choice of the output to be presented was made, also in relation to the type of end-users that will have to manage (regional authority employees) and view (citizens) the published information.\n   In order to properly design the requested Web-GIS application, as a first step the structure of the geodatabase has been designed locally into the Qgis software, one of the most famous open-source GIS software. Among the main geodatabase formats, the geopackage, an open, OGC (Open Geospatial Consortium) standards-based, platform-independent, portable, self-describing, compact format for transferring geospatial information, has been selected. The GeoPackage standard describes a set of conventions for storing it within a SQLite database. The geopackage format has been selected considering the geometric entities of the public works that must be stored within the database, together with their attributes, that consist of points, multi-lines, and multi-polygons elements. In fact, the public works that must be judged by the C.R.T.A. of the Abruzzo Region can be buildings (strategic or scholar buildings or healthcare constructions), road works, hydraulic works, or land defense. These public works, as required by the Abruzzo Region, do not have an exact type of geometry but, depending on its type and the type of project can be represented in the most appropriate way to understand the intervention itself. The geopackage format allows storing all the information related to the public work in a single file, simplifying their management.\n   The use of QGIS solution was made keeping in mind the idea of using LizMap software to publish directly the contents of the geodatabase designed locally in a simple way. Lizmap is an open source software designed by 3Liz, a service company revolving around QGIS software, which facilitates the publishing of web mapping applications from QGIS Desktop using QGIS Server as Map Server. Another important aspect for this choice consists in the fact that QGIS environment is well-known among the public authorities employees and this simplified the interaction during the design phase of the database. This allows verifying if the structure of the designed database satisfies all the requirements of the \u201cCivil Engineering\u201d authority of the Abruzzo Region. In addition, in the future, the \u201cCivil Engineering\u201d authority of the Abruzzo Region will be able to modify or update autonomously the public works that will be subject to the judgment of the Regional Technical Administrative Committee (C.R.T.A), directly in QGIS Desktop.\n   After the realization of the project in Qgis Desktop, in order to share the map online, the Lizmap plugin inside Qgis Desktop was used to configure the publishing options, i.e. scales, base layers, metadata, etc. . Once the file configuration is compiled, it is possible to synchronize the working folder with the Qgis Server. When synchronisation is complete, the QGIS project can also be accessed on the Internet, through the Lizmap Web Client application using a web browser. Lizmap Web Client is installed on QGIS Server in order to insert projects and it allows to configure the project and the displayed web page. All this step can be performed locally, (intranet network) and finally, the project and the created settings files have to be transferred to the region geoportal of Abruzzo Region. In conclusion, the use of Lizmap to transfer Qgis Desktop projects on the web represents a good solution to move Public Administration towards the use of Open-source solutions and towards the digitalization procedures required by the European Commission. In addition, this tool had the purpose of ensuring maximum transparency to citizens who, although not insiders, can access the geoportal to see how the funds allocated by the Region, the Italian Nation, and the European Community are distributed and spent.\\n\\nAlicandro Maria\\nSara Zollini\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/JW3X9G/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-24/Room_Hall_3A/19 Marc Bohlen -Rajif Iryadi.mp4", "persons": "marc b\u00f6hlen, Rajif Iryadi", "pretalx_id": "33PMHD", "title": "FOSS4G 2022 | Who speaks for the forest? Participatory mapping and contested land cover classification in Central Bali, Indonesia", "description": "Overview:\n\nThis presentation will discuss the ongoing effort to map, in unprecedented detail, a forested area in Central Bali, Indonesia, the use and ownership of which is currently a contested question. The presentation will outline the historical and political reasons for the contested nature of the land area under investigation, and then discuss participatory field mapping methods and a collaborative analysis pipeline developed to represent via formal GIS methodologies the land and its use with the needs of different and differing stakeholders in mind.\n\nBackground:\n\nOur research approach is informed by current approaches to community mapping in general [Cochrane2020] and specific to emerging economies, with a particular focus on the conditions in Indonesia [Sulistyawan2018]. In particular, we are studying an area is Central Bali in the vicinity of the Taman Wisata Alam (TWA) Buyan -Tamblingan comprising 1,491 hectare of forest area including Alas Merta Jati [Suryawan2021], part of the Batukaru nature reserve which is estimated to contain sufficient springs to meet Bali\u2019s water needs [Zen, 2019] (Fig. 1). The Alas Merta Jati is contested as it is currently claimed as ancestral lands  (or \u201ccustomary forest\u201d) by the Tamblingan people and at the same time claimed as a state forest by the Indonesian government. While both entities claim to want to protect the forest along fashionable \u201csustainable\u201d principles [Strauss2015], each entity interprets the responsibilities and benefits of sustainable actions in different ways. Subjecting the area to GIS compliant analysis approaches is one way by which differences and commonalities across stakeholders can become tractable.\n\nCollaboration framework :\n\nOur work is coordinated and overseen by a local NGO, the WISNU foundation (https://www.wisnu.or.id/) with which we have a memorandum of understanding outlining work methods, data collection and data ownership as well as ownership of intellectual property, creating formal boundary conditions for an equitable long-term outcome of the project. Moreover, our research team includes GIS professionals from the Indonesia National Research and Innovation Agency with expertise in remote sensing of tropical forests.\n\nData sources and field work:\n\nOur data collection relies on a combination of high-resolution satellite imagery from PlanetScope (PS) provided by Planet Labs (integration of Sentinel-2 data is in progress as well) and field level data collection through inhabitants of the area. PS with a resolution of 3.7 m/pixel containing four channels:  Blue (455 - 515 nm), Green (500 - 590 nm), Red (590 - 670 nm), and Near-Infrared (780 - 860 nm) [Raza et al. 2020]. Our first step follows standard practices. We study the composite\u2019s PS satellite data in comparison with Google Earth (GE) images to identify a first round of land cover features. However, we then also check questionable areas with local informants who collect short video recordings of the actual situation on the ground (Fig. 2) and upload these verification datasets to a shared server. Moreover, our system is set up to support low-tech input data collected with old-fashioned paper and pencil. A handwritten set of longitude, latitude and identified land cover class is sent (via email) to the evaluation team where custom python scripts convert the information to an entry into a vector data set suitable for classification purposes.\n\nComplex land cover classes:\n\nThe single most significant issue we encounter in this project is the fact that local knowledge and local interests are not represented in GIS maps nor in the land cover categories that routinely constitute formal categories in GIS representation. The existing GIS knowledge production pipeline, with its reliance on visual evidence, is not sufficient to address these needs.\n\nFor example, how might one monitor and detect the outcome of efforts of the \"jaga teleng\" (traditional forest guards) as opposed to modern forest regrowth approaches? Even some quotidian and concrete \u201cuse\u201d classes in the study area are resistant to visual-only inspection. Coffee plant farms typically grow together with and often under clove tree gardens and cannot be distinguished even with high-resolution (3.0m/pixel) satellite imagery without additional field level data collection. In general, the land use conditions in Bali are characterized by a variety of mixed uses and mixed conditions, with untouched areas mingling with secondary forests and overgrown light use agricultural areas creating a complex assemblage of \u201cquasi-natural\u201d conditions. And the tropical conditions on the island ensure that an agricultural area that has been harvested or abandoned, regrows to a semi-wild area in months. While this project contains many elements, the image interpretation and metadata creation that can be ingested into a GIS framework to represent some of the convention challenging categories listed above, is by far the most challenging aspect of the effort.\n\nA GIS analysis framework for experimentation and collaboration:\n\nIn order to support the challenging data interpretation work and enable a collaborative testing environment, we have developed a cloud-based GIS environment (COCKTAIL) that combines elements of established QGIS, GDAL, OTB and SAGA environments such that we can create processing pipelines across these various widely used GIS systems and run this software cocktail remotely in the cloud. This allows our research partners to work in their respective time zones and explore different approaches to the data analysis and classification approaches within a shared analysis framework. Importantly, our pipeline records the large collection of local setting and internal evaluation parameters to a file such that each member can easily recreate the output of the other team member experiments. Results are transferred to a shared remote server such that results can easily be visually inspected together during remote meetings.\n\nAt the time of this writing, Cocktail is used in our research group to combine satellite imagery with texture maps, to create change maps (from the start of the datasets to this year) and to perform land cover classification (Fig. 3). Cocktail includes Support Vector Machine, Random Forest and Neural Network classifiers, the suitability of which we are now analyzing in an iterative manner, collecting more data as the need arises (see resources).\\n\\nmarc b\u00f6hlen\\nRajif Iryadi\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/33PMHD/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Modulo_3A/1 Maxime Collombin.mp4", "persons": "Ertz Olivier, Collombin Maxime", "pretalx_id": "GBPPCM", "title": "FOSS4G 2022 | OGC API State of Play - A practical testbed for the National Spatial Data Infrastructure in Switzerland", "description": "# Context and purpose\n\nOGC standards shape a backbone within the OSGeo community in defining a pathway to software implementation toward the standardization of geospatial information and related services ensuring interoperability between FOSS4G software. Since 2016, the OGC has initiated the specification of a new generation of standards based on the OpenAPI so as to facilitate integration in modern web applications and systems.\n\nUnderpinning the OGC API roadmap, the development of all these standards represents a significant amount of activities carried out by various OGC working groups, testbeds and pilots from the OGC Innovation Program. Some standards have been approved, many are still under development and it is therefore not always easy to follow the progress. Indeed, while some geodata infrastructures involving national entities are already deploying this new generation (e.g. Canada MSC GeoMet), some initiatives run a phase of experimentation (e.g. Geonovum Testbed Platform for the Dutch geoportal).\n\nFrom a practical perspective, how can organizations and institutions anticipate to leverage this new generation of standards to deploy a geospatial data infrastructure? This issue is what this article is about, introducing a project that seeks to address it by running an OGC API testbed platform with a special focus to the Swiss context. This project is embedded in the Resources for the NSDI Program (related to the Swiss Geoinformation Strategy) with the purpose to contribute to the upcoming revision of e-government standards regarding geoinformation (e.g. eCH-0056 Geoservices application profile). The project is about a study jointly carried out by swisstopo and complementary academic partners (HEIG-VD, SUPSI, UNIGE).\n\n# Approach\n\nAs a result of the above mentioned complexity and overlapping of existing standards, the project team has applied a benchmark study approach, where different standards are tested in experimental cases and evaluated in comparison of other existing solutions. The outcomes include both quantitative and qualitative results that will be condensed in practical recommendations for implementation and adoption of the OGC API family.\n\nThis research aims at evaluating a selection of different OGC specifications as well as different server and client implementations in order to define e-government recommendations to promote collaboration between authorities, companies and individuals.\n\nThe selected mainstream topic for the experimental cases is about climate change. While not yet connected in a complex pilot study, each case represents one of the required components: from sensing (remote/in-situ) to data visualization and exploration, through data offering and elaboration. The study is organized in three parts:\n\n - The hydro-meteorological monitoring network of the Canton Ticino, which is currently managed using the SOS standard, has been selected as representative of a practical implementation of basic data required for the climate change impact assessment pipeline. The network, which has a 40 years long time-series, is currently composed of 60 stations and 140 sensors observing precipitation, air temperature and humidity, water temperature, river height. Collected information is operationally used by the local administration to design and actuate water resources protection and allocation to guarantee a sustainable management of the resource and the natural environment while protecting from the impacts of extreme events like floods and droughts. The Sensor Things API operational applicability is evaluated by testing this standard to fulfil all the major in place daily practical operations like for example data quality management, data sharing with third parties, data collection from vendor specific sensors and data analyses and visualization.\n\n - Switzerland was the second country in the World after Australia to have an operational satellite Earth Observations (EO) Data Cube. The Swiss Data Cube (SDC) is a tera-scale analytical cloud-computing platform allowing users the access, analysis and visualize up to 38 years (1984-2022) of consistent calibrated and spatially co-registered optical and radar Analysis Ready Data. The SDC leverages the information power of Big Earth Data for monitoring the environment by minimizing time and knowledge required for analysing large volumes of raster data. The derived analytical products provide an effective means to build socially robust, replicable, and reusable knowledge, to generate ready-to-use products supporting evidence-based decisions. Currently, all the data products and their related description (i.e. metadata) are accessible through \u201ctraditional\u201d OGC services such as WMS, WCS, CSW. For example, the Normalized Difference Water Index (NDWI) time-series can be used to estimate and monitor the evolution of vegetation water content over the entire country. The aim of the experimental case will be to use a set of new OGC APIs implemented on top of the Swiss Data Cube to track the evolution of NDWI. To reach this objective we will implement the OGC API Coverages, Processes, EDR, Records, STAC APIs to access NDWI raster data time-series and compute zonal statistics using different administrative units/levels (e.g. national, canton).\n\n - Given past activities of the team project related to portrayal interoperability with OGC standards like WMS, WMTS, SLD/SE, this part aims to challenge a set of specifications of the OGC API, especially Features, Tiles, Maps, Styles and to provide insights about OGC SymCore. At one side, the experimental case will consider outputs from running Geoclimate, an open source geospatial toolbox to compute a set of urban climate related parameters describing a given area of study using OpenStreetMap data as a base. The intent is to make these indicators discoverable and to serve them as data and maps through the OGC API. At the other side, the aim is to address national needs for geodata visualization using the Minimum Geodata Models (MGDM) in conjunction with their styling models, testing how the symbol description may be encoded in a standard way with modern formats and techniques to build styles and symbology (i.e. from SLD/SE to GeoCSS with or without cascading, etc).\n\nFor all these experimental cases, FOSS4G are deployed, especially at the server level with FROST, pygeoapi, Geoserver, QGIS Server. The results are useful for developers, government agencies and organizations who want to implement and use the new family of OGC standards.\\n\\nErtz Olivier\\nCollombin Maxime\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/GBPPCM/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Modulo_3A/2 Clara Tatton.mp4", "persons": "Clara Tattoni", "pretalx_id": "GDD8XU", "title": "FOSS4G 2022 | Effect of water level on bird habitat at lake Maggiore", "description": "Lake Maggiore and the Ticino River are water bodies shared by\nItaly and Switzerland: they are important resources for drinking\nwater, irrigation and hydroelectricity generation as well as for\ntourism and biodiversity. The cross-border character and the\noften conflicting needs of the different users make the shared\nmanagement of this resource very complex, but of great importance.\nThe `\u2018Parchi Verbano Ticino\u00b4\u2019 project, funded by Regione\nLombardia / EU \u2013 INTERREG Italia Svizzera 2014/2020, aims\nto study the effects of water levels of the lake on various environmental\ncomponents with a particular focus on protected\nnatural areas. The level of the lake is regulated by a dam located\nat the southern shore of the lake. In this framework, this\nstudy aims to analyse the effect of water level on bird migration\nby: 1) Calculate the inundated bird habitat using a simulation\nbased on measured water level; 2) calculate the inundated habitat\nfrom Sentinel-1 remote sensing imagery 3) Use the flooded\narea derived from S1 as ground truth to validate the previous\nsimulation 1).\nThe study area is centerend around Bolle di Magadino (Switzerland,\n8\u00b051\u201956.90\u201dE, 46\u00b09\u201942.17\u201dN, a protected wetland located\non the north shore of lake Maggiore at the confluence with the\nTicino river. The area is a recognized nesting and stopover\nsite for birds, listed as a Ramsar Wetland of International Importance\nand as Important Bird and Biodiversity Area (IBA).\nWe defined the habitats of interest  using\na vegetation map provided by Fondazione Bolle di Magadino.\nThe vegetation types collected from a phytosociological field\nstudy were aggregated into ten land cover classes that described\nthe habitat types and land use. The final habitat map covers\nan extent of 6.7 km\u00b2, including the 1500 ha of wetland called\nBolle di Magadino. Daily passage of migrant birds have been\nrecorded at Magadino ringing station and since 2019, traditional\nnet captures were coupled with an Avian Vertical-looking Radar\nIn this study we focus on the following periods, during which\nbird monitoring systems were both deployed: P1: 2019-05-01\u2013\n2019-06-20; P2 2019-10-01\u20132020-02-20 and P3 2021-02-01\u2013\n2021-07-20.\nThe lake level measured at the hydrological station of Locarno\n(CH) was used to determine the inundated area in GRASS GIS\nusing ther.fill module (GRASS Development Team, 2022) and\na DTM that included the lake bathymetry (cell size 0.5 m). The\nlake level fluctuated between 192.3 and 194.9 m.a.s.l. over the\nstudy period, with a minimum in April and May, when the waters\nare used to irrigate the rice fields downstream, and a maximum\nin late autumn.\n\nWe used the Google Earth Engine Platform (GEE) (Gorelick et\nal., 2017) to extract Sentinel-1 Synthetic Aperture Radar (SAR)\nimages (ESA, 2021) as they are suited for surface water mapping\nand not affected by cloud coverage (Ovakoglou et al., 2021).\nWe used Edge Otsu Algorithm with terrain correction (Markert\net al., 2020) to estimate the inundated areas of the collection of\na total of 236 images for the three time periods when bird migration\nwas also monitored. The calculation was implemented\nGEE with the approach described by Gorelick et al. (2017) calibrating\nthe threshold for our study area, adapting the code provided\nby Open Geo Blog (2021). The inundated areas were then\noverlapped with the land use map in order to estimate the extent\nof the submerged vegetation over the three time period defined.\nThe resolution of all maps was 10 m, except the DTM that has\n0.5 m, the CRS used in this work were WGS84 in GEE and the\nlocal CRS GCS CH1903 for all the other analysis.\nThe area covered with water, according to S1, varied between\n103.9 and 471.7 ha (210+- 83.6), some of the surface is a permanent\nwetland so it is never completely dry. Each habitat was\naffected differently by the flooding: when the water was at its\nhighest, croplands were completely inundated, grasslands and\nreeds were submerged for 80% of their extent whereas urban\nareas and infrastructures were not affected (less than 1% underwater).\nThe flooded area calculated by filling the terrain model\nat the level of the ranged from 130.4 to 248.90 ha (208+- 48.6).\nThe correlation between inundated areas obtained using r.fill in\nGRASS and S1 on the same dates was fair for P1 and P2, but\nnot for P3, when the water of the lake were taken for irrigation,\nbut the habitats were flooded by rainfall. An interpolation of the\nflooded from S1 is a more efficient way to obtain an estimate of\nthe flooded habitat on a daily basis, that is necessary to study\nits effect on migratory birds.\nThe results presented here will contribute to the definition sustainable\nmanagement tools of water management of lake Maggiore\ntaking into account the effect of lake level on biodiversity\nin general and on bird habitat in particular.\\n\\nClara Tattoni\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/GDD8XU/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Modulo_3A/3 Michele Tobias.mp4", "persons": "Michele Tobias", "pretalx_id": "JFWQQM", "title": "FOSS4G 2022 | Classifying American Viticultural Areas Based on Environmental Data", "description": "Introduction: Legally defined appellation areas are used by governments throughout the world to demarcate geographic areas that produce agricultural products, such as wine, cheese, or preserved meats, with a specific quality or set of characteristics.  In the United States, the American Viticultural Areas (AVAs) define wine growing areas that are distinctly different from others.  These boundaries are created by the US Alcohol and Tobacco Tax and Trade Bureau (TTB) through a legal process and the definitions are published in the United States Federal Register in narrative form defined using United States Geological Survey (USGS) topographic maps for their landmarks. Despite their geographic definition, a full spatial dataset of these boundaries following the legal definitions did not exist until they were created by a team of researchers led by the University of California Davis\u2019 (UC Davis) library.  The purpose of the dataset is to produce open data suitable for use in research and cartography following a well-documented set of methods that represents the official boundary descriptions with as high fidelity as possible. Using the UC Davis AVA dataset alongside datasets defining environmental characteristics such as soils, climate, and elevation, we seek to understand how the characteristics present within the AVA boundaries are similar to each other using a hierarchical clustering process. Through this case study, we will describe the UC Davis AVA boundary dataset and demonstrate a use case for the data.\nData: The UC Davis AVA dataset was created by digitizing the boundary narrative onto the USGS topographic maps described in the legal documents (officially known as the \u201capproved maps\u201d) for each AVA by a team of collaborators at UC Davis, UC Santa Barbara, and Virginia Tech University, as well as community volunteers. For each boundary, we recorded attributes including an identifier, the official name of the AVA, any synonyms for the name, the dates the AVA officially was recognized, the start and end date for the given polygon, who petitioned to define the AVA, which TTB staff member wrote the official documents, the list of approved maps, the list of maps used to digitize the boundary (to record any necessary substitutions), and the official boundary description.  In addition to the currently defined boundaries, we also created a boundary polygon for the previous iterations of any boundaries that have undergone revisions.  The dataset is stored in geojson format in a publically available GitHub repository and updated as AVAs are created or amended.\nFor each AVA, we summarized the environmental data over the area of the polygon. The PRISM dataset (from Oregon State University) provided the climate data (30-year climate normals for precipitation and temperature) and elevation data in raster format with an 800m cell size. For each variable, we calculated the mean and the range within the AVA boundaries.\nWe also plan to expand this analysis over the coming weeks to include additional environmental characteristics available from PRISM, such as vapor pressure and solar radiation that would be important considerations for grape growth, as well as soil data from the United States Department of Agriculture\u2019s (USDA) SSURGO (Soil Survey Geographic) soil dataset.  SSURGO is a spatially-enabled dataset of soil characteristics for the United States. It includes geologic soil series names as well as the soil\u2019s chemical attributes.\nAnalysis: For each attribute, the value at each AVA was assigned a z-score, calculated as the mean of the attribute field subtracted from the value and divided by the standard deviation of the field. This was done to normalize the data and reduce the effect of differing scales of measurements (for example, depth of precipitation compared with temperature in degrees Celsius). To assess how similar any given AVA is to other AVAs, we performed a hierarchical clustering analysis using R\u2019s hclust() hierarchical clustering function.  This tool uses a dissimilarity matrix to assign each polygon to a hierarchical series of groups based on how similar (or dissimilar) each polygon is to each other. The results can be displayed in a dendrogram to visualize the structure of the classes. The classes can also be used to create a map of the AVAs to help interpret the groups.\nResults: Preliminary results group AVAs into clusters that appear to be somewhat based on geographic regions, but not entirely. When the dendrogram is cut into 6 groups, the AVAs in the eastern half of the country primarily fall into one group, however, the western AVAs comprise the remaining 5 groups. This could be driven by the higher degree of variation in elevations, precipitation, and temperature in the west.  In the southwest, the AVAs appear to correspond to one group, however, the west coast states have many groups, including some AVAs that correspond with the eastern group. Expanding the analysis to include additional environmental factors will likely clarify some of these groups, perhaps defining more variation in the east. This paper will include maps and diagrams that clearly show the relationships between the groups.\nDiscussion: Investigating the relationship between the AVA boundaries is an important exercise. With the availability of the AVA boundaries as a geographic dataset, we are now able to combine this data with other existing open datasets to better understand the relationship and differences between these areas. All of the datasets used in this analysis are freely available and demonstrates not only the usefulness of the UC Davis AVA dataset but also the depth of the work possible with open data. This particular exploration builds on work I have published with colleagues investigating the Sierra Foothills AVAs in the state of California and the emerging wine growing region in the state of Arizona.\\n\\nMichele Tobias\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/JFWQQM/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Modulo_3A/4 Peter Vogt.mp4", "persons": "Peter Vogt, pierrick rambaud", "pretalx_id": "KB7UV9", "title": "FOSS4G 2022 | Tackling the challenges of software provision", "description": "1. Introduction\n\nFor most end-users, the term \u2018software\u2019 is equivalent with executing a given application to obtain a desired result. Moreover, the highest importance is usually attributed to the software being free to use. Besides intuitive use, a key requirement for success and wider acceptance of a software application is easy access, which is often facilitated though open-source projects. While users naturally only care about stability and functionality of the software, software developers often see their task completed once the application reaches a certain degree of maturity and its source code is made available. However, in addition to ease of use and targeted software development, a third component in the life cycle of software design [Vogt 2019] is the software provision. The importance of adequate software dissemination entails a wide range of aspects, which are often undervalued but are crucial to best meet end-user expectations and to achieve the highest application acceptance.\nIn this manuscript, we outline a perspective on approaches to appropriately address issues of software provision aimed at promoting software in an efficient way. We illustrate the motivation and features of various aspects of software provision on the recently published software GWB [Vogt et al., 2022] [1] and its implementation on the FAO cloud computing platform SEPAL [2].\n\n 2. Software provision\n\nThis section summarises reflections on various aspects when disseminating a software application.\n\n - Source code: The provision of the source code is often perceived as a final product delivery. However, most end-users cannot make any use of the source code because they do not understand the programming language, do not know how to compile it or how to properly link required dependencies. The large number of Linux distributions provides an additional challenge due to varying inter-dependencies of distribution-specific compiled libraries and packaging policies. Packaging - the conversion of source code into a functional executable binary - is a science on its own and is beyond the skills of a typical end-user.\n\n - Target platform: Maximum outreach is achieved through a software setup that will work on as many platforms and operating systems (OS) as possible.\n\n - Software packaging: The scope of packaging is to bundle the entire application into a single archive, including or linking OS-specific dependencies, pre- and post-installation instructions, and the integration into the OS via menu entries. Examples are rpm and deb-packages (Linux), dmg-packages (macOS), and exe/msi-packages (MS-Windows). Packaging allows for efficient system-wide software management: installation, upgrades, and removal of the application and provides application access to all OS users. However, it also requires administrator rights, which are not available on many secured or closed IT environments, such as in government agencies, where users may fully access a limited OS-space only, i.e., their $HOME directory. Yet, this situation can be addressed by setting up the software and all required components in a self-contained single directory, which is then compressed into a self-extracting installer. Any user can then download such a standalone installer, extract it and have full access to the application without administrator rights. A similar result can be achieved with a Docker container [3].\n\n - Documentation: Documentation is crucial for software adoption, including a user manual, product sheets with application examples, and guided instructions in workshop material. The manual should also be completed by a user community to help end-users answer the questions they will raise while using the software. Developers of the tools should be actively involved in tackling these questions [Srba et al., 2016].\n\n 3. Application\n\nThe GuidosToolbox Workbench (GWB) [Vogt et al., 2022] provides various generic image analysis modules as command line scripts on 64-bit Linux systems.  In this section we use GWB to exemplify how we addressed the software provision points mentioned before.\n\n - Source code: in addition to the distribution-independent compiled executables we provide the plain text source code for all modules in a dedicated subdirectory of the application.\n - Software packaging: all modules are launched via customised Bash scripts and setup in the IDL programming language [4]. Because IDL provides its own set of highly efficient processing libraries, all scripts and required libraries can be stored in a single, distribution-independent application directory. Combined with customised packaging setup-files, this archive is then converted into distribution-specific packages for common Linux distributions. In addition, we provide a generic standalone installer using the makeself [5] archiving tool. The standalone installer can be used on any Linux distribution for either, system-wide installation, or installation in user space on restricted systems, i.e., under $HOME. All installer packages include two sample images and module-specific usage descriptions, aimed at generating sample output illustrating the features of each module.\n - Target platform:  With its focus as a server-application, GWB is setup for the Linux OS, which can also be used on a regular desktop PC. The installation on cloud computing platforms, including an interface to upload/download personal data, greatly enlarges the outreach into the user community and allows usage of the software from any device having a Web browser and Internet access. A Jupyter [Kluyver, T., 2016] based application was developed within the SEPAL platform [2]. This application uses widgets and interactive displays to help the end-user provide personal data to the software. This application is developed in Python using the sepal-ui [8] framework, embedding a fully independent set of requirements. As the application is run using the voila dashboarding tool [QuantStack, 2019], the end-user is never confronted with the CLI, vastly improving the scope of potential end-user to non-IT experts.\n - Documentation: the project homepage [1] provides a brief overview and installation instructions. Highly detailed usage instructions are available on SEPAL for the command-line use [6] and the interactive Jupyter dashboard [7].\n\n 4. Conclusion\n\nSoftware provision is an often overlooked yet critical component in software design. It comprises various aspects, which when addressed appropriately, can make a great impact in the promotion, outreach and acceptance of a software application.\\n\\nPeter Vogt\\npierrick rambaud\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/KB7UV9/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Modulo_3A/5 Robert Spang.mp4", "persons": "Robert Spang", "pretalx_id": "MENQ73", "title": "FOSS4G 2022 | Making Sense of the Noise: Integrating Multiple Analyses for Stop and Trip Classification", "description": "### Motivation & Contribution\n\nMobility researchers using GPS first obtain raw coordinates and timestamps from GPS instead of the variables they're interested in. Conversion is needed to acquire, for example, the time spent out of home, the number of revisited places, or the total time spent on the go. All of these rely on the ability to precisely identify stops and trips and are therefore fundamental when it comes to mobility research.\n\nThe commonly adopted strategy involves a combination of a distance and a time threshold to identify significant places (Ash- brook and Starner, 2002, Ye et al., 2009). Here, GPS records are grouped together, if they lie within such a pre-defined radius and time. When we planned the technical basis for a mobility intervention study, we tested several existing systems based on this approach. We observed, on the one hand, significant segmentation of the identified stops, due to the relatively large amount of signal noise. On the other hand, we could only identify stops having a duration greater than a pre-defined time threshold, usually five minutes. Hence, the temporal resolution of this analysis was sub-optimal. Reduced this threshold, lead to an increased number of falsely identified stops (false positives) and segmentation. To solve this, we developed a modern stop and trip identification algorithm.\n\nFor a human annotator, this task is fairly easy: when dwelling on a spot, the GPS records scatter around the true position because of its imperfect signal. Records obtained from a trajectory through an environment are clearly distinguishable - although the imperfect signal diverges from the true position similarly. This observation inspired us to create a new algorithm around the idea of investigating the signal patterns, and therefore the geometric properties of the signal noise.\n\nWe describe the algorithm's mechanics in detail and discuss its design decisions. Further, we provide benchmark results against established and frequently cited libraries.\n\n### Approach\n\nFundamentally, the algorithm is based on a multitude of different, geometric analyses. Each analysis method is applied to a rolling window of subsequent GPS samples. For example, one metric evaluates the ratio between total path length and the bounding box of the set. Another is concerned with the mean angles between the point vectors. Subsequently, all metrics are combined to form a majority-based classification decision for each individual GPS sample. This way, the different methods can compensate for a wrong decision of a minority of the metrics.\n\nIf available, the acceleration of the device is also taken into account to exclude unambiguous periods of non-movement. Therefore, we created a simple metric that transforms a three-dimensional vector of x, y, and z acceleration into a motion score that expresses the amount of physical movement of the recording device.\n\nThe labels of individual GPS samples are then used to aggregate stop intervals. In the last step, the resulting stop intervals are filtered. Therefore, each interval is compared against the neighboring ones to decide if a) it should be kept as it is, b) if it should be merged with a close stop-interval to reduce segmentation, or c) if it should be discarded.\n\n### Validation\n\nTo test the accuracy of our analysis approach, we benchmarked the system against the built-in methods for stop and trip detection of Moving Pandas (Graser, 2019) and Scikit Mobility (Pap- palardo et al., 2019). These represent a large share of the most commonly used tools for mobility research.\n\nTo test the classification performance, we created a large dataset containing trajectories from over 126 days of everyday life and captured 692 stops.\n\nThis reference acts as ground truth for the comparison of different frameworks. We investigate sample-by-sample classification metrics (accuracy, precision, recall/sensitivity, specificity, and F1) and stop/trip interval specific metrics (stop-counts, several metrics to quantify the number of detected stops against the reference, such as % matched reference stops, absolute duration error, missed stop duration, absolute start deviation, absolute end deviation, and position deviation). To ensure a fair comparison of the algorithmic approaches, we did not take the acceleration data into account, as the reference systems do not support filtering stop and trip intervals using this kind of data.\n\n### Results & Discussion\n\nOur Stop & Go Classifier outperforms other systems in most metrics: it identifies more stops correctly, the stops it misses are shorter in duration, and the start and end times of the identified stops are almost twice as precise as the closest competitor.\n\nThe core ideas of the system are a) it uses unfiltered, raw GPS data, b) it analyzes these regarding their geometric properties, and c) it uses multiple scoring mechanisms to create one solid classification.\n\n### Code Availability\n\nThe Stop & Go Classifier is free software under a BSD 3-Clause license. The repository includes a reference implementation of the algorithm and small usage examples: https://github.com/RGreinacher/Stop-Go-Classifier\\n\\nRobert Spang\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/MENQ73/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Modulo_3A/6 Nobusuke Iwasaki.mp4", "persons": "Nobusuke Iwasaki", "pretalx_id": "M9WUSQ", "title": "FOSS4G 2022 | Client-side Web Mapping system for vineyard suitability assessment", "description": "Currently, various kinds of geospatial data are provided as open data/or map tile data. This implies that geospatial data have become easier to obtain and use than older data with traditional licenses and formats. By combining map tile data with Web Mapping clients, such as Open Layers and Leaflet, we can browse maps of any location without complicated procedures, i.e., downloading data, transforming coordinate system, extracting area of interest, and installing software. These web mapping technologies have been developed mainly in the field of human interpretation of map images.\n\nIn addition, there has been the development of technologies for usage of map tiles not only background image of Web Mapping, but also processing and visualizing data in a client-side Web browser.   The Geological Survey of Japan (GSJ) has proposed Data PNG and related format (1) for distributing data as map tiles. This format provides data in the PNG format which allows retaining numerical attributes, such as temperature, elevation, and geological classification. It is also possible to develop web applications with good responsiveness to user requests and promote diverse data use (Nishioka, 2019). The GSI published a demonstration site for the Data PNG tile (2) (3). Kitao (2020) developed a Web application for visualizing mapping point cloud data provided as Data PNG. Mapbox Terrain-RGB provides elevation data in PNG format and Mapbox GL JS visualizes these data as a 3D map. These applications were implemented with the capabilities of WebGL. WebGL is a cross-platform, open web standard JavaScript API for 2D and 3D graphics in modern Web browsers that allows the GPU-accelerated usage of image processing without the use of plug-ins.\n\nAs described above, there are many applications for client-side data visualization using WebGL. However, an implementation of data analysis using WebGL, especially the map algebra function, has not been progressively developed. This paper aims to develop map algebra functions for Data PNG tiles with WebGL in a client-side Web mapping system.\n\nIn this study, we attempted to develop map algebra functions for vineyard suitability assessment in Nagano Prefecture, Japan. In recent years, \u201cJapan Wine,\u201d made exclusively from grapes grown in Japan, has been gaining international recognition, and new wineries in Japan are also increasing. Thus, there is an urgent need to provide information to support the selection of appropriate vineyard sites and grape varieties. There have been attempts to assess the suitability of agricultural fields for crop production applying GIS. Despite these efforts, suitable site evaluation of vineyards has not been fully disseminated due to the lack of the following components: (1) sufficient quality, quantity, and accurate information necessary to determine the suitable site; (2) appropriate criteria for evaluating suitable sites based on the information, and (3) methods for providing evaluation results to consumers, such as new farmers. Therefore, we attempt to develop the client-side Web mapping system, using only a Web browser without any special skills and specific software, which enables new farmers to evaluate suitable sites for vineyards.\n\nA variety of environmental information is required for assessing vineyard suitability. In this report, we converted spatial information about geology, soils, topography, and meteorology, which is available as open data, to Data PNG tiles with FOSS4G tools, such as QGIS, TileMill, and MBUtil for suitability assessment. The vineyard suitability assessment system consists of the following map algebra functions:\n\n 1. Generate assessment values from a Data PNG tile layer by performing quadrature calculations, specifying the order of operations using parentheses, and classification based on logical operation formulae.\n\n 2. Comprehensive assessment function that performs a quadratic calculation, specifies the order of operations using parentheses, and classification based on logical operation formulae between the layers generated by the above procedure.\n\n 3. Vineyard suitability visualize function based on the comprehensive assessment\n\nThe Web Mapping interface was developed with Leaflet, which has a graphical interface to input map algebra formulae and a function to display and export the image of vineyard suitability based on the comprehensive assessment result described above. A prototype of the vineyard suitability assessment system is available in the following URL: https://wata909.github.io/web-map-algebra/index_e.html.\n\nIn this system, data used for assessment are provided as Data PNG tiles, and a map algebra function is performed by WebGL on a client-side. In other words, unlike many other Web Mapping systems, our system does not require server-side systems and/or middleware and can be operated using only a web browser. This means that various entities can be operated on the same system at a low cost or on a free Web service, such as GitHub pages. Additionally, the functions implemented in this system can be applied to various evaluations using the map algebra functions.\n\nHowever, our system contains only seven items for assessing suitable locations, which is not sufficient. The arithmetic functions of the system are limited to four arithmetic and logical operations, and it is not capable of implementing the complex model calculations required for highly realistic assessment. We are currently constructing a suitability assessment model using machine learning, information on the distribution of vineyards obtained from field surveys, and various environmental factors derived from field monitoring and published open data. In the future, we will use these data to improve the system and make it more practical.\\n\\nNobusuke Iwasaki\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/M9WUSQ/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Modulo_3A/7 Moritz Schott.mp4", "persons": "Moritz Schott", "pretalx_id": "MCGBBT", "title": "FOSS4G 2022 | OpenStreetMap Element Vectorisation - A tool for high resolution data insights and its usability in the land-use and land-cover domain", "description": "# Introduction\n\nOpenStreetMap (OSM) has evolved to one of the most used geographic databases. It is a major knowledge source for many geographic topics addressed by researchers, professionals and the general public. To satisfy these diverse needs and capabilities, the linked communities surrounded the project with an ever growing ecosystem of analyses tools (e.g. OSM Contributors, 2022). The most prominent analysis topic is data quality (Senaratne et al. 2015) where e.g. intrinsic indicators are used to estimate completeness (Br\u00fcckner et al. 2021). Furthermore the community is also interested in insights such as leader-boards or activity reports (e.g. Neis, 2022). In recent years analyses have also more and more shifted towards doing large scale analyses (e.g. Herfort et al. 2021).\n\nThis diversity of tools can be a challenge for data users who will find themselves in a universe of highly specialised or complex tools using different programming languages, platforms, interfaces, output formats etc. While there have been efforts to provide users with higher level data insight and analyses platforms, these still mostly concentrate on or are limited to certain topics or regions. To our knowledge no tool exists to analyse and combine topic independent aspects of the data at the highest possible resolution: single OSM elements.\n\nThe presented software (available at https://gitlab.gistools.geog.uni-heidelberg.de/giscience/ideal-vgi/osm-element-vectorisation) sets out to bridge this gap by integrating multiple aspects of the OSM ecosystem into one workflow that allows the quantitative assessment of selected OSM elements or all elements in a defined region. This enables new insights in a formalised and easy to use manner. The result is a vectorisation of single OSM elements (sometimes also called embedding or feature construction). By producing a machine readable result, the tool can be used for manual data investigations as well as for the ever growing field of machine learning where it can be linked to a range of labels.\n\n# Software\n\nThe tool is centred around a python package providing a command line interface suitable also for novice users. It draws on other sources where necessary such as POST-requests and Java. Further data processing is done using the R scripting language while all data is stored in a PostGIS enhanced PostgreSQL database and can be exported automatically to .csv-files. The AGPL v3 license as well as the code structure and documentation enable others to also use it as a framework to implement their own analyses logic in combination with the current procedure. A default setup using Docker is provided for fast installation including a minimal example. The tool is fully functional and in use in our current research. Yet, it is under active development towards a web interface and functionality extensions. While the development was made with land-use and land-cover (LULC) information in mind, the tool can be seamlessly applied to any polygonal OSM data such as buildings and also supports linear and point data. The tool is resilient towards missing data and can recover from many common issues like failed connections. The backend remains in a sane state throughout the workflow and error messages enable the user to adapt to any failures and simply rerun the tool that will automatically pick up from the last savepoint. Benchmarks have shown that the tool is capable of processing around 1k elements per hour making it a suitable tool for larger analyses of custom regions or element sets.Out of the endless number of possible data aspects, a set of 32 are currently available for the user to choose. These cover aspects concerning the element itself (e.g. object area, geometric complexity and object age) but also the surrounding data (e.g. the mapping saturation and community activeness) and the editors (e.g. their experience, localness or editing software used).\n\n# Application\n\nTo prove its potential, the tool is applied to a set of 1k randomly selected OSM LULC elements. We picked OSM LULC as an example as it has been shown to be valuable for applications such as earth surface monitoring. The results provide a status report on the already available data to the OSM community. It further enables a more informed planning of future activities like organised mapping or data curation efforts and enables data consumers to make informed decisions on data usage by answering the question: What is OSM LULC made of? First, three exemplary hypotheses were tested statistically on a global as well as a continental scale to analyse the triangular relation between elements' size, age and location in terms of population density. In a second step,  k-means clustering was used to identify clusters based on the properties of the OSM objects. Before clustering, the data were standardised and stripped of any geographic information as we were hypothesising that the different clusters might be linked to different geographic regions.\n\nThe results showed that larger objects were more frequently encountered in regions with a lower population density due to the 'natural' factor of higher fragmentation in these areas. Yet, the effect was surprisingly small on a global scale. A general mapping order where areas of high population density are mapped before lower population density areas could not be confirmed globally. This may be caused by a complex interaction between several indicators and regional tendencies, that remains to be fully understood. Regional tendencies were shown e.g. for the age of objects with North America and Europe containing older objects than Africa and Asia. The five k-means clusters formed interesting groups worth further investigation. For example the North American lakes or the complex European elements were each detected as distinct clusters by the algorithm.\n\n# Outlook\n\nOur current and future work will investigate the causes of these insights and link them e.g. to data quality to identify OSM elements that need the communities' attention. The presented tool already enables other data users to join us on this path.\\n\\nMoritz Schott\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/MCGBBT/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Modulo_3A/8 Peter Mooney.mp4", "persons": "Peter Mooney", "pretalx_id": "EGMDJQ", "title": "FOSS4G 2022 | Geospatial data exchange using binary data serialization approaches", "description": "Data-driven innovation, as outlined by Granell et al. (2022), has seen recent advances in technology driven by the continuous influx of data, miniaturization and massive deployment of sensing technology, data-driven algorithms, and the Internet of Things (IoT). Data-driven innovation is considered key in several policy efforts, including the recently published European strategy for data, where the European Commission acknowledged Europe\u2019s huge potential in the data economy by leveraging on available data produced by all actors (including public sector, private sector, academia and citizens). Technologies currently used for the management, exchange and transmission of data, including geospatial data, must be evaluated in terms of their suitability to efficiently adapt to streams of larger data and datasets. As more users access data services through mobile devices and service providers are faced with the challenges of making larger volumes of data available, we must consider how to optimise the exchange of data between these clients and servers (services). For many years JSON, GeoJSON, CSV and XML have been considered as the 'de facto' standard for data serialisation formats. These formats, which enjoy near ubiquitous software tool support, are commonly used for the storage and sharing of large amounts of data in an interoperable way. Most Application Programming Interfaces (APIs) available today facilitate data sharing and exchange, for a myriad of different types of applications and services, using these exchange formats (Vaccari et al., 2020). However, there are many limitations to approaches based on JSON and XML when the volume of data is likely to be large. Potentially the most serious of these limitations is related to reduced computational performance, when exchanging or managing large volumes of data where there are high computational costs associated with (de)serializing and processing these data.\n\nAgainst this background, binary data serialization approaches allowing for the interoperable exchange of large volumes of data have been used extensively within scientific communities such as meteorology and astronomy for decades. In recent years, popular distributors of geospatial data have also begun making use of binary data formats. Examples are OpenStreetMap (OSM) data (e.g. the OSM Planet and OSM Full History Planet files, providing access to the whole OSM database and its history) as well as the popular ESRI Shapefile format's main file (.shp), which also contains geometry data and is stored as a binary data file.\n\nIn this paper we describe the methodology, implementation and analysis of a set of experiments to analyse the use of binary data serialization as an alternative to data exchange in XML or JSON data formats for several commonly encountered GIS workflows. Binary data serialization allows for the storage and exchange of large amounts of data in an interoperable fashion (Vanura and Kriz, 2018). While anecdotal evidence indicates binary serialization approaches are more efficient in terms of computation costs, processing times, etc., there are additional overheads to consider with these approaches including special software tools, additional configuration, schema definitions, etc. (Viotti and Kinderkhedia, 2022). Additionally, there have been few, if any, investigations of binary data serialization approaches specifically for geographical data. Our set of experiments investigates the advantages and disadvantages of binary data serialization for three common GIS workflow scenarios: (1) geolocation point data from an OGC SensorThings API; (2) geolocation point data from a very large static GeoPackage dataset representing the conflation of address data from the National Land Survey of Finland and OpenStreetMap; and (3) geographic polygon datasets containing land cover polygons (currently ongoing work). We consider comparisons of JSON and GeoJSON with two very popular binary data formats (Proos and Carlsson, 2020), namely Google Protocol Buffers and Apache Avro. Protocol Buffers (Protobuf) is an open source project developed by Google providing a platform neutral mechanism for serializing structured data. Apache Avro, another very popular schema-based binary data serialization technique, is also a language-neutral approach which was originally developed for serializing data within Apache Hadoop. Both Protobuf and Avro have wide support in many popular languages such as C++, C#, Java and Python. The full paper will provide detailed descriptions of the implementations of our experiments. However, here we provide a summary of some of the key results and highlights of our analysis.\nAs binary data formats such as Protobuf and Avro are not self-describing schemata and schema definitions are required for each dataset or data stream, these definitions are required for the serialization and deserialization of the binary data files. Any changes in the underlying data models of the dataset or data stream will require a change in the schema definitions.\nFor all of our experiments the serialized binary data files were at least 20% smaller on average than the original non-binary data files. Processing times for binary serialization of data from API sources were approximately 3.7 times faster on average than serialization to JSON or GeoJSON formats. Processing times for binary serialization of the datasets were, on average, at least 10% faster than serialization to JSON or GeoJSON formats.\nIt is difficult to point to a clearly defined set of results which indicate that binary data formats are an overwhelmingly better choice for data exchange than XML, JSON or GeoJSON. While binary data formats enjoy very good expert developer level support in major programming language implementations, this is dwarfed by the near universal levels of support for XML, JSON and GeoJSON in almost all major programming languages.\n\nThere are a number of potential avenues for future, including automated semantic interoperability for binary data serialization using linked geodata, opportunities for more integrated software tool support for binary data processing and further computational experimentation on different types of datasets and services which could benefit from binary data serialization.\n\nThe software implementation is carried out using Python 3 on Ubuntu Linux. All software code is made publicly available via the GitHub repository https://github.com/petermooney/jrc_binarydata. Detailed instructions on how to reproduce and replicate all of the experimental analysis are provided within the repository.\\n\\nPeter Mooney\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/EGMDJQ/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Modulo_3A/9 Massimiliano Cannata.mp4", "persons": "Massimiliano Cannata", "pretalx_id": "NTQNJ7", "title": "FOSS4G 2022 | Tourism, natural protected areas and Open Source Geospatial technologies", "description": "The Covid-19 outbreak has greatly impacted society behaviours fostering proximity tourism and valorising the social role of peri-urban natural protected areas as key locations for outdoor activities [1]. This shift in habits calls for an adaptation in the next years of the offerings and management of these areas to respond to users' expectations of positive experience opportunities in near-by locations [2]. In the context of digital transformation and peri-urban protected areas, this research investigates the contribution that open geospatial technologies can provide in the creation of new economic, social and cultural values to propose solutions and identify gaps or open issues.\nThe adopted methodology is the \u201ccase study approach\u201d, in which real cases are used to design, develop, implement, collect and analyse data to extrapolate information that contributes to a deeper knowledge of the matter. This research is framed in the context of the Interreg INSUBRI.PARKS (www.insubriparksturismo.eu) and among the project\u2019s parks the selected case studies for technological testing are the Parco Gole della Breggia and the Collina del Penz. While being two natural protected areas closely located in the southern part of Switzerland, in the Canton Ticino, they greatly differ for in-place management structure, available offers and users\u2019 type and therefore represents different needs. From the discussion with local tourism organisations and park administrators we have identified three specific aspects that are of particular concern: (a) the creation of 3D digital products, (b) the monitoring of touristic fluxes and (c) the conduction of parks management activities. This work presents the intermediate results of the development and testing of different selected solutions which describes the approach, the issues and the potential of explored solutions with respect to the open source software.\n\n3D digital products - In addition to a more traditional use for conservation scopes and activity planning [3], 3D models can be used to offer positive experiences thanks to an enhanced understanding of specific intangible aspects [4]. For example, in the case study of the Parco Gole della Breggia, it might be difficult for a tourist to fully realise the extent of the anthropic impacts on nature. The area is geologically relevant for the visible calcareous formation hundreds of millions of years old. From 1961 to 2003 the Breggia shores hosted a large cement plant that strongly modified the territory. Today, only a small part of the plant is still in place as a testimonial of the anthropic impacts and element of industrial archeology. To support the perception of the real antropic impact we decide to implement three digital models representing the territory at three key epochs: before the cement plant construction, at the maximum expansion of the plant and at the present state. The present state model can be created by means of laser scanning and photogrammetric surveys while the other two can be realised by digitising historical maps,  technical plans and historical pictures. The investigation identified a workflow based on the evaluation of CloudCompare, Riegl RiSCAN Pro and Cyclone 3DR for 3D survey, Regard 3D; GRASS, QGIS and ESRI ArcGIS Pro for spatial data collection and management; Blender, AutoCAD 3D, Rhinoceros and Sketchup for vector modelling of spatial elements; Nubigon and Potree for a better graphical representation and further web dissemination of the results.\n\nMonitoring of tourtistic fluxes - The monitoring of touristic flux is important for the correct management of the natural protected areas to assure the Tourism Carrying Capacity (TCC) of trails is not exceeded, to assure adequate economic resources are allocated to maintain the assets, to understand the tourist behaviours and consequently develop strategies and plans to maximise the touristic value of the park [5]. While different solutions were proposed to this scope (accelerometers on iron plates and proximity radar sensors) it is important to capture specific tourist characteristics, like for example the presence of animals, the direction and the use of bicycles or cars. To this aim, Machine Learning models can help to automate the collection of such information by image analyses and object detection [6]. The present paper presents a fully open prototype to implement and deploy a real-time tourist monitoring system composed of: sensing device, data communication, data management and data visualisation platform. The system includes the usage of the YOLO open source solutions for image recognition, the OGC SoS open standard and the istSOS implementation for data management and sharing and the open source Grafana software for data visualisation and analysis. The results from the testing of the prototype in two locations for a period of 6 months is presented supplemented with field validation data.\n\nDigital Management of Protected areas - Protected areas are currently managed using different tools that are very often scarcely digitised. This approach does not exploit the potentiality of digitalization and does not foster the capacity to extract insights from data. While different open source project management software exists, none is specifically designed to address natural area management processes. For this reason a novel application, based on an open source platform has been developed and implemented. The cloud solution named Park Asset Management (PAM) is based on the usage of PostgreSQL/PostGIS and OpenLayers in conjunction with KeyCloak authorization platform, the Hasura GraphQL Engine integrated in the Vue.js framework. The containerized application offers the following features: park asset management and information sharing, working task management and execution, rentals management, notification management, offering a map interface and a more classic calendar and table views. This platform enables insights extraction like maintenance cost of itineraries, income from location rental by months and by years, cost and time required to replace items and the frequency of occurrence of events.\\n\\nMassimiliano Cannata\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/NTQNJ7/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/1 Joana Simoes - Antonio Cerciello.mp4", "persons": "Antonio Cerciello, Joana Simoes", "pretalx_id": "R7S8UY", "title": "FOSS4G 2022 | Serving Geospatial Data using Modern and Legacy Standards: a Case Study from the Urban Health Domain", "description": "Urban planning and design play an important role in amplifying or diminishing built environmental threats to health promotion and disease prevention (Keedwell 2017; Hackman, et al. 2019). However, there is still a lack of good evidence and objective measures on how environmental aspects impact individual behavior. The eMOTIONAL Cities project (eMOTIONAL Cities - Mapping the cities through the senses of those who make them 2021) sets out to understand how the natural and built environment can shape the feelings and emotions of those who experience it. It does so with a cross-disciplinary approach which includes urban planners, doctors, psychologists, neuroscientists and engineers.\nAt the core of this research project, lies a Spatial Data Infrastructure (SDI) which assembles disparate datasets that characterise the emotional landscape and built environment, in different cities across Europe and the US. The SDI is a key tool, not only to make the research data available within the project consortium, but also to allow cross-fertilisation with other ongoing projects from the Urban Health Cluster and later on, to reach a wider public audience.\n\nThe notion of SDIs emerged more than 20 years ago and has been constantly evolving, in response to both technological and organisational developments. Traditionally, SDIs adopt the OGC W_s service interfaces (e.g.: WMS, WFS, WCS), which are based on SOAP, the Simple Object Access Protocol. However, in recent times, we have seen the rise of new architectural approaches, which can be characterised by their data-centrism (Simoes and Cerciello 2021). Web-based APIs have numerous advantages, which speak for their efficiency and simplicity. They provide a simple approach to data processing and management functionalities, offer different encodings of the payload (e.g.: JSON, HTML, JSON-LD), can easily be integrated into different tools, and can facilitate the discovery of data through mainstream search engines such as Google and Bing (Kotsev et al. 2020). These APIs often follow a RESTful architecture, which simplifies its usage, while minimising the bandwidth usage. Moreover, the OpenAPI specification (OpenAPI Initiative 2011) allows to document APIs in a vendor-independent, portable and open manner, which provides an interactive testing client within the API documentation.\nOGC has embraced this new approach in its new family of standards called OGC APIs (OGC 2020a). Although still under active development, it already produced several approved standards: the \u2018OGC API - Features\u2019\u2019 (OGC 2022b, the \u2018OGC API - EDR\u2019 (OGC 2022c), the \u2018OGC API Common\u2019 (OGC 2022d) and the \u2018OGC API - Processes\u2019 (OGC 2022e) which provide standardised APIs for ensuring modern access to spatial data and processes using those data.\nThere are many similarities in the process of designing and implementing open source and open standards. OSGeo encourages the use of open standards, like those from OGC and there is even a Memorandum of Understanding between the two organisations (OSGeo 2012). In practice, many long-standing OSGeo projects implement OGC standards and they often contribute to the standards development (e.g.: GDAL, Geoserver, QGIS, OpenLayers, Leaflet). However, in the majority of cases they still implement the legacy W_s standards, rather than the new OGC APIs.\n\nIn the eMOTIONAL Cities project we have set out to create an SDI based on OGC APIs, but realised that we needed to support some legacy standards, because an OGC API equivalent was not widely supported yet. This has led us to create two stacks: one OGC APIs (e.g.: modern) and another one using W*s services (e.g.: legacy). Both stacks rely on FOSS/OSGeo software, and whenever relevant we have contributed to some of those projects. The modern stack includes Elasticsearch and Kibana (Elastic), which add extra capabilities in terms of searching, analytics and visualisation.\nFor the sake of reproducibility, all software components were virtualized into docker (Wikipedia 2022) containers and they are orchestrated using docker-compose. The results are published in the eMOTIONAL Cities public github repository (eMOTIONAL Cities H2020 Project 2021).\n\nDespite its numerous advantages, we still see a lack of adoption of the OGC APIs within most SDIs. In part this could be due to the standards not being well known, but it could also be due to a lack of knowledge about which implementations are available out there, specially as FOSS. In this paper we would like to share our modern SDI architecture, and the reasons for choosing pygeoapi (Kralidis 2019) for publishing data as OGC API Features, Vector Tiles and Records. Although the standards we selected target the Urban Health use case, we believe they are generic enough to be useful for sharing data in other contexts (e.g.: climate change, cross-border datasets).\nWe are confident about a transition to OGC APIs, but we are also conscious that this may take time, and for a period of time many solutions will have to offer both modern and legacy standards.\n\nPlease find the complete list of references on this page: https://github.com/emotional-cities/foss4g_ref/blob/master/references.md\\n\\nAntonio Cerciello\\nJoana Simoes\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/R7S8UY/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/2 St\u00e9phane Gobron.mp4", "persons": "Christophe Muller, St\u00e9phane Gobron", "pretalx_id": "REQLGD", "title": "FOSS4G 2022 | Earth Observation DataCubes Multi-visualization Toolbox", "description": "Context\n\nIt is said that data visualization is as important as the data itself. As the amount of data generated from Earth observation (EO) satellites \u2013 i.e. Copernicus program (Jutz and Milagro-P\u00e9rez, 2020) \u2013 is getting bigger and bigger, we need more ef\ufb01cient tools to deal with this onslaught of data. To help data scientists better extract relevant information from datacubes, we noticed that an under-exploited computer graphics tools could bring new perspectives to specialists. Datacubes are known to be the reference format to handle EO data; several techniques such as Web WorldWind developed by NASA exist to process and interact with them. Recent works have shown focus on the preparation of largescale geospatial data (Mazroob Semnani et al., 2020), a highly technical subject, could bene\ufb01t from optimizations. QGIS is another tool frequently used in the field, that can be enhanced by plugins and can retrieve data from Web platforms. A modern approach to process efficiency is the use of GPUs. Still, when reviewing the use of GPUs to process geospatial data, the emphasis is often put on the parallel processing of geospatial datasets rather than focusing on their visualization (Saupi Teri et al., 2022).\n\nObjectives\n\nOne of the main contributions of this paper is to consider geospatial data using GPU resources for intermediate computation and visualization. Considering the increasing interest to interact with this data directly using Web pages or Notebooks, this article presents tools allowing a program to run on the GPU and display the desired datacubes using the WebGL API. This can result in high performances thanks to its low-level control and possibility to use GPGPU algorithms. WebGL running natively on most web browsers, another bene\ufb01t will be the end-user ease of use. The end goal is to display even large (i.e. 1024^3) datacubes rendered on the \ufb02y in real time on a PC, still well-equipped.\n\nMethodology\n\nTo keep our applied research efforts focused, we have set up an independent international expert advisory group. Indeed, we wanted above all to provide something useful and concrete for the actors in the field. The represented institutes are ESA (EC), EURAC (Italy), GISAT (Czech Republic), Terrasigna (Romany), TU Wien (Austria), VITO (Belgium), and even a former NASA (USA) analyst. They have been regularly interviewed to get constant feedback on the suitability of our developed application, the \ufb01nal goal of our project being to build a toolbox of models to ef\ufb01ciently visualize different EO datacubes formats.\n\nModels\n\nThis paper presents three main models applicable to datacubes from an EO context, some relatively standard and others innovative, still all revisited via the GPGPU architecture.\nImplicit curves model \u2013 This model has two main approaches: discrete and math-based sub-models. Especially adequate to process (x, y) or (x, y, t) datacubes in a 2D or 3D visualization we developed and compared both sub-models with their dependencies. Sets of given iso and \u03b4 values are extracted from the data and stored as sets of curves. They can be displayed in a 2D environment or in 3D with additional information such as: (1) the simulation of the data as a 3D surface; (2) different colormaps for the surface representing yet other external data; (3) surface render in steps to emphasize the given iso and \u03b4 values; (4) user customizable colormaps; and (5), a water level simulation rendering.\n\nDerivative 3D rendering model \u2013 This model is specialized in analyzing (x, y, t) datacubes as a volume where the time t is part of the visualization. Indeed, the aim is to visualize the evolution in time of a geographical area by highlighting the temporal differences within a volume. After selecting the (x, y) region of interest the user selects a reference layer representing the state of an area at a de\ufb01ned time t and a time interval \u0394t. The cumulated differences between the two are visible in a colored sub-volume de\ufb01ned by the time interval. In order to add more contextual information in the visualized geographical area, we have added the possibility to display an additional map (such as topographic data) at the reference layer level within the volume.\n\nJupyter Notebook massive rendering model \u2013 To make the toolset even easier to use, we have developed a visualization model deployable in Jupyter. This model allows rendering of (x,y,z) and (x,y,z,t) data volumes. Two rendering algorithms are already available: (1) the implicit surface simulation for any iso intensity -- but only via the discrete approach -- and (2), an XRay-cast simulation.\n\nDiscussion\n\nResults show our models can process large amounts of data and render them in real-time. Where large 3D datasets would normally become problematic to handle for any GPU, we developed specialized tools to overcome software and hardware limitations. For instance, a 3D datacube can be sorted into a 2D texture to be directly loaded into GPU memory, thus improving performance. When the textures become too big to work with WebGL, their information can be split in the RGBA channels of standard 2D textures for a four-fold decrease in memory use. Furthermore, when displaying our rendering models, and in the case of machines without sufficiently powerful graphics cards, we propose to display only the fraction of the data that interests the user. All of these highly ef\ufb01cient rendering models are assembled together in a toolbox dedicated to datacube visualization.\n\nConclusion\n\nIn this paper we demonstrate an example of application retrieving raw data from a server, formatting it for local use with GPGPU, and rendering it with several innovative models. We developed these tools for a Web application and Jupyter Notebooks to better fit with the needs of data scientists. To better understand the scope of the possibilities of this work, several illustrations are available here: https://bit.ly/3th8JBF. Finally, we would also like to point out that this work has been granted by national funds, therefore our development is open and does not have any external software dependencies.\\n\\nChristophe Muller\\nSt\u00e9phane Gobron\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/REQLGD/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/3 Jaroslav Hofierka.mp4", "persons": "Jaroslav Hofierka", "pretalx_id": "KQ7NSA", "title": "FOSS4G 2022 | Assessing land surface temperature in urban areas using open-source geospatial tools", "description": "Land surface temperature (LST) in urban areas is an important environmental variable considered a reliable indicator of the urban heat island (UHI) phenomenon. LST is affected by various factors such as solar irradiance, cloudiness, wind or urban morphology. Traditionally, LST is observed and recorded by thermal remote sensors. For example, thermal satellite sensors are very popular for assessing the UHI effect on a global scale such as MODIS, Sentinel 3, ASTER, Landsat 7 ETM+, or Landsat 8 TIRS. However, these sensors provide rather low spatial (60 m to 1000 m) and temporal resolutions (several hours to days) of satellite observations that limit the accurate estimation of LST in urban areas for local studies and specific time periods (Mushore et al., 2017), (Hu and Wendel, 2019). Airborne or terrestrial remote sensing can be viewed as another option for capturing higher spatial resolution of thermal data but it is not feasible to be used for large urban areas with increased periodicity. However, the increasing availability of the high-resolution geospatial data and adequate modeling techniques provide an alternative approach to high-resolution estimation of LST in urban areas.\n\nSeveral studies showed the potential of geographic information system (GIS) tools, digital surface models (DSM) and 3-D city models for the estimation of solar radiation in urban areas (e.g., Hofierka and Ka\u0148uk, 2009; Hofierka and Zlocha, 2012; Freitas et al., 2015; Biljecki et al., 2015). Solar irradiance is a key factor affecting LST during daylight periods, especially under clear sky situations. Nevertheless, LST assessment requires a physical model combining surface-atmosphere interactions and energy fluxes between the atmosphere and the ground. Properties of urban materials, in particular, solar reflectance, thermal emissivity, and heat capacity influence the LST and subsequently the development of UHI, as they determine how the Sun\u2019s radiation energy is reflected, emitted, and absorbed (Hofierka et al., 2020b; Kole\u010dansk\u00fd et al., 2021). It is clear, that the problem complexity requires a comprehensive GIS-based approach.\n\nOur solution is based on open-source solar radiation tools available in GRASS GIS, a 3D city modeling and spatially distributed data representing thermal properties of urban surfaces and meteorological conditions (Hofierka et al., 2020a, 2020b; Kole\u010dansk\u00fd et al., 2021) . The proposed LST model is calculated using the methodology implemented in GRASS GIS as a LST module written using a script (shellscripts, Python). In these scripts, the r.sun and v.sun solar radiation models in GRASS GIS were used to calculate the effective solar irradiance for selected time horizons during the day . The solar irradiance calculation accounts for attenuation of beam solar irradiance by clouds estimated by field measurements. The proposed LST model also accounts for a heat storage in urban structures depending on their thermal properties and geometric configuration. The 2D LST model uses the output of the r.sun solar radiation model and a DSM representing urban surfaces and the 3D LST model uses the output of the v.sun solar radiation model and a vector-based 3D city model. Computed LST values for selected urban surfaces were validated using field measurements of LST in 10 locations within the study area with acceptable accuracy.  The proposed approach has the advantage of providing high spatial detail coupled with the flexibility of GIS to evaluate various geometrical and land surface properties for any daytime horizon. The methodology can be used for evaluation of proposed UHI mitigation measures such as increasing albedo of urban surfaces or expanding green areas including green roofs and trees.\n\nReferences:\n\nBiljecki, F., Stoter, J., Ledoux, H., Zlatanova, S., \u00c7\u00f6ltekin A., 2015. Applications of 3-D city models: State of the art review. ISPRS International Journal of Geo-Information, 4, 2842\u20132889. https://doi.org/10.3390/ijgi4042842.\n\nFreitas, S., Catita, C., Redweik, P., Brito, M. C., 2015. Modelling solar potential in the urban environment: State-of-the-art review. Renewable and Sustainable Energy Reviews, 41, 915\u2013931. http://dx.doi.org/10.1016/j.rser.2014.08.060.\n\nHofierka, J., Bog\u013earsk\u00fd, J., Kole\u010dansk\u00fd, \u0160., Enderova, A., 2020a. Modeling Diurnal Changes in Land Surface Temperature in Urban Areas under Cloudy Conditions. ISPRS Int. J. Geo-Inf., 9, 534.\n\nHofierka, J., Gallay, M., Ona\u010dillov\u00e1, K., Hofierka, J. Jr., 2020b. Physically-based land surface temperature modeling in urban areas using a 3-D city model and multispectral satellite data. Urban Climate, 31, 100566.\n\nHofierka, J., Ka\u0148uk, J., 2009. Assessment of photovoltaic potential in urban areas using open-source solar radiation tools. Renewable Energy, 34, 2206\u20132214. https://doi.org/10.1016/j.renene.2009.02.021.\n\nHofierka, J., Zlocha, M.,  2012. A New 3-D Solar Radiation Model for 3-D City Models. Transactions in GIS, 16, 681\u2013690. https://doi.org/10.1111/j.1467-9671.2012.01337.x.\n\nHu, L., Wendel, J., 2019. Analysis of urban surface morphologic effects on diurnal thermal directional anisotropy. ISPRS Journal of Photogrammetry and Remote Sensing, 148, 1\u201312. https://doi.org/10.1016/j.isprsjprs.2018.12.004.\n\nKole\u010dansk\u00fd, \u0160., Hofierka, J., Bog\u013earsk\u00fd, J., \u0160upinsk\u00fd, J., 2021. Comparing 2D and 3D Solar Radiation Modeling in Urban Areas. Energies, 14, 8364.\n\nMushore, T.D., Odindi, J., Dube, T., Matongera, T.N., Mutanga, O., 2017. Remote sensing applications in monitoring urban growth impacts on in-and-out door thermal conditions: A review. Remote Sensing Applications: Society and Environment, 8, 83\u201393. https://doi.org/10.1016/j.rsase.2017.08.001.\\n\\nJaroslav Hofierka\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/KQ7NSA/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/4 Lorenzo Amici.mp4", "persons": "Lorenzo Amici", "pretalx_id": "LHVPAD", "title": "FOSS4G 2022 | Monitoring landslide displacements through maximum cross-correlation of satellite images", "description": "In the last years we have witnessed a huge increase in the availability of free and open multispectral, multitemporal and global coverage satellite imagery. At the same time, new open software tools for exploiting these images have arisen. Given the availability of short-revisiting time open satellite images, this study focuses on the analysis of satellite imagery using free and open source GIS software to identify displacements of single landslides.\nIn particular, the Ruinon landslide was selected as the subject for this analysis. It is situated in Northern Lombardy, Italy, and it is one of the most active landslides of the Alps. The landslide is situated at the base of a Deep-seated Gravitational Slope Deformation, that affects the entire slope up to the summit at 3000 m a.s.l. Two major scarps can be identified: the upper one is a sub-vertical rock cliff of about 30 m in height, while the lower one is characterized by a more widespread debris cover.\nThe general strategy employed in this work for obtaining landslide displacements in terms of direction and magnitude is to apply a local maximum cross-correlation on a multitemporal images stack. This was achieved using GRASS GIS and custom Python scripts.\nThe images were selected from both the Sentinel-2 catalogue, which is free, and the Planet catalogue, available for free for research purposes.\nThe main preprocessing steps are: creation of a suitable multi-temporal stack, clipping the satellite images to the selected AOI and applying cloud masking and an atmospheric correction; image co-registration to ensure that the images become spatially aligned so that any feature in one image overlaps as well as possible its footprint in all other images in the stack; histogram matching to transform one image so that the cumulative distribution function (CDF) of values in each band matches the CDF of bands in another image.\nThe main processing is based on the Maximum Cross-Correlation method implemented on couples of images. The first image of the couple will be refererred to as reference image, and the second one as secondary image. This algorithm was previously applied to land cover changes (You et al., 2017) and to the movement of desert sand dunes (Oxoli et al., 2020). In the developed procedure, the processing phase starts by placing a window in the same position of both images. The window on the secondary image is then shifted in all directions, and a cross-correlation coefficient is computed for each of the shifts. The shifted window with the highest cross-correlation coefficient is selected, and a displacement vector is computed between the center pixel of the reference image window and the center pixel of the new shifted window of the secondary image.\nThe outputs are shifts (in pixels) in X and Y directions which are actually the distances required to register the window of the secondary image with the one of the reference image.\nIt is important to note that the smallest displacement that can be identified by this procedure is a displacement of 1 pixel, i.e. a displacement of 10 m if considering Sentinel-2 data. Therefore, smaller movements cannot be sensed by because of the native resolution of input satellite data. Secondly, errors can arise from the images having differences in terms of co-registration and histogram distribution, since this process highly relies on the images being as aligned and similar as possible.\nFor monitoring the activity of the Ruinon landslide, two different sets of images were considered. The first one consists of one image per year in the period 2015-2020, with the idea to track the evolution of the landslide throughout the last few years. Since the landslide is situated in a mountainous region, it is often covered by clouds, and in the winter months by snow. Because of this, only the best image for each year was selected for the analysis. The other set is composed of three images, one per month, in the period July 2019 - September 2019, aiming at highlighting a large movement that took place in the summer of 2019.\nTo compare and evaluate the performances of the cross-correlation approach, data coming from UAV surveys (provided by the local environmental agency ARPA Lombardia) of the landslide were used. At first, the results obtained with the procedure were compared with the output given by the procedure when applied to RGB images obtained from the surveys, which have a resolution of 1m. The two outputs were found to be very similar, both for the displacement magnitudes and directions. Secondly, photogrammetric point cloud comparisons created from the UAV observations in periods close to the considered ones for satellite monitoring were investigated. In particular, the displacement along the vertical axis was inspected, and accumulation zones were found in correspondence to the largest movements of the landslide detected from the algorithm. Because of this, the results were considered consistent with the data of the surveys.\nThe increased availability of high-resolution multitemporal satellite imagery promotes the use of these images for monitoring purposes. While on the field monitoring can produce very accurate results, a procedure like the one applied in this work has the advantage to be more flexible, scalable and cost-effective than an analysis on the field. The experimental procedure developed in this work led to promising results, despite being a first stage approach to landslide monitoring applying the maximum cross-correlation method. Many approaches were considered, varying the main parameters of the procedure (adding or removing a classification phase, considering different intervals between satellite images, modifying the size of the moving window and others), and the whole process was progressively improved and refined until satisfactory results were achieved.\\n\\nLorenzo Amici\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/LHVPAD/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/5 Markus Neteler.mp4", "persons": "Markus Neteler, Peter L\u00f6we", "pretalx_id": "MAYYPL", "title": "FOSS4G 2022 | OSGeo, Persistent Identifiers and the shape of things to come", "description": "This article is a work in progress report on the introduction and exploitation of persistent identifiers (PID) within the OSGeo Foundation and its software project communities. Following an introduction to the topic of Persistent Identifiers (PID), an overview of the currently achieved states and emerging new opportunities, but also new challenges is given. The latter enables the OSGeo project communities to actively participate in the further development of data-driven open science and the evolution of the FAIR (Findable, Accessible, Interoperable, Reusable) Guiding Principles for scientific data management and stewardship from the original data focus to research software and community software projects. With the rise of the Internet and World Wide Web, Universal Resource Locators (URL) have become common practice to reference web resources. A URL specifies its location on a computer network and a mechanism for retrieving it. However, URLs are not a sustainable practice for scientific citation because they will break once the referenced resource is transferred to another web address; i.e., the original URL cannot be resolved anymore and an error message is returned instead (e.g., HTTP error 404). To counter this, persistent identifiers have been introduced as long-lasting references to web resources, including research data, source code, audiovisual content, and also human individuals or communities. Persistence is always achieved by infrastructure services which resolve the references to their target objects. This requires open standards, operation of infrastructure services and best practices for sustainable long term use. The adoption of PID use in the OSGeo Foundation continues for different application areas, with increasing synergy effects forming the foundation of a greater whole. The introduction of PID in OSGeo started in 2014 for a newly discovered version of the historical GRASS GIS informational video from 1987, which is preserved in the AV Portal of TIB Hannover (https://av.tib.eu/) and can be accessed through a permanent Digital Object Identifier (DOI) (https://doi.org/10.5446/12963, https://doi.org/10.5446/31768). Since 2016, OSGeo conference videos have been collected as a permanent service in the AV Portal, with the collection growing by approximately 100 hours of video recordings annually (pre-Covid). In 2017, the rasdaman software project registered a DOI for the first time for release version 9.4.2 in the Zenodo data repository (https://doi.org/10.5281/zenodo.1040170).  Zenodo is a general-purpose open-access repository operated by the European Organization for Nuclear Research (CERN) since 2015. In 2019, the next DOI registration followed for the GMT software project for release version 6.0.0 (https://doi.org/10.5281/zenodo.3407865). Further improvements of the technical integration of project software repositories hosted on the GitHub platform and Zenodo have enabled a simplified handling of software versioning: When registering a DOI as a PID for a software project, at least two references are created, which are linked to each other: The Concept DOI, which represents the software project as a higher-level intellectual construct, and an initial Version DOI, which references a specific software release. With the integration now available between GitHub and Zenodo, the successive creation of additional Version DOI for upcoming new software releases can be done automatically. Since 2021, the number of DOI registrations by OSGeo software projects has increased significantly. Currently, DOIs are already available for 19 software repositories related to OSGeo projects (https://wiki.osgeo.org/wiki/DOI). More than half of the official OSGeo software projects can already be referenced by means of DOI. All projects that have registered a DOI have chosen an official scheduled release to initiate DOI versioning. Equipping OSGeo projects and content with PID results in significant added value for scientific users, but also for the respective project communities. Well formatted citations for software project DOI can be conveniently generated in thousands of different citation styles by online citation services (e.g. https://citation.crosscite.org/). Citation of OSGeo projects is already actively used in scientific publications (e.g. Springer Handbook of Geo Information, 2nd Ed. https://doi.org/10.1007/978-3-030-53124-9, in print). The metadata of a PID for data and software can also reference PIDs for the authors and others involved. As a result, it is now possible that once the Version DOI of a software release is cited, the involved persons can also be referenced using an individual PID, such as the Open Researcher and Contributor ID (ORCID), and receive measurable scientific credit for their effort. This allows that that collaboration efforts in FOSS software projects will become a measurable and rewarding part of the scientific track record. Furthermore, PID of software, data and other information sources can be related to each other by specifying related persistent identifiers in the metadata. This field is currently undergoing rapid development. A further step will be the linking of the now available concept and version DOI of the OSGeo projects with the PID of the OSGeo conference videos, which will improve the discoverability and re-use of the conference contributions.The OSGeo Foundation can be understood as a growing continuum of software projects, functionalities, groups of people, but also knowledge and information.\nProviding an up-to-date mapping of internal linkages and dependencies of the OSGeo continuum has not been satisfactorily solved yet. In the past, there have been several approaches (e.g. http://pathfinder.terrasigna.com/oss/index2.html or https://doi.org/10.5446/14652), which have remained snapshots due to the lack of persistent references to the described objects and manual maintenance for regular updates. The availability of PID for software and persons creates a stable base for this for the first time, seconded by the conceptual approach of an integrated PID-based graph, which was developed in the FREYA project (https://www.project-freya.eu/). This approach models resources which are identified by PIDs (software projects, data, publication, persons) and the connections between them in a graph of the network of interconnected PID systems, based on their PID metadata.\\n\\nMarkus Neteler\\nPeter L\u00f6we\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/MAYYPL/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/6 Valerio Marzaioli.mp4", "persons": "Valerio Baiocchi", "pretalx_id": "S9ACUV", "title": "FOSS4G 2022 | Simulation of the effects of possible regulations for the location of wind and photovoltaic power plants in the Lazio Regional Administration (Italy)", "description": "The need to make electricity production increasingly sustainable requires careful planning of production plants, mainly for wind and photovoltaic energy conversion. Planning areas correctly, while respecting existing environmental constraints, is not an easy task and requires the collaboration of a panel of experts with different skills.\n\nThe need to search for new sites to be allocated to renewable energy generation plants is dictated by the most pressing current events, the search for non-impacting energy sources to whose research and development specific points of the National Resistance and Resilience Plan are dedicated, to which are added the consequences of the newborn Ukrainian conflict that has definitively discovered the problematic relationship-dependence of Italy and Europe with energy supplies from non-European countries. Both issues are pushing the country towards a rapid search for new energy strategies for environmental reasons and to make up for natural shortages that require massive imports of gas and other resources from abroad.\nIn particular, the National Recovery and Resilience Plan (PNRR), part of the European Next Generation EU (NGEU) programme, a 750 billion euro package allocated by the European Union to counteract the economic damage caused by the Covid-19 global pandemic, is an economic plan worth 248 billion euro that Italy can use in the five-year period from 2021 to 2026 to implement various reforms and repair the damage created by the pandemic crisis.\nThe plan, presented to the EU under the name 'Italia Domani', envisages investments along three main axes: digitalisation and innovation, ecological transition and social inclusion. These economic interventions are intended to resolve the drama caused by the advent of the Sars-Cov2 virus and help solve structural problems in the Italian economy, accompanying the country towards a path of ecological and environmental transition. It also aims to resolve important issues such as territorial, generational and gender gaps.\nIt is in this context that the national legislation is undergoing a revision, which has entrusted the regional administrations with the task of identifying the territorial criteria that favour or prevent the establishment of certain plants in the various areas of the territory. Each regional administration has the right to graduate the criteria according to the specific geomorphologic characteristics of its own territory and therefore the most efficient procedure would be to verify, with simulations in GIS environments, the effect of defining certain criteria on the territory to assess in advance which and how many areas could have greater or lesser suitability. On the basis of this consideration, we proceeded to experiment with the effects of the most common constraints by developing a real simulation on the territory of the Lazio Region.\n\nThe experimentation used the well-known open environment QGIS 3.22, which made it possible to exploit the possibilities offered by the open territorial databases of the Lazio Region.\nIt should be noted that the Lazio Region (like most Italian regions) has made many spatial data available in open format in recent years. The European directive called \"Inspire\" gave a boost to the use, standardisation and free dissemination of spatial data. It provides for the creation of a Community data infrastructure that simplifies the sharing between public administrations and user access to spatial information. In Italy, the directive was transposed into Italian law by Legislative Decree no. 32 of 27 January 2010, which established the National Infrastructure for Spatial Information and Environmental Monitoring as a node of the Community infrastructure. As a result of this implementation, the National Geoportal was created, which was followed by the various Regional Geoportals, such as that of the Lazio region.\n\nThe implementation of the open data in QGIS 3.12 made it possible to identify topological inaccuracies in the files provided and shared on the Lazio Region site, which led to necessary decisions such as the correction of some polygons that presented errors, such as their overlapping or imperfect closure (the correction of the latter case was suggested by QGis itself, through the \"reopen geometries\" function).\nA possible inaccuracy was also found in the \"lowland species\" and \"mountain species\" files of the Regional Ecological Network, which seems to show an error in the transcription of the relative geodetic datum on the website, where it is reported as WGS84, UTM33N and resulting from verifications and overlapping more likely ED50 . Uncategorised areas also emerged in the file called \"PTPR Regione Lazio (Tav. A - Tav. B)\" which were however excluded from those considered to be unsuitable since a more detailed analysis revealed the area of the Parco della Caffarella in Rome, which is hardly conceivable as the site for a wind farm or large-scale photovoltaic plant. Extraterritorial areas within the Region's territory belonging to the State of \"Vatican City\" were also added as \"unsuitable\".\nThe first results show that the remaining areas after eliminating all those that are certainly unsuitable are a limited part of the Region itself. It should be noted that these areas are not definitely suitable areas but those that are not unsuitable or potentially suitable, even if further investigation is required to ascertain their suitability.\nThe limited extent of the areas remaining after the exclusion of the unsuitable areas suggested that we make an initial estimate of the sustainability of a total conversion to these energy sources for the whole region in order to assess its potential energy autonomy.\nThe analysis was extended to individual municipalities by comparing average yields per conceivable plant area, then comparing them with inhabitants for an initial estimate of energy needs at least for domestic use.\\n\\nValerio Baiocchi\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/S9ACUV/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/7 Pierre Soille.mp4", "persons": "soille, Peter Vogt", "pretalx_id": "QACV83", "title": "FOSS4G 2022 | Morphological Spatial Pattern Analysis: Open Source Release", "description": "In this section, we describe the main routines of the MSPA code with reference to the morphological image analysis operations they rely on with links to their implementation in the open source Morphological Image Analysis Library (MIAL) recently released on GitHub at github.com/ec-jrc/jeolib-miallib by the first author. All morphological image analysis operators at the basis of MSAP are described in [Soille, 2004]. We briefly present the main MSPA foreground classes with reference to source code of the main morphological function used to compute them: core, boundaries, islets, connectors, and branches. The actual pseudo-code will be added in the final version of this paper and will include details on the computation of all MSPA feature classes including those of connected components of background pixels. The underlying code in the C programming language is available on GitHub at github.com/ec-jrc/jeolib-miallib/blob/master/core/c/mspa.c\n\n# Performance\n\nThe performance of the algorithm is evaluated on images of increasing size as well as for on-the-fly computation for interactive analysis and visualisation. We demonstrate experimentally that the complexity of the proposed implementation is linear. That is, the computational time increases linearly with the number of pixels. We also show that the algorithm can handle images up to 2^64 pixels. For example, a Global MSPA map of forest cover in equal area projection and with a pixel resolution of 100 meter (400,748 x 147,306 pixels) was processed on the JRC Big Data Analytics Platform [Soille et al. 2018] in 12 hours. Processing large images is very much needed to mitigate dependencies with regards to the image definition domain because pixel classes may depend on the observation domain.\n\nAs for the on-the-fly computation for interactive analysis and exploratory visualisation based on Jupyter notebooks [De Marchi and Soille, 2019], we show that the proposed implementation is fast enough for integration in JupyterLab with on-the-fly computation in an area corresponding to the mapview area and at resolution matching its zoom level. A Voila dashboard is in preparation and will be available for demonstration at the conference.\n\n# Conclusion\n\nMorphological spatial pattern analysis has gained traction since its inception in 2008. For many years, we maintain a dedicated MSPA website with extensive documentation, various GIS extensions and a user-friendly provision of MSPA within the desktop application GTB and the server application GWB. The present open release of MSPA will further expand the potential user-community. We are in the process of making MSPA directly available in the pyjeo python package [Kempeneers et al., 2019], so that data scientists using python for their analysis will directly benefit from the MSPA open source release. Since MSPA is available through a library compiled in C, it can be easily integrated in other data science environments. We therefore expect the release of the MSPA code under an open source license to further boost its use for the analysis of geospatial patterns and indeed any other types of spatial patterns occurring in other scientific domains.\n\n# References\n\n - Soille, P., Vogt, P. \"Morphological segmentation of binary patterns\" (2009) Pattern Recognition Letters, doi: 10.1016/j.patrec.2008.10.015\n - Soille, P. et al. 2018. \"A versatile data-intensive computing platform for information retrieval from big geospatial data\" Future Generat. Comput. Syst. doi: 10.1016/j.future.2017.11.007\n - Ossola, A. et al. \"Yards increase forest connectivity in urban landscapes\" Landscape Ecol 10.1007/s10980-019-00923-7\n - Julien Carlier et al. \"Using open-source software and digital imagery to efficiently and objectively quantify cover density of an invasive alien plant species\" Journal of Environmental Management doi: 10.1016/j.jenvman.2020.110519\n - Victor Rincon et al. \"Proposal of new Natura 2000 network boundaries in Spain based on the value of importance for biodiversity and connectivity analysis for its improvement\" Ecological Indicators doi: 10.1016/j.ecolind.2021.108024\n - Giuseppe Modica et al. \"Implementation of multispecies ecological networks at the regional scale: analysis and multi-temporal assessment\" Journal of Environmental Management, Volume 289, 2021, doi: 10.1016/j.jenvman.2021.112494\n - Vogt, P. and Riitters, K. \"GuidosToolbox: Universal digital image object analysis (2017) European Journal of Remote Sensing\" doi: 10.1080/22797254.2017.1330650\n - Peter Vogt et al. \"GuidosToolbox Workbench: spatial analysis of raster maps for ecological applications\" (2022) Ecography. doi: 10.1111/ecog.05864\n - Soille, P. \"Morphological Image Analysis: Principles and Applications\" (2004). Springer, doi: 10.1007/978-3-662-05088-0\n - D. De Marchi and P. Soille, \"Advances in interactive processing and visualisation with JupyterLab on the JRC big data platform (JEODPP)\", in Proc. of BiDS'19, 2019. doi: 10.5281/zenodo.3239239\n - Kempeneers, P. et al. \"pyjeo: A Python Package for the Analysis of Geospatial Data\" ISPRS Int. J. Geo-Inf. 2019. doi: 10.3390/ijgi8100461\\n\\nsoille\\nPeter Vogt\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/QACV83/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/8 Andrea Masiero.mp4", "persons": "Andrea Masiero", "pretalx_id": "UJJRQJ", "title": "FOSS4G 2022 | Development of a graphical user interface to support the semi-automatic semantic segmentation of UAS-images", "description": "Image semantic segmentation focuses on the problem of properly separating and classifying different regions in an image depending on their specific meaning or use, e.g. belonging to the same object. It is worth to notice that in general segmentation is a ill posed problem: it is not possible to provide a unique solution to such problem, different solutions can typically be acceptable, depending on the segmentation criterion which is applied. Nevertheless, regularization techniques are typically used to reduce the issues related to ill posedness, hence ensuring the computability of a unique solution. In the case of semantic segmentation, ill posedness is also reduced by the specific data and object interpretation that shall be included in the semantic part of the data.\nIt is also worth to notice that image semantic segmentation tools can be useful in many several applications, related both to the interpretation of images themselves, but also of other entities related to such images. The latter is for instance the case of a point cloud, whose objects and areas are also described by some images. In this case, a proper image semantic segmentation could be back projected from the images to the point cloud, in such a way to exploit such process to properly segment the point cloud itself.\nAutomatic image semantic segmentation is a quite challenging problem that nowadays is usually handled by taking advantage of the use of artificial intelligence tools, such as deep learning based neural networks.\nThe availability of reliable image segmentation datasets plays a key role in the training phase of any artificial intelligence and machine learning tool based on the image analysis: indeed, despite artificial intelligence tools can currently be considered as the state of the art method in terms of recognition and segmentation ability, they do require a huge size learning dataset in order to ensure reliable segmentation results.\nThe developed graphical user interface aims at supporting the semi-automatic semantic segmentation of images, hence easing and speeding up the generation of a ground truth segmentation database. Then, such database can be of remarkable importance for properly training any machine or deep learning based classification and segmentation method.\nDespite the development of the proposed graphical user interface has been originally motivated by the need of easing the process of producing a ground truth segmentation and classification of plastic objects in maritime and fluvial environments, within a project aiming at reducing plastic pollution in rivers, the developed tool can actually be used in contexts that are more general.\nIndeed, the interface supports in particular two types of quite specific operations: 1) segmenting and identifying objects in a single image, 2) exporting previously obtained results in new images, while also enabling the computation of certain related parameters (e.g. navigation related, such as tracking the same object over different data frames). Different types of images are supported: standard RGB, multispectral images (already available as TIFF (Tagged Image File Format) images) and thermal ones.\nFor what concerns the semantic segmentation of a single image, several alternative segmentation options are supported, starting from manual and going to semi-automatic segmentation methods. First, the manual segmentation of the objects is ensured by means of properly inserted polylines. Then, intensity based and graph based methods are implemented as well. On the semi-automatic side, two tools are provided: a) a machine learning based method, exploiting few click choices by the user (implementing a rationale similar to that in (Majumder et al., \u201cMulti-Stage Fusion for One-Click Segmentation\u201d, 2020), i.e. aiming at minimize the user input), b) when images are periodically acquired by a UAS, at quite high frequencies, two successive frames are expected to be not that different from each other. Consequently, the system aims at determining the camera motion between different frames, and using machine learning tools to properly extend and generalize the results in the previous image to those of the new one.\nThe latter method opens to a wider scenario, where some more information may come by the availability of consecutive frames. In particular, such additional information that could be determined by properly analyzing consecutive frames could be used to: assess and track the UAS movements while acquiring the video frames, increase the automation in the segmentation and classification process of an object.\nOverall, the developed graphical user interface is expected to be useful to support the semi-automatic identification of objects, and to help determining the UAS and the object movements as well.\nDespite full autonomous image semantic segmentation would clearly be of interest, its development seems to be quite challenging. Nevertheless, future investigations will be dedicated to these aspects, in order to increase the procedure automation level.\nThe simulator will be freely available for download from the website of the GeCo (Geomatics and Conservation) laboratory of the University of Florence (Italy).\\n\\nAndrea Masiero\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/UJJRQJ/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/9 Joseph Holler.mp4", "persons": "Joseph Holler", "pretalx_id": "VJPFRN", "title": "FOSS4G 2022 | Mainstreaming metadata into research workflows to advance reproducibility and open geographic information science", "description": "Free and open source software for geospatial analysis (FOSS4G) supports burgeoning possibilities for practicing open and computationally reproducible human-environment and geographical research (Singleton et al 2016).\nOpen and reproducible research practices may accelerate the pace of scientific discovery and enhance the scientific community's functions of knowledge verification, correction, and diffusion (Rey 2009, Kedron and Holler 2022).\nGeospatial metadata provides the foundation for reproducibility and open science and accordingly, requires more support in open source geospatial software.\nFollowing Wilson and others' (2021) five star guide for reproducibility, researchers can achieve four stars by conducting research with open data and software and documenting metadata according to the standards of the International Organization for Standardization (ISO) and OGC (Open Geospatial Consortium).\nFor Tullis and Kar (2021), metadata is the key to documenting the provenance of research data artifacts, preserving information about every detail of data creation and transformation.\nWilkinson and others' (2016) FAIR Guiding Principles for scientific data management enumerate functions for metadata in each of the principles for research: findable, accessible, interoperable, and reusable.\nHowever, open source geospatial software platforms generally lack the tools necessary for mainstreaming geospatial metadata into the full research workflow in support of more efficient research work and enhanced reproducibility and open science.\nThis research on metadata is part of a larger human-environment and geographical sciences reproducibility and replicability (github.com/HEGSRR) project aimed at conducting formal reproduction and replication studies in the geographical sciences and integrating reproducibility into undergraduate and graduate level curricula in research methods.\n\nFollowing the National Academies of Science, Engineering and Medicine (NASEM, 2019), a reproduction study aims find the same results using the same data and methodology as a published study.\nA replication study aims to test the findings of a published study by collecting new data and following a similar methodology, which may intentionally modify one or more research parameters.\nTogether, reproduction and replication studies offer a deep understanding of the original research, test its credibility and generalizability, and enhance the self-corrective mechanisms of the scientific community.\nMetadata is information about data, including essential contextual information about the data's spatial structure, attributes, creation, maintenance, access, licensing, and provenance.\n\nA key component of reproducible research is an executable research compendium containing all of the data, code, and narrative required to compile a research publication from raw data (Nust and Pebesma 2021 and the Opening Reproducible Research Project).\nComputational notebooks like Jupyter notebooks or R Markdown are commonly used to interweave narrative with code in executable compendia.\nIn order to maximize replicability and inferential power, the research compendium should begin with a pre-registered research plan prior to data collection, requiring researchers to fully specify metadata for all of the research data and analyzes that they intend to create (Nosek et al. 2018).\nIt is recommended to store compendia in version tracking systems like Git in order to preserve a full history of changes to the research project.\nFinally, the compendium should be published parallel to academic publications so that other researchers can independently re-run, check and verify the analysis, or incorporate the research in future projects.\nIn order to maximize the findability and legibility of the research compendium for both humans and machines, the overall repository and each of its components must be meticulously documented with metadata according to international standards (Wilkinson et al. 2016, Wilson et al. 2021).\n\nIn this three-part research paper, we focus on metadata in research compendia and related research products through all phases of the research workflow.\nFirst, we specify ideal requirements of geospatial metadata in support of reproducible research workflows and open science.\nWe consider metadata needs at each step of the research process, including proposal writing, pre-analysis registration, ethics review board approval, data collection and analysis, publishing, and reproducing published research.\nThe metadata software needs assessment is based on literature review of reproducibility and open science, and on teaching and practicing reproducibility with geographic methods.\n\nSecond, we review the Dublin Core and International Organization for Standardization (ISO) geospatial metadata standards and popular open source platforms for geospatial research and their support for the requirements of geospatial metadata articulated in the first part.\nThe scope of the review includes metadata functionality available through spatial analysis software platforms, including R, Python, QGIS, GRASS and SAGA; and it also includes metadata or cataloging tools, including GeoNetwork, GeoNode, the USGS Metadata Wizard, and mdeditor.\n\nFinally, we articulate a vision for open source geospatial metadata software development in support of open and reproducible human-environment and geographical research.\nIn this vision, metadata software tools shall integrate with executable research compendium to assist researchers with their workflow from inception to publishing and archiving.\nThe vision builds off our HEGSRR project, in which we independently reproduce and replicate published studies with open source geospatial software, integrate reproduction and replication studies into project-based geographic information science courses, and develop curricula and infrastructure for reproducible research.\nEach section of the paper is thus supplemented with experiences and examples drawn from the HEGSRR project.\nOf particular relevance, we have already completed seven reproduction or replication studies with graduate and undergraduate students using open source geospatial software, encountering numerous barriers caused by inadequate use or documentation of metadata in research planning, execution, and archiving.\nWe have also developed a template Git repository compendium for reproducible research and prototyped its use in our studies and teaching, discovering software barriers to documenting metadata and opportunities to integrate metadata into more efficient and reproducible research practices.\n\nWe have selected FOSS4G for this research paper in hopes of reaching both the academic audience and developer audience at the conference. We hope to raise awareness in the academic audience of the critical importance of geospatial metadata in each stage of the research workflow. We hope to raise interest in the open source geospatial software community for collaboration on improved support for geospatial metadata in research workflows.\\n\\nJoseph Holler\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/VJPFRN/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/10 Valerio Baiocchi.mp4", "persons": "Valerio Baiocchi", "pretalx_id": "TNWYJL", "title": "FOSS4G 2022 | Efficient three-dimensional survey techniques and their comparison in open software in the archaeological test site of \"Ninfeo maggiore\" and \"Ninfeo minore\" of Formia (latina, Italy)", "description": "The survey took place in part of the so-called Roman Villa of Caposele, also known as Villa Rubino (Giuliani and Guaitoli 1972; Cassieri 2015). The Villa, built by the Dukes of Marzano and subsequently passed into the hands of Charles of Ligny, Prince of Caposele, was purchased by Ferdinand II of Bourbon in 1845, with the aim of making it a luxurious summer residence. The building overlooks the inlet of Caposele, where there must have been a small harbour, and is squeezed between the Via Appia and the sea. To the west of the small port are the remains of an imposing structure with a central courtyard, datable to the 1st century B.C., which scholarly tradition has identified as Cicero's Academy or School, although it is probably a horreum, testifying to the utilitarian vocation of this area of the villa. In later phases, while retaining its intended use, the horreum would be incorporated into a residential building complex together with other structures further to the west that, too, may have served as warehouses in the earlier phase. To the east of the marina is the residential area, the area in which the survey operations were concentrated. Here, on a front about 140 metres long, there are a series of rooms with barrel vaults that were probably part of the basis villae of the building. In two of these rooms are the so-called minor and major nymphaea. The first consists of an almost quadrangular room with a roof supported by four Doric brick columns; on the back wall, in a large niche, spring water gushes out. The wall decorations include stucco, shells and incrustations of glass paste and small stones. The main nymphaeum, on the other hand, is divided into three naves and covered with a rounded coffered vault supported by Doric columns. The large niche at the bottom of the nymphaeum contains a pool of spring water; the floor is in white mosaic with polychrome dots. These nymphaeums constitute the focus of the intervention.\nIn front of this front there was a very large fishpond, which ran into the sea for about one hundred metres in length, with a width of over 200.\nBecause of its architectural features and good state of preservation, the central body of the monument has always been a great attraction for visitors and scholars, many of whom have left descriptions and drawings in their diaries.\n\nThe two nymphaeums have to be surveyed both for conservation and study purposes and in order to allow a virtual visit, which is particularly important since they are located inside a private property. As already described, the structure is complex, with a succession of rooms and environments in an archaeological complex extending approximately 480 metres in an east-west direction and approximately 50 metres in a south-north direction. The survey of such an extension and such an articulation with consolidated techniques such as terrestrial laser scanning would probably have required days of work, and for this purpose we wanted to test the possible use of the most modern SLAM techniques, in particular using a GEOSLAM Zeb Horizon, totally transportable by an operator and with a range of up to 100 metres (https://geoslam.com/solutions/zeb-horizon/).\nIn order to compare the times, modes, precision and accuracy of the point cloud thus obtained, we took advantage of the possibilities provided by the open software \"Cloud Compare 2.11.3 64 bit version\", which allows us to compare point clouds of different origins. Cloud Compare allows comparisons to be made with various methods of calculating distance and to estimate precision and accuracy separately, allowing one cloud to be fitted to the other or to be compared while remaining within their absolute coordinates.\nIn the present experimentation it was therefore decided to survey both nymphaea with the \"GEOSLAM\", also surveying all the internal connecting rooms and corridors between these two environments. The whole survey was carried out in a few tens of minutes and therefore the survey continued over most of the exterior of the entire structure.\nThe survey of the entire complex was not carried out because the main interest of this project was to test the SLAM technology and validate its precision and accuracy in comparison with more consolidated techniques.\nFor comparison, only the major nymphaeum was surveyed with a more consolidated laser\nFaro\" terrestrial scanning laser.\nIn order to verify the validity of the Slam also on the external part, a survey was carried out using a DJI Matrix drone with laser scanning. Finally, the same survey was also carried out with an optical camera on the same Matrix drone and with the most widely used drone for photogrammetry, i.e. the \"Phantom 4 pro\", also by DJI.\nAll the surveys were framed with respect to the same network of ground control points, in order to refer them to the same framing system and be able to assess their precision and accuracy.\nIt should be noted that Slam was only able to station a few of the GCPs while, as can be easily guessed, the drones acquired practically all of them.\n\nThe comparison showed very limited deviations whose statistical validation is in progress, demonstrating that the SLAM technique can advantageously be used in such vast archaeological complexes where the completeness of the survey is more important than millimetric accuracy.\\n\\nValerio Baiocchi\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/TNWYJL/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/11 Larry Stanislawski\u00e0.mp4", "persons": "Larry Stanislawski", "pretalx_id": "T9LLQV", "title": "FOSS4G 2022 | Scaling-up deep learning predictions of hydrography from IFSAR data in Alaska", "description": "1. INTRODUCTION\n    In a new initiative to deliver higher-quality data and support improved geospatial analysis, the U.S. Geological Survey (USGS) is upgrading the elevation and hydrography datasets into the 3D National Topography Model (3DNTM), which will include fully integrated hydrography and elevation. The USGS 3D Elevation Program (3DEP) recently completed acquisition of interferometric synthetic aperture radar (IfSAR) elevation data at 5-meter spatial resolution for Alaska (USGS, 2022). Other parts of the United States are being mapped at higher resolution with lidar-derived elevation data.\n\nUnder the 3DNTM, new hydrography data are acquired through methods that derive or extract the features directly from best available 3DEP elevation data to ensure proper integration of the hydrography and elevation layers. By applying specifications for deriving 1:24,000 or larger scale hydrography from high resolution elevation data (Archuleta and Terziott, 2020; Terziotti and Archuleta, 2020), a tenfold increase in the number of features in the National Hydrography Dataset (NHD) is expected. Consequently, highly automated machine learning methods to extract and validate the hydrography data collection are being investigated.\n\nXu et al. (2021) demonstrated that the U-net fully convolutional neural network (Ronneberger, Fischer, and Brox, 2015) is capable of extracting hydrography from lidar elevation data with 80 to 90 percent accuracy. Stanislawski et al. (2021) applied a similar U-net model using several IfSAR and IfSAR-derived input layers to predict hydrography for a 50-watershed study area in northcentral Alaska, where 68 percent average F1-score accuracies were achieved on test watersheds. Further work to refine U-net predictions of hydrography using IfSAR for the same 50-watershed area in Alaska achieved average F1-scores for test watershed of better than 80 percent (Stanislawski et al., 2022). Research presented in this paper builds upon this earlier work by testing transfer learning methods and scaling-up U-net predictions of hydrography from IfSAR for other areas of Alaska using workflows in high-performance computing environment.\n\n 2. METHODS\n    A workflow was developed to automate downloads and processing of IfSAR-derived tiles of digital elevation model (DEM), digital terrain model (DTM), and orthorectified intensity (ORI) data for user-selected watersheds from the 3DEP database. The workflow mosaics common tiles and derives several raster data layers from the DEM that are related to surface hydrology, such as topographic position index and shallow water channel depth. Overall, seventeen data layers are generated and coordinated with identical raster projection systems. The layers were used in U-net modelling for predicting hydrography for the 50-watershed Kobuk River study area (Stanislawski et al., 2022). In this study a transfer learning process begins with the Kobuk River U-net model and subsequently includes additional training data from outside the Kobuk area. Hydrography predictions are then generated from the transfer learning model and assessed. Several levels of refinements to training data are tested and the accuracy of predictions are assessed. Reference data consist of vector hydrography features derived by USGS contractors.\n\nThe data processing workflows are implemented with Python, linux shell scripts, and opensource software libraries such as the Geospatial Data Abstraction Library (GDAL). Neural network modelling is implemented through TensorFlow, and data processing is completed on a 12-node linux cluster and through the GPU nodes of the USGS Tallgrass computing facilities (https://hpcportal.cr.usgs.gov/hpc-user-docs/Tallgrass/Overview.html).\n\n 3. DISCUSSION\n    Mapping hydrography for the state of Alaska is a daunting task, given its vast area and terrain that is difficult to navigate. Big challenges with large high-quality datasets are well suited to take advantage of recent advancements in neural networks (Usery et al., 2021). This research demonstrates the tremendous potential to improve and speed up mapping of surface water features in Alaska, and elsewhere in the world having challenging terrain and limited resources.\n\nReported accuracy scores measure how well a machine can reproduce hydrography generated with meticulous editing by numerous subject matter experts. It is not a score of how well the surface water features are mapped by the model. The human factor in contemporary broad scale mapping efforts cannot be ignored and warrants consideration as a source of uncertainty in the related accuracy metrics. How well the maps fit what is on the ground can only be definitively confirmed by being on the ground at any given point in time, as hydrologic conditions are constantly in flux. Thus, the work here could be used as an aid to human cartographers in their efforts to interpret what is important to the map user.\n\nThis work could also benefit change detection efforts. As new and better elevation data are collected, automated strategies such as the model presented here could be used to identify regions with significant changes in surface water distribution. This type of automation would be valuable to maintain an accurate national map over time and help address the numerous challenges that society faces related to hydrology.\\n\\nLarry Stanislawski\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/T9LLQV/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/12 Yao Ming Liu.mp4", "persons": "ShuZhuWang, YaoMing Liu", "pretalx_id": "ZBGHFH", "title": "FOSS4G 2022 | Creating a land use/land cover dictionary  based on multiple pairs of OSM and reference datasets", "description": "1. Background\n    OpenStreetMap (OSM) can supply useful information to improve land use/land cover (LULC) mapping (Arsanjani, 2013; Schultz, 2017; Zhou, 2019). A dictionary is needed to convert each OSM tag into an LULC class. However, such a dictionary was mostly created subjectively or with only one pair of OSM and reference datasets. As a result, the existing dictionaries may not be applicable to other study areas. This study designed four measures: sample count, average area percentage, sample ratio and average maximum percentage; and used multiple pair of OSM and reference datasets to create a dictionary. 50 pan-European metropolitans were involved for testing and 1409 different OSM tags were found. We further found that: 1) Only a small proportion of OSM tags play a decisive role for LULC mapping. 2) An OSM tag may correspond to multiple different LULC classes, but the issue that which and how different LULC classes correspond to each OSM tag can be determined. Moreover, not only the proposed dictionary is useful for various applications, e.g., producing LULC maps, obtaining training and/or validation samples, assessing the quality of an OSM dataset, but also the approach to creating this dictionary can be applicable to different study areas and/or LULC datasets.\n\n 2. Data\n    OSM datasets of the 50 metropolitans were acquired for free from http://download.geofabrik.de/index.html in June 2020.   Corresponding reference datasets (called urban atlas or UA) were available from https://land.copernicus.eu/local/urban-atlas/urban-atlas-2012/# in June 2020 freely.\n\n 3. Methodology\n    The tenet of our approach is to use multiple pairs of OSM and reference datasets for creating an OSM-LULC dictionary. In each pair of datasets, an OSM tag may correspond to different LULC classes, it is therefore necessary to determine which is the most appropriate LULC class for each OSM tag. we assumed that most OSM tags have been tagged by volunteers   correctly (Zhou et al. 2019). Following this assumption, the way to determine the most appropriate LULC class for each OSM tag includes two steps. Firstly, all objects of an OSM tag are intersected with those of different LULC classes, respectively. After that, the   LULC class with the maximum intersecting area is viewed as the most appropriate one for this OSM tag. Four attributes and four measures are designed to describe an OSM- LULC dictionary. They are: Tag ID, Tag Name, Class ID and Class Name in terms of attributes; and Sample Count, Average Area Percentage, Sample Ratio and Average Maximum Percentage in terms of measures. They are introduced as follows: 1. Tag ID denotes the ID of an OSM tag, 2. Tag Name denotes the name of an OSM tag. 3. Class ID denotes the ID of an LULC class. 4. Class Name denotes the ID of an LULC class.5. Sample Count (SC) denotes how frequent an OSM tag is appeared in different study areas or datasets. 6. Average Area Percentage (AAP) denotes the average of the area percentages of an OSM tag in multiple different OSM datasets. 7. Sample Ratio (SR) denotes the percentage of study areas or datasets that an OSM tag corresponds to an LULC class. 8. Average Maximum Percentage (AMP) denotes the average of all the maximum percentage in different study areas or datasets.\n\n 4. Conclusion and application\n    This study proposed an approach to creating an OSM-LULC dictionary. The tenet of this approach was to involve multiple pairs of OSM and reference datasets for the analysis. First of all, each pair of OSM and reference datasets were intersected and the most appropriate LULC class for each OSM tag was determined. Then, the four measures, i.e., sample count (SC), average area percentage (AAP), sample ratio (SR) and average maximum percentage (AMP), were designed and calculated based on multiple pairs of OSM and reference datasets.  More precisely, a total of 50 pairs of OSM and reference datasets in pan-European metropolitans were chosen as study areas for creating an OSM-LULC dictionary. Finally, a number of 1409 different OSM tags were found and they were reclassified into five and 14 different LULC classes, respectively. Moreover, this dictionary was also analyzed with the four proposed measures. Results showed that:\n    Firstly, most OSM tags (\uff1e 1,000) were only found in less than five study areas (SC \uff1c 5). Moreover, only 37 of the 1409 OSM tags had a percentage of average area (AAP) larger than 0.1%. This indicates that a small proportion of OSM tags can play a decisive role.\n    Secondly, an OSM tag may correspond to multiple different LULC classes within a pair of OSM and reference datasets; The most appropriate LULC class for each OSM tag may also vary among different pairs of datasets. Thus Both the SR and AMP may also vary in different pairs of OSM tag and LULC class.\n    With the proposed dictionary, it is possible to understand the differences of different OSM tags and different pairs of OSM tag and LULC class. This is essential not only for producing LULC maps, but also for picking up training and/or validation data from an OSM dataset and also for detecting incorrect tags in an OSM dataset. Therefore, we concluded that it has benefits for creating an OSM-LULC dictionary based on multiple pairs of OSM and reference datasets.\\n\\nShuZhuWang\\nYaoMing Liu\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/ZBGHFH/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/13 Dina Jovanovic.mp4", "persons": "Dina Jovanovic", "pretalx_id": "SUVEZL", "title": "FOSS4G 2022 | From QGIS to Python: comparison of free and open tools for statistical analysis of cultural heritage and data representation", "description": "Thankfully to the European Commission initiatives such as INSPIRE (2007) and other governmental policies, spatial data are available publicly on different national, regional and municipality geoportals for further use. When it comes to the cultural heritage and Italian context, based on the decree of the Ministry of Culture (MiBACT, 2008), different activities concerning heritage has been assigned to the ICCD (i.e., Central Institute for Catalogue and Documentation) such as research and technical-scientific collection of the documentation and coordination of cataloguing of cultural heritage and its digitalization. These regulations allowed the public entities to share substantial information about geographical and spatial data with a wider audience. Specifically in the region of Lombardy, data about cultural heritage are catalogued in SIRBeC (i.e., Regional information System for Cultural Heritage) that has been promoted since 1992 and continues collecting, managing, and publishing a vast amount of information. Vector shapefiles are freely available for download on the Geoportale Lombardia. The scope of the research was collecting information about cultural heritage in Lombardy that is freely accessible online. Data downloaded are point and polygon features files of the position of the cultural heritage. Furtherly, the methodology developed deals with the use of QGIS, as the open and free software together with the Python console integrated into the software and finally using the online software of the integrated development environment (IDE) named Replit that is free, open, collaborative and in-browser Python coding application.\nThe methodology is based exclusively on free and open sources, starting from the collection of data to their processing. Each vector file is enriched with the metadata in the attribute table but the methodology is providing a combination of software to obtain other data (e.g., coordination, area, etc.) and statistical analysis (e.g., ratio, percentage, position, distribution, etc.), which are the initial part of each elaborated cultural heritage project. Additionally, the methodology is discussing different approaches to reach the desired result and compares their differences. Firstly, the Python console in QGIS was examined, and metadata were extracted from the vector file to the .csv file to be used in Replit. The online codding application gave a higher degree of flexibility while coding, and it was possible to implement data extracted in a .csv file into a coding panel, using them to produce different statistical analyses. Furtherly, the methodology discusses the use of the plugin of QGIS called DataPlotly and data differences, from the representation to the utility level.\nResults through the Python Console in QGIS allowed the extraction of necessary data for further analysis, deleting the ones which are not needed. The good side of this approach is that metadata of the shapefile stay untacked, and the Python is simply extracting selected data in a new external file. There have been selected four categories of interest: Name, Category, Typology and Municipality of the cultural heritage. The area of interest was a northern part of Milan, in the province of Monza e Brianza which has a dense and diverse category of cultural heritage. Using the python code, these four categories are temporarily printed and saved in the console panel. Since there is no information about coordinates inside the metadata, there are two approaches that are tested to obtain them. The first one used was the QGIS integrated option \"Add geometry attributes\", which created the new shapefile enriched with the information about longitudinal and latitudinal coordinates. The second approach was extracting the coordinates through the Python console with the f.geometry() function. Information about the four categories selected and coordinates are printed temporarily in the console, and the user can control the order of the columns and delimited type, following the saving and extracting the .txt file.\nThe second part of the analysis also discusses two methods that were tested for the creation of statistical analysis of extracted data and their representation, firstly in the QGIS plugin DataPlotly and then using Replit. Presenting statistical analysis in the form of different charts is available directly through the plugin. Nevertheless, when it comes to the great amount of data the plugin resulted not be very efficient for the representation nor easy to manage the view. Another constrain is that there is no option for exporting graphs in a .pdf file. On the other side, creating the charts through the Python packages such as matplotlib or pandas shows a better degree of control over a graph. The advantage is that there is a possibility of exporting it in many different files, such as a .pdf or .svg file. Additionally, through the Python in-browser application, there is a higher degree of control and change of the visual representation of charts.\nIn conclusion, the process of extracting the coordinates from the previously georeferenced shapefiles can be useful when it comes to the georeferentiation of other collected material, such as dense point clouds created by photogrammetric techniques and other photographic material collected in-situ. In the past years, a lot of students, researchers, and professionals were not able to continue their work because of the inaccessibility to the site and unavailability to perform the field survey which is necessary when it comes to the investigation of cultural heritage. The process of using and combining open and free software, including both those which are used off and online, can provide to a certain degree some information that is not visible in attributes so that the study can be continued, and research can be conducted also in a remote. The methodology, processes and tools used are simple, yet they are creating clear guidelines of the potentiality and importance of freely shared data and stresses again the power of geographic information tools in urban and architectural analyses.\\n\\nDina Jovanovic\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/SUVEZL/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/14 Baran Topcuoglu.mp4", "persons": "Baran Topcuoglu", "pretalx_id": "ZCEZF9", "title": "FOSS4G 2022 | Speed-related traffic accident analysis using GIS-based DBSCAN and NNH clustering", "description": "Traffic accidents are a significant problem facing the world, as they result in many deaths and injuries every year. Generally, the probability of traffic accidents occurring at any point is not random. Factors such as the condition of the road, where the accidents occurred, and the general structure of the land play an essential role in the accidents that will occur at one point. For this reason, traffic accidents tend to occur intensively in areas where these factors are different from usual.\n\nIt is critical to identify such areas and take the necessary measures to ensure road safety and reduce traffic accidents. Identifying the different geographic locations where traffic accidents occur can help prevent more traffic accidents, personal injuries, and fatal accidents and understand the different accident occurrence conditions. When the literature is considered, it is seen that many studies in this field are handled with different methods. Analyzing the locations where traffic accidents occur by considering the hot spots with spatial clustering methods plays a very active role in examining the tendency of traffic accidents to occur. In this study, it is thought to deal with detecting traffic accident hot spots by using the GIS-based Nearest Neighbor Hierarchical Clustering Method (NNH) and Density-based clustering Method (DBSCAN).\n\nNearest Neighbor Hierarchical Clustering Method (NNH) is a hot spot spatial clustering method that detects accident hot spots. This method considers two types of criteria for spatial mapping clustering of spatial point data: the threshold distance (d), which is the Euclidean distance between each pair of data points, and the minimum number of points that must be present in a cluster (nmin) (Kundakci E, 2014; Kundakci and Tuydes-Yaman, 2014; Levine, 1996; Levine et al., 2004; Ture Kibar and Tuydes-Yaman, 2020). At the point of realizing this method, the crime stat program, which was developed especially for hot spot clustering analysis of crimes, is widely used. CrimeStat is a crime mapping software program developed by Ned Levine (Levine, 1996).\n\nDensity-based clustering, on the other hand, is also known as DBSCAN, is a method for finding specific predefined events and hotspots. The algorithm, moreover, is open source and recommended for noisy data in large spatial databases (Ester et al., 1996). This method identifies a cluster as the most densely connected set of points possible. There are two criteria addressed in this method: Epsilon and minimum scores. The maximal radius of the neighbourhood is epsilon, and the minimal number of points in the epsilon-neighbourhood to describe a cluster is minimum points. This clustering algorithm separates the point data into three different forms (Schubert et al., 2017).\n\nIn the study, the Mersin province of Turkey was chosen as the pilot region for the analyses using the mentioned methods. Mersin is a port city located in the Mediterranean Region of Turkey, located between 36-37\u00b0 north latitude and 33-35\u00b0 east longitude. As of 2021, it has a population of 1.891.145 (URL-1, 2022). It is the most important domestic tourism center of Turkey and is on the way to becoming Turkey's new tourism region with the appointments made in tourism in recent years and new hotels built on the beach.\n\nThis study predicted determining the risky areas where speed-related traffic accidents will occur in Mersin, which is an important point for the country, and to make predictions by making evaluations depending on the road geometry at the determined points. In addition, it will be examined whether the measures to be taken based on the analysis at the determined points are made comparatively with two different methods and whether these evaluations create differences by considering both based on a large region and the basis of a more local region.\n\nThe study was planned in four phases. First of all, spatial and non-spatial data of the selected pilot region will be provided. For this stage, traffic accidents data between 2013-2020 will be obtained from the general directorate of safety and the general command of the gendarmerie. The obtained data will be organized and then transferred to the geographic database for GIS-based analyses in the second stage. Since speed-related traffic accident hot spot analysis will be performed in the study, the database will be suitable to include speed-related accidents. The NNH and the DBSCAN method will be performed in the third stage, and the results will be discussed. At this stage, the Crime Stat III program will be used for the NNH method, and the open-source GIS program QGIS will be used for the DBSCAN method. All results will be analyzed, visualized, and evaluated through the QGIS program. In the last stage of the study, the results obtained will be examined according to the probability of accidents. Finally, the obtained risky areas according to the analysis results will be evaluated according to the geometry of the road. In short, it will be examined within the framework of accident-road geometry whether the structure of the road and the high-risk areas of the accidents overlap.\n\nThe fact that the points where speed-related accidents will tend to cluster will be determined, with the study to be carried out, will address a significant gap in this field. Since the effectiveness of the methods will be compared with a different analysis, a study will be constituted a base for studies in a similar field. In addition, since the reasons such as whether these methods produce effective results in large regions and more local regions will be examined, it is thought that important suggestions will be made and contributions to the literature. Finally, since the results obtained in the study will be evaluated depending on the road geometry, the traffic accident-road geometry relationship will be discussed. Thus, a base for similar studies will be provided.\\n\\nBaran Topcuoglu\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/ZCEZF9/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/15 Maryam Lotfian.mp4", "persons": "Maryam Lotfian", "pretalx_id": "VMNCM3", "title": "FOSS4G 2022 | An approach for real-time validation of the location of biodiversity observations contributed in a citizen science project", "description": "Motivation:\n\nBecause of technological advancements, public participation in scientific projects, known as citizen science, has grown significantly in recent years (Schade and Tsinaraki 2016; Land-Zandstra et al. 2016). Contributors to citizen science projects are very diverse, coming from a variety of expertise, age groups, cultures, and so on, and thus the data contributed by them should be validated before being used in any scientific analysis. Experts typically validate data in citizen science, but this is a time-consuming process. One disadvantage of this is that volunteers will not receive feedback on their contributions and may become demotivated to continue contributing in the future. Therefore, a method for (semi)-automating validation of citizen science data is critical. One way that researchers are now focusing on is the use of machine learning (ML) algorithms to validate citizen science data.\n\nMethodology:\n\nWe developed a citizen science project with the goal of collecting and automatically validating biodiversity observations while also providing participants with real-time feedback. We implemented the application with the Django framework and a PostgreSQL/PostGIS database for data preservation. In general, the focus of biodiversity citizen science applications is on automatically identifying or validating species images, with less emphasis on automatically validating the location of observations. Our application's focus, aside from image and date validation (Lotfian et al. July 15-20, 2019), is on automatically validating the location of biodiversity observations based on the environmental variables surrounding the observation point. In this project, we generated species distribution models using various machine learning algorithms (Random Forest, Balanced Random Forest, Deep Neural Network, and Naive Bayesian) and used the models to validate the location of a newly added observation. After comparing the performance of the various algorithms, we chose the one with the best performance to use in our real-time location validation application.\n\nWe developed an API that validates new observations using the trained models of the chosen algorithm. The Flask framework was used to create the API. The API uses the location and species name as parameters to predict the likelihood of observing a species (for the time being, a bird species) in a given neighborhood. Moreover, the model prediction, as well as information on species habitat characteristics are then communicated to participants in the form of real-time feedback. The API has three endpoints: a POST request that takes the species name and location of observation and returns the model prediction for the probability of observing the species in a 1km neighborhood around the location of observation; a GET request that takes the location of observations and returns the top five species likely to be observed in a 1km neighborhood around the location of observation; and a GET request that returns the species common names in English.\n\nUser experiment:\n\nA user experiment was carried out to investigate the impact of automatic feedback on simplifying the validation task and improving data quality, as well as the impact of real-time feedback on sustaining participation. Furthermore, a questionnaire was distributed to volunteers, who were asked about their feedback on the application interface as well as the impact of real-time feedback on their motivation to continue contributing to the application.\n\nResults:\n\nThe results were divided into two parts: first, the performance of the machine learning algorithms and their comparison, and second, the results of testing the application through the user experiment.\n\nWe used the AUC metric to compare the performance of the machine learning algorithms, and the results showed that while DNN had a higher median AUC (0.86) than the other three algorithms, DNN performance was very poor for some species (below 0.6). Balanced Random Forest (AUC median 0.82) performed relatively better for all species in comparison to the other three algorithms. Furthermore, for some species where the other three algorithms performed poorly (AUC less than 70%), Balanced-RF outperforms the others.\n\nThe user experiment results provided us with preliminary findings that support the combination of citizen science and machine learning. According to the findings of the user experiment, participants with a higher number of contributions found real-time feedback to be more useful in learning about biodiversity and stated that it increased their motivation to contribute to the project. Besides that, as a result of automatic data validation, only 10% of observations were flagged for expert verification, resulting in a faster validation process and improved data quality by combining human and machine power.\n\nWhy it should be considered:\n\nData validation and long-term participation have always been two of the most difficult challenges in citizen science and VGI (volunteer geographic information) projects. Various studies have been conducted on biodiversity data validation, focusing primarily on observation images with automatic species identification; however, not enough attention has been paid to observation location validation, particularly automatic location validation taking into account species habitat characteristics. Furthermore, to the best of our knowledge, the combination of machine learning and citizen science for sustaining participation by providing real-time user-centered and machine generated feedback to participants has received, till now, little attention and therefore our work is new, original and completely coherent with the vision of community citizen science, where scientists and citizen scientists are supposed to learn from each other.\n\nBibliography:\n\nLand-Zandstra, Anne M., Jeroen L. A. Devilee, Frans Snik, Franka Buurmeijer, and Jos M. van den Broek. 2016. \u201cCitizen Science on a Smartphone: Participants\u2019 Motivations and Learning.\u201d Public Understanding of Science  25 (1): 45\u201360.\n\nLotfian, Maryam, Jens Ingensand, Olivier Ertz, Simon Oulevay, and Thibaud Chassin. July 15-20, 2019. \u201cAuto-Filtering Validation in Citizen Science Biodiversity Monitoring: A Case Study.\u201d In Proceedings of the 29th ICA Conference. Vol. 2. https://doi.org/10.5194/ica-proc-2-78-2019.\n\nSchade S, Tsinaraki C.; Survey report: data management in Citizen Science projects; EUR 27920 EN; Luxembourg (Luxembourg): Publications Office of the European Union; 2016; doi:10.2788/539115\\n\\nMaryam Lotfian\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/VMNCM3/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/16 Lucas van der Meer.mp4", "persons": "Lucas van der Meer", "pretalx_id": "VSSKSB", "title": "FOSS4G 2022 | Semantic querying in earth observation data cubes", "description": "Earth observation (EO) imagery has become an essential source of information to better monitor and understand the impact of major social and environmental issues. In recent years we have seen significant improvements in availability and accessibility of these data. Programs like Landsat and Copernicus release new images every day, freely and openly available to everyone. Technological improvements such as data cubes (e.g. OpenDataCube), scalable cloud-based analysis platforms (e.g. Google Earth Engine) and standardized data access APIs (e.g. OpenEO) are easing the retrieval of the data and enabling higher processing speeds.\n\nAll these developments have lowered the barriers for utilizing the value of EO imagery, yet translating EO imagery directly into information using automated and repeatable methods remains a main challenge. Imagery lacks inherent semantic meaning, thus requires interpretation. For example, consider someone who uses EO imagery to monitor vegetation loss. A multi-spectral satellite image of a location may consist of an array of digital numbers representing the intensity of reflected radiation at different wavelengths. The user, however, is not interested in digital numbers, they are interested in a semantic categorical value stating if vegetation was observed. Inferring this semantic variable from the reflectance values is an inherently ill-posed problem, since it requires bridging a gap between the two-dimensional image domain and the four-dimensional spatio-temporal real-world domain. Advanced technical expertise in the field of EO analytics is needed for this task, making it a remaining barrier on the way to a broad utilization of EO imagery across a wide range of application domains.\n\nWe propose a semantic querying framework for extracting information from EO imagery as a tool to help bridge the gap between imagery and semantic concepts. The novelty of this framework is that it makes a clear separation between the image domain and the real-world domain.\n\nThere are three main components in the framework. The first component forms the real-world domain. This is where EO data users interact with the system. They can express their queries in the real-world domain, meaning that they directly reference semantic concepts that exist in the real world (e.g. forest, fire). For simplicity reasons, we currently work on a higher level of abstraction, and focus on concepts that correspond to land-cover classes (e.g. vegetation). For example, a user can query how often vegetation was observed at a certain location during a certain timespan. These queries do not contain any information on how the semantic concepts are represented by the underlying data.\n\nThe second component forms the image domain. This is where the EO imagery is stored in a data cube, a multi-dimensional array organizing the data in a way that simplifies storage, access and analysis. Besides the imagery itself, the data cube may be enriched with automatically generated layers that already offer a first degree of interpretation for each pixel (i.e. a semantically-enabled data cube [1]), as well as with additional data sources that can be utilized to better represent certain properties of real-world semantic concepts (e.g. digital elevation models).\n\nThe third component serves as the mapping between the real-word domain and the image domain. This is where EO data experts bring their expertise into the system, by formalizing relationships between the observed data values and the presence of a real-world semantic concept. In our current work these relationships are always binary, meaning that the concept is marked either as present or not present. However, the structure allows also for non-binary relationships, e.g. probabilities that a concept is present given the observed data values.\n\nWe implemented a proof-of-concept of our proposed framework as an open-source Python library (see https://github.com/ZGIS/semantique). The library contains functions and classes that allow users to formulate their queries and call a query processor to execute them with respect to a specific mapping. Queries are formulated by chaining together semantic concept references and analytical processes. The query processor will translate each referenced semantic concept into a multi-dimensional array covering the spatio-temporal extent of the query. It does so by retrieving the relevant data values from the data storage, and subsequently applying the rules that are specified in the mapping. If the relationships are binary, the resulting array will be boolean, with \u201ctrue\u201d values for those pixels that are identified as being an observation of the referenced concept, and \u201cfalse\u201d values for all other pixels. Analytical processes can then be applied to this array. Each process is a well-defined array operation performing a single task. For example, applying a function to each pixel or reducing a particular dimension. The workflow of chaining together different building blocks can easily be supported by a visual programming interface, and thus lowering the technical barrier for information extraction even more. This is demonstrated already in an operational setting by Sen2Cube.at, a nation-wide semantic data cube infrastructure for Austria, which uses our proposed semantic querying framework [2].\n\nWe believe our proposed framework is an important contribution to more widely accessible EO imagery. It lowers the barrier to extract valuable information from EO imagery for users that lack the advanced technical knowledge of EO data, but can benefit from the applications of it in their specific domain. They can now formulate queries by directly referencing real-world semantic concepts, without having to formalize how they are represented by the EO data. To execute the queries, they can use pre-defined mappings, which are application-independent and shareable.  The framework eases interoperability of EO data analysis workflows also for expert users. Mappings can easily be shared and updated, and the queries themselves are robust against changes in the image domain.\\n\\nLucas van der Meer\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/VSSKSB/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/17 Luca Morandini.mp4", "persons": "Luca Morandini", "pretalx_id": "MNJ3TT", "title": "FOSS4G 2022 | Mapping the Chatter: Spatial Metaphors for Dynamic Topic Modelling of Social Media", "description": "opic modelling is a branch of Natural Language Processing that deals with the discovery of conversation topics in a document corpus. In social media, it translates into aggregating posts into topics of conversation and observing how these topics evolve over time (hence the \u201cdynamic\u201d adjective [Murakami, 2021]). Conveying the results of topic modelling to an analyst is challenging since the topics often do not lend themselves naturally to meaningful labelling, where relationships between them can involve hundreds of dimensions. Furthermore,  the popularity of topics is itself subject to change over time.\n\nIn this paper, we propose a spatialization technique based on open-source software that reduces the intrinsic complexity of dynamic topic modelling output to familiar topographic objects, namely: ridges, valleys, and peaks. This offers new possibilities for understanding complex relationships that change over time, that overcomes issues with traditional topic modelling visualisation approaches such as network graphs [Karpovich, 2017].\n\nSpatialization [Fabrikant, 2017], a technique that uses spatial metaphors to aid cognitive tasks, has been a research field since the early \u201890s. It can be used to make sense of vast amounts of information by reducing them to a physical landscape. In this work, we consider spatialization of topics in a 3D space where the X-axis is the similarity of topics posted on the same day, the Y-axis is the similarity of topics across time and how their relationships evolve, and the Z-axis is a measure of the topic popularity. With this approach, a topic is therefore reduced to a single point in a 3D space, and the interpolated surface constructed out of these points becomes a landscape with peaks, ridges, and valleys. More precisely, the \u201cvalleys\u201d represent less popular topics, while \u201cpeaks\u201d are the more popular ones and flat surfaces indicate the average topics.\n\nOur team is working on the Australian Data Observatory project, which has been collecting tweets and other social media posts (Instagram, Reddit, YouTube, Flickr, etc)) related to Australia for the last 12 months. Through the use of the new Twitter academic license, the project is harvesting 10s of millions of tweets per month. The social media posts are stored and analyzed daily using the deep learning BERTopic package. The BERTopic output is then stored and served through a ReST API, which is used by different clients (at present these are Jupyter notebooks and a web application). The intended audience of our platform is composed of the average topics domain researchers including social scientists, linguists, and data journalists. The goal is to support big data exploration at scale and overcome the smaller scale cottage industry of social media research that has hitherto been the norm in academia in Australia\n\nTopic modelling is often presented using 2D visualizations, such as circles with size proportional to topic popularity and position related to the similarity between topics, The dynamic (temporal) aspect of topic evolution is typically shown with animations that show how topics morph into different ones and wax and wane in popularity or it is ignored completely and researchers just use static topic modelling visualisations. here is merit in trying a different approach for dynamic topic visualisation: namely, to map the social media landscape to the physical one, as this metaphor allows the simultaneous appreciation of time, topic similarity, and popularity while allowing -via zoom operations- the aggregation/disaggregation of topics into bigger/smaller cluster of posts. This 3D landscape naturally aids the end-user in understanding complex highly dimensional data at a scale and volume that would otherwise be impossible. The formation of islands, archipelagos, mountain ranges or valleys related to mainstream topics such as Covid, vaccination, lockdown, through to geopolitical events such as the invasion of Ukraine provides a finger on the pulse of what is being discussed at scale by the broader population across the social media landscape.\n\nThis approach is currently realised using a web application that enables the \u201ctopographic\u201d exploration of the topic landscape with functions to improve the user experience in the areas of topic labelling and inter-topic distance.\n\nThere are a few criticalities in the proposed visualization:\ndistance between topics has to be drastically reduced in dimensionality from the ones provided by the Deep Learning model to just one (the X-axis);\nthe Y-axis (time) has to be put in relation to a completely different measure (distance between topics) to make it amenable to an interpolation;\ntopic popularity (the Z-axis) has a huge variability leading to irregular surfaces, hence the need for a non-linear scaling of the Z-axis;\ncommunicating the meaning of each topic to the user is difficult, as the top terms of each topic may not be meaningful to a human, and make for a poor label.\nThe proposed processing and visualization is developed using only open-source tools and frameworks, leveraging the work of the open-source geospatial community.\n\nAll the software developed in the course of the Australian Data Observatory project is available under the Apache 2.0 license, and available through the University of Melbourne GitLab source code repository.\\n\\nLuca Morandini\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/MNJ3TT/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/18 Dalia Varanka.mp4", "persons": "Dalia Varanka", "pretalx_id": "CHBS39", "title": "FOSS4G 2022 | A knowledge graph prototype for national topographic data", "description": "Spatial data infrastructures prioritize data interoperability to serve their diverse communities. Geospatial knowledge graphs (GKG) are a form of database representation and handling that aim to meet the challenges of data interoperability, reasoning for information storage and knowledge creation, and user access that provide coherent spatial context to a domain of information.  This paper discusses the development of a prototype GKG based on national topographic databases. Geospatial data are used to test interoperability aspects of ontology creation, faceted search and retrieval using GeoSPARQL (Open Geospatial Consortium, 2022), and user interface for data visualization and evaluation. The challenges are to capture and represent geographic semantics inherent in the source data, to integrate data from outside sources through SPARQL Protocol and RDF Query Language (SPARQL) queries and to visualize the data using a cartographic user interface.\n\nPoore (2003) identified four levels of data interoperability: articulation, sharing, integration, and alignment. These concepts are carried into the semantic technology design and application. Called the Map as Knowledge Base (MapKB), the approaches use software components to build a system architecture aligned with available standardized vocabularies and is composed entirely of free and open-source software for geospatial data The application was created in the context of The National Map of the U.S. Geological Survey (USGS). For purposes of data interoperability, the GKG ontology, queries, and visualization were studied for the system.\nData pre-processing involved creating a GKG ontology. The ontology was semi-automatically transformed from source databases through the application of rules on schema attribute, domain, and metadata files to create classes, properties, and other triple resources of Resource Description Framework (RDF) and Web Ontology Language (OWL) (Hayes and Patel-Schneider, 2014; Hitzler and others, 2012). An R2RML file was created using Web-Karma for transforming the feature-level instance data using the ontology and confirmed using standards specifications (University of Southern California, 2016; Das and others, 2012). The converted data and ontology are imported into a triplestore for data handling.\n\nA cartographic user interface (UI) was created as a foundation for the visualization and interaction of users with the triplestore graphs. The general guidelines given by the information search process model serves to guide UI functionality (Kuhlthau, 2004). The user interface offers menu search options by namespace for typically retrieving initial results. Multiple graphs can be visualized at once. Other queries can be performed on the initial results appearing on a map or table by faceted search and by query builder interfaces for SPARQL. An advanced feature description function retrieves related properties to support browsable graph searches. Linked Open Data were retrieved using SPARQL endpoints to test linking triples. Some GeoSPARQL support was created for geospatial queries on feature geometries of the GKG use cases.\n\nThe automated transformation ontology revealed aspects of data silos that were known to exist. However, the ontology model created a new perspective of data resources across the enterprise, where resource semantics could be streamlined for reuse. This was demonstrated in the post-processing stage of the ontology creation. The system and ontology design were validated through reasoning of semantically related data and pre-determined competency questions relevant to reasoning results. An ontology pattern of aligning feature classes represented as codes and geometries of The National Map matched to the GeoSPARQL ontology feature and geometry classes was validated using reasoners. The ontology for feature interoperability provided inferred information for competency questions such as \u201cWhat type of feature is classified as FCode 73002,\u201d or \u201cHow are streams represented geometrically?\u201d  The GKG alignment with Linked Open Data used some specific widely used vocabularies to be reused between graphs, and problems encountered could be resolved by designing a better metadata annotation approach for structural alignment in addition to syntax matching.  Multiple GeoSPARQL queries executing topological relations on features were successfully demonstrated with a pre-built query to find specified buildings on a road section between two cross streets.  Such a query can depend on the shape of the road, building distance from the roadway, and other factors. The queries required a change in viewpoint from machine computation to landscape cognition creating related semantic factors, and then were followed by GeoSPARQL function computation.\n\nThis project tested some key challenges for GKG applications for spatial data infrastructure interoperability including data transformation, ontology design, information search and retrieval, and multi-modality cartographic visualization.  Completing the resulting ontology from automated data transformation for knowledge representation is still a cognitive activity.  RDF and OWL vocabulary were sufficiently expressive to demonstrate linking and reasoning successes. Improved metadata annotation systems are needed for on-the-fly entity resolution. Although initial tests of GeoSPARQL techniques were successful, the full capabilities of SPARQL as a rule-based reasoning tool would need further research for queries that leverage the full semantic capabilities of knowledge graphs and for their portrayal.\n\nDisclaimer Any use of trade, firm, or product names is for descriptive purposes only and does not imply endorsement by the U.S. Government.\\n\\nDalia Varanka\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/CHBS39/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/19 Daniele Codato.mp4", "persons": "Daniele Codato", "pretalx_id": "NN8FGL", "title": "FOSS4G 2022 | Geo-ICTs for Good: a MOOC on GIScience for Climate Justice", "description": "The last two decades have seen the development and diffusion of new technologies and digital ecosystems for managing geographic data. These include, among others, smartphones, drones and open access satellites on the one hand, and the web 4.0, GIS, WebGIS, geo-app and georeferenced data, both open-source or proprietary, on the other. This great variety of tools, accompanied by the sharing of new digital knowledge and skills, have made the creation and management of spatial information much more accessible than it was in the past.\nThis has led to a proliferation of processes for exploring, creating and sharing geographical data from below as a way for citizens, that assume the role of neo-geographers or prosumers, to take part in decision-making in different kind of processes, such as territorial, environmental and climate change issues (Goodchild, 2009; Capineri et al., 2016; See et al., 2016).\nHowever, these are ongoing processes that have still to face technological, cognitive and economic barriers. Universities with the use of open-source geo-information and communication technologies (Geo-ICTs) in enhance geographical learning should be a primary actor in supporting students and citizens in developing their own spatial thinking in a more efficient and engaging way (K\u00e4yhk\u00f6 et al., 2021). In fact, this is remarked also in objective 4 of the Sustainable Development Goals \"to guarantee quality, inclusive and equitable education and to promote lifelong learning opportunities for all\u201d and many universities have signed the Higher Education Sustainability Initiative (HESI) which commits them to integrate the concepts of sustainable development into the curricula.\nIn this framework is involved also University of Padova (Italy) with its Jean Monnet Centre of Excellence on Climate Justice (Jean Monnet Erasmus+ project 2021-2023) led by the research group \u201cClimate change, territories, diversities\u201d (https://www.climate-justice.earth/). The Centre is trying to respond to the need of bringing the issues of Climate Justice and just transition from the EU Green Deal framework into the dialogue between the academic world, society, and policy makers. To do this, it is carrying out different research and didactical activities, among which the development of a MOOC (Massive Open Online Course) on GIScience for Climate Justice with the use of opensource and freeware Geo-ICTs, that will be freely available for all before the end of 2022.\nThis MOOC will provide videos and materials about practical activities concerning climate change and climate justice issues, that the students can carry out autonomously using open-source and freeware tools. For every activity the workflow and a graphical abstract will be provided with aims and skills to be acquired and an introductive video with a real example of use and suggestions about how to build collective projects of citizen science. An auto-evaluation module will be available to students. MOOC will be tested with selected students and eventually adjusted before its online publication. A feedback and comment area to interact with staff members will be also available in the platform. The programme will follow learning by doing approach and is design to drive students through the main phases of a GIScience project:\n\n - The exploration and use of the European Platforms (e.g Earth Observation Portals, Joint Research portals, European Environment Agency portals, European Environmental Bureau)\n - The exploration and use of the Geonode on Climate Justice (https://research.climate-justice.earth/), the geo-platform of the Centre that will be available to everyone with all the information collected by the Centre and the possibility to create online maps and to upload and share data by interested users or association groups.\n - The Collection and sharing of environmental and social information using geo-app and webGIS (e.g odk collect app and ona platform)\n - The exploration and use of Google Earth Pro and the OpenStreetMap project Umap\n - The creation of storymaps to share climate change fighting initiatives and climate justice stories on the web (e.g knight lab storymap and geonode storymap tools)\n\nBy completing the MOOC, students will learn how to autonomously update and increase their knowledge on climate change and climate justice issues, learning to navigate and use European platforms and portals and to search for the documentation available in the European and international institutions. Practical activities will improve skills of students and organizations of civil society to obtain and use data and information produced by European institutions, to produce and share their own data, and to prepare and manage collaborative projects for sustainability and environmental monitoring.\nOpen-source software will be also the basis for the setup of the MOOC, from its preparation using open video editing and open document formats, to its publication using the Moodle of the University of Padova.\nIn this contribution, the theoretical background, the entire methodology and workflow process for the preparation and dissemination of the MOOC will be presented and discussed, with the aim to disseminate and share this experience to actors interested in developing similar activities of using of Geo-ICTs for Good.\\n\\nDaniele Codato\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/NN8FGL/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/20 Daniele Strigaro.mp4", "persons": "Daniele Strigaro", "pretalx_id": "YSG7XQ", "title": "FOSS4G 2022 | Automatic assessment of lake health status using an open source approach: Lugano lake case study", "description": "Lakes are a fundamental resource with a number of environmental benefits and with a not negligible influence on the local economy and on the quality of life. They work as a storage of water when floods or droughts occur, in the first case, they are useful to laminate the excessed flux of water, in the second as water supply during shortages. In addition, they influence the filling of groundwater and they play a role in the preservation of the general habitat biodiversity. From an economical point of view, they are an attraction for tourism, residential living as well as a source of recreation and of work for fishers.\nUnfortunately, climate changes together with human activities are more and more threatening such resources modifying the known dynamics and affecting the general health status of lakes (Fenocchi et al. 2018; Free et al. 2021; Lepori et al. 2018).\nIn this context, the INTERREG project SIMILE (System for the Integrated Monitoring of Insubric Lakes and their Ecosystems), born from the collaboration between Italy and Switzerland, aim at developing an information system using an open source approach and based on innovative technologies to help decision maker in the management and evaluation of the status of the transboundary and sub-alpines lakes such as Lake Maggiore, Lugano and Como. The SIMILE project wants to intensify the monitoring of these lakes by creating an open real-time monitoring system and by integrating data coming from different sources in order to create the possibility to fully exploit the potential with the heterogeneity of the available information and better studying the resource.\nThe work presented in this paper is focused on the achievements reached by the research carried out on lake Lugano in the context of the SIMILE project after two years of work. In particular, the presented research is oriented on the automatic generation of some indicators that are usually calculated to evaluate the lake status through the use of open standard, software and hardware.\nLake Lugano is a transboundary lake divided in two main watersheds, North and South, respectively with an area of 27.5 Km2 and 21.4 Km2 and a maximum depth of 288 and 89 m. It is a eutrophic lake which has a critical health status in particular during the 70s, but thanks to new regulations and to the mitigation actions studied by the Swiss administration it is recovering. One of the fixed targets is to reach 150 gC/y which corresponds to a mesotrophic status. This value gives information about the metabolism activity of the lake and can be calculated using different approaches. At this moment, on lake Lugano, to get such information monthly campaign according to the Nielsen method (Nielsen, 1952). This approach is the one recognized by the administration and it is conducted by specialist limnologists. However, it has some issues that can be synthetized in three points: 1) it needs the use of radioactive components; 2) it is quite expensive in terms of man hour and the engagement of an external laboratory to analyze such kind of special samples; 3) since it has a monthly temporal resolution it needs mathematical model to interpolate data between the different campaigns.\nAccording to this overview, the proposed paper wants to investigate a fully open web solution in order to calculate indicators that can help in understanding the health status of the lake and try to solve the individuated limits that are currently affecting the water monitoring. Such an open platform uses open standards as the Sensor Observation Service (SOS) of the Open Geospatial Consortium (OGC) to integrate different sources of data and to offer the possibility to gather the information in a standardized way. Thanks to this achievement, it was possible to develop.  The scope is to standardize the calculations and provide a solution where indicators can be calculated automatically saving also time since the traditional process. Potentially such an approach could calculate in real-time the indicators thanks to the use of the LISTEN/NOTIFY feature which exists in PostgreSQL, the database technology on which the platform is based. Finally, in this paper is presented the preliminary results  of the development of a new algorithm to calculate the lake metabolism which can, if validated, offer a new approach that can solve the individual issue of the current one. Basically, the developed open monitoring system implemented and deployed on the lake offers real-time data\nThe platform is composed of dockerized and specialized services in order to offer a suite that is easily replicable, scalable and upgradeable.\nIn conclusion, an overview of the results reached during these years of project is presented. Such a solution increases the replicability of the system since it is fully open and guarantees the openness of data, source code, standards and also the hardware part. Such technologies help in developing an automatic system that can calculate indicators to help decision makers in managing the water resource and scientists to better study the new unknown dynamic and facing the new challenges to which lakes are exposed.\\n\\nDaniele Strigaro\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/YSG7XQ/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-25/Room_Hall_3A/21 Nedjma Hadj Kaddour.mp4", "persons": "Nedjma Hadj Kaddour", "pretalx_id": "XTRBUU", "title": "FOSS4G 2022 | Development of a collaborative platform for intelligent territorial mapping of the city of Oran", "description": "In developing countries, sustainable development and territorial intelligence are of greater interest to public authorities and citizens. In Algeria, the combination of resources with technological innovation goes in the direction of building a productive territorial intelligence. This translates into a process aiming at developing a systemic approach of the territory in order to analyse its physical, social and economic dimensions in order to exchange the different points of view of the territorial, social and economic actors and to make the policies more coherent. In this contribution, we have focused the research on studies related to decisional computing used by governmental entities, especially in the field of public services. It turned out that the use of collaborative web platforms involving several actors belonging to different spheres (government, economy, social, etc.), constitutes a tool for the development of territorial intelligence thanks to the availability of data which allows a considerable saving of time and cost. Indeed, the construction of a territorial information system makes possible the networking of these actors, to elaborate clear and reliable schemes of urban planning for a liveable environment, which led us to think about the implementation of a web platform for exchanges, collections, production and dissemination of data and social animation to reach equitable consensus. This will allow, among other things, the development of project management through the formalisation of objectives and collaborative work for the planning and optimisation of tasks. Geographical information is a crucial element in most of the daily uses thanks to the intelligent applications put online and exploited by different categories of connected people. Therefore, the interest and necessity of sharing geo-located information for decision support systems is well proven nowadays. In the same context, participatory mapping initiatives through voluntary geographic information (VGI), citizen-generated content or crowdsourcing are now being used as a new instrument for information gathering and two-way exchange between the various entities in the urban environment ranging from ordinary citizens to leading actors. This direct data is a key element in all the decision-making processes leading to the achievement of urban governance modalities. The objective of our work is to provide an interactive solution ensuring the collaboration of actors (decision-makers and citizens) on a webmapping platform for the reporting of needs by citizens in terms of public services such as road defects, public lighting failures and any other existing problems in an urban area. This application could also be used for emergency alerts (road accidents, natural disasters, etc.). As a study area, we chose the city of Oran, located in the west of Algeria, which is the second largest urban metropolis in the country. The realization of the collaborative web mapping platform is based on Free and Open-Source Software for Geospatial (FOSS4G). As a spatial database management system, we used PostgreSQL with its spatial extension PostGIS, which is classified as one of the most powerful open source DBMS. The GIS server used in our application is GeoServer, which guarantees to satisfy a maximum of required webmapping services (WMS, WFS, WMTS, WCS, etc.). The webmapping interface must offer two main components: an interactive citizen space with the web map and a space for decision makers who will be able to consult, verify and validate the data sent in order to proceed with the action. Among the development options for this type of webmapping interface, we are interested in GeoNode, an open source framework based on mature and robust frameworks and software like Django, OpenLayers, PostGIS, GeoServer and pycsw. In our case, GeoNode will allow the integration of a multitude of geospatial functions for manipulating data and responding to any type of request on the web map. The platform, which we have named \"Wilayati\", will offer new participatory methods for monitoring activities in the urban environment. Its functionalities will ensure, on the one hand, the sharing of data on a map based on voluntary contributions from the citizens of Oran and, on the other hand, the visualisation and manipulation of the data by decision-makers in order to give them a support for the management of localised interventions. Different types of data on the urban fabric of the city of Oran were collected from the processing of satellite images as well as datasets on the road network of Oran obtained from OpenStreetMap after improving the intrinsic quality. In parallel, a campaign on social networks will soon be launched, with the aim of better analysing the orientations of the public services most requested by citizens. The application, under development, will provide a new source of data that can be easily exploited in urban governance and will provide a way for citizens to participate in improving their environment through regular updates of the geographical database. Finally, as a perspective, the results, after deployment of the platform, will give an overview of the impact of citizens in participatory mapping highlighting points of interest and urban infrastructures of cities in Algeria.\\n\\nNedjma Hadj Kaddour\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/XTRBUU/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Modulo_3A/1 Antoine Drabble.mp4", "persons": "Antoine Drabble, Bertil Chapuis", "pretalx_id": "XHUGFC", "title": "FOSS4G 2022 | Maplibre-rs: Toward portable map renderers", "description": "Map renderers play a crucial role in various applications deployed in Web, desktop, mobile, and embedded environments. For instance, we rely upon them to travel, commute, find the best hotels and restaurants, and locate our closed ones. More digital applications emerge in various areas, such as urban planning, transportation, or even pandemic monitoring, as they get adopted. Beyond digital environments, it is worth noting that maps also get printed in books, reports, or pieces of urban furniture.\n\nIn this context, code portability, i.e., the ability to use the same codebase on various platforms, is a common problem. For instance, Mapbox and Maplibre both maintain a JavaScript codebase for the Web (e.g., maplibre-gl-js) and a C++ codebase for native platforms (e.g., maplibre-gl-native). These codebases enable their renderers to run in all major browsers (thanks to WebGL), in the main desktop and mobile environments, on servers (e.g., for headless rendering), and in cars, planes, or embedded settings. Guarantying that these renderers behave similarly and produce the same outputs on all these platforms is hard, costly, and slows down the ability of development teams to innovate and improve renderers.\n\nIn this paper, we review the most popular map renderers from a portability point of view. We show that the existing codebases written in Javascript, C++, and Java fail at least in one area or another at producing a portable map renderer. Additionally, we present a state of the art for code portability, and we describe emerging standards and technologies that promise to enable truly portable and high-performance map renderers written in C++ or Rust to emerge. Among these emerging technologies, we find:\n\n - *Rust -* Rust is a high-level programming language designed for safety and high performance. The project started at Mozilla and is now developed by the Rust foundation. Its compiler targets native architecture, enabling it to compile applications for desktop (x86) and mobile (arm) environments. Additionally, the Rust compiler can target WebAssembly, a binary instruction format that can run on web browsers with near-native speeds. This not only enables Rust applications to run in native environment but also to be included as a library in Web applications. As a result, the same codebase can be used anywhere with only a few modifications.\n\n - *WebGPU\t-* WebGPU is a 3D low-level API that runs on top of DirectX, Metal, Vulkan or OpenGL depending on the platform and gives the developer access to the GPU. It is developed by the W3C GPU for the Web Community Group with engineers from Apple, Microsoft, Mozilla, Google, and others. It is considered the successor of WebGL version 2. Contrary to WebGL version 1 and WebGL version 2, which were solely designed for the Web, WebGPU implements a standard header file (webgpu.h) that makes it cross-platform.\n\nBased on the emerging technologies identified in the review, we study the feasibility of creating a truly portable map renderer. We present maplibre-rs, a proof-of-concept released under the terms of the Apache Software License, that can render vector tiles natively and in the browser. We describe its overall architecture and highlight some of the challenges encountered while devising a portable solution that transforms vector tiles into 2d and 3d objects. These challenges include:\n\n - *Rendering 2d vector tiles in a 3d environment -* The vector tile specification describes simple 2d objects encoded in grid coordinates, such as points, lines, polygons, multi-polygons, and polygons with holes. Several steps enable to convert these 2d objects into 3d objects that can be rendered in a scene, including: the conversion of grid coordinates into 3d scene coordinates; the tessellation of polygons to display surfaces in the 3d environment; the extrusion of buildings based on their number of storeys with an attribute stored in the vector tiles.\n\n - *Using WebGPU as a portable 3d rendering pipeline -* WebGPU exposes a wide variety of features to render 3d scenes. Among them, we explore: the rendering of the 3d objects with the WebGPU Shading Language (WGSL) based on styling rules and object attributes; The navigation within the 3d world with the camera, user inputs, rotation on 3 axes, levels of details and occlusion culling; The configuration of the graphic card, graphics API and more.\n\n - *Devising a portable network library -* Rust does not provide a network library that works both natively and in the browser. We created a uniform interface to download vector tiles to address this issue. This interface, based on the facade pattern, uses macros to select the proper implementation at compile-time depending on the targeted architecture. The native implementation relies on the HTTP package of the standard library. The WebAssembly implementation relies on Fetch API bindings.\n\nFinally, we present our future work and explore possible ameliorations. Overall, this review and feasibility study gives an exciting glimpse on a possible future for map renderers, where the same code can run natively and in a browser.\\n\\nAntoine Drabble\\nBertil Chapuis\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/XHUGFC/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Modulo_3A/2 Lorena Abad.mp4", "persons": "Lorena Abad", "pretalx_id": "XTSQPL", "title": "FOSS4G 2022 | An open-source-based workflow for DEM generation from Sentinel-1 for landslide volume estimation", "description": "Digital elevation models (DEMs) are a representation of the topography of the Earth, stored as elevation values in regular raster grid cells. These data serve as basis for various geomorphological applications, for example, for landslide volume estimation. Access to timely, accurate and comprehensive information is crucial for landslide analysis, characterisation and for understanding (post-failure) behaviours. This information can subsequently be used to effectively assess and manage potential cascading hazards and risks, such as landslide dam outburst floods or debris flows. Freely available DEM data has been an important asset for landslide volume estimation. Earth observation (EO) techniques, such as DEM differencing, can be leveraged for volume estimation. However, their applicability is reduced by high costs for commercial DEM products, limited temporal and spatial coverage and resolution, or insufficient accuracy.\n\nSentinel-1 synthetic aperture radar (SAR) data from the European Union's Earth observation programme Copernicus opens the opportunity to leverage free SAR data to generate on-demand multi-temporal topographic datasets. Sentinel-1 A & B data provide a new opportunity to tackle some of the problems related to data costs and spatio-temporal availability. Moreover, the European Space Agency (ESA) guarantees the continuity of the Sentinel-1 mission with the planned launch of another two satellites, i.e., Sentinel-1 C & D. Interferometric SAR (InSAR) approaches based on Sentinel-1 have often been used to detect surface deformation; however, few studies have addressed DEM generation (Braun, 2021). For example, Dabiri et al. (2020) tested Sentinel-1 for landslide volume estimation, but highlighted the need to further research and systematically assess the accuracy of the generated DEMs. InSAR analysis is often conducted using commercial software; however, a well-structured workflow based on free and open-source software (FOSS) increases the applicability and transferability of the DEM generation method. Although a general workflow for DEM generation from Sentinel-1 imagery based on InSAR has been described and documented (ASF DAAC, 2019; Braun, 2020, 2021), there is still a need for improvement, harmonisation and automation of the required steps based on open-source tools.\n\nWithin the project SliDEM (Assessing the suitability of DEMs derived from Sentinel-1 for landslide volume estimation), we explore the potential of Sentinel-1 for the generation of multi-temporal DEMs for landslide assessment leveraging FOSS. Relying on the open-source Sentinel Application Platform (SNAP) developed by the ESA, the Statistical-Cost, Network-Flow Algorithm for Phase Unwrapping (SNAPHU) developed by Stanford University, and several other open-source software publicly available for geospatial and geomorphological applications, we work on a semi-automated and transferable workflow bundled in an open-source Python package that is currently under active development. The workflow uses available Python SNAP application programming interfaces (APIs), such as snappy and snapista. We distribute the SliDEM package within a Docker container, which allows its usage along with all its software dependencies in a structured and straightforward way, reducing usability problems related to software versioning and different operating systems. The final package will be released under an open-source license on a public GitHub repository.\n\nThe package consists of different modules to 1) query Sentinel-1 image pairs based on perpendicular and temporal baseline thresholds that also match a given geographical and temporal extent; 2) download and archive suitable Sentinel-1 image pairs; 3) produce DEMs using InSAR techniques and perform necessary post-processing such as terrain correction and co-registration; 4) perform DEM differencing of pre- and post-event DEMs to quantify landslide volumes; and 5) assess the accuracy and validate the generated DEMs and volume estimates against reference data. The core module focusses on DEM generation from Sentinel-1 using InSAR techniques available in SNAP. The script co-registers and debursts Sentinel-1 image pairs before generating and filtering an interferogram. Phase unwrapping is performed using SNAPHU. The unwrapped phase is then converted into elevation values, which are finally geometrically corrected and co-registered to a reference DEM. Co-registration is based on assessing the normalised elevation biases over stable terrain (after Nuth and K\u00e4\u00e4b, 2011).\n\nWe assess errors and uncertainties for each step and the quality of the Sentinel-1 derived DEMs using reference data and statistical approaches. The semi-automated workflow allows for the generation of DEMs in an iterative and structured manner, where a systematic evaluation of the resulting DEM quality can be performed by testing the influence of different temporal and perpendicular baselines, the usage of ascending and descending passes, distinct land use/land cover and topography, among other factors. Several major landslides in Austria and Norway have been selected to evaluate and validate the workflow in terms of reliability, performance, reproducibility, and transferability.\n\nThe SliDEM workflow represents an important contribution to the field of natural hazard research by developing an open-source, low-cost, transferable, and semi-automated method for DEM generation and landslide volume estimation. From a practical perspective, disaster risk management can benefit from efficient methods that deliver added-value information. From a technical point of view, SliDEM tackles scientific questions on the validity of EO-based methods and the quality of results related to the assessment of geomorphological characteristics of landslides.\\n\\nLorena Abad\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/XTSQPL/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Modulo_3A/3 Victor N.Sunday-.mp4", "persons": "Victor N.Sunday", "pretalx_id": "Y98TUU", "title": "FOSS4G 2022 | Analysis of Local and Remote Mappers\u2019 Open Geographic Data Contribution to Oil Spill Disaster Response in Niger Delta Region, Nigeria", "description": "Open mapping leverages on volunteer mappers mobilized and engaged from the public.  volunteers most often are trained and coordinated virtually to carry out dedicated mapping task, irrespective of their geographic location, professional and academic background. In this study volunteer mappers engaged are categorized into two namely: the Local Volunteer Mappers (LVM) comprising of all the potential and actual mappers resident in Nigeria and the Remote Volunteer Mappers (RVM) comprising of all potential and actual mappers not resident in Nigeria.\nThe study   sampled 2 Local Government Areas (LGAs) of River State from the 4 vulnerable oil spill disaster LGAs of Ogoni land communities. Ogoni land is a major oil spill disaster vulnerable area of Nigeria, being the major host communities of crude oil exploitation in the Niger Region of Nigeria. Following the hazardous impact and damage of Ogoni land by oil Spill disaster over the years of oil exploitation in Niger Delta, UNEP assessed that the environmental restoration of Ogoni land would require coordinated efforts on the part of government agencies at all levels, industry operators and communities. UNEP also presented its recommendations as a major opportunity to bring new investment, employment opportunities and a culture of cooperation to Ogoni land in addition to driving improvements in the environmental and health situation on the ground. To effectively implement the UNEP recommendations for restoration of Ogoni land, there is a need for a geographic data that provides critical building footprint in the area, especially, to identify and access the vulnerable oil spill communities. Maps produced would be used by government agencies and other stakeholders working to implement UNEP report on Ogoni land restoration as well sustainable development.\nConsequently, the study engaged volunteer mappers to respond to sampled Oil spill communities viz-viz 3 LGAs in Rivers State, Niger Delta Region of Nigeria. To assess the level of participation of Local (mappers in Nigeria) and Remote Mappers (Not Resident in Nigeria), two mapping projects were created in HOT tasking manager for local and remote mappers respectively. For the purpose of campaigning for Volunteer Mappers the 2 project tasks were tagged \u2018\u2019 Mapathon Battle for Vulnerable Oil Spill Disaster Communities in Niger Delta\u2019\u2019 respectively. Project task 6358 was created exclusively for remote mappers outside Nigeria to map Tai LGA, while, project task 6359 was created exclusively local mappers resident Nigeria to map Gokana LGA in a Mapathon battle challenge. Project task 6358 had a total grided cells of 825 mapping tasks for online engagement of mappers while project task 6359 had an automated grided cells of 706 mapping tasks due to differences in the size of the area.  The Mapathon unveiled the following research results. Engagement of remote mappers for project task 6358-Tai LGA shows that out of the 583 tasks completely mapped, only 13 were yet to be validated after 2 years of creating the project. This is as a result of archiving the project and diversion of attention to urgent tasks. The project recorded a total of about 16,416 edits comprising of 13,552 buildings and 858km of roads mapped in Tai LGA within the timeline of the study. Demographic characteristics of the contributors to project 6358 on the basis of HOT Tasking Manager users by experience and level shows that 50% were advance mappers and 100 % has more than 1 year mapping experience  .The project engaged a total of 56 contribtors  by mapping and validation. All mappers and validators by experience has used the tasking manager for more than  1 year while their  mapping levels ranges between  40% for beginner mapper, 10 % for intermediate and 50 % for advanced mappers. The project timeline as illustrated by the graph shows that mapping and validation of the Tai LGA task commenced on the same date: 6th August,2019 at the rate of 12% mapping and 2 % validation. Mapping progressively ascended to 64% on the 4th day and got to its peak on the 9th day being 15th August with 99% of the entire task mapped. However, validation of the mapping task had a straight curve with the highest peak of validation being the 12th of September with 95% of the task being validated. By 8th January ,2020, being 6th months of the project,100% of the tasks were completely mapped while 13 of the 596 tasks were yet to be validated. The timeline statistics also shows that an average of 20mintes 46 seconds was the time spent per task to map a total of 583 tasks of 16,416 edits. Also, an average of 6minutes 16seconds was spent for validation per task leaving about 1hour 21minutes 29seconds to finish up the validation of 13 tasks left unvalidated due to a shift to other project tasks and less passion for the project under study. However, the analysis of local mappers engaged in HOT Project Task 6359 Gokana LGA also unveiled the following: The study shows that 706 (100%) of the tasks were completely mapped except for validation of 473(67%) tasks which requires further coordination of mappers. There is no record of bad imagery and tasks left unmapped. The project also recorded a total of about 2064 changesets for mapping a total of about 18,367 edits, comprising of 14,983 buildings and 521 km of roads. The project also recoded a total of 173 contributors comprising of 169 mappers and 8 validators. These mappers (100%) had more than 1year experience in online mapping with OpenStreetMap and are categorized into beginner mappers (72%), intermediate (6%) and advance mappers (21%). The entire project timeline by mapping and validation took a period of about 2years 4months(28months) from 6th August 2019 to 27th December ,2021 as at the time of writing this report. Conclusively, there is a lacuna worthy of research investigation in the mapping response level and capability of remote mappers from other countries and local mappers from Nigeria in crowdsourced rapid response mapping using OpenStreetMap.\\n\\nVictor N.Sunday\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/Y98TUU/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Modulo_3A/4 Alex Orenstein-.mp4", "persons": "Alex Orenstein", "pretalx_id": "YRLJNG", "title": "FOSS4G 2022 | Using Sentinel 2 images to quantify agricultural encroachment in Burkina Faso\u2019s protected livestock reserves", "description": "In many parts of Burkina Faso, competition over land use has increased tensions and often conflicts between farming and herding communities. Allocating land for farming or grazing is increasingly perceived as a zero-sum calculation among these communities. As a response, the government of Burkina Faso created \u201cPastoral Zones\u201d across the country as reserves for livestock herders where animals could graze without the risk of entering cropland. Farming in these areas is typically prohibited unless done by herders residing within the reserve. However, farms have appeared in pastoral zones over the years, reducing resources available to herders and exacerbating already fraught tensions between herding and farming communities (N\u00e9bie et al 2019). This study uses Sentinel 2 imagery to quantify to what extent agricultural growth is encroaching on two such pastoral zones in Southern Burkina Faso, Niassa and Sondr\u00e9-Est. This study found a significant growth of agricultural cultivation in both zones between the period of 2016 and 2021.\n\nTo map agricultural growth, Sentinel 2 imagery was used in Google Earth Engine (GEE). Reproducibility and accessibility were prioritized, hence the use of a free platform and open EO data was prioritised. Google Earth Engine stood out as an accessible cloud platform to easily access the imagery and run the analysis (Gorelick et al, 2017). To visualise agricultural areas, the \u201c3 Period Timescan\u201d (3PTS) Method was employed. This method uses a series of NDVI Images from the Sentinel 2 satellite throughout a growing season to isolate areas of active cultivation. This product consists of a Red-Green-Blue composite of Sentinel-2 Images where the red band represents the maximum NDVI value during the first period of the growing season, the green the maximum NDVI in the middle, and the blue the maximum NDVI at the end. As a result, the method is able to create a seasonal time-series profile of NDVI. A single NDVI product provides an indication of vegetation presence on a given date, but it is not sufficient to distinguish croplands from other types of vegetation. Croplands are thus identified by their temporal evolution of NDVI values throughout the different phases of the agricultural season: photosynthetic activity of crops is low during the planting period (\u201cbeginning of the season\u201d, approximated by 15th June to 1st August), increases during the growing phase (\u201cmiddle\u201d, 2nd August to 1st September) until reaching a maximum value right before the harvest; once harvested, NDVI values decrease drastically  (\u201cend of season\u201d, 2nd September to 15th October). Thus, the approach employed for investigating cropland change considers maximum NDVI values for those three separate subperiods of the agricultural season and aggregates this information into a higher-level product, a RGB color composite so-called 3-Period TimeScan, reflecting the vegetation temporal evolution during the agricultural period, at 10m resolution (Boudinaud and Orenstein, 2021).\n\n3PTS images allow for a user-friendly method to visually identify cropland. Cropland pixels from 3PTS images, when visualized in GEE appear in a dark blue due to the sharp changes from the 2nd and 3rd periods of the time series. This contrasts well with natural vegetation, which has a smoother temporal profile with a noticeable peak in the 2nd period and thus appears greener or a much lighter blue.  Forests, due to their high NDVI values throughout the entire growing season appear in white, due to the saturation of all 3 bands. Bare soil, with it\u2019s low NDVI values throughout all 3 periods appears as nearly black pixels.\n\nRather than machine learning, visual identification was the preferred method of identification due to the relatively small size of each pastoral zone. The time needed to prepare training data and clean the results of a supervised classification would have exceeded the time to manually identify each area of cropland. As a result, once the images were treated by GEE, they were manually traced within QGIS. The 3PTS script, originally made for GEE was then translated to run in PyQGIS. Once run, the script created a raster image for each year\u2019s growing season in the archive (2016-2021) and polygons were traced over each visualised cluster of cropland. The total surface area of all polygons was then calculated for each year. A github repository contains both the PyQGIS and GEE code and can be run with no prerequisites (https://github.com/oren-sa/3PTS).\n\nThe results of the study indicate a significant increase in cultivation in both zones between 2016 and 2021. For Sondr\u00e9 Est, this change amounted to 40% and 160% for Niassa.Curiously, the largest increase in cultivation seems to occur between 2016 and 2017. This is especially so for Niassa. Nonetheless, increases in cultivation increased with each passing year until the present year of 2021.  A number of these fields are suspected to be encroachments, given their proximity to the border of the zone and that many are contiguous with the agricultural fields outside of the zone\u2019s borders. However, it is estimated that a number of the fields are the result of the zones\u2019 resident herders planting fodder or other cereals. The latter assumption is made based on the location of the fields in question (far from the borders of the reserves) and their proximity to permanent structures in the reserves (habitations, wells or park buildings).\\n\\nAlex Orenstein\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/YRLJNG/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Modulo_3A/5 Nils Hempelmann-.mp4", "persons": "Nils Hempelmann, Carsten Ehbrecht", "pretalx_id": "YWMWFK", "title": "FOSS4G 2022 | Deployment of AI-enhanced services in climate resilience information systems", "description": "Producing and providing useful information for climate services requires vast volumes of data to come together that further requires technical standards. Beside ordinary base processes for climate data processing like polygon subsetting, there is the special case of extreme climate events and their impacts, where scientific methods for appropriate assessments, detection or even attribution are facing high complexity for the data processing workflows. Therefore the production of climate information services requires optimal science based technical systems, named in this paper climate resilience information systems (CRIS).  CRIS like the Climate Data Store (CDS) of the Copernicus Climate Change Service (C3S) are connected to distribute data archives, storing huge amounts of raw data themselves and containing processing services to transform the raw data into usable enhanced information about climate related topics. Ideally this climate information can be requested on demand and is then produced by the CRIS on request by the user. This kind of CRIS can be enhanced when scientific workflows for general climate assessment or even extreme events detection are optimized as information production service, accordingly deployed to be usable by extreme events experts to facilitate their work through a frontend. Deployment into federated data processing systems like CDS requires that scientific methods and their algorithms be wrapped up as technical services following standards of application programming interfaces (API) and, as good practice, even FAIR principles. FAIR principles means to be Findable within federated data distribution architectures, including public catalogs of well documented scientific analytical processes. Remote storage and computation resources should be operationally Accessible to all, including low bandwidth regions and closing digital gaps to \u2018Leave No One Behind\u2019. Aggreeing on standards for Data inputs, outputs, and processing API are the necessary conditions to ensure the system is Interoperable. Finally they should be built from Reusable building blocks that can be realized by modular architectures with swappable components, data provenance systems and rich metadata.\nGeneral building blocks for climate resilience information systems\nA particular focus will be the \"roocs\" (Remote Operations on Climate Simulations) project, a set of tools and services to provide \"data-aware\" processing of ESGF (Earth System Grid Federation) and other standards-compliant climate datasets from modelling initiatives such as CMIP6 and CORDEX. One example is \u2018Rook\u2019 an implementation of the OGC Web Processing service (WPS) standard, that enables remote operations, such as spatio-temporal subsetting, on climate model data. It exposes all the operations available in the \u2018daops\u2019 library based on Xarray. Finch is a WPS-based service for remote climate index calculations, also used for the analytics of ClimateData.ca, that dynamically wraps Xclim, a Python-based high-performance distributed climate index library. Finch automatically builds catalogues of available climate indicators, fetches data using \u201clazy\u201d-loading, and manages asynchronous requests with Gunicorn and Dask. Raven-WPS provides parallel web access to a dynamically-configurable \u2018RAVEN\u2019 hydrological modelling framework with numerous pre-configured hydrological models (GR4J-CN, HBV-EC, HMETS, MOHYSE) and terrain-based analyses. Coupling GeoServer-housed terrain datasets with climate datasets, RAVEN can perform analyses such as hydrological forecasting without requirements of local access to data, installation of binaries, or local computation.\n\nThe EO Exploitation Platform Common Architecture (EOEPCA) describes an app-to-the-data paradigm where users select, deploy and run application workflows on remote platforms where the data resides. Following OGC Best Practices for EO Application Packages, Weaver executes workflows that chain together various applications and WPS inputs/outputs. It can also deploy near-to-data applications using Common Workflow Language (CWL) application definitions. Weaver was developed especially with climate services use cases in mind.\n\nCase of AI for extreme events investigations\nHere we present challenges and preliminary prototypes for services which are based on OGC API standards for processing (https://ogcapi.ogc.org/processes/) and implementation of Artificial Intelligence (AI) solutions. We will presenting blueprints on how AI-based scientific workflows can be ingested into climate resilience information systems to enhance climate services related to extreme weather and impact events. The importance of API standards will be pointed out to ensure reliable data processing in federated spatial data infrastructures. Examples will be taken from the EU Horizon2020 Climate Intelligence (CLINT; https://climateintelligence.eu/) project, where extreme events components could optionally be deployed in C3S. Within this project, appropriate technical services will be developed as building blocks ready to deploy into digital data infrastructures like C3S but also European Science Cloud, or the DIAS. This deployment flexibility results out of the standard compliance and FAIR principles. In particular, a service employing state-of-the-art deep learning based inpainting technology to reconstruct missing climate information of global temperature patterns will be developed. This OGC-standard based web processing service (WPS) will be used as a prototype and extended in the future to other climate variables. Developments focus on heatwaves and warm nights, extreme droughts, tropical cyclones and compound and concurrent events, including their impacts, whilst the concepts are targeting generalized opportunities to transfer any kind of scientific workflow to a technical service underpinning scientific climate service. The blueprints take into account how to chain the data processing from data search and fetch, event index definition and detection as well as identifying the drivers responsible for the intensity of the extreme event to construct storylines.\\n\\nNils Hempelmann\\nCarsten Ehbrecht\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/YWMWFK/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Modulo_3A/6 Jakub Nowosad.mp4", "persons": "Jakub Nowosad, Mateusz Iwicki", "pretalx_id": "VUQSVM", "title": "FOSS4G 2022 | A method for universal superpixels-based regionalization (preliminary results)", "description": "Generalization is one of the fundamentals of scientific research. In the context of spatial information, generalization needs to allow for finding common properties but also for spatial contiguity. Therefore, such generalization is often made through regionalization - partitioning of space into spatial clusters or regions. This process is vital for environmental studies, where many patterns and processes are autocorrelated spatially. Examples of regionalizations include delineation of ecoregions, detection of homogeneous zones for precision agriculture, definition of climate regions, and so on.\n\nTraditionally spatial generalization was performed manually, often based on a compilation of pre-existing, independently conducted studies. This approach lack of quantitative framework, and thus no systematic checks, modifications or objective updates are possible. Currently, the abundance of remote sensing spatial data, such as satellite imagery, gridded climate data, or land cover maps, allows fast extraction of relevant spatial information on regional and global scales, making possible studies rooted in a clear quantitative framework.\n\nSuch data, however, still requires spatially-aware generalization to formulate general concepts or claims. Remote sensing data stores information as a set of raster cells, where a single cell is unaware of its spatial context. This is often not enough to understand underlying objects or processes.\n\n(Geographic) object-based image analysis (OBIA) (Blaschke 2010) is frequently applied to resolve this issue. It is an approach to partition space consisting of raster cells into homogeneous objects and thus make spatial regionalization possible. Several generalization techniques were developed for OBIA, including a superpixels approach that proved to perform best for image processing and remote sensing data analysis (Csillik 2017).\n\nThe main idea of superpixels is to create connected groupings of cells with similar values (Ren and Malik 2003; Achanta et al. 2012). Each superpixel represents a desired level of homogeneity while at the same time maintaining spatial structures. Superpixels also carry more information than each cell alone, and thus they can speed up the subsequent processing efforts (Ren and Malik 2003; Achanta et al. 2012).\n\nThe original superpixels algorithm has, however, two major drawbacks for spatial data problems other than RGB images. Firstly, the algorithm uses the Euclidean distance, which is adequate in many cases, such as RGB images. However, it limits the possible usability for environmental datasets \u2013 Euclidean distance is not suitable for many types of spatial raster data (e.g., categorical rasters) and has undesirable properties for multi-dimensional data (e.g., a set of monthly climate data), where the results based on Euclidean distance contradict human intuition (Aggarwal, Hinneburg, and Keim 2001).  Secondly, the superpixels technique does not result in regions per se but rather over-segmentation \u2013 some spatial objects/regions could be represented by one superpixel, while others could consist of many very similar superpixels.\n\nOur preliminary results presented during the GIScience 2021 conference (Nowosad and Stepinski 2021) provide a basis for using other distance measures to create superpixels. The proposed extension can also be used for various scenarios, such as creating regions of similar multi-dimensional spatial and temporal patterns or similarly ranked areas. The extension is also already available as an open-source software in the form of an R package. The supercells package has extensive documentation in the form of a help file and additional vignettes that can be found, together with its installation instructions, at https://jakubnowosad.com/supercells/.\n\nThe second issue is, however, still not resolved. Many clustering methods exist that could be used for merging similar connected superpixels, including traditional ones such as hierarchical clustering and spatial-aware ones such as SKATER or REDCAP. Wang et al. (2018) developed a REDCAP-based workflow for merging superpixels, which showed good image results and outperformed similar techniques; however, their work was based on the original superpixels algorithm and thus used Euclidean distance on 3-dimensional RGB images only. Additionally, it could be worth testing how good modern unsupervised machine learning techniques would perform in this task.\n\nOur main goal is to present the work in progress related to developing a robust method for merging superpixels and thus creating high-quality regionalization. We will test clustering/grouping methods based on three main criteria: accuracy, universality, and computational performance. Accuracy will be obtained based on the resulting regions\u2019 internal homogeneity and their isolation compared to the neighbors. Universality will be tested on several datasets to check if the method works for various scenarios, including RGB images, categorical rasters, spatial time-series, etc. The computational performance will be evaluated based on the time needed for each method\u2019s calculation and their use of computer resources.\n\nReferences\n\nAchanta, R., A. Shaji, et al. 2012. \u201cSLIC Superpixels Compared to State-of-the-Art Superpixel Methods.\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence 34 (11): 2274\u201382. https://doi.org/f39g5f.\n\nAggarwal, Charu C., Alexander Hinneburg, et al. 2001. \u201cOn the Surprising Behavior of Distance Metrics in High Dimensional Space.\u201d In Database Theory \u2014 ICDT 2001, edited by Jan Van den Bussche and Victor Vianu, 1973:420\u201334. Lecture Notes in Computer Science. Springer Berlin Heidelberg. https://doi.org/10.1007/3-540-44503-X_27.\n\nBlaschke, T. 2010. \u201cObject Based Image Analysis for Remote Sensing.\u201d ISPRS Journal of Photogrammetry and Remote Sensing 65 (1): 2\u201316. https://doi.org/d4ksqf.\n\nCsillik, Ovidiu. 2017. \u201cFast Segmentation and Classification of Very High Resolution Remote Sensing Data Using SLIC Superpixels.\u201d Remote Sensing 9 (3): 243. https://doi.org/f92zgd.\n\nNowosad, J., and T. Stepinski. 2021. \u201cGeneralizing the Simple Linear Iterative Clustering (SLIC) Superpixels.\u201d GIScience 2021 Short Paper Proceedings. 11th International Conference on Geographic Information Science. September 27-30 2021. Pozna\u0144: Poland (Online). https://doi.org/gnw982.\n\nRen, and Malik. 2003. \u201cLearning a Classification Model for Segmentation.\u201d In Proceedings Ninth IEEE International Conference on Computer Vision, 10\u201317 vol.1. Nice, France: IEEE. https://doi.org/c6s237.\n\nWang, Mi, Zhipeng Dong, et al. 2018. \u201cOptimal Segmentation of High-Resolution Remote Sensing Image by Combining Superpixels With the Minimum Spanning Tree.\u201d IEEE Transactions on Geoscience and Remote Sensing 56 (1): 228\u201338. https://doi.org/gct8gv.\\n\\nJakub Nowosad\\nMateusz Iwicki\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/VUQSVM/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Modulo_3A/7 Mirko Blinn-.mp4", "persons": "Mirko Blinn", "pretalx_id": "QBP83H", "title": "FOSS4G 2022 | How to grow? -Modeling land use change to develop sustainable pathways for settlement growth in the hinterland of Cologne, Germany", "description": "Urban sprawl is associated with negative environmental impacts such as the loss of habitat and the  loss of  most fertile soils for agriculture. The hinterland of Cologne, Germany is facing these challenges. The area is expected to face a population increase by 200,000 inhabitants in the next twenty years. Given past development trends, this population increase will have to be mainly absorbed by the cities and villages in the hinterland. While this provides ample economic opportunities, negative impacts on ecosystems as well as on agriculture have to be assumed due to urban sprawl and increasing fragmentation. The region is known as as one of the most productive agricultural regions in Central Europe. As highest fertile soils are located in the direct neighborhood of existing settlements, urban sprawl will lead to strong trade-offs with agricultural production.\nThe aim of the scientific project NACHWUCHS is to identify alternatives to the continuation of existing development patterns. Therefore, we developed a baseline land use model and compare it to scenarios that assume different brownfield development activities. Stakeholder involvement is at the core of the project, as policies for alternative pathways cannot be successfully implemented without the support by farmers, real estate companies, environmental stakeholder , the municipalities and the district administration. The most important aspect of land use change in the region is the allocation of new housing areas. This is modeled by a tool-chain based on a free software stack, that uses PostgresSQL with a Postgis extention, Python and QGIS. The allocation model for new housing areas is currently based on a random forest classifier that has been trained on the official governmental ATKIS vector land use data set. The predictors of the model included distance to public transport and social infrastructure as well as existing land use development plans. The allocation of new housing areas was limited to areas outside of protected areas. Furthermore, only a few land use classes \u2013 mainly agriculture \u2013 were allowed for the allocation of new housing areas. The distance-based predictors were calculated by the openrouteservice, which uses OpenStreetMap data to build the routing graph and to assign routing weights.\nA 100 by 100m vector grid was  used for model training and prediction. Model performance was evaluated based on a split in test and training data that considered spatial relationships. Based on the suitability of the grid cells  the demand for projected new housing areas was allocated. We used nine scenarios that differed  in the building density for new housing areas as well as by the extent of brownfield development . In the study presented, building density is expressed in residential units per hectare.  Residential units per hectare is simplified as the number of flats in a building.  In the simulated scenarios, three density classes (10, 30 and 50 residential units per hectare) and three different proportions of brownfield development (10, 20 and 40 per cent) were combined. In the simulated period from 2018 to 2040, we had an area increase of more than fifty percent between the scenario with the lowest density and the lowest proportion of brownfield development and the scenario with the highest density and the highest proportion of brownfield development . The results of the allocation procedure was evaluated based on a set of indicators which cover environmental, agricultural and social aspects. Examples are the supply of agriculture related ecosystem services, soil fertility, economic value of agricultural production and hemeroby.We used the Open Data of the State of North Rhine-Westphalia, which contained geodata for the relevant domains  economy, environment and nature conservation, agriculture, social affairs and transport. The data are Inspire-compliant  and   available under a free licence (DL-DE->Zero-2.0) .  The data set further allowed  the evaluation of the model results with regard to the consequences of the flood disaster of the 14th July 2021, which severely affected parts of the hinterland of Cologne.\nOur results will be used in the context of a mission statement for the future regional development, developed together with locals stakeholders. The mission statement defined development goals for  four sub-regions derived by socio-economic and environmental properties based on 17 UN SDGs. With the help of the above-mentioned indicators, we will evaluate how close or how far the results of the different scenarios  are to these goals and assist  local stakeholders, e.g. in the search for locations of new residential areas. A transfer of the model to regions with similar settings is possible as long as suitable data is available for retraining the model and for the estimation of the indicator sets, highlighting again the importance of open data. The ATKIS data used is openly available for some of the federal states of Germany but not beyond. For North-Rhine Westphalia a transfer semms reasonable- Test runs based on the CORINE land use / land cover product lead to comparable results, indicating that this might be a suitable replacement for the ATKIS based land use information.The Python code of the model, the necessary scripts to generate the required postgisdatabase, a QGIS project example for the visualisation of the results as well as a set of training and test data are provided under free licence via a Gitlab repository.\\n\\nMirko Blinn\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/QBP83H/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Modulo_3A/8 Stefania Viaggio.mp4", "persons": "Bianca Federici, Stefania Viaggio", "pretalx_id": "P8PLUS", "title": "FOSS4G 2022 | Landslide susceptibility assessment: soil moisture monitoring data processed by an automatic procedure in GIS for 3D description of the soil shear strength", "description": "Slope stability is strongly influenced by soil hydraulic conditions, affected by the meteoric events to which the site is subject. With particular reference to shallow landslides triggered by rainfalls, the stability conditions can be influenced by the propagation of the saturation front inside the unsaturated zone. The soil shear strength varies in the vadose zone depending on the type of soil and the variations of soil moisture.  In general, monitoring of the unsaturated zone can be done by measuring suction and/or water content.\n\nThe measurement of the volumetric water content can be performed using low-cost instrumentation, such as the Waterscout SM100 capacitive sensors (Spectrum Tec.), distributed over the study areas. Such sensors provide data in near-real time and are relatively easy to install and replace. However, it is essential to perform a site-specific calibration of the instrumentation, since previous work (Bovolenta et al. 2020) has shown that the factory settings lead to a general overestimation of the actual volumetric soil water content. Therefore, following a sampling of the analyzed soil and a specific laboratory procedure, it is necessary to define the calibration curve that allows the transition from raw data, meant as the ratio between sensor output voltage and input voltage, to soil water content.\n\nThen, the knowledge of soil water content allows the estimation of the suction parameter, thanks to a Water Retention Curve (WRC), and consequently the definition of the soil shear strength in partly saturated conditions.\n\nSeveral methodologies for landslide susceptibility assessment, based on global Limit Equilibrium (LEM) or Finite Element (FEM) methods, need the soil shear strength description in order to evaluate the slope stability conditions. Both in the recent literature (Escobar-Wolf et al. 2020, Moresi et al. 2020) and in the GRASS GIS software (r.shalstab), models are already proposed for shallow landslide susceptibility estimation in GIS, based mainly on LEM. However, these models do not usually consider the unsaturated soil behaviour, but at most take into account the strength contribution provided by the vegetation root systems.\n\nThe present contribution describes the implementation of an automatic procedure in GRASS GIS that, starting from monitoring data related to the soil volumetric water content, provides a 3D description of the soil shear strength in the vadose zone, that is essential for the subsequent landslide susceptibility assessment, especially in the case of shallow landslides.\n\nSoil moisture sensors data come from five monitoring networks that were set up between 2019 and 2021 in the framework of the Interreg Alcotra AD-VITAM project. Each network was organized into measurement nodes (from three to five) instrumented with four soil moisture sensors each and communicating via radio with a receiver. The receiver was then connected to a modem for remote data transmission. The four sensors in each node have been placed in the soil at four different depths (-15, -35, -55, -85 cm from the ground level). The monitoring systems allow to obtain data with a minimum frequency of 5 minutes, in .csv format so that can feed a geodatabase.\n\nStarting from a properly storing of data recorded by the monitoring network in a geodatabase, at the moment within GRASS GIS but in the near future in PostGIS, the equation of the site-specific sensor calibration, defined in laboratory, and the equation of the WRC are implemented in a procedure that allows to pass automatically from the raw sensor data to the soil water content, and then to the evaluate the suction parameter. Hence, the soil strength can be estimated for each depth at which a soil moisture sensor is installed. Moreover, since the study area is often in the order of few square kilometers, the information must be spatialized over the entire area of interest, through appropriate techniques of interpolation and extrapolation.\n\nThis procedure could be integrated into a LEM or FEM, including the above cited, taking advantage of the soil moisture measurements to improve the evaluation of the stability conditions over time, by analysing the evolution of the saturation front according to the weather conditions.\n\nThe authors, in particular, will integrate it into a system called LAMP (LAndslide Monitoring and Predicting), which has been under development for several years through the implementation in a GIS environment of an Integrated Hydrological-Geotechnical (IHG) 3D model for the assessment of landslide risk triggered by measured or forecasted precipitation. The integration of this procedure in LAMP will allow to obtain a simple but effective modelling for the assessment of susceptibility to shallow landslides, too.\n\nNote that the contribution in the landslide risk management of the present procedure could be important even in the days following the rainfall event of interest, providing the technical staff in charge of territorial protection with a useful tool for the landslide susceptibility assessment, especially in the case of shallow landslides.\n\nIn order to allow the scientific community to evaluate the usefulness of the proposed procedure and consequently to have the possibility to implement it in the above-mentioned methods (LEM-FEM) improving the assessment of landslide susceptibility, soil moisture data at a specific site, related to significant rainfall events, and the implemented procedure will be openly shared, once the testing phase is completed.\\n\\nBianca Federici\\nStefania Viaggio\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/P8PLUS/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Modulo_3A/9 Ilaria Ferrando -.mp4", "persons": "Ilaria Ferrando", "pretalx_id": "QGSJLX", "title": "FOSS4G 2022 | Photogrammetric processing and fruition of products in open-source environment applied to the case study of the Archaeological Park of Pompeii", "description": "The geomatic strategy for the survey campaign, data processing and product fruition in an archaeological context is presented and discussed. The case study is the Domus V situated in the Archaeological Park of Pompeii (Regio VII, Insula 14), which was surveyed in September 2020 by the Geomatics Laboratory of Genoa University in collaboration with the archaeologist group of the same University, under the ministerial concession DG 553 Class 34.31.07/246.7 of 26 January 2016 and its renewal on 9 April 2019 (34.31.07/3.4.7/2018).\nThe survey campaign involved the following integrated geomatic techniques:\n\n - UAV photogrammetry, performed with DJI Mavic 2 Pro. The shooting geometry was nadiral with two different altitudes of 40 m and 15 m. An additional survey with a tilting angle of 45\u00b0 at a flight altitude of 15 m was performed along concentric paths around the site. The UAV dataset is composed of 1400 images. The photogrammetric surveys are framed thanks to temporary Ground Control Points (GCPs), surveyed with GNSS in Network Real Time Kinematic (NRTK) positioning strategy.\n - Terrestrial photogrammetry, 7000 images of the internal vertical walls were taken with a Canon Eos 40D camera at a shooting distance of about 2 m following a bottom-to-top trajectory.\n - Terrestrial laser scanning, using the Z+F 5006h phase difference instrument.\n\nThe integrated survey allowed to move from a general view of the entire site to an increasingly detailed one, mainly aimed at the vertical walls, thanks to the global framing provided by the UAV survey.\nThe UAV and terrestrial photogrammetry campaigns were processed through the open-source software MicMac [1] to create the dense point clouds, and CloudCompare [2] to align the different blocks.\nMicMac was chosen for its open-sourceness and its rigorousness in the photogrammetric processing, both related to the estimation of the external/internal orientation parameters and the dense matching to obtain the 3D point clouds from the images, that is based on a multi-scale, multi-resolution pyramidal approach that minimizes the outliers and the noise.\nDue to the not linear computational time in respect of the number of images, the MicMac processing was split in blocks of 500 images each (about 24 hours of processing time), with 100 overlapping images between two consecutive blocks, to align them through a point-to-point strategy. The obtained 3D point cloud was oriented and scaled using 15 natural points found on the terrestrial laser scanner point cloud, obtaining deviations on points positions ranging between 1 and 2 cm. The quality of the alignment was tested computing the distance between the laser scanner and the photogrammetric point clouds using CloudCompare M3C2 algorithm [3] on a representative area of 1.60 m \u00d7 2.25 m of the fresco on the central wall of the surveyed room, obtaining distances of \u00b1 5 mm orthogonally to the wall.\nMoreover, the software MAGO [4], developed in C++ environment within the Geomatics Laboratory, was used to produce high-resolution orthophotos of vertical walls. MAGO exploits a step-by-step self-adaptive mesh that fits the dense point clouds considering a triangular plane area, where the image pixel is projected at its original resolution via the collinearity equations. The needed inputs are the image(s) to be orthorectified, the external and internal orientation parameters, the user-defined orthophoto plane and the output orthophoto resolution. MAGO was recently updated to generate orthophotos of non-coplanar adjacent walls, i.e., forming an edge between them, through a rotation so that the two walls are in a continuous common plane.\nThe orthophotos were made accessible and viewable via a QGIS [5] project built so to manage two different reference frames, i.e, the traditional planimetric plane (X,Y) and the vertical plane of the walls (X-Y,Z), where the X-Y represent the planimetric coordinates along the wall direction. This allows to introduce the third dimension in the typical GIS representation, thus realizing a 3D GIS environment. The QGIS project is organized with a \u201cmaster-slave\u201d architecture, where the master project is dedicated to the (X,Y) plane and reports the vectorial geometries (lines) representing the perimeter of the walls, whereas a different slave project is dedicated to each specific wall with the corresponding orthophoto in a (X-Y,Z) plane. Each slave project is connected to the master thanks to a QGIS action that opens it when clicking on the corresponding wall in the master project. In each sub-project, the orthophoto of the wall is displayed together with three default shapefiles: point, line and polygon shapefile, respectively. The attribute tables of the three shapefiles are set to automatically be updated with the following information once the user introduces a new geometry:\n\n - point shapefile: the image coordinates (x, y) in pixel units and in the corresponding object coordinates (E, N, Z), where E and N represent the east and north coordinates in ETRF2000-2008.0/UTM33N reference frame and Z is the height of the point on the wall;\n - line shapefile: length of the drawn line in meters;\n - polygon shapefile: length of the perimeter and polygon surface, in meters and square meters, respectively.\n\nAn additional feature of the QGIS project is the possibility of performing the orthophoto classification based on the state of conservation of the wall, i.e., crumbling, degraded, good conditions, preserved, through user-defined training areas, from which the spectral signatures to be used in the supervised classification are computed.\nThanks to this \"nested GIS\" environment, the ensemble of the produced orthophotos can be viewed and linked to the corresponding geometry, forming a catalogue for an overall analysis of the entire archaeological site, taking advantage of an increasingly detailed and precise zooming in the areas of interest. This environment can also be used by non-expert geomatics users, making the survey products available for analysis in different specific disciplines.\\n\\nIlaria Ferrando\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/QGSJLX/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Hall_3A/1 Devika Jain.mp4", "persons": "Devika Kakkar", "pretalx_id": "QZNUNL", "title": "FOSS4G 2022 | RINX: A Solution for Information Extraction from Big Raster Datasets", "description": "Processing Earth observation data modeled in a time-series of raster format is critical to solving some of the most complex problems in geospatial science ranging from climate change to public health. Researchers are increasingly working with these large raster datasets that are often terabytes in size. At this scale, traditional GIS methods may fail to handle this processing and new approaches are needed to analyze these datasets. The objective of this work is to develop methods to interactively analyze big raster datasets with the goal of most efficiently extracting vector data over specific time periods from any set of raster data.\n\nIn this paper, we describe RINX (Raster INformation eXtraction) which is an end-to-end solution for automatic extraction of information from large rasters datasets. RINX heavily utilizes open source geospatial techniques for information extraction. It also complements the traditional approaches with state-of-the-art high-performance computing techniques. This paper will discuss details of achieving this big temporal data extraction including methods used, code developed, processing time statistics, project conclusions, and next steps.\n\nThe input for RINX is a set of rasters from which the information has to be extracted and a set of data point locations for which the information needs to be extracted. The output for RINX is a structured representation of extracted information from the raster datasets for each data point in CSV text format. The loading and pre-processing of the input datasets to RINX is accomplished using a combination of Bash and SQL scripting techniques for automation. This pre-processed input is then fed into the open source spatial database PostGIS to extract the required information by using multiple spatial techniques. Finally, the extracted output is post-processed for deduplication  and  standardization of extracted information for research use. RINX is designed in a way that makes it easy to deploy and scale on any local, cloud, or  cluster computing platform.\n\nRINX was created to aid the study of environmental conditions and how they affect the health of people over their lifespans. This involves calculating exposures such as air pollution, humidity, precipitation, temperature, and other exposures at cohort member address locations over time. For initial work with one cohort, daily precipitation, temperature, and humidity estimates were needed for 4,796 cohort address locations for a 19 year time period, 1999 \u2013 2017.\n\nThe 800-meter resolution PRISM Spatial Climate Dataset for the Conterminous United States was used as the input for this data extraction. PRISM refers to Parameter-elevation Relationships on Independent Slopes Model, created by the PRISM Climate Group, Oregon State University. The PRISM dataset is published in .BIL raster format, with one raster representing one climate variable per day for the time period 1981 - 2020. The total size of the dataset is around 8 TB with over 100,000 rasters of size 85 MB each.\n\nFor work on the initial cohort, RINX enabled the extraction of 7 key climate variables: precipitation, temperature (maximum, minimum, mean), dew point temperature (mean), and vapor pressure deficit (minimum, maximum) for 19 years of data from 48,500 800-meter resolution rasters for 4,796 data points. This resulted in a total of 10.3 Million \u201cpatient-day\u201d calculations creating a total of 72.1M observations. Additionally, absolute and relative humidity were calculated using the existing mean temperature and dewpoint variables. RINX provided a unified solution of 9 climate variables for all persons/days for the entire dataset. It was deployed and scaled on multiple servers on a high-performance computing cluster. Our initial results reveal that it is extremely fast and efficient in processing large raster datasets. It took 1 day to load and 4 days to process and extract 7 climate variables from 48,500 rasters for the 72.1M observations at 4,796 locations. RINX enabled the researchers to analyze this big climate dataset at a fine-grained address level with high efficiency and speed. Once the scripts were written, tested, and fine tuned, processing time was reduced from months to days compared to traditional methods, resulting in substantial time savings.\n\nWe are currently testing RINX on a much larger dataset of 100,000 input point locations for a time period of 1981 - 2020, spanning the full range of the PRISM 800m data. This climate data is only available for purchase, however the PRISM Climate Group has made a version of this data available for free at a resolution of 4 kilometers. To make our solution entirely repeatable with open source software, code, and data, we will use RINX to extract point location data from the freely available 4km PRISM data. Results from these analyses will be presented as part of this paper.\n\nOur solution is based on open source technology, using PostGIS that can be deployed on local or  cluster computing environments. It provides an efficient way to solve geospatial big data problems, particularly those involving large temporal raster datasets where point location data extraction is desired. Big data is changing the ways data is managed and analyzed. The next generation GIS tools can help researchers process big data at scale. RINX is an end-to-end data extraction and processing solution for large raster datasets. RINX is open-source and will be shared on Github. It can be easily deployed and scaled on any local, cloud, or cluster computing environment. We used RINX for processing on a large number of PRISM climate datasets, however our solution could be applied to any temporal raster data such as NDVI, night lights, and more.\\n\\nDevika Kakkar\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/QZNUNL/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Hall_3A/2 Elena Belcore.mp4", "persons": "Elena Belcore", "pretalx_id": "DTQGKM", "title": "FOSS4G 2022 | Laying the foundation for an artificial neural network for photogrammetric riverine bathymetry", "description": "The submerged topography of rivers is a crucial variable in fluvial processes and hydrodynamics models. Fluvial bathymetry is traditionally realised through echo sounders embedded on vessels or total stations and GNSS receivers whether the surveyed riverbeds are small streams or dry. Besides being time-consuming and often spatially limited, traditional riverine bathymetry is strongly constrained by currents and deep waters. In such a scenario, remote sensing techniques have progressively complemented traditional bathymetry providing high-resolution information. To date, the peak of innovation for bathymetry has been reached with the use of optical sensors on uncrewed aerial vehicles (UAV) systems, along with green lidars (V\u00e9lez-Nicol\u00e1s et al., 2021). The main obstacle in optical-derived bathymetry is the refraction of the light passing the atmosphere-water interface. The refraction distorts the photogrammetric scene reconstruction, causing in-water measures to be underestimated (i.e., shallower than reality). To correct these distortions, radiometric-based methods are frequently applied. They are focused on the spectral response of the means crossed by the light and are typically built on the theory that the total radiative energy reflected by the water column is function of the water depth (Makboul et al., 2017). The primary goal of the research on submerged topography is to understand the relationship between the water column reflectance and the water depth using statistical and trigonometrical models. The spread of artificial intelligence has given a new light of interest on spectral-based bathymetry by investigating the non-linear and very complex relationship between variables (Mandlburger et al., 2021). To train artificial intelligence models, large amounts of data are usually necessary; therefore, participatory approach and data sharing are required to build statistically-relevant datasets. In this scenario, FOSS tools and distributed resources are mandatory to manage the dataset and allow the replicability of the methodology.\nThis work aims to test the effectiveness of artificial intelligence to correct water refraction in shallow inland water using very high-resolution images collected by Unmanned Aerial Vehicles (UAV) and processed through a total FOSS workflow. The tests focus on using synthetic information extracted from the visible component of the electromagnetic spectrum. An artificial neural network is created with the data from three different case studies placed in west-north Italy, and geologically and morphologically similar.\nThe data for the analysis were collected in 2020. Each data collection was realised using a UAV commercial solution (DJI Phantom 4 Pro), and the following datasets were generated: i) RGB georeferenced orthomosaic of the riverbed and banks obtained from photogrammetric process, ii) georeferenced Digital Elevation Model (DEM) of the riverbed obtained from photogrammetric process, iii) GNSS measures of the riverbed and the riverbanks.\nThe UAV-collected frames were elaborated through a standard structure from motion (SfM) procedure. Visual SfM was employed to align images and the 3D point cloud computation. The digital surface model (DSM) and the orthomosaic production were generated starting from the point cloud in Cloud Compare software. By applying the so-called direct-photogrammetry, the point clouds were directly georeferenced in the WGS84-UTM32 coordinate system thanks to the positioning information retrieved from the embedded GNSS dual-frequency receiver (Chiabrando, Lingua and Piras, 2013). Using the information regarding the camera position and the local height model provided by the national military Geographic Institute (IGM), the ellipsoidal heights were translated into orthometric heights. The GNSS measures had 3 cm accuracy on the vertical component and 1.5cm on the horizontal components.\nThe RGB information, DSM and seven radiometric indices (i.e., Normalised Difference Turbidity Index; Red and Green Ratio; Red and Blue Ratio; Green and Red Ratio; Green and Blue Ratio; Blue and Red Ratio; Blue and Green Ratio) were calculated and stacked in an 11-bands raster (input raster). The Up component of the bathymetry cross-sections constituted the so-called \"Z_GNSS\" dataset and is the dependent variable of the regression. The position (Easting, Northing, Up) of each Z-GNSS observation was used to extract the pixel values of each band of the input photogrammetric dataset, including the photogrammetric DEM. The dataset was then normalised and divided into test (20% observations) and training (80% observations) datasets.\nIn this work, a 5-layer multilayer perceptron (MLP) networks model with three hidden layers was built in Python using the deep learning library Keras with TensorFlow backend (Abadi et al., 2016). The ReLu activation function was added to the ANN layers to bring non-linear properties in the network. The dimension of the input layer is 11, and the weights are initialised to small Gaussian random values (kernel initialiser 'Normal') despite usually skewed or bimodal. A kernel regulizer, L1, was added to reduce the overfitting. The applied optimiser to update weights in the network is the Adaptive Moment Estimation (Adam) search technique, and the loss function, which evaluates the model used by the optimiser to navigate the weights, is the mean absolute error between the predicted output and the target output.\nThe network was trained on the normalised dataset. The r-squared score, the Mean squared error and the Mean absolute error were computed. Finally, the permutation importance was measured using the eli5 python library.\nThe neural network regressor performed over 0.80 of r-squared score on the test dataset. As expected, the permutation importance analysis reveals the high impact of the DEM and visible bands, and low importance scores are reported for ratios bands.\nThe results are satisfying and quite relevant, although the model is the first step through a more complex and deeper neural network to correct water distortions in rivers. It has been trained on a relatively small dataset, but we intend to follow up with the research, add more data, and develop a free and open tool for the scientific community.  The present work, provide a good insight about the high reliability and accuracy of artificial intelligence approaches in optical-derived bathymetry.\\n\\nElena Belcore\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/DTQGKM/\\n\\n#foss4g2022\\n#academictrack\\n"}
{"video_file": "/osgeo/foss4gvideos/2022-08-26/Room_Hall_3A/3 Robin Lovelace.mp4", "persons": "Robin Lovelace", "pretalx_id": "L3TESQ", "title": "FOSS4G 2022 | Exploring jittering and routing options for converting origin-destination data into route networks: towards accurate estimates of movement at the street level", "description": "Introduction\n\nOrigin-destination (OD) datasets provide information on aggregate travel patterns between zones and geographic entities. OD datasets are \u2018implicitly geographic\u2019, containing identification codes of the geographic objects from which trips start and end. A common approach to converting OD datasets to geographic entities, for example represented using the simple features standard (Open Geospatial Consortium Inc 2011) and saved in file formats such as GeoPackage and GeoJSON, is to represent each OD record as a straight line between zone centroids. This approach to representing OD datasets on the map has been since at least the 1950s (Boyce and Williams 2015) and is still in use today (e.g. Rae 2009).\n\nBeyond simply visualising aggregate travel patterns, centroid-based geographic desire lines are also used as the basis of many transport modelling processes. The following steps can be used to convert OD datasets into route networks, in a process that can generate nationally scalable results (Morgan and Lovelace 2020):\n\n```\nOD data converted into centroid-based geographic desire lines\nCalculation of routes for each desire line, with start and end points at zone centroids\nAggregation of routes into route networks, with values on each segment representing the total amount of travel (\u2018flow\u2019) on that part of the network, using functions such as overline() in the open source R package stplanr (Lovelace and Ellison 2018)```\n\nThis approach is tried and tested. The OD -> desire line -> route -> route network processing pipeline forms the basis of the route network results in the Propensity to Cycle Tool, an open source and publicly available map-based web application for informing strategic cycle network investment, \u2018visioning\u2019 and prioritisation (Lovelace et al. 2017; Goodman et al. 2019). However, the approach has some key limitations:\n\n```\nFlows are concentrated on transport network segments leading to zone centroids, creating distortions in the results and preventing the simulation of the diffuse networks that are particularly important for walking and cycling\nThe results are highly dependent on the size and shape of geographic zones used to define OD data\nThe approach is inflexible, providing few options to people who want to use valuable OD datasets in different ways```\n\nTo overcome these limitations we developed a \u2018jittering\u2019 approach to conversion of OD datasets to desire lines that randomly samples points within each zone (Lovelace, F\u00e9lix, and Carlino Under Review). While that paper discussed the conceptual development of the approach, it omitted key details on its implementation in open source software.\n\nIn this paper we outline the implementation of jittering and demonstrate how a single Rust crate can provide the basis of implementations in other languages. Furthermore, we demonstrate how jittering can be used to create more diffuse and accurate estimates of movement at the level of segments (\u2018flows\u2019) on transport network, in reproducible code-driven workflows and with minimal computational overheads compared with the computationally intensive process of route calculation (\u2018routing\u2019) or processing large GPS datasets. The overall aim is to describe the jittering approach in technical terms and its implementation in open source software.\n\nBefore describing the approach, some definitions are in order:\n\n```\nOrigins: locations of trip departure, typically stored as ID codes linking to zones\nDestinations: trip destinations, also stored as ID codes linking to zones\nAttributes: the number of trips made between each \u2018OD pair\u2019 and additional attributes such as route distance between each OD pair\nJittering: The combined process of \u2018splitting\u2019 OD pairs representing many trips into multiple \u2018sub OD\u2019 pairs (disaggregation) and assigning origins and destinations to multiple unique points within each zone```\n\nApproach\n\nJittering represents a comparatively simple \u2014 compared with \u2018connector\u2019 based methods (Jafari et al. 2015) \u2014 approach is to OD data preprocessing. For each OD pair, the jittering approach consists of the following steps for each OD pair (provided it has required inputs of a disaggregation threshold, a single number greater than one, and sub-points from which origin and destination points are located):\n\n```\nChecks if the number of trips (for a given \u2018disaggregation key\u2019, e.g. \u2018walking\u2019) is greater than the disaggregation threshold.\nIf so, the OD pair is disaggregated. This means being divided into as many pieces (\u2018sub-OD pairs\u2019) as is needed, with trip counts divided by the number of sub-OD pairs, for the total to be below the disaggregation threshold.\nFor each sub-OD pair (or each original OD pair if no disaggregation took place) origin and destination locations are randomly sampled from sub-points which optionally have weights representing relative probability of trips starting and ending there.```\n\nThis approach has been implemented efficiently in the Rust crate odjitter, the source code of which can be found at https://github.com/dabreegster/odjitter.\nResults\n\nWe have found that jittering leads to more spatially diffuse representations of OD datasets than the common approach to desire lines that go from and to zone centroids. We have used the approach to add value to numerous OD datasets for projects based in Ireland, Norway, Portugal, New Zealand and beyond. Although useful for visualising the complex and spatially diffuse reality of travel patterns, we found that the most valuable use of jittering is as a pre-processing stage before routing and route network generation. Route networks generated from jittered desire lines are more diffuse, and potentially more realistic, that centroid-based desire lines.\n\nWe also found that the approach, implemented in Rust and with bindings to R and Python (in progress), is fast. Benchmarks show that the approach can \u2018jitter\u2019 desire lines representing millions of trips in a major city in less than a minute on consumer hardware.\n\nWe also found that the results of jittering depend on the geographic input datasets representing start points and trip attractors, and the use of weights. This highlights the importance of exploring the parameter space for optimal jittered desire line creation.\nNext steps\n\nWe plan to create/improve R/Python interfaces to the odjitter and enable others to benefit from it.\n\nWe plan to improve the package\u2019s documentation and to test its results, supporting reproducible sustainable transport research worldwide.\\n\\nRobin Lovelace\\n\\nhttps://talks.osgeo.org/foss4g-2022-academic-track/talk/L3TESQ/\\n\\n#foss4g2022\\n#academictrack\\n"}
